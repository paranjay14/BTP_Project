['options.ckptDir: valDir_cOut32_mFC2_16', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 32', 'options.mlpFC1: 516', 'options.mlpFC2: 16']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 181.696 | Train Acc: 37.198 | Val Loss: 1.506 | Val Accuracy: 48.600
10 Train Loss: 96.041 | Train Acc: 67.088 | Val Loss: 1.137 | Val Accuracy: 61.200
20 Train Loss: 74.727 | Train Acc: 74.935 | Val Loss: 1.164 | Val Accuracy: 60.700
30 Train Loss: 60.400 | Train Acc: 79.849 | Val Loss: 1.213 | Val Accuracy: 61.400
40 Train Loss: 46.864 | Train Acc: 85.339 | Val Loss: 1.325 | Val Accuracy: 60.400
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 37.310 | Train Acc: 88.976 | Val Loss: 1.447 | Val Accuracy: 60.300
60 Train Loss: 29.855 | Train Acc: 92.927 | Val Loss: 1.475 | Val Accuracy: 60.300
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 28.042 | Train Acc: 93.549 | Val Loss: 1.506 | Val Accuracy: 60.100
80 Train Loss: 26.328 | Train Acc: 94.359 | Val Loss: 1.516 | Val Accuracy: 59.900
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 25.903 | Train Acc: 94.480 | Val Loss: 1.526 | Val Accuracy: 59.800
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 25088])
Kmeans trained successfully...
printing expected split from k means
{8: 0, 5: 0, 2: 0, 4: 0, 9: 0, 7: 0, 0: 0, 3: 0, 1: 1, 6: 0}
Printing final_dict items...
{0: 0, 8: 0, 4: 0, 2: 0, 7: 0, 9: 1, 6: 1, 3: 1, 5: 1, 1: 1}
Image Statistics before MLP : L R :  24500 24500
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 105.315 | Acc: 73.720
1 Loss: 89.959 | Acc: 79.080
2 Loss: 82.023 | Acc: 81.349
3 Loss: 75.134 | Acc: 83.145
4 Loss: 70.689 | Acc: 84.351
5 Loss: 65.643 | Acc: 85.437
6 Loss: 61.818 | Acc: 86.398
7 Loss: 58.006 | Acc: 87.431
8 Loss: 52.851 | Acc: 88.749
9 Loss: 50.392 | Acc: 89.124
10 Loss: 40.952 | Acc: 91.478
11 Loss: 36.848 | Acc: 92.400
12 Loss: 33.432 | Acc: 93.133
13 Loss: 32.122 | Acc: 93.492
14 Loss: 30.398 | Acc: 93.800
15 Loss: 28.453 | Acc: 94.265
16 Loss: 26.471 | Acc: 94.753
17 Loss: 26.179 | Acc: 94.722
18 Loss: 23.902 | Acc: 95.363
19 Loss: 23.309 | Acc: 95.412
20 Loss: 18.547 | Acc: 96.502
21 Loss: 16.551 | Acc: 96.839
22 Loss: 15.998 | Acc: 96.904
23 Loss: 15.609 | Acc: 96.980
24 Loss: 14.681 | Acc: 97.253
25 Loss: 13.792 | Acc: 97.422
26 Loss: 13.440 | Acc: 97.500
27 Loss: 13.017 | Acc: 97.596
28 Loss: 12.478 | Acc: 97.700
29 Loss: 12.215 | Acc: 97.704
30 Loss: 10.935 | Acc: 98.061
31 Loss: 10.282 | Acc: 98.155
32 Loss: 9.802 | Acc: 98.286
33 Loss: 9.638 | Acc: 98.294
34 Loss: 9.668 | Acc: 98.245
35 Loss: 9.309 | Acc: 98.335
36 Loss: 9.202 | Acc: 98.347
37 Loss: 8.632 | Acc: 98.427
38 Loss: 8.879 | Acc: 98.435
39 Loss: 8.927 | Acc: 98.398
40 Loss: 8.199 | Acc: 98.539
41 Loss: 8.065 | Acc: 98.608
42 Loss: 7.827 | Acc: 98.596
43 Loss: 7.430 | Acc: 98.657
44 Loss: 7.466 | Acc: 98.659
45 Loss: 7.856 | Acc: 98.614
46 Loss: 7.820 | Acc: 98.612
47 Loss: 7.680 | Acc: 98.657
48 Loss: 7.076 | Acc: 98.739
49 Loss: 7.528 | Acc: 98.692
50 Loss: 7.448 | Acc: 98.722
51 Loss: 7.003 | Acc: 98.727
52 Loss: 6.974 | Acc: 98.747
53 Loss: 7.010 | Acc: 98.780
54 Loss: 6.895 | Acc: 98.820
55 Loss: 7.049 | Acc: 98.773
56 Loss: 7.306 | Acc: 98.729
57 Loss: 6.646 | Acc: 98.824
58 Loss: 6.803 | Acc: 98.790
59 Loss: 6.698 | Acc: 98.816
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([24500])
rTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([24500])
lValDict[data].shape:  torch.Size([500, 3, 32, 32])   lValDict[label].shape:  torch.Size([500])
rValDict[data].shape:  torch.Size([500, 3, 32, 32])   rValDict[label].shape:  torch.Size([500])
# of Left images:  24500.0
# of Right images:  24500.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [4900, 0, 4900, 0, 4900, 0, 0, 4900, 4900, 0]
rclasses:  [0, 4900, 0, 4900, 0, 4900, 4900, 0, 0, 4900]
noOfLeftClasses:  5
noOfRightClasses:  5
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
nodeId:  3 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
Running nodeId:  2
0 Train Loss: 131.706 | Train Acc: 47.204 | Val Loss: 1.085 | Val Accuracy: 56.800
10 Train Loss: 62.726 | Train Acc: 76.073 | Val Loss: 0.823 | Val Accuracy: 67.200
20 Train Loss: 48.250 | Train Acc: 82.494 | Val Loss: 0.788 | Val Accuracy: 71.000
30 Train Loss: 37.577 | Train Acc: 86.743 | Val Loss: 0.870 | Val Accuracy: 70.400
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 28.165 | Train Acc: 90.653 | Val Loss: 0.978 | Val Accuracy: 69.600
50 Train Loss: 21.780 | Train Acc: 94.306 | Val Loss: 0.974 | Val Accuracy: 70.200
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 20.165 | Train Acc: 95.086 | Val Loss: 1.007 | Val Accuracy: 68.800
70 Train Loss: 18.872 | Train Acc: 95.706 | Val Loss: 1.005 | Val Accuracy: 69.600
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 18.549 | Train Acc: 95.784 | Val Loss: 1.015 | Val Accuracy: 69.400
90 Train Loss: 18.211 | Train Acc: 95.976 | Val Loss: 1.014 | Val Accuracy: 69.600
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 25088])
Kmeans trained successfully...
printing expected split from k means
{4: 1, 1: 0, 2: 0, 3: 0, 0: 1}
Printing final_dict items...
{3: 0, 2: 0, 1: 1, 0: 1, 4: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 67.667 | Acc: 79.559
1 Loss: 55.403 | Acc: 83.567
2 Loss: 48.167 | Acc: 86.118
3 Loss: 44.086 | Acc: 87.780
4 Loss: 40.621 | Acc: 88.424
5 Loss: 35.990 | Acc: 90.008
6 Loss: 34.230 | Acc: 90.722
7 Loss: 30.022 | Acc: 92.094
8 Loss: 28.225 | Acc: 92.245
9 Loss: 26.022 | Acc: 92.996
10 Loss: 18.166 | Acc: 95.424
11 Loss: 16.071 | Acc: 95.955
12 Loss: 14.241 | Acc: 96.388
13 Loss: 12.471 | Acc: 96.959
14 Loss: 11.525 | Acc: 97.253
15 Loss: 11.063 | Acc: 97.273
16 Loss: 10.513 | Acc: 97.473
17 Loss: 9.362 | Acc: 97.763
18 Loss: 8.639 | Acc: 97.951
19 Loss: 8.533 | Acc: 97.947
20 Loss: 5.927 | Acc: 98.731
21 Loss: 5.299 | Acc: 98.869
22 Loss: 5.427 | Acc: 98.743
23 Loss: 4.943 | Acc: 98.914
24 Loss: 4.283 | Acc: 99.053
25 Loss: 4.269 | Acc: 99.082
26 Loss: 3.747 | Acc: 99.208
27 Loss: 3.757 | Acc: 99.204
28 Loss: 3.672 | Acc: 99.155
29 Loss: 3.462 | Acc: 99.245
30 Loss: 3.330 | Acc: 99.318
31 Loss: 2.694 | Acc: 99.441
32 Loss: 2.564 | Acc: 99.429
33 Loss: 2.431 | Acc: 99.465
34 Loss: 1.992 | Acc: 99.624
35 Loss: 2.245 | Acc: 99.518
36 Loss: 2.516 | Acc: 99.469
37 Loss: 2.194 | Acc: 99.522
38 Loss: 2.078 | Acc: 99.527
39 Loss: 2.156 | Acc: 99.535
40 Loss: 1.918 | Acc: 99.592
41 Loss: 1.889 | Acc: 99.645
42 Loss: 1.686 | Acc: 99.714
43 Loss: 2.040 | Acc: 99.608
44 Loss: 1.590 | Acc: 99.690
45 Loss: 1.763 | Acc: 99.698
46 Loss: 1.850 | Acc: 99.604
47 Loss: 1.546 | Acc: 99.698
48 Loss: 1.501 | Acc: 99.657
49 Loss: 1.722 | Acc: 99.665
50 Loss: 1.356 | Acc: 99.702
51 Loss: 1.568 | Acc: 99.698
52 Loss: 1.553 | Acc: 99.698
53 Loss: 1.573 | Acc: 99.682
54 Loss: 1.489 | Acc: 99.706
55 Loss: 1.693 | Acc: 99.637
56 Loss: 1.578 | Acc: 99.673
57 Loss: 1.248 | Acc: 99.751
58 Loss: 1.631 | Acc: 99.633
59 Loss: 1.381 | Acc: 99.694
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [0, 0, 4900, 4900, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 4900, 0, 0, 4900, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  5 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  3
0 Train Loss: 123.261 | Train Acc: 49.363 | Val Loss: 0.982 | Val Accuracy: 58.200
10 Train Loss: 60.206 | Train Acc: 76.453 | Val Loss: 0.733 | Val Accuracy: 72.800
20 Train Loss: 44.678 | Train Acc: 83.004 | Val Loss: 0.717 | Val Accuracy: 71.000
Epoch     4: reducing learning rate of group 0 to 2.0000e-04.
30 Train Loss: 33.076 | Train Acc: 88.286 | Val Loss: 0.756 | Val Accuracy: 71.600
40 Train Loss: 26.308 | Train Acc: 92.147 | Val Loss: 0.757 | Val Accuracy: 71.400
Epoch     6: reducing learning rate of group 0 to 4.0000e-05.
50 Train Loss: 24.275 | Train Acc: 93.094 | Val Loss: 0.771 | Val Accuracy: 71.600
60 Train Loss: 22.664 | Train Acc: 94.004 | Val Loss: 0.772 | Val Accuracy: 71.400
Epoch     8: reducing learning rate of group 0 to 8.0000e-06.
70 Train Loss: 22.200 | Train Acc: 94.135 | Val Loss: 0.777 | Val Accuracy: 71.800
80 Train Loss: 21.835 | Train Acc: 94.367 | Val Loss: 0.776 | Val Accuracy: 71.400
Epoch    10: reducing learning rate of group 0 to 1.6000e-06.
90 Train Loss: 21.737 | Train Acc: 94.420 | Val Loss: 0.777 | Val Accuracy: 71.400
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 25088])
Kmeans trained successfully...
printing expected split from k means
{4: 0, 2: 1, 0: 0, 3: 1, 1: 0}
Printing final_dict items...
{4: 0, 0: 0, 1: 1, 2: 1, 3: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 37.701 | Acc: 90.673
1 Loss: 24.325 | Acc: 94.245
2 Loss: 20.295 | Acc: 95.082
3 Loss: 16.774 | Acc: 95.996
4 Loss: 13.899 | Acc: 96.686
5 Loss: 11.800 | Acc: 97.249
6 Loss: 10.153 | Acc: 97.690
7 Loss: 9.273 | Acc: 97.800
8 Loss: 7.861 | Acc: 98.122
9 Loss: 6.663 | Acc: 98.441
10 Loss: 3.454 | Acc: 99.188
11 Loss: 2.720 | Acc: 99.367
12 Loss: 2.053 | Acc: 99.555
13 Loss: 1.608 | Acc: 99.633
14 Loss: 2.329 | Acc: 99.506
15 Loss: 1.679 | Acc: 99.690
16 Loss: 1.563 | Acc: 99.678
17 Loss: 1.325 | Acc: 99.722
18 Loss: 1.171 | Acc: 99.755
19 Loss: 1.246 | Acc: 99.767
20 Loss: 1.084 | Acc: 99.767
21 Loss: 0.677 | Acc: 99.882
22 Loss: 0.518 | Acc: 99.898
23 Loss: 0.417 | Acc: 99.931
24 Loss: 0.485 | Acc: 99.902
25 Loss: 0.512 | Acc: 99.922
26 Loss: 0.320 | Acc: 99.947
27 Loss: 0.400 | Acc: 99.910
28 Loss: 0.266 | Acc: 99.963
29 Loss: 0.482 | Acc: 99.898
30 Loss: 0.243 | Acc: 99.947
31 Loss: 0.199 | Acc: 99.967
32 Loss: 0.241 | Acc: 99.959
33 Loss: 0.289 | Acc: 99.943
34 Loss: 0.196 | Acc: 99.980
35 Loss: 0.170 | Acc: 99.963
36 Loss: 0.129 | Acc: 99.992
37 Loss: 0.167 | Acc: 99.976
38 Loss: 0.087 | Acc: 99.996
39 Loss: 0.099 | Acc: 99.984
40 Loss: 0.184 | Acc: 99.971
41 Loss: 0.214 | Acc: 99.971
42 Loss: 0.124 | Acc: 99.984
43 Loss: 0.161 | Acc: 99.963
44 Loss: 0.139 | Acc: 99.971
45 Loss: 0.107 | Acc: 99.984
46 Loss: 0.126 | Acc: 99.971
47 Loss: 0.107 | Acc: 99.988
48 Loss: 0.105 | Acc: 99.971
49 Loss: 0.121 | Acc: 99.971
50 Loss: 0.158 | Acc: 99.988
51 Loss: 0.092 | Acc: 99.988
52 Loss: 0.067 | Acc: 100.000
53 Loss: 0.101 | Acc: 99.984
54 Loss: 0.083 | Acc: 99.992
55 Loss: 0.087 | Acc: 99.988
56 Loss: 0.187 | Acc: 99.976
57 Loss: 0.126 | Acc: 99.980
58 Loss: 0.093 | Acc: 99.984
59 Loss: 0.075 | Acc: 99.988
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [4900, 0, 0, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  7 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  4
0 Train Loss: 60.885 | Train Acc: 67.327 | Val Loss: 0.512 | Val Accuracy: 71.500
10 Train Loss: 27.675 | Train Acc: 88.459 | Val Loss: 0.318 | Val Accuracy: 87.000
20 Train Loss: 18.960 | Train Acc: 92.449 | Val Loss: 0.331 | Val Accuracy: 89.000
30 Train Loss: 11.573 | Train Acc: 96.143 | Val Loss: 0.343 | Val Accuracy: 88.000
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 6.554 | Train Acc: 98.490 | Val Loss: 0.400 | Val Accuracy: 86.500
50 Train Loss: 4.330 | Train Acc: 99.510 | Val Loss: 0.412 | Val Accuracy: 87.500
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 3.628 | Train Acc: 99.704 | Val Loss: 0.429 | Val Accuracy: 87.500
70 Train Loss: 3.265 | Train Acc: 99.755 | Val Loss: 0.430 | Val Accuracy: 87.000
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 3.138 | Train Acc: 99.776 | Val Loss: 0.439 | Val Accuracy: 86.500
90 Train Loss: 3.038 | Train Acc: 99.806 | Val Loss: 0.438 | Val Accuracy: 87.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 92.220 | Acc: 78.306
1 Loss: 69.289 | Acc: 84.898
2 Loss: 56.034 | Acc: 87.704
3 Loss: 48.673 | Acc: 89.531
4 Loss: 42.358 | Acc: 91.051
5 Loss: 35.055 | Acc: 92.806
6 Loss: 30.633 | Acc: 93.612
7 Loss: 25.737 | Acc: 94.929
8 Loss: 22.192 | Acc: 95.724
9 Loss: 19.995 | Acc: 96.224
10 Loss: 10.023 | Acc: 98.224
11 Loss: 7.845 | Acc: 98.541
12 Loss: 6.346 | Acc: 98.949
13 Loss: 5.501 | Acc: 99.163
14 Loss: 4.902 | Acc: 99.163
15 Loss: 3.886 | Acc: 99.388
16 Loss: 4.927 | Acc: 99.224
17 Loss: 3.322 | Acc: 99.459
18 Loss: 3.330 | Acc: 99.480
19 Loss: 4.460 | Acc: 99.286
20 Loss: 1.919 | Acc: 99.714
21 Loss: 1.713 | Acc: 99.745
22 Loss: 1.078 | Acc: 99.847
23 Loss: 1.010 | Acc: 99.867
24 Loss: 0.974 | Acc: 99.867
25 Loss: 1.273 | Acc: 99.755
26 Loss: 1.496 | Acc: 99.755
27 Loss: 0.905 | Acc: 99.847
28 Loss: 0.691 | Acc: 99.908
29 Loss: 0.870 | Acc: 99.878
30 Loss: 0.719 | Acc: 99.918
31 Loss: 0.784 | Acc: 99.857
32 Loss: 0.409 | Acc: 99.959
33 Loss: 0.422 | Acc: 99.969
34 Loss: 0.462 | Acc: 99.949
35 Loss: 0.393 | Acc: 99.969
36 Loss: 0.378 | Acc: 99.939
37 Loss: 0.399 | Acc: 99.929
38 Loss: 0.301 | Acc: 99.969
39 Loss: 0.482 | Acc: 99.949
40 Loss: 0.453 | Acc: 99.929
41 Loss: 0.574 | Acc: 99.918
42 Loss: 0.405 | Acc: 99.949
43 Loss: 0.217 | Acc: 99.990
44 Loss: 0.368 | Acc: 99.939
45 Loss: 0.227 | Acc: 99.959
46 Loss: 0.294 | Acc: 99.969
47 Loss: 0.364 | Acc: 99.939
48 Loss: 0.517 | Acc: 99.929
49 Loss: 0.517 | Acc: 99.959
50 Loss: 0.175 | Acc: 99.980
51 Loss: 0.181 | Acc: 100.000
52 Loss: 0.246 | Acc: 99.969
53 Loss: 0.285 | Acc: 99.969
54 Loss: 0.251 | Acc: 99.959
55 Loss: 0.420 | Acc: 99.969
56 Loss: 0.221 | Acc: 99.980
57 Loss: 0.209 | Acc: 99.980
58 Loss: 0.235 | Acc: 99.959
59 Loss: 0.388 | Acc: 99.949
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 4
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 4
nodeId:  8 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 4900
nodeId:  9 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  5
0 Train Loss: 77.174 | Train Acc: 65.367 | Val Loss: 0.631 | Val Accuracy: 74.667
10 Train Loss: 37.712 | Train Acc: 85.585 | Val Loss: 0.555 | Val Accuracy: 77.667
20 Train Loss: 27.113 | Train Acc: 89.864 | Val Loss: 0.581 | Val Accuracy: 77.667
30 Train Loss: 18.917 | Train Acc: 93.605 | Val Loss: 0.642 | Val Accuracy: 78.000
40 Train Loss: 14.169 | Train Acc: 95.537 | Val Loss: 0.713 | Val Accuracy: 79.667
50 Train Loss: 9.549 | Train Acc: 97.524 | Val Loss: 0.792 | Val Accuracy: 78.667
Epoch     7: reducing learning rate of group 0 to 2.0000e-04.
60 Train Loss: 7.202 | Train Acc: 98.469 | Val Loss: 0.920 | Val Accuracy: 78.667
70 Train Loss: 4.477 | Train Acc: 99.476 | Val Loss: 0.895 | Val Accuracy: 78.667
Epoch     9: reducing learning rate of group 0 to 4.0000e-05.
80 Train Loss: 4.031 | Train Acc: 99.633 | Val Loss: 0.916 | Val Accuracy: 79.000
90 Train Loss: 3.639 | Train Acc: 99.701 | Val Loss: 0.920 | Val Accuracy: 79.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 25088])
Kmeans trained successfully...
printing expected split from k means
{1: 0, 0: 1, 2: 1}
Printing final_dict items...
{1: 0, 0: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 47.474 | Acc: 84.089
1 Loss: 36.008 | Acc: 88.603
2 Loss: 32.092 | Acc: 89.808
3 Loss: 27.530 | Acc: 90.829
4 Loss: 25.914 | Acc: 91.788
5 Loss: 21.853 | Acc: 92.836
6 Loss: 20.217 | Acc: 93.240
7 Loss: 19.014 | Acc: 93.774
8 Loss: 15.936 | Acc: 95.027
9 Loss: 14.698 | Acc: 95.212
10 Loss: 10.198 | Acc: 96.774
11 Loss: 7.399 | Acc: 97.774
12 Loss: 7.235 | Acc: 97.801
13 Loss: 5.980 | Acc: 98.274
14 Loss: 5.859 | Acc: 98.260
15 Loss: 5.099 | Acc: 98.411
16 Loss: 4.619 | Acc: 98.712
17 Loss: 4.589 | Acc: 98.692
18 Loss: 4.013 | Acc: 98.938
19 Loss: 3.378 | Acc: 99.075
20 Loss: 2.696 | Acc: 99.315
21 Loss: 2.071 | Acc: 99.521
22 Loss: 1.910 | Acc: 99.514
23 Loss: 1.933 | Acc: 99.507
24 Loss: 2.110 | Acc: 99.445
25 Loss: 1.953 | Acc: 99.521
26 Loss: 1.621 | Acc: 99.534
27 Loss: 1.358 | Acc: 99.699
28 Loss: 1.312 | Acc: 99.671
29 Loss: 1.298 | Acc: 99.699
30 Loss: 1.248 | Acc: 99.699
31 Loss: 0.998 | Acc: 99.747
32 Loss: 0.905 | Acc: 99.733
33 Loss: 0.778 | Acc: 99.829
34 Loss: 0.742 | Acc: 99.788
35 Loss: 0.874 | Acc: 99.801
36 Loss: 0.913 | Acc: 99.815
37 Loss: 0.967 | Acc: 99.774
38 Loss: 0.704 | Acc: 99.829
39 Loss: 0.727 | Acc: 99.815
40 Loss: 0.610 | Acc: 99.890
41 Loss: 0.523 | Acc: 99.904
42 Loss: 0.670 | Acc: 99.842
43 Loss: 0.644 | Acc: 99.863
44 Loss: 0.561 | Acc: 99.849
45 Loss: 0.560 | Acc: 99.877
46 Loss: 0.601 | Acc: 99.870
47 Loss: 0.418 | Acc: 99.952
48 Loss: 0.393 | Acc: 99.918
49 Loss: 0.575 | Acc: 99.856
50 Loss: 0.409 | Acc: 99.911
51 Loss: 0.433 | Acc: 99.938
52 Loss: 0.384 | Acc: 99.911
53 Loss: 0.416 | Acc: 99.925
54 Loss: 0.405 | Acc: 99.925
55 Loss: 0.535 | Acc: 99.877
56 Loss: 0.524 | Acc: 99.877
57 Loss: 0.515 | Acc: 99.884
58 Loss: 0.445 | Acc: 99.877
59 Loss: 0.471 | Acc: 99.904
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 2
nodeId:  10 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
nodeId:  11 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  6
0 Train Loss: 67.793 | Train Acc: 62.398 | Val Loss: 0.569 | Val Accuracy: 73.500
10 Train Loss: 25.295 | Train Acc: 89.980 | Val Loss: 0.345 | Val Accuracy: 87.000
20 Train Loss: 15.584 | Train Acc: 94.449 | Val Loss: 0.329 | Val Accuracy: 87.500
30 Train Loss: 9.892 | Train Acc: 97.184 | Val Loss: 0.394 | Val Accuracy: 85.000
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 4.687 | Train Acc: 99.378 | Val Loss: 0.451 | Val Accuracy: 85.000
50 Train Loss: 3.038 | Train Acc: 99.755 | Val Loss: 0.460 | Val Accuracy: 85.000
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 2.529 | Train Acc: 99.888 | Val Loss: 0.477 | Val Accuracy: 86.500
70 Train Loss: 2.251 | Train Acc: 99.929 | Val Loss: 0.488 | Val Accuracy: 85.000
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 2.142 | Train Acc: 99.918 | Val Loss: 0.491 | Val Accuracy: 85.000
90 Train Loss: 2.061 | Train Acc: 99.929 | Val Loss: 0.493 | Val Accuracy: 85.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 99.688 | Acc: 76.337
1 Loss: 69.681 | Acc: 85.357
2 Loss: 58.642 | Acc: 87.429
3 Loss: 47.823 | Acc: 90.245
4 Loss: 40.554 | Acc: 91.643
5 Loss: 34.498 | Acc: 92.796
6 Loss: 30.154 | Acc: 94.061
7 Loss: 24.823 | Acc: 95.184
8 Loss: 21.267 | Acc: 96.184
9 Loss: 17.131 | Acc: 96.878
10 Loss: 9.192 | Acc: 98.357
11 Loss: 5.284 | Acc: 99.194
12 Loss: 4.884 | Acc: 99.276
13 Loss: 4.165 | Acc: 99.378
14 Loss: 3.679 | Acc: 99.347
15 Loss: 4.056 | Acc: 99.286
16 Loss: 3.616 | Acc: 99.418
17 Loss: 3.077 | Acc: 99.490
18 Loss: 3.468 | Acc: 99.408
19 Loss: 3.569 | Acc: 99.367
20 Loss: 2.073 | Acc: 99.684
21 Loss: 1.017 | Acc: 99.837
22 Loss: 1.117 | Acc: 99.796
23 Loss: 1.079 | Acc: 99.867
24 Loss: 1.048 | Acc: 99.867
25 Loss: 1.047 | Acc: 99.878
26 Loss: 1.102 | Acc: 99.837
27 Loss: 0.619 | Acc: 99.908
28 Loss: 0.751 | Acc: 99.949
29 Loss: 0.600 | Acc: 99.918
30 Loss: 0.440 | Acc: 99.929
31 Loss: 0.458 | Acc: 99.949
32 Loss: 0.396 | Acc: 99.980
33 Loss: 0.383 | Acc: 99.949
34 Loss: 0.542 | Acc: 99.918
35 Loss: 0.430 | Acc: 99.949
36 Loss: 0.402 | Acc: 99.949
37 Loss: 0.479 | Acc: 99.949
38 Loss: 0.530 | Acc: 99.898
39 Loss: 0.483 | Acc: 99.969
40 Loss: 0.361 | Acc: 99.949
41 Loss: 0.258 | Acc: 99.939
42 Loss: 0.294 | Acc: 99.969
43 Loss: 0.477 | Acc: 99.949
44 Loss: 0.252 | Acc: 99.980
45 Loss: 0.257 | Acc: 99.980
46 Loss: 0.165 | Acc: 99.990
47 Loss: 0.320 | Acc: 99.959
48 Loss: 0.197 | Acc: 99.980
49 Loss: 0.272 | Acc: 99.969
50 Loss: 0.152 | Acc: 99.990
51 Loss: 0.198 | Acc: 99.980
52 Loss: 0.154 | Acc: 99.990
53 Loss: 0.255 | Acc: 99.990
54 Loss: 0.203 | Acc: 99.980
55 Loss: 0.264 | Acc: 99.980
56 Loss: 0.223 | Acc: 99.959
57 Loss: 0.364 | Acc: 99.949
58 Loss: 0.252 | Acc: 99.969
59 Loss: 0.156 | Acc: 99.980
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  12 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 4900
nodeId:  13 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  7
0 Train Loss: 110.029 | Train Acc: 47.061 | Val Loss: 0.926 | Val Accuracy: 55.333
10 Train Loss: 57.252 | Train Acc: 75.612 | Val Loss: 0.748 | Val Accuracy: 67.667
20 Train Loss: 44.359 | Train Acc: 82.381 | Val Loss: 0.754 | Val Accuracy: 67.000
Epoch     4: reducing learning rate of group 0 to 2.0000e-04.
30 Train Loss: 33.142 | Train Acc: 87.762 | Val Loss: 0.879 | Val Accuracy: 67.333
40 Train Loss: 26.551 | Train Acc: 91.898 | Val Loss: 0.864 | Val Accuracy: 67.667
50 Train Loss: 24.349 | Train Acc: 92.959 | Val Loss: 0.898 | Val Accuracy: 68.667
60 Train Loss: 22.241 | Train Acc: 94.000 | Val Loss: 0.922 | Val Accuracy: 68.000
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 20.043 | Train Acc: 94.918 | Val Loss: 0.959 | Val Accuracy: 66.667
80 Train Loss: 18.697 | Train Acc: 95.884 | Val Loss: 0.961 | Val Accuracy: 67.333
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 18.313 | Train Acc: 96.014 | Val Loss: 0.968 | Val Accuracy: 66.667
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 25088])
Kmeans trained successfully...
printing expected split from k means
{1: 0, 0: 0, 2: 1}
Printing final_dict items...
{0: 0, 1: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 85.316 | Acc: 63.726
1 Loss: 74.958 | Acc: 69.541
2 Loss: 68.236 | Acc: 72.842
3 Loss: 62.345 | Acc: 76.233
4 Loss: 55.477 | Acc: 78.897
5 Loss: 49.152 | Acc: 81.932
6 Loss: 44.414 | Acc: 83.979
7 Loss: 39.396 | Acc: 86.158
8 Loss: 35.383 | Acc: 87.842
9 Loss: 30.729 | Acc: 89.938
10 Loss: 21.018 | Acc: 93.247
11 Loss: 16.450 | Acc: 94.726
12 Loss: 14.260 | Acc: 95.630
13 Loss: 12.890 | Acc: 96.123
14 Loss: 10.964 | Acc: 96.849
15 Loss: 10.968 | Acc: 96.733
16 Loss: 9.856 | Acc: 97.336
17 Loss: 8.555 | Acc: 97.486
18 Loss: 8.986 | Acc: 97.603
19 Loss: 7.675 | Acc: 97.822
20 Loss: 5.124 | Acc: 98.705
21 Loss: 4.518 | Acc: 98.842
22 Loss: 4.055 | Acc: 98.966
23 Loss: 4.132 | Acc: 98.911
24 Loss: 3.998 | Acc: 98.918
25 Loss: 3.460 | Acc: 99.185
26 Loss: 2.938 | Acc: 99.267
27 Loss: 2.813 | Acc: 99.308
28 Loss: 3.154 | Acc: 99.226
29 Loss: 2.757 | Acc: 99.308
30 Loss: 2.254 | Acc: 99.418
31 Loss: 2.428 | Acc: 99.411
32 Loss: 2.286 | Acc: 99.397
33 Loss: 2.002 | Acc: 99.514
34 Loss: 1.884 | Acc: 99.575
35 Loss: 1.995 | Acc: 99.582
36 Loss: 1.825 | Acc: 99.521
37 Loss: 1.962 | Acc: 99.610
38 Loss: 1.827 | Acc: 99.596
39 Loss: 1.809 | Acc: 99.616
40 Loss: 1.552 | Acc: 99.664
41 Loss: 1.305 | Acc: 99.726
42 Loss: 1.555 | Acc: 99.589
43 Loss: 1.255 | Acc: 99.699
44 Loss: 1.488 | Acc: 99.623
45 Loss: 1.195 | Acc: 99.760
46 Loss: 1.163 | Acc: 99.740
47 Loss: 1.470 | Acc: 99.630
48 Loss: 1.388 | Acc: 99.644
49 Loss: 1.066 | Acc: 99.795
50 Loss: 1.218 | Acc: 99.733
51 Loss: 1.044 | Acc: 99.747
52 Loss: 1.164 | Acc: 99.747
53 Loss: 1.247 | Acc: 99.733
54 Loss: 1.452 | Acc: 99.623
55 Loss: 1.209 | Acc: 99.733
56 Loss: 1.003 | Acc: 99.808
57 Loss: 1.430 | Acc: 99.610
58 Loss: 0.984 | Acc: 99.753
59 Loss: 1.019 | Acc: 99.822
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
nodeId:  14 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
nodeId:  15 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  8
Running nodeId:  9
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 66.630 | Train Acc: 66.061 | Val Loss: 0.551 | Val Accuracy: 70.500
10 Train Loss: 28.730 | Train Acc: 88.449 | Val Loss: 0.431 | Val Accuracy: 78.000
20 Train Loss: 19.763 | Train Acc: 92.500 | Val Loss: 0.442 | Val Accuracy: 81.500
30 Train Loss: 13.361 | Train Acc: 95.173 | Val Loss: 0.433 | Val Accuracy: 85.000
40 Train Loss: 8.716 | Train Acc: 97.357 | Val Loss: 0.422 | Val Accuracy: 85.500
50 Train Loss: 5.915 | Train Acc: 98.561 | Val Loss: 0.522 | Val Accuracy: 84.000
Epoch     7: reducing learning rate of group 0 to 2.0000e-04.
60 Train Loss: 3.838 | Train Acc: 99.337 | Val Loss: 0.571 | Val Accuracy: 83.000
70 Train Loss: 2.192 | Train Acc: 99.857 | Val Loss: 0.584 | Val Accuracy: 83.500
Epoch     9: reducing learning rate of group 0 to 4.0000e-05.
80 Train Loss: 1.931 | Train Acc: 99.867 | Val Loss: 0.625 | Val Accuracy: 82.500
90 Train Loss: 1.719 | Train Acc: 99.918 | Val Loss: 0.611 | Val Accuracy: 84.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 90.828 | Acc: 79.051
1 Loss: 63.418 | Acc: 86.745
2 Loss: 53.511 | Acc: 88.592
3 Loss: 45.110 | Acc: 90.673
4 Loss: 37.470 | Acc: 92.418
5 Loss: 32.984 | Acc: 93.245
6 Loss: 26.826 | Acc: 94.551
7 Loss: 23.161 | Acc: 95.357
8 Loss: 20.591 | Acc: 95.837
9 Loss: 20.835 | Acc: 95.969
10 Loss: 10.433 | Acc: 98.235
11 Loss: 6.802 | Acc: 98.755
12 Loss: 5.678 | Acc: 98.969
13 Loss: 5.863 | Acc: 98.949
14 Loss: 5.146 | Acc: 99.051
15 Loss: 3.529 | Acc: 99.327
16 Loss: 5.200 | Acc: 99.102
17 Loss: 3.929 | Acc: 99.337
18 Loss: 3.832 | Acc: 99.316
19 Loss: 4.605 | Acc: 99.245
20 Loss: 2.362 | Acc: 99.633
21 Loss: 1.249 | Acc: 99.878
22 Loss: 1.616 | Acc: 99.735
23 Loss: 1.558 | Acc: 99.714
24 Loss: 1.408 | Acc: 99.796
25 Loss: 1.038 | Acc: 99.847
26 Loss: 1.118 | Acc: 99.827
27 Loss: 0.953 | Acc: 99.857
28 Loss: 0.950 | Acc: 99.827
29 Loss: 0.993 | Acc: 99.847
30 Loss: 0.846 | Acc: 99.857
31 Loss: 1.084 | Acc: 99.867
32 Loss: 0.725 | Acc: 99.908
33 Loss: 0.572 | Acc: 99.939
34 Loss: 0.533 | Acc: 99.939
35 Loss: 0.462 | Acc: 99.949
36 Loss: 0.590 | Acc: 99.929
37 Loss: 0.571 | Acc: 99.929
38 Loss: 0.536 | Acc: 99.929
39 Loss: 0.568 | Acc: 99.918
40 Loss: 0.499 | Acc: 99.908
41 Loss: 0.566 | Acc: 99.929
42 Loss: 0.383 | Acc: 99.949
43 Loss: 0.346 | Acc: 99.949
44 Loss: 0.404 | Acc: 99.939
45 Loss: 0.368 | Acc: 99.939
46 Loss: 0.730 | Acc: 99.929
47 Loss: 0.464 | Acc: 99.949
48 Loss: 0.402 | Acc: 99.959
49 Loss: 0.348 | Acc: 99.929
50 Loss: 0.377 | Acc: 99.949
51 Loss: 0.545 | Acc: 99.929
52 Loss: 0.277 | Acc: 99.980
53 Loss: 0.539 | Acc: 99.929
54 Loss: 0.301 | Acc: 99.959
55 Loss: 0.312 | Acc: 99.949
56 Loss: 0.169 | Acc: 100.000
57 Loss: 0.430 | Acc: 99.949
58 Loss: 0.299 | Acc: 99.969
59 Loss: 0.203 | Acc: 99.980
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  16 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 4900
nodeId:  17 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  12
Running nodeId:  13
Running nodeId:  14
Running nodeId:  15
0 Train Loss: 53.409 | Train Acc: 73.949 | Val Loss: 0.529 | Val Accuracy: 74.000
10 Train Loss: 20.347 | Train Acc: 92.204 | Val Loss: 0.313 | Val Accuracy: 87.000
20 Train Loss: 13.110 | Train Acc: 95.480 | Val Loss: 0.344 | Val Accuracy: 86.000
Epoch     4: reducing learning rate of group 0 to 2.0000e-04.
30 Train Loss: 7.906 | Train Acc: 97.561 | Val Loss: 0.343 | Val Accuracy: 85.500
40 Train Loss: 5.049 | Train Acc: 99.224 | Val Loss: 0.335 | Val Accuracy: 86.500
50 Train Loss: 4.252 | Train Acc: 99.367 | Val Loss: 0.339 | Val Accuracy: 87.500
60 Train Loss: 3.525 | Train Acc: 99.684 | Val Loss: 0.360 | Val Accuracy: 87.000
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 2.936 | Train Acc: 99.765 | Val Loss: 0.395 | Val Accuracy: 87.000
80 Train Loss: 2.503 | Train Acc: 99.878 | Val Loss: 0.371 | Val Accuracy: 87.500
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 2.389 | Train Acc: 99.857 | Val Loss: 0.373 | Val Accuracy: 87.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 74.486 | Acc: 83.602
1 Loss: 51.365 | Acc: 89.520
2 Loss: 42.224 | Acc: 91.388
3 Loss: 34.228 | Acc: 93.071
4 Loss: 30.975 | Acc: 93.724
5 Loss: 26.387 | Acc: 94.949
6 Loss: 23.058 | Acc: 95.255
7 Loss: 18.496 | Acc: 96.327
8 Loss: 16.792 | Acc: 96.745
9 Loss: 15.186 | Acc: 97.102
10 Loss: 7.142 | Acc: 98.694
11 Loss: 5.315 | Acc: 99.163
12 Loss: 4.065 | Acc: 99.429
13 Loss: 4.327 | Acc: 99.286
14 Loss: 3.840 | Acc: 99.378
15 Loss: 3.582 | Acc: 99.398
16 Loss: 4.027 | Acc: 99.347
17 Loss: 2.790 | Acc: 99.469
18 Loss: 2.567 | Acc: 99.541
19 Loss: 3.012 | Acc: 99.520
20 Loss: 2.006 | Acc: 99.622
21 Loss: 1.475 | Acc: 99.827
22 Loss: 0.947 | Acc: 99.847
23 Loss: 0.722 | Acc: 99.878
24 Loss: 1.118 | Acc: 99.827
25 Loss: 1.049 | Acc: 99.847
26 Loss: 0.724 | Acc: 99.888
27 Loss: 0.612 | Acc: 99.929
28 Loss: 0.559 | Acc: 99.918
29 Loss: 0.867 | Acc: 99.888
30 Loss: 0.577 | Acc: 99.908
31 Loss: 0.305 | Acc: 99.980
32 Loss: 0.464 | Acc: 99.939
33 Loss: 0.375 | Acc: 99.969
34 Loss: 0.550 | Acc: 99.959
35 Loss: 0.350 | Acc: 99.969
36 Loss: 0.312 | Acc: 99.949
37 Loss: 0.413 | Acc: 99.959
38 Loss: 0.441 | Acc: 99.939
39 Loss: 0.456 | Acc: 99.959
40 Loss: 0.205 | Acc: 99.980
41 Loss: 0.218 | Acc: 99.980
42 Loss: 0.294 | Acc: 99.980
43 Loss: 0.237 | Acc: 99.980
44 Loss: 0.320 | Acc: 99.959
45 Loss: 0.297 | Acc: 99.959
46 Loss: 0.311 | Acc: 99.949
47 Loss: 0.233 | Acc: 99.969
48 Loss: 0.176 | Acc: 99.980
49 Loss: 0.246 | Acc: 99.969
50 Loss: 0.157 | Acc: 99.980
51 Loss: 0.182 | Acc: 99.980
52 Loss: 0.207 | Acc: 99.969
53 Loss: 0.184 | Acc: 99.980
54 Loss: 0.129 | Acc: 100.000
55 Loss: 0.210 | Acc: 99.969
56 Loss: 0.103 | Acc: 100.000
57 Loss: 0.176 | Acc: 99.990
58 Loss: 0.159 | Acc: 99.980
59 Loss: 0.160 | Acc: 99.990
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 5
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 5
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  18 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 4900
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 60.430
Split Acc: 82.940
lTrainDict[data].shape:  torch.Size([4904, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4904])
rTrainDict[data].shape:  torch.Size([5096, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([5096])
# of Left images:  4904.0
# of Right images:  5096.0
giniRightRatio:  0.8573578809618281
giniLeftRatio:  0.8539534927042943
impurityDrop:  0.8540817585099157
giniGain:  0.04591824149008428
lclasses:  [884, 117, 732, 217, 804, 210, 129, 831, 848, 132]
rclasses:  [116, 883, 268, 783, 196, 790, 871, 169, 152, 868]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([4904, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4904
nodeId:  3 , imgTensorShape :  torch.Size([5096, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5096
Nodes sizes =  5 5
Node 2 Acc: 62.847
Split Acc: 75.020
lTrainDict[data].shape:  torch.Size([1936, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1936])
rTrainDict[data].shape:  torch.Size([2968, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2968])
# of Left images:  1936.0
# of Right images:  2968.0
giniRightRatio:  0.7919615158274059
giniLeftRatio:  0.7197825242469778
impurityDrop:  0.7448798016428678
giniGain:  0.1090736910614265
lclasses:  [36, 11, 141, 104, 656, 127, 57, 753, 17, 34]
rclasses:  [848, 106, 591, 113, 148, 83, 72, 78, 831, 98]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([1936, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1936
nodeId:  5 , imgTensorShape :  torch.Size([2968, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2968
Nodes sizes =  2 3
Node 3 Acc: 61.401
Split Acc: 79.062
lTrainDict[data].shape:  torch.Size([1973, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1973])
rTrainDict[data].shape:  torch.Size([3123, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3123])
# of Left images:  1973.0
# of Right images:  3123.0
giniRightRatio:  0.7946979887172618
giniLeftRatio:  0.6425194253183306
impurityDrop:  0.6985570006973799
giniGain:  0.15880088026444816
lclasses:  [65, 843, 24, 34, 13, 14, 23, 35, 109, 813]
rclasses:  [51, 40, 244, 749, 183, 776, 848, 134, 43, 55]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([1973, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1973
nodeId:  7 , imgTensorShape :  torch.Size([3123, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3123
Nodes sizes =  2 3
Node 4 Acc: 63.326
Split Acc: 64.876
lTrainDict[data].shape:  torch.Size([962, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([962])
rTrainDict[data].shape:  torch.Size([974, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([974])
# of Left images:  962.0
# of Right images:  974.0
giniRightRatio:  0.6210128642444839
giniLeftRatio:  0.4848397093719339
impurityDrop:  0.4865174073785772
giniGain:  0.23326511686840057
lclasses:  [16, 7, 34, 38, 80, 66, 9, 680, 9, 23]
rclasses:  [20, 4, 107, 66, 576, 61, 48, 73, 8, 11]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([962, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 962
nodeId:  9 , imgTensorShape :  torch.Size([974, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 974
Nodes sizes =  1 1
Node 5 Acc: 60.815
Split Acc: 70.283
lTrainDict[data].shape:  torch.Size([939, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([939])
rTrainDict[data].shape:  torch.Size([2029, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2029])
# of Left images:  939.0
# of Right images:  2029.0
giniRightRatio:  0.6844903653067971
giniLeftRatio:  0.6906969438178291
impurityDrop:  0.687362704992287
giniGain:  0.1045988108351189
lclasses:  [62, 13, 494, 72, 99, 59, 57, 47, 25, 11]
rclasses:  [786, 93, 97, 41, 49, 24, 15, 31, 806, 87]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([939, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 939
nodeId:  11 , imgTensorShape :  torch.Size([2029, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2029
Nodes sizes =  1 2
Node 6 Acc: 70.046
Split Acc: 71.820
lTrainDict[data].shape:  torch.Size([990, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([990])
rTrainDict[data].shape:  torch.Size([983, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([983])
# of Left images:  990.0
# of Right images:  983.0
giniRightRatio:  0.4809410021225534
giniLeftRatio:  0.4467503315988164
impurityDrop:  0.4465068578514449
giniGain:  0.19601256746688572
lclasses:  [19, 723, 11, 11, 6, 9, 18, 9, 65, 119]
rclasses:  [46, 120, 13, 23, 7, 5, 5, 26, 44, 694]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([990, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 990
nodeId:  13 , imgTensorShape :  torch.Size([983, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 983
Nodes sizes =  1 1
Node 7 Acc: 54.659
Split Acc: 58.854
lTrainDict[data].shape:  torch.Size([988, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([988])
rTrainDict[data].shape:  torch.Size([2135, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2135])
# of Left images:  988.0
# of Right images:  2135.0
giniRightRatio:  0.7614547329278392
giniLeftRatio:  0.719338540215378
impurityDrop:  0.7419648976117212
giniGain:  0.052733091105540586
lclasses:  [26, 15, 73, 470, 59, 189, 67, 48, 21, 20]
rclasses:  [25, 25, 171, 279, 124, 587, 781, 86, 22, 35]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([988, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 988
nodeId:  15 , imgTensorShape :  torch.Size([2135, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2135
Nodes sizes =  1 2
Node 8 Acc: 70.686
Node 9 Acc: 59.138
Node 10 Acc: 52.609
Node 11 Acc: 67.570
Split Acc: 70.429
lTrainDict[data].shape:  torch.Size([1051, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1051])
rTrainDict[data].shape:  torch.Size([978, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([978])
# of Left images:  1051.0
# of Right images:  978.0
giniRightRatio:  0.4344536866272724
giniLeftRatio:  0.536834567413935
impurityDrop:  0.54447649409842
giniGain:  0.14001387120837705
lclasses:  [702, 44, 77, 23, 37, 12, 7, 26, 79, 44]
rclasses:  [84, 49, 20, 18, 12, 12, 8, 5, 727, 43]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([1051, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 1051
nodeId:  17 , imgTensorShape :  torch.Size([978, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 978
Nodes sizes =  1 1
Node 12 Acc: 73.030
Node 13 Acc: 70.600
Node 14 Acc: 47.571
Node 15 Acc: 59.204
Split Acc: 59.859
lTrainDict[data].shape:  torch.Size([1062, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1062])
rTrainDict[data].shape:  torch.Size([1073, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1073])
# of Left images:  1062.0
# of Right images:  1073.0
giniRightRatio:  0.5113898807378257
giniLeftRatio:  0.6862491621181653
impurityDrop:  0.6844565692987955
giniGain:  0.07699816362904366
lclasses:  [9, 18, 85, 205, 52, 542, 45, 71, 12, 23]
rclasses:  [16, 7, 86, 74, 72, 45, 736, 15, 10, 12]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1062, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1062
nodeId:  19 , imgTensorShape :  torch.Size([1073, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1073
Nodes sizes =  1 1
Node 16 Acc: 66.794
Node 17 Acc: 74.335
Node 18 Acc: 51.036
Node 19 Acc: 68.593
[[702  19  62  26  20   9  16  16  84  46]
 [ 44 723  13  15   4  18   7   7  49 120]
 [ 77  11 494  73 107  85  86  34  20  13]
 [ 23  11  72 470  66 205  74  38  18  23]
 [ 37   6  99  59 576  52  72  80  12   7]
 [ 12   9  59 189  61 542  45  66  12   5]
 [  7  18  57  67  48  45 736   9   8   5]
 [ 26   9  47  48  73  71  15 680   5  26]
 [ 79  65  25  21   8  12  10   9 727  44]
 [ 44 119  11  20  11  23  12  23  43 694]]

Acc: 63.440

                                                             1                                                                 
                   ┌─────────────────────────────────────────┴───────────────────────────┐                                     
                   2                                                                     3                                     
       ┌───────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
       4                         5                                         6                           7                       
 ┌─────┴─────┐            ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
 8           9            10                   11                   12            13            14                   15        
                                        ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                        16            17                                                      18            19 

                                                       -1                                                      
                   ┌───────────────────────────────────┴───────────────────────┐                               
                   -1                                                          -1                              
       ┌───────────┴───────────┐                                   ┌───────────┴───────────┐                   
       -1                      -1                                  -1                      -1                  
 ┌─────┴─────┐           ┌─────┴───────────┐                 ┌─────┴─────┐           ┌─────┴───────────┐       
 7           4           2                 -1                1           9           3                 -1      
                                     ┌─────┴─────┐                                               ┌─────┴─────┐ 
                                     0           8                                               5           6 

                                                                         49000                                                                         
                           ┌───────────────────────────────────────────────┴───────────────────────────────┐                                           
                         24500                                                                           24500                                         
           ┌───────────────┴───────────────┐                                               ┌───────────────┴───────────────┐                           
          9800                           14700                                            9800                           14700                         
   ┌───────┴───────┐               ┌───────┴───────────────┐                       ┌───────┴───────┐               ┌───────┴───────────────┐           
  4900            4900            4900                    9800                    4900            4900            4900                    9800         
                                                   ┌───────┴───────┐                                                               ┌───────┴───────┐   
                                                  4900            4900                                                            4900            4900 

                                                   {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                  
                                   ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────┐                                                       
             {0: 4900, 2: 4900, 4: 4900, 7: 4900, 8: 4900}                                                       {1: 4900, 3: 4900, 5: 4900, 6: 4900, 9: 4900}                                 
               ┌───────────────────┴───────────────────┐                                                           ┌───────────────────┴───────────────────┐                                   
       {4: 4900, 7: 4900}                 {0: 4900, 2: 4900, 8: 4900}                                      {1: 4900, 9: 4900}                 {3: 4900, 5: 4900, 6: 4900}                      
     ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐                             ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐               
 {7: 4900}           {4: 4900}           {2: 4900}                 {0: 4900, 8: 4900}                {1: 4900}           {9: 4900}           {3: 4900}                 {5: 4900, 6: 4900}      
                                                                 ┌─────────┴─────────┐                                                                               ┌─────────┴─────────┐     
                                                             {0: 4900}           {8: 4900}                                                                       {5: 4900}           {6: 4900} 

                                                               82.94                                                                  
                       ┌─────────────────────────────────────────┴───────────────────────────┐                                        
               75.02039151712887                                                     79.06200941915228                                
         ┌─────────────┴─────────────┐                                         ┌─────────────┴──────────────┐                         
 64.87603305785125           70.28301886792453                         71.81956411556006           58.853666346461736                 
  ┌──────┴──────┐             ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴──────────────┐           
 0.0           0.0           0.0            70.4287826515525           0.0           0.0           0.0            59.859484777517565  
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐    
                                           0.0           0.0                                                      0.0           0.0   

                                                         0.09999999999999987                                                         
                       ┌──────────────────────────────────────────┴───────────────────────────┐                                      
              0.24444444444444458                                                    0.24444444444444458                             
         ┌─────────────┴──────────────┐                                         ┌─────────────┴──────────────┐                       
        0.5                  0.41666666666666674                               0.5                  0.41666666666666674              
  ┌──────┴──────┐             ┌──────┴─────────────┐                     ┌──────┴──────┐             ┌──────┴─────────────┐          
 0.0           0.0           0.0                  0.5                   0.0           0.0           0.0                  0.5         
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐   
                                           0.0           0.0                                                      0.0           0.0  

