==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  50000 ,  len(valInputDict["data"]):  0 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([50000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 50000
Running nodeId:  1
trainInputDict[data].shape :  torch.Size([50000, 3, 32, 32])
copy.shape :  torch.Size([50000, 3072])
copyLabel.shape :  torch.Size([50000])
Class 0 has 5000 instances after oversampling
Class 1 has 5000 instances after oversampling
Class 2 has 5000 instances after oversampling
Class 3 has 5000 instances after oversampling
Class 4 has 5000 instances after oversampling
Class 5 has 5000 instances after oversampling
Class 6 has 5000 instances after oversampling
Class 7 has 5000 instances after oversampling
Class 8 has 5000 instances after oversampling
Class 9 has 5000 instances after oversampling
0 Train Loss: 177.246 | Train Acc: 37.916
1 Train Loss: 148.880 | Train Acc: 47.872
2 Train Loss: 136.418 | Train Acc: 52.378
3 Train Loss: 132.068 | Train Acc: 53.810
4 Train Loss: 126.597 | Train Acc: 55.706
5 Train Loss: 123.646 | Train Acc: 56.838
6 Train Loss: 120.314 | Train Acc: 57.976
7 Train Loss: 118.040 | Train Acc: 58.998
8 Train Loss: 115.639 | Train Acc: 59.652
9 Train Loss: 113.236 | Train Acc: 60.650
10 Train Loss: 111.123 | Train Acc: 61.306
11 Train Loss: 109.876 | Train Acc: 61.812
12 Train Loss: 108.882 | Train Acc: 62.118
13 Train Loss: 106.814 | Train Acc: 62.864
14 Train Loss: 105.334 | Train Acc: 63.560
15 Train Loss: 104.289 | Train Acc: 63.930
16 Train Loss: 103.157 | Train Acc: 64.266
17 Train Loss: 102.024 | Train Acc: 64.552
18 Train Loss: 100.916 | Train Acc: 65.052
19 Train Loss: 99.975 | Train Acc: 65.280
20 Train Loss: 96.271 | Train Acc: 66.900
21 Train Loss: 95.517 | Train Acc: 67.176
22 Train Loss: 94.958 | Train Acc: 67.504
23 Train Loss: 94.489 | Train Acc: 67.512
24 Train Loss: 94.384 | Train Acc: 67.656
25 Train Loss: 93.931 | Train Acc: 67.938
26 Train Loss: 93.572 | Train Acc: 67.698
27 Train Loss: 93.384 | Train Acc: 67.972
28 Train Loss: 92.830 | Train Acc: 68.078
29 Train Loss: 92.200 | Train Acc: 68.328
30 Train Loss: 91.952 | Train Acc: 68.398
31 Train Loss: 91.653 | Train Acc: 68.644
32 Train Loss: 91.270 | Train Acc: 68.636
33 Train Loss: 91.247 | Train Acc: 68.716
34 Train Loss: 90.594 | Train Acc: 68.926
35 Train Loss: 90.446 | Train Acc: 68.916
36 Train Loss: 90.030 | Train Acc: 69.240
37 Train Loss: 89.678 | Train Acc: 69.462
38 Train Loss: 89.364 | Train Acc: 69.388
39 Train Loss: 88.892 | Train Acc: 69.596
40 Train Loss: 87.252 | Train Acc: 70.414
41 Train Loss: 87.089 | Train Acc: 70.472
42 Train Loss: 86.986 | Train Acc: 70.558
43 Train Loss: 86.832 | Train Acc: 70.562
44 Train Loss: 86.686 | Train Acc: 70.734
45 Train Loss: 86.618 | Train Acc: 70.568
46 Train Loss: 86.422 | Train Acc: 70.724
47 Train Loss: 86.407 | Train Acc: 70.610
48 Train Loss: 86.162 | Train Acc: 70.752
49 Train Loss: 86.046 | Train Acc: 70.796
50 Train Loss: 85.935 | Train Acc: 70.818
51 Train Loss: 85.715 | Train Acc: 70.922
52 Train Loss: 85.636 | Train Acc: 70.942
53 Train Loss: 85.556 | Train Acc: 70.856
54 Train Loss: 85.409 | Train Acc: 71.078
55 Train Loss: 85.284 | Train Acc: 71.080
56 Train Loss: 85.140 | Train Acc: 71.170
57 Train Loss: 85.090 | Train Acc: 70.994
58 Train Loss: 84.954 | Train Acc: 71.190
59 Train Loss: 84.663 | Train Acc: 71.310
60 Train Loss: 84.049 | Train Acc: 71.566
61 Train Loss: 83.896 | Train Acc: 71.690
62 Train Loss: 83.814 | Train Acc: 71.764
63 Train Loss: 83.831 | Train Acc: 71.650
64 Train Loss: 83.722 | Train Acc: 71.692
65 Train Loss: 83.690 | Train Acc: 71.778
66 Train Loss: 83.706 | Train Acc: 71.724
67 Train Loss: 83.558 | Train Acc: 71.854
68 Train Loss: 83.566 | Train Acc: 71.836
69 Train Loss: 83.485 | Train Acc: 71.772
70 Train Loss: 83.365 | Train Acc: 71.812
71 Train Loss: 83.350 | Train Acc: 71.888
72 Train Loss: 83.261 | Train Acc: 71.984
73 Train Loss: 83.203 | Train Acc: 71.940
74 Train Loss: 83.159 | Train Acc: 71.918
75 Train Loss: 83.126 | Train Acc: 71.914
76 Train Loss: 83.034 | Train Acc: 71.944
77 Train Loss: 83.033 | Train Acc: 71.984
78 Train Loss: 82.997 | Train Acc: 72.108
79 Train Loss: 82.891 | Train Acc: 71.996
80 Train Loss: 82.602 | Train Acc: 72.186
81 Train Loss: 82.579 | Train Acc: 72.216
82 Train Loss: 82.545 | Train Acc: 72.126
83 Train Loss: 82.493 | Train Acc: 72.244
84 Train Loss: 82.471 | Train Acc: 72.254
85 Train Loss: 82.474 | Train Acc: 72.184
86 Train Loss: 82.447 | Train Acc: 72.186
87 Train Loss: 82.419 | Train Acc: 72.286
88 Train Loss: 82.400 | Train Acc: 72.268
89 Train Loss: 82.407 | Train Acc: 72.258
90 Train Loss: 82.362 | Train Acc: 72.258
91 Train Loss: 82.329 | Train Acc: 72.290
92 Train Loss: 82.317 | Train Acc: 72.218
93 Train Loss: 82.306 | Train Acc: 72.322
94 Train Loss: 82.296 | Train Acc: 72.262
95 Train Loss: 82.259 | Train Acc: 72.246
96 Train Loss: 82.217 | Train Acc: 72.186
97 Train Loss: 82.246 | Train Acc: 72.212
98 Train Loss: 82.167 | Train Acc: 72.318
99 Train Loss: 82.176 | Train Acc: 72.328
CNN trained successfully...
image_next_flat.shape :  torch.Size([50000, 12544])
printing expected split from k means
{9: 0, 1: 0, 8: 0, 7: 1, 2: 1, 6: 1, 4: 1, 5: 1, 0: 0, 3: 1}
Printing final_dict items...
{9: 0, 1: 0, 8: 0, 7: 1, 2: 1, 6: 1, 4: 1, 5: 1, 0: 0, 3: 1}
Image Statistics before MLP : L R :  24222 25778
expectedMlpLabels.shape :  torch.Size([50000])
0 Loss: 11.830 | Acc: 97.392
1 Loss: 6.999 | Acc: 98.446
2 Loss: 5.184 | Acc: 98.932
3 Loss: 4.876 | Acc: 98.954
4 Loss: 4.182 | Acc: 99.112
5 Loss: 3.133 | Acc: 99.364
6 Loss: 3.225 | Acc: 99.324
7 Loss: 2.937 | Acc: 99.392
8 Loss: 2.998 | Acc: 99.382
9 Loss: 2.468 | Acc: 99.446
10 Loss: 1.006 | Acc: 99.812
11 Loss: 0.916 | Acc: 99.864
12 Loss: 0.746 | Acc: 99.852
13 Loss: 0.627 | Acc: 99.894
14 Loss: 0.754 | Acc: 99.850
15 Loss: 0.625 | Acc: 99.892
16 Loss: 0.661 | Acc: 99.894
17 Loss: 0.729 | Acc: 99.880
18 Loss: 0.671 | Acc: 99.880
19 Loss: 0.615 | Acc: 99.868
20 Loss: 0.385 | Acc: 99.936
21 Loss: 0.146 | Acc: 99.982
22 Loss: 0.131 | Acc: 99.974
23 Loss: 0.223 | Acc: 99.970
24 Loss: 0.153 | Acc: 99.982
25 Loss: 0.103 | Acc: 99.986
26 Loss: 0.081 | Acc: 99.992
27 Loss: 0.062 | Acc: 99.996
28 Loss: 0.060 | Acc: 99.990
29 Loss: 0.072 | Acc: 99.992
30 Loss: 0.059 | Acc: 99.992
31 Loss: 0.056 | Acc: 99.996
32 Loss: 0.047 | Acc: 99.996
33 Loss: 0.034 | Acc: 99.996
34 Loss: 0.069 | Acc: 99.986
35 Loss: 0.055 | Acc: 99.992
36 Loss: 0.025 | Acc: 99.998
37 Loss: 0.043 | Acc: 99.994
38 Loss: 0.057 | Acc: 99.994
39 Loss: 0.042 | Acc: 99.992
40 Loss: 0.054 | Acc: 99.994
41 Loss: 0.050 | Acc: 99.998
42 Loss: 0.021 | Acc: 100.000
43 Loss: 0.020 | Acc: 99.998
44 Loss: 0.025 | Acc: 99.998
45 Loss: 0.027 | Acc: 99.998
46 Loss: 0.017 | Acc: 100.000
47 Loss: 0.019 | Acc: 99.998
48 Loss: 0.013 | Acc: 100.000
49 Loss: 0.036 | Acc: 99.996
50 Loss: 0.010 | Acc: 100.000
51 Loss: 0.016 | Acc: 100.000
52 Loss: 0.014 | Acc: 100.000
53 Loss: 0.016 | Acc: 99.998
54 Loss: 0.010 | Acc: 100.000
55 Loss: 0.015 | Acc: 99.998
56 Loss: 0.026 | Acc: 99.998
57 Loss: 0.014 | Acc: 99.998
58 Loss: 0.014 | Acc: 100.000
59 Loss: 0.009 | Acc: 100.000
MLP trained successfully...
# of Left images:  24222.0
# of Right images:  25778.0
giniRightRatio:  0.8755293840522719
giniLeftRatio:  0.8722844602844926
impurityDrop:  0.8724803289082286
giniGain:  0.027519671091771447
lclasses:  [4249, 3362, 1863, 1731, 1279, 1594, 693, 1514, 4543, 3394]
rclasses:  [751, 1638, 3137, 3269, 3721, 3406, 4307, 3486, 457, 1606]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([24222, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([24222])
rTrainDict[data].shape:  torch.Size([25778, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([25778])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([24222, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 24222
nodeId:  3 , imgTensorShape :  torch.Size([25778, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 25778
Running nodeId:  2
trainInputDict[data].shape :  torch.Size([24222, 16, 28, 28])
copy.shape :  torch.Size([24222, 12544])
copyLabel.shape :  torch.Size([24222])
Class 0 has 4543 instances after oversampling
Class 1 has 4543 instances after oversampling
Class 2 has 4543 instances after oversampling
Class 3 has 4542 instances after oversampling
Class 4 has 4542 instances after oversampling
Class 5 has 4542 instances after oversampling
Class 6 has 4542 instances after oversampling
Class 7 has 4542 instances after oversampling
Class 8 has 4543 instances after oversampling
Class 9 has 4543 instances after oversampling
0 Train Loss: 209.224 | Train Acc: 25.497
1 Train Loss: 177.269 | Train Acc: 36.409
2 Train Loss: 160.908 | Train Acc: 42.692
3 Train Loss: 154.363 | Train Acc: 45.006
4 Train Loss: 150.397 | Train Acc: 46.382
5 Train Loss: 142.406 | Train Acc: 50.199
6 Train Loss: 141.813 | Train Acc: 50.111
7 Train Loss: 140.127 | Train Acc: 50.769
8 Train Loss: 133.304 | Train Acc: 54.127
9 Train Loss: 132.396 | Train Acc: 54.208
10 Train Loss: 126.319 | Train Acc: 56.284
11 Train Loss: 124.006 | Train Acc: 57.065
12 Train Loss: 123.937 | Train Acc: 57.145
13 Train Loss: 120.509 | Train Acc: 58.204
14 Train Loss: 116.987 | Train Acc: 60.482
15 Train Loss: 115.125 | Train Acc: 60.843
16 Train Loss: 113.037 | Train Acc: 61.475
17 Train Loss: 110.285 | Train Acc: 62.485
18 Train Loss: 104.658 | Train Acc: 64.707
19 Train Loss: 106.158 | Train Acc: 63.875
20 Train Loss: 97.437 | Train Acc: 67.734
21 Train Loss: 95.549 | Train Acc: 68.161
22 Train Loss: 94.080 | Train Acc: 68.731
23 Train Loss: 94.441 | Train Acc: 68.368
24 Train Loss: 93.494 | Train Acc: 68.733
25 Train Loss: 91.224 | Train Acc: 69.567
26 Train Loss: 91.854 | Train Acc: 69.644
27 Train Loss: 90.299 | Train Acc: 70.149
28 Train Loss: 90.964 | Train Acc: 69.887
29 Train Loss: 90.174 | Train Acc: 70.021
30 Train Loss: 89.114 | Train Acc: 70.466
31 Train Loss: 87.946 | Train Acc: 70.910
32 Train Loss: 88.791 | Train Acc: 70.490
33 Train Loss: 89.663 | Train Acc: 69.821
34 Train Loss: 85.425 | Train Acc: 71.824
35 Train Loss: 86.589 | Train Acc: 71.408
36 Train Loss: 85.158 | Train Acc: 72.192
37 Train Loss: 84.160 | Train Acc: 72.159
38 Train Loss: 85.232 | Train Acc: 71.833
39 Train Loss: 83.455 | Train Acc: 72.632
40 Train Loss: 80.561 | Train Acc: 73.633
41 Train Loss: 79.684 | Train Acc: 74.122
42 Train Loss: 79.367 | Train Acc: 73.999
43 Train Loss: 79.718 | Train Acc: 74.056
44 Train Loss: 78.727 | Train Acc: 74.353
45 Train Loss: 78.158 | Train Acc: 74.481
46 Train Loss: 78.191 | Train Acc: 74.730
47 Train Loss: 78.464 | Train Acc: 74.441
48 Train Loss: 78.909 | Train Acc: 74.199
49 Train Loss: 78.062 | Train Acc: 74.444
50 Train Loss: 78.019 | Train Acc: 74.730
51 Train Loss: 76.684 | Train Acc: 75.192
52 Train Loss: 77.232 | Train Acc: 75.005
53 Train Loss: 76.956 | Train Acc: 75.093
54 Train Loss: 76.763 | Train Acc: 75.075
55 Train Loss: 77.087 | Train Acc: 74.959
56 Train Loss: 77.117 | Train Acc: 74.844
57 Train Loss: 75.885 | Train Acc: 75.379
58 Train Loss: 75.816 | Train Acc: 75.511
59 Train Loss: 74.988 | Train Acc: 75.742
60 Train Loss: 73.945 | Train Acc: 76.132
61 Train Loss: 73.938 | Train Acc: 76.227
62 Train Loss: 73.904 | Train Acc: 76.139
63 Train Loss: 73.653 | Train Acc: 76.315
64 Train Loss: 73.576 | Train Acc: 76.269
65 Train Loss: 74.119 | Train Acc: 76.088
66 Train Loss: 73.676 | Train Acc: 76.211
67 Train Loss: 73.331 | Train Acc: 76.566
68 Train Loss: 73.428 | Train Acc: 76.302
69 Train Loss: 73.396 | Train Acc: 76.385
70 Train Loss: 72.991 | Train Acc: 76.473
71 Train Loss: 73.221 | Train Acc: 76.509
72 Train Loss: 73.325 | Train Acc: 76.449
73 Train Loss: 73.478 | Train Acc: 76.225
74 Train Loss: 72.869 | Train Acc: 76.671
75 Train Loss: 72.714 | Train Acc: 76.605
76 Train Loss: 72.660 | Train Acc: 76.696
77 Train Loss: 72.459 | Train Acc: 76.810
78 Train Loss: 72.592 | Train Acc: 76.693
79 Train Loss: 72.317 | Train Acc: 76.784
80 Train Loss: 71.914 | Train Acc: 76.949
81 Train Loss: 71.812 | Train Acc: 77.013
82 Train Loss: 71.675 | Train Acc: 76.997
83 Train Loss: 71.624 | Train Acc: 77.167
84 Train Loss: 71.551 | Train Acc: 77.222
85 Train Loss: 71.713 | Train Acc: 77.088
86 Train Loss: 71.618 | Train Acc: 77.154
87 Train Loss: 71.465 | Train Acc: 77.096
88 Train Loss: 71.529 | Train Acc: 77.156
89 Train Loss: 71.443 | Train Acc: 77.173
90 Train Loss: 71.420 | Train Acc: 77.165
91 Train Loss: 71.500 | Train Acc: 77.074
92 Train Loss: 71.280 | Train Acc: 77.233
93 Train Loss: 71.236 | Train Acc: 77.213
94 Train Loss: 71.317 | Train Acc: 77.211
95 Train Loss: 71.347 | Train Acc: 77.110
96 Train Loss: 71.257 | Train Acc: 77.259
97 Train Loss: 71.254 | Train Acc: 77.226
98 Train Loss: 71.079 | Train Acc: 77.292
99 Train Loss: 71.177 | Train Acc: 77.187
CNN trained successfully...
image_next_flat.shape :  torch.Size([45425, 9216])
printing expected split from k means
{9: 0, 1: 0, 8: 0, 7: 1, 2: 1, 6: 1, 3: 1, 5: 1, 0: 0, 4: 1}
Printing final_dict items...
{9: 0, 1: 0, 8: 0, 7: 1, 2: 1, 6: 1, 3: 1, 5: 1, 0: 0, 4: 1}
Image Statistics before MLP : L R :  17975 27450
expectedMlpLabels.shape :  torch.Size([45425])
0 Loss: 26.278 | Acc: 92.975
1 Loss: 12.291 | Acc: 96.447
2 Loss: 11.092 | Acc: 96.834
3 Loss: 10.140 | Acc: 97.094
4 Loss: 9.246 | Acc: 97.310
5 Loss: 9.244 | Acc: 97.354
6 Loss: 7.607 | Acc: 97.772
7 Loss: 7.222 | Acc: 97.939
8 Loss: 7.031 | Acc: 98.065
9 Loss: 6.161 | Acc: 98.261
10 Loss: 4.386 | Acc: 98.822
11 Loss: 3.845 | Acc: 98.937
12 Loss: 3.692 | Acc: 99.025
13 Loss: 3.223 | Acc: 99.091
14 Loss: 3.013 | Acc: 99.212
15 Loss: 3.207 | Acc: 99.130
16 Loss: 2.718 | Acc: 99.236
17 Loss: 2.625 | Acc: 99.293
18 Loss: 2.498 | Acc: 99.313
19 Loss: 2.403 | Acc: 99.386
20 Loss: 1.980 | Acc: 99.456
21 Loss: 1.591 | Acc: 99.575
22 Loss: 1.469 | Acc: 99.621
23 Loss: 1.553 | Acc: 99.595
24 Loss: 1.427 | Acc: 99.639
25 Loss: 1.466 | Acc: 99.604
26 Loss: 1.456 | Acc: 99.606
27 Loss: 1.431 | Acc: 99.643
28 Loss: 1.416 | Acc: 99.646
29 Loss: 1.272 | Acc: 99.679
30 Loss: 1.024 | Acc: 99.742
31 Loss: 0.950 | Acc: 99.773
32 Loss: 1.009 | Acc: 99.758
33 Loss: 0.992 | Acc: 99.740
34 Loss: 1.008 | Acc: 99.762
35 Loss: 1.026 | Acc: 99.747
36 Loss: 0.871 | Acc: 99.800
37 Loss: 1.059 | Acc: 99.745
38 Loss: 0.940 | Acc: 99.778
39 Loss: 0.978 | Acc: 99.789
40 Loss: 0.782 | Acc: 99.824
41 Loss: 0.778 | Acc: 99.819
42 Loss: 0.763 | Acc: 99.791
43 Loss: 0.744 | Acc: 99.811
44 Loss: 0.693 | Acc: 99.839
45 Loss: 0.692 | Acc: 99.848
46 Loss: 0.757 | Acc: 99.846
47 Loss: 0.645 | Acc: 99.846
48 Loss: 0.624 | Acc: 99.853
49 Loss: 0.613 | Acc: 99.850
50 Loss: 0.738 | Acc: 99.848
51 Loss: 0.651 | Acc: 99.846
52 Loss: 0.716 | Acc: 99.841
53 Loss: 0.698 | Acc: 99.835
54 Loss: 0.632 | Acc: 99.864
55 Loss: 0.684 | Acc: 99.822
56 Loss: 0.693 | Acc: 99.835
57 Loss: 0.648 | Acc: 99.846
58 Loss: 0.666 | Acc: 99.837
59 Loss: 0.749 | Acc: 99.822
MLP trained successfully...
# of Left images:  13837.0
# of Right images:  10385.0
giniRightRatio:  0.8865052530999004
giniLeftRatio:  0.7917913396429983
impurityDrop:  0.7603081976831305
giniGain:  0.11197626260136206
lclasses:  [3255, 2884, 591, 137, 423, 83, 136, 186, 3932, 2210]
rclasses:  [994, 478, 1272, 1594, 856, 1511, 557, 1328, 611, 1184]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([13837, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([13837])
rTrainDict[data].shape:  torch.Size([10385, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([10385])
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([13837, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 13837
nodeId:  5 , imgTensorShape :  torch.Size([10385, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10385
Running nodeId:  3
trainInputDict[data].shape :  torch.Size([25778, 16, 28, 28])
copy.shape :  torch.Size([25778, 12544])
copyLabel.shape :  torch.Size([25778])
Class 0 has 4307 instances after oversampling
Class 1 has 4307 instances after oversampling
Class 2 has 4307 instances after oversampling
Class 3 has 4307 instances after oversampling
Class 4 has 4307 instances after oversampling
Class 5 has 4307 instances after oversampling
Class 6 has 4307 instances after oversampling
Class 7 has 4307 instances after oversampling
Class 8 has 4307 instances after oversampling
Class 9 has 4307 instances after oversampling
0 Train Loss: 221.283 | Train Acc: 19.034
1 Train Loss: 195.974 | Train Acc: 28.623
2 Train Loss: 172.646 | Train Acc: 38.249
3 Train Loss: 158.951 | Train Acc: 42.730
4 Train Loss: 160.037 | Train Acc: 42.510
5 Train Loss: 150.464 | Train Acc: 45.549
6 Train Loss: 150.470 | Train Acc: 45.686
7 Train Loss: 148.259 | Train Acc: 46.668
8 Train Loss: 145.398 | Train Acc: 47.102
9 Train Loss: 143.133 | Train Acc: 48.816
10 Train Loss: 146.548 | Train Acc: 48.110
11 Train Loss: 139.313 | Train Acc: 50.179
12 Train Loss: 136.492 | Train Acc: 50.868
13 Train Loss: 135.698 | Train Acc: 51.449
14 Train Loss: 132.649 | Train Acc: 52.737
15 Train Loss: 127.589 | Train Acc: 54.681
16 Train Loss: 128.784 | Train Acc: 54.251
17 Train Loss: 125.435 | Train Acc: 55.890
18 Train Loss: 124.956 | Train Acc: 55.301
19 Train Loss: 122.838 | Train Acc: 56.564
20 Train Loss: 117.211 | Train Acc: 58.951
21 Train Loss: 115.346 | Train Acc: 59.498
22 Train Loss: 113.948 | Train Acc: 59.998
23 Train Loss: 112.812 | Train Acc: 60.599
24 Train Loss: 112.698 | Train Acc: 60.532
25 Train Loss: 111.453 | Train Acc: 60.994
26 Train Loss: 112.022 | Train Acc: 60.673
27 Train Loss: 111.838 | Train Acc: 61.033
28 Train Loss: 111.684 | Train Acc: 60.799
29 Train Loss: 110.191 | Train Acc: 61.590
30 Train Loss: 108.866 | Train Acc: 61.741
31 Train Loss: 109.211 | Train Acc: 61.860
32 Train Loss: 109.650 | Train Acc: 61.686
33 Train Loss: 109.274 | Train Acc: 61.628
34 Train Loss: 107.504 | Train Acc: 62.549
35 Train Loss: 106.961 | Train Acc: 62.921
36 Train Loss: 108.037 | Train Acc: 62.185
37 Train Loss: 106.182 | Train Acc: 63.021
38 Train Loss: 105.860 | Train Acc: 62.953
39 Train Loss: 107.859 | Train Acc: 62.289
40 Train Loss: 103.315 | Train Acc: 64.040
41 Train Loss: 102.433 | Train Acc: 64.456
42 Train Loss: 102.571 | Train Acc: 64.451
43 Train Loss: 102.292 | Train Acc: 64.435
44 Train Loss: 101.912 | Train Acc: 64.699
45 Train Loss: 101.777 | Train Acc: 64.618
46 Train Loss: 101.470 | Train Acc: 64.871
47 Train Loss: 102.297 | Train Acc: 64.597
48 Train Loss: 101.510 | Train Acc: 64.767
49 Train Loss: 101.422 | Train Acc: 64.904
50 Train Loss: 101.328 | Train Acc: 64.678
51 Train Loss: 101.733 | Train Acc: 64.662
52 Train Loss: 100.651 | Train Acc: 65.315
53 Train Loss: 101.387 | Train Acc: 64.813
54 Train Loss: 100.412 | Train Acc: 65.094
55 Train Loss: 100.393 | Train Acc: 65.192
56 Train Loss: 99.928 | Train Acc: 65.247
57 Train Loss: 99.542 | Train Acc: 65.540
58 Train Loss: 100.409 | Train Acc: 65.275
59 Train Loss: 99.972 | Train Acc: 65.368
60 Train Loss: 98.574 | Train Acc: 65.904
61 Train Loss: 98.477 | Train Acc: 66.120
62 Train Loss: 98.505 | Train Acc: 65.937
63 Train Loss: 98.331 | Train Acc: 66.081
64 Train Loss: 98.443 | Train Acc: 66.007
65 Train Loss: 98.055 | Train Acc: 66.197
66 Train Loss: 98.126 | Train Acc: 66.208
67 Train Loss: 97.906 | Train Acc: 66.315
68 Train Loss: 97.762 | Train Acc: 66.183
69 Train Loss: 97.910 | Train Acc: 66.092
70 Train Loss: 97.725 | Train Acc: 66.292
71 Train Loss: 97.705 | Train Acc: 66.348
72 Train Loss: 97.729 | Train Acc: 66.246
73 Train Loss: 97.858 | Train Acc: 66.280
74 Train Loss: 97.574 | Train Acc: 66.420
75 Train Loss: 97.381 | Train Acc: 66.485
76 Train Loss: 97.343 | Train Acc: 66.276
77 Train Loss: 97.395 | Train Acc: 66.592
78 Train Loss: 97.736 | Train Acc: 66.313
79 Train Loss: 97.508 | Train Acc: 66.348
80 Train Loss: 96.901 | Train Acc: 66.596
81 Train Loss: 96.664 | Train Acc: 66.678
82 Train Loss: 96.616 | Train Acc: 66.745
83 Train Loss: 96.572 | Train Acc: 66.845
84 Train Loss: 96.561 | Train Acc: 66.729
85 Train Loss: 96.563 | Train Acc: 66.789
86 Train Loss: 96.537 | Train Acc: 66.773
87 Train Loss: 96.572 | Train Acc: 66.684
88 Train Loss: 96.482 | Train Acc: 66.808
89 Train Loss: 96.505 | Train Acc: 66.726
90 Train Loss: 96.530 | Train Acc: 66.733
91 Train Loss: 96.405 | Train Acc: 66.900
92 Train Loss: 96.406 | Train Acc: 66.784
93 Train Loss: 96.324 | Train Acc: 66.847
94 Train Loss: 96.339 | Train Acc: 66.866
95 Train Loss: 96.292 | Train Acc: 66.938
96 Train Loss: 96.255 | Train Acc: 66.833
97 Train Loss: 96.235 | Train Acc: 66.947
98 Train Loss: 96.255 | Train Acc: 66.877
99 Train Loss: 96.134 | Train Acc: 66.975
CNN trained successfully...
image_next_flat.shape :  torch.Size([43070, 9216])
printing expected split from k means
{1: 0, 9: 0, 3: 1, 2: 1, 4: 1, 0: 1, 7: 1, 6: 1, 5: 1, 8: 0}
Printing final_dict items...
{1: 0, 9: 0, 3: 1, 2: 1, 4: 1, 0: 1, 7: 1, 6: 1, 5: 1, 8: 0}
Image Statistics before MLP : L R :  14871 28199
expectedMlpLabels.shape :  torch.Size([43070])
0 Loss: 16.580 | Acc: 95.201
1 Loss: 11.787 | Acc: 96.359
2 Loss: 10.555 | Acc: 96.536
3 Loss: 9.360 | Acc: 96.977
4 Loss: 8.865 | Acc: 97.123
5 Loss: 7.633 | Acc: 97.492
6 Loss: 6.903 | Acc: 97.799
7 Loss: 6.177 | Acc: 97.931
8 Loss: 5.784 | Acc: 98.161
9 Loss: 5.319 | Acc: 98.442
10 Loss: 4.123 | Acc: 98.702
11 Loss: 3.425 | Acc: 98.976
12 Loss: 2.995 | Acc: 99.104
13 Loss: 3.018 | Acc: 99.062
14 Loss: 2.720 | Acc: 99.197
15 Loss: 2.400 | Acc: 99.310
16 Loss: 2.443 | Acc: 99.327
17 Loss: 2.225 | Acc: 99.362
18 Loss: 2.256 | Acc: 99.389
19 Loss: 2.042 | Acc: 99.443
20 Loss: 1.723 | Acc: 99.510
21 Loss: 1.458 | Acc: 99.591
22 Loss: 1.346 | Acc: 99.594
23 Loss: 1.307 | Acc: 99.629
24 Loss: 1.337 | Acc: 99.633
25 Loss: 1.237 | Acc: 99.647
26 Loss: 1.229 | Acc: 99.649
27 Loss: 1.203 | Acc: 99.668
28 Loss: 1.311 | Acc: 99.647
29 Loss: 1.216 | Acc: 99.656
30 Loss: 1.021 | Acc: 99.726
31 Loss: 0.960 | Acc: 99.747
32 Loss: 0.870 | Acc: 99.777
33 Loss: 0.973 | Acc: 99.719
34 Loss: 0.882 | Acc: 99.765
35 Loss: 0.851 | Acc: 99.786
36 Loss: 0.822 | Acc: 99.786
37 Loss: 0.829 | Acc: 99.786
38 Loss: 0.813 | Acc: 99.779
39 Loss: 0.757 | Acc: 99.805
40 Loss: 0.763 | Acc: 99.800
41 Loss: 0.753 | Acc: 99.798
42 Loss: 0.713 | Acc: 99.814
43 Loss: 0.717 | Acc: 99.812
44 Loss: 0.629 | Acc: 99.831
45 Loss: 0.734 | Acc: 99.798
46 Loss: 0.732 | Acc: 99.803
47 Loss: 0.617 | Acc: 99.849
48 Loss: 0.644 | Acc: 99.819
49 Loss: 0.701 | Acc: 99.810
50 Loss: 0.633 | Acc: 99.847
51 Loss: 0.648 | Acc: 99.803
52 Loss: 0.597 | Acc: 99.858
53 Loss: 0.631 | Acc: 99.821
54 Loss: 0.623 | Acc: 99.831
55 Loss: 0.621 | Acc: 99.826
56 Loss: 0.577 | Acc: 99.856
57 Loss: 0.641 | Acc: 99.835
58 Loss: 0.662 | Acc: 99.821
59 Loss: 0.710 | Acc: 99.789
MLP trained successfully...
# of Left images:  6073.0
# of Right images:  19705.0
giniRightRatio:  0.8429742302102422
giniLeftRatio:  0.8454733287946322
impurityDrop:  0.843744442121077
giniGain:  0.031784941931194854
lclasses:  [397, 1538, 286, 420, 250, 338, 475, 587, 351, 1431]
rclasses:  [354, 100, 2851, 2849, 3471, 3068, 3832, 2899, 106, 175]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([6073, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([6073])
rTrainDict[data].shape:  torch.Size([19705, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([19705])
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([6073, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 6073
nodeId:  7 , imgTensorShape :  torch.Size([19705, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 19705
Running nodeId:  4
trainInputDict[data].shape :  torch.Size([13837, 16, 24, 24])
copy.shape :  torch.Size([13837, 9216])
copyLabel.shape :  torch.Size([13837])
Class 0 has 3932 instances after oversampling
Class 1 has 3932 instances after oversampling
Class 2 has 3932 instances after oversampling
Class 3 has 3932 instances after oversampling
Class 4 has 3932 instances after oversampling
Class 5 has 3932 instances after oversampling
Class 6 has 3932 instances after oversampling
Class 7 has 3932 instances after oversampling
Class 8 has 3932 instances after oversampling
Class 9 has 3932 instances after oversampling
0 Train Loss: 229.412 | Train Acc: 10.234
1 Train Loss: 203.973 | Train Acc: 27.520
2 Train Loss: 179.940 | Train Acc: 36.361
3 Train Loss: 151.171 | Train Acc: 47.976
4 Train Loss: 128.672 | Train Acc: 57.017
5 Train Loss: 111.860 | Train Acc: 63.070
6 Train Loss: 100.293 | Train Acc: 67.360
7 Train Loss: 90.334 | Train Acc: 70.931
8 Train Loss: 83.495 | Train Acc: 73.065
9 Train Loss: 76.795 | Train Acc: 75.295
10 Train Loss: 69.184 | Train Acc: 77.737
11 Train Loss: 65.396 | Train Acc: 78.802
12 Train Loss: 60.538 | Train Acc: 80.432
13 Train Loss: 55.223 | Train Acc: 82.063
14 Train Loss: 53.955 | Train Acc: 82.383
15 Train Loss: 50.990 | Train Acc: 83.385
16 Train Loss: 44.717 | Train Acc: 85.557
17 Train Loss: 42.986 | Train Acc: 86.043
18 Train Loss: 40.649 | Train Acc: 86.905
19 Train Loss: 41.716 | Train Acc: 86.480
20 Train Loss: 34.780 | Train Acc: 88.896
21 Train Loss: 32.710 | Train Acc: 89.578
22 Train Loss: 31.840 | Train Acc: 89.751
23 Train Loss: 32.221 | Train Acc: 89.621
24 Train Loss: 30.604 | Train Acc: 90.203
25 Train Loss: 30.423 | Train Acc: 90.109
26 Train Loss: 29.211 | Train Acc: 90.699
27 Train Loss: 28.603 | Train Acc: 90.791
28 Train Loss: 28.708 | Train Acc: 90.753
29 Train Loss: 27.810 | Train Acc: 91.086
30 Train Loss: 27.001 | Train Acc: 91.289
31 Train Loss: 27.057 | Train Acc: 91.302
32 Train Loss: 26.331 | Train Acc: 91.475
33 Train Loss: 26.197 | Train Acc: 91.582
34 Train Loss: 24.715 | Train Acc: 92.052
35 Train Loss: 24.386 | Train Acc: 92.195
36 Train Loss: 23.764 | Train Acc: 92.419
37 Train Loss: 23.273 | Train Acc: 92.464
38 Train Loss: 23.075 | Train Acc: 92.520
39 Train Loss: 22.645 | Train Acc: 92.683
40 Train Loss: 21.241 | Train Acc: 93.410
41 Train Loss: 20.795 | Train Acc: 93.596
42 Train Loss: 20.458 | Train Acc: 93.733
43 Train Loss: 20.637 | Train Acc: 93.619
44 Train Loss: 20.211 | Train Acc: 93.772
45 Train Loss: 20.044 | Train Acc: 93.840
46 Train Loss: 20.178 | Train Acc: 93.767
47 Train Loss: 19.809 | Train Acc: 93.929
48 Train Loss: 19.599 | Train Acc: 93.995
49 Train Loss: 19.325 | Train Acc: 93.998
50 Train Loss: 19.346 | Train Acc: 94.008
51 Train Loss: 19.234 | Train Acc: 94.049
52 Train Loss: 19.369 | Train Acc: 93.962
53 Train Loss: 19.002 | Train Acc: 94.156
54 Train Loss: 18.757 | Train Acc: 94.245
55 Train Loss: 18.769 | Train Acc: 94.217
56 Train Loss: 18.484 | Train Acc: 94.257
57 Train Loss: 18.337 | Train Acc: 94.349
58 Train Loss: 18.268 | Train Acc: 94.374
59 Train Loss: 18.171 | Train Acc: 94.293
60 Train Loss: 17.567 | Train Acc: 94.695
61 Train Loss: 17.416 | Train Acc: 94.695
62 Train Loss: 17.276 | Train Acc: 94.804
63 Train Loss: 17.373 | Train Acc: 94.700
64 Train Loss: 17.138 | Train Acc: 94.832
65 Train Loss: 17.100 | Train Acc: 94.804
66 Train Loss: 17.013 | Train Acc: 94.799
67 Train Loss: 17.080 | Train Acc: 94.789
68 Train Loss: 16.913 | Train Acc: 94.870
69 Train Loss: 17.020 | Train Acc: 94.802
70 Train Loss: 16.793 | Train Acc: 94.954
71 Train Loss: 16.756 | Train Acc: 94.852
72 Train Loss: 16.720 | Train Acc: 94.967
73 Train Loss: 16.703 | Train Acc: 94.964
74 Train Loss: 16.610 | Train Acc: 94.934
75 Train Loss: 16.532 | Train Acc: 95.028
76 Train Loss: 16.503 | Train Acc: 95.013
77 Train Loss: 16.351 | Train Acc: 95.023
78 Train Loss: 16.331 | Train Acc: 94.992
79 Train Loss: 16.296 | Train Acc: 95.081
80 Train Loss: 16.076 | Train Acc: 95.137
81 Train Loss: 16.014 | Train Acc: 95.234
82 Train Loss: 16.012 | Train Acc: 95.163
83 Train Loss: 16.028 | Train Acc: 95.158
84 Train Loss: 15.991 | Train Acc: 95.170
85 Train Loss: 15.921 | Train Acc: 95.244
86 Train Loss: 15.849 | Train Acc: 95.280
87 Train Loss: 15.919 | Train Acc: 95.249
88 Train Loss: 15.851 | Train Acc: 95.280
89 Train Loss: 15.805 | Train Acc: 95.264
90 Train Loss: 15.841 | Train Acc: 95.275
91 Train Loss: 15.840 | Train Acc: 95.244
92 Train Loss: 15.743 | Train Acc: 95.295
93 Train Loss: 15.746 | Train Acc: 95.252
94 Train Loss: 15.726 | Train Acc: 95.267
95 Train Loss: 15.685 | Train Acc: 95.323
96 Train Loss: 15.713 | Train Acc: 95.275
97 Train Loss: 15.641 | Train Acc: 95.308
98 Train Loss: 15.605 | Train Acc: 95.326
99 Train Loss: 15.533 | Train Acc: 95.338
CNN trained successfully...
image_next_flat.shape :  torch.Size([39320, 6400])
printing expected split from k means
{9: 1, 2: 0, 8: 1, 5: 0, 0: 0, 3: 0, 6: 0, 4: 0, 1: 1, 7: 0}
Printing final_dict items...
{9: 1, 2: 0, 8: 1, 5: 0, 0: 0, 3: 0, 6: 0, 4: 0, 1: 1, 7: 0}
Image Statistics before MLP : L R :  23706 15614
expectedMlpLabels.shape :  torch.Size([39320])
0 Loss: 35.998 | Acc: 87.823
1 Loss: 20.677 | Acc: 93.764
2 Loss: 17.927 | Acc: 94.677
3 Loss: 15.601 | Acc: 95.308
4 Loss: 14.253 | Acc: 95.697
5 Loss: 12.375 | Acc: 96.256
6 Loss: 12.279 | Acc: 96.345
7 Loss: 11.205 | Acc: 96.696
8 Loss: 10.427 | Acc: 96.971
9 Loss: 10.131 | Acc: 96.951
10 Loss: 7.480 | Acc: 97.851
11 Loss: 6.878 | Acc: 98.072
12 Loss: 6.353 | Acc: 98.184
13 Loss: 6.119 | Acc: 98.296
14 Loss: 5.860 | Acc: 98.380
15 Loss: 5.955 | Acc: 98.316
16 Loss: 5.675 | Acc: 98.393
17 Loss: 4.990 | Acc: 98.616
18 Loss: 5.040 | Acc: 98.632
19 Loss: 4.844 | Acc: 98.650
20 Loss: 3.786 | Acc: 98.983
21 Loss: 3.741 | Acc: 99.023
22 Loss: 3.468 | Acc: 99.049
23 Loss: 3.267 | Acc: 99.143
24 Loss: 3.318 | Acc: 99.153
25 Loss: 3.175 | Acc: 99.173
26 Loss: 3.083 | Acc: 99.191
27 Loss: 2.876 | Acc: 99.262
28 Loss: 3.109 | Acc: 99.153
29 Loss: 2.550 | Acc: 99.357
30 Loss: 2.331 | Acc: 99.415
31 Loss: 2.385 | Acc: 99.405
32 Loss: 2.509 | Acc: 99.369
33 Loss: 2.130 | Acc: 99.463
34 Loss: 2.257 | Acc: 99.405
35 Loss: 2.218 | Acc: 99.458
36 Loss: 2.146 | Acc: 99.446
37 Loss: 2.321 | Acc: 99.395
38 Loss: 2.056 | Acc: 99.514
39 Loss: 2.104 | Acc: 99.479
40 Loss: 1.819 | Acc: 99.545
41 Loss: 1.922 | Acc: 99.512
42 Loss: 1.897 | Acc: 99.496
43 Loss: 1.824 | Acc: 99.522
44 Loss: 1.644 | Acc: 99.593
45 Loss: 1.730 | Acc: 99.542
46 Loss: 1.787 | Acc: 99.504
47 Loss: 1.686 | Acc: 99.585
48 Loss: 1.673 | Acc: 99.550
49 Loss: 1.933 | Acc: 99.552
50 Loss: 1.621 | Acc: 99.588
51 Loss: 1.568 | Acc: 99.583
52 Loss: 1.650 | Acc: 99.624
53 Loss: 1.715 | Acc: 99.547
54 Loss: 1.616 | Acc: 99.596
55 Loss: 1.771 | Acc: 99.557
56 Loss: 1.632 | Acc: 99.596
57 Loss: 1.801 | Acc: 99.509
58 Loss: 1.605 | Acc: 99.578
59 Loss: 1.675 | Acc: 99.575
MLP trained successfully...
# of Left images:  4052.0
# of Right images:  9785.0
giniRightRatio:  0.770894977843774
giniLeftRatio:  0.7252898888974428
impurityDrop:  0.7520097636985994
giniGain:  0.039781575944398906
lclasses:  [1584, 101, 437, 67, 288, 44, 82, 36, 1300, 113]
rclasses:  [1671, 2783, 154, 70, 135, 39, 54, 150, 2632, 2097]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([4052, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([4052])
rTrainDict[data].shape:  torch.Size([9785, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([9785])
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([4052, 16, 20, 20])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 4052
nodeId:  9 , imgTensorShape :  torch.Size([9785, 16, 20, 20])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 9785
Running nodeId:  5
trainInputDict[data].shape :  torch.Size([10385, 16, 24, 24])
copy.shape :  torch.Size([10385, 9216])
copyLabel.shape :  torch.Size([10385])
Class 0 has 1594 instances after oversampling
Class 1 has 1594 instances after oversampling
Class 2 has 1594 instances after oversampling
Class 3 has 1594 instances after oversampling
Class 4 has 1594 instances after oversampling
Class 5 has 1594 instances after oversampling
Class 6 has 1594 instances after oversampling
Class 7 has 1594 instances after oversampling
Class 8 has 1594 instances after oversampling
Class 9 has 1594 instances after oversampling
0 Train Loss: 206.812 | Train Acc: 23.940
1 Train Loss: 164.818 | Train Acc: 43.858
2 Train Loss: 147.280 | Train Acc: 49.780
3 Train Loss: 140.127 | Train Acc: 52.836
4 Train Loss: 128.182 | Train Acc: 57.384
5 Train Loss: 123.654 | Train Acc: 58.745
6 Train Loss: 121.429 | Train Acc: 59.718
7 Train Loss: 113.752 | Train Acc: 62.673
8 Train Loss: 109.920 | Train Acc: 63.858
9 Train Loss: 106.450 | Train Acc: 64.944
10 Train Loss: 101.658 | Train Acc: 66.462
11 Train Loss: 94.652 | Train Acc: 69.065
12 Train Loss: 93.610 | Train Acc: 69.661
13 Train Loss: 86.750 | Train Acc: 71.719
14 Train Loss: 84.546 | Train Acc: 72.164
15 Train Loss: 81.221 | Train Acc: 73.934
16 Train Loss: 77.481 | Train Acc: 75.138
17 Train Loss: 75.370 | Train Acc: 75.445
18 Train Loss: 70.869 | Train Acc: 77.051
19 Train Loss: 71.001 | Train Acc: 77.585
20 Train Loss: 61.351 | Train Acc: 81.186
21 Train Loss: 59.175 | Train Acc: 81.844
22 Train Loss: 58.287 | Train Acc: 81.851
23 Train Loss: 56.394 | Train Acc: 82.616
24 Train Loss: 55.785 | Train Acc: 82.980
25 Train Loss: 54.481 | Train Acc: 83.532
26 Train Loss: 53.359 | Train Acc: 83.745
27 Train Loss: 51.913 | Train Acc: 84.391
28 Train Loss: 51.195 | Train Acc: 84.718
29 Train Loss: 50.635 | Train Acc: 84.806
30 Train Loss: 49.596 | Train Acc: 85.232
31 Train Loss: 47.995 | Train Acc: 85.546
32 Train Loss: 47.173 | Train Acc: 85.972
33 Train Loss: 46.554 | Train Acc: 86.129
34 Train Loss: 45.269 | Train Acc: 86.738
35 Train Loss: 44.323 | Train Acc: 87.177
36 Train Loss: 42.995 | Train Acc: 87.246
37 Train Loss: 42.177 | Train Acc: 87.974
38 Train Loss: 41.862 | Train Acc: 87.641
39 Train Loss: 40.849 | Train Acc: 88.269
40 Train Loss: 37.619 | Train Acc: 89.937
41 Train Loss: 37.423 | Train Acc: 89.762
42 Train Loss: 37.002 | Train Acc: 89.937
43 Train Loss: 36.444 | Train Acc: 90.144
44 Train Loss: 36.060 | Train Acc: 90.251
45 Train Loss: 35.778 | Train Acc: 90.477
46 Train Loss: 35.336 | Train Acc: 90.571
47 Train Loss: 35.049 | Train Acc: 90.765
48 Train Loss: 34.778 | Train Acc: 90.715
49 Train Loss: 34.443 | Train Acc: 90.759
50 Train Loss: 34.052 | Train Acc: 90.979
51 Train Loss: 33.653 | Train Acc: 91.255
52 Train Loss: 33.324 | Train Acc: 91.192
53 Train Loss: 32.934 | Train Acc: 91.437
54 Train Loss: 32.510 | Train Acc: 91.568
55 Train Loss: 32.329 | Train Acc: 91.568
56 Train Loss: 31.852 | Train Acc: 91.794
57 Train Loss: 31.432 | Train Acc: 91.844
58 Train Loss: 31.285 | Train Acc: 91.838
59 Train Loss: 30.789 | Train Acc: 92.051
60 Train Loss: 29.690 | Train Acc: 92.635
61 Train Loss: 29.496 | Train Acc: 92.785
62 Train Loss: 29.415 | Train Acc: 92.760
63 Train Loss: 29.235 | Train Acc: 92.767
64 Train Loss: 29.145 | Train Acc: 92.817
65 Train Loss: 29.000 | Train Acc: 92.967
66 Train Loss: 28.778 | Train Acc: 92.980
67 Train Loss: 28.800 | Train Acc: 92.886
68 Train Loss: 28.574 | Train Acc: 93.005
69 Train Loss: 28.506 | Train Acc: 93.093
70 Train Loss: 28.234 | Train Acc: 93.231
71 Train Loss: 28.147 | Train Acc: 92.999
72 Train Loss: 28.048 | Train Acc: 93.181
73 Train Loss: 27.786 | Train Acc: 93.319
74 Train Loss: 27.691 | Train Acc: 93.450
75 Train Loss: 27.590 | Train Acc: 93.269
76 Train Loss: 27.523 | Train Acc: 93.338
77 Train Loss: 27.336 | Train Acc: 93.413
78 Train Loss: 27.192 | Train Acc: 93.419
79 Train Loss: 27.005 | Train Acc: 93.545
80 Train Loss: 26.580 | Train Acc: 93.701
81 Train Loss: 26.492 | Train Acc: 93.896
82 Train Loss: 26.445 | Train Acc: 93.846
83 Train Loss: 26.405 | Train Acc: 93.814
84 Train Loss: 26.320 | Train Acc: 93.877
85 Train Loss: 26.282 | Train Acc: 93.883
86 Train Loss: 26.210 | Train Acc: 93.940
87 Train Loss: 26.150 | Train Acc: 93.952
88 Train Loss: 26.120 | Train Acc: 93.959
89 Train Loss: 26.055 | Train Acc: 93.959
90 Train Loss: 26.028 | Train Acc: 93.990
91 Train Loss: 25.937 | Train Acc: 93.946
92 Train Loss: 25.877 | Train Acc: 93.921
93 Train Loss: 25.836 | Train Acc: 94.059
94 Train Loss: 25.775 | Train Acc: 94.015
95 Train Loss: 25.726 | Train Acc: 94.090
96 Train Loss: 25.646 | Train Acc: 94.084
97 Train Loss: 25.610 | Train Acc: 94.141
98 Train Loss: 25.565 | Train Acc: 94.134
99 Train Loss: 25.558 | Train Acc: 94.147
CNN trained successfully...
image_next_flat.shape :  torch.Size([15940, 6400])
printing expected split from k means
{9: 0, 4: 1, 0: 0, 3: 1, 2: 1, 7: 1, 6: 1, 1: 1, 5: 1, 8: 1}
Printing final_dict items...
{9: 0, 4: 1, 0: 0, 3: 1, 2: 1, 7: 1, 6: 1, 1: 1, 5: 1, 8: 1}
Image Statistics before MLP : L R :  5200 10740
expectedMlpLabels.shape :  torch.Size([15940])
0 Loss: 32.282 | Acc: 88.181
1 Loss: 22.734 | Acc: 91.336
2 Loss: 20.337 | Acc: 92.284
3 Loss: 18.084 | Acc: 93.068
4 Loss: 17.238 | Acc: 93.582
5 Loss: 14.890 | Acc: 94.404
6 Loss: 12.912 | Acc: 95.075
7 Loss: 12.776 | Acc: 95.364
8 Loss: 11.938 | Acc: 95.678
9 Loss: 10.254 | Acc: 96.223
10 Loss: 7.748 | Acc: 97.108
11 Loss: 6.394 | Acc: 97.735
12 Loss: 6.146 | Acc: 97.905
13 Loss: 5.531 | Acc: 98.112
14 Loss: 5.375 | Acc: 98.143
15 Loss: 4.974 | Acc: 98.243
16 Loss: 5.028 | Acc: 98.262
17 Loss: 4.841 | Acc: 98.281
18 Loss: 4.438 | Acc: 98.444
19 Loss: 4.336 | Acc: 98.626
20 Loss: 3.329 | Acc: 98.915
21 Loss: 2.881 | Acc: 99.034
22 Loss: 2.732 | Acc: 99.065
23 Loss: 2.764 | Acc: 99.147
24 Loss: 2.545 | Acc: 99.191
25 Loss: 2.462 | Acc: 99.172
26 Loss: 2.396 | Acc: 99.172
27 Loss: 2.418 | Acc: 99.241
28 Loss: 2.203 | Acc: 99.285
29 Loss: 2.064 | Acc: 99.272
30 Loss: 1.954 | Acc: 99.341
31 Loss: 1.761 | Acc: 99.404
32 Loss: 1.889 | Acc: 99.310
33 Loss: 1.718 | Acc: 99.417
34 Loss: 1.487 | Acc: 99.498
35 Loss: 1.649 | Acc: 99.435
36 Loss: 1.456 | Acc: 99.498
37 Loss: 1.618 | Acc: 99.504
38 Loss: 1.533 | Acc: 99.473
39 Loss: 1.516 | Acc: 99.548
40 Loss: 1.456 | Acc: 99.523
41 Loss: 1.345 | Acc: 99.561
42 Loss: 1.326 | Acc: 99.573
43 Loss: 1.345 | Acc: 99.536
44 Loss: 1.188 | Acc: 99.655
45 Loss: 1.173 | Acc: 99.561
46 Loss: 1.411 | Acc: 99.492
47 Loss: 1.176 | Acc: 99.605
48 Loss: 1.368 | Acc: 99.504
49 Loss: 1.115 | Acc: 99.617
50 Loss: 1.030 | Acc: 99.661
51 Loss: 1.159 | Acc: 99.630
52 Loss: 1.131 | Acc: 99.630
53 Loss: 1.198 | Acc: 99.586
54 Loss: 1.108 | Acc: 99.649
55 Loss: 1.093 | Acc: 99.624
56 Loss: 1.114 | Acc: 99.642
57 Loss: 0.998 | Acc: 99.686
58 Loss: 1.181 | Acc: 99.611
59 Loss: 1.057 | Acc: 99.592
MLP trained successfully...
# of Left images:  3983.0
# of Right images:  6402.0
giniRightRatio:  0.8705185362157893
giniLeftRatio:  0.8755323355493587
impurityDrop:  0.8736378681035755
giniGain:  0.012867384996324893
lclasses:  [623, 267, 363, 376, 248, 267, 179, 677, 231, 752]
rclasses:  [371, 211, 909, 1218, 608, 1244, 378, 651, 380, 432]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([3983, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([3983])
rTrainDict[data].shape:  torch.Size([6402, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([6402])
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([3983, 16, 20, 20])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3983
nodeId:  11 , imgTensorShape :  torch.Size([6402, 16, 20, 20])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 6402
Running nodeId:  6
trainInputDict[data].shape :  torch.Size([6073, 16, 24, 24])
copy.shape :  torch.Size([6073, 9216])
copyLabel.shape :  torch.Size([6073])
Class 0 has 1538 instances after oversampling
Class 1 has 1538 instances after oversampling
Class 2 has 1538 instances after oversampling
Class 3 has 1538 instances after oversampling
Class 4 has 1538 instances after oversampling
Class 5 has 1538 instances after oversampling
Class 6 has 1538 instances after oversampling
Class 7 has 1538 instances after oversampling
Class 8 has 1538 instances after oversampling
Class 9 has 1538 instances after oversampling
0 Train Loss: 219.291 | Train Acc: 19.720
1 Train Loss: 187.559 | Train Acc: 32.685
2 Train Loss: 164.518 | Train Acc: 43.973
3 Train Loss: 153.863 | Train Acc: 47.627
4 Train Loss: 137.078 | Train Acc: 56.099
5 Train Loss: 121.923 | Train Acc: 61.463
6 Train Loss: 110.209 | Train Acc: 66.105
7 Train Loss: 98.579 | Train Acc: 69.909
8 Train Loss: 89.110 | Train Acc: 73.004
9 Train Loss: 83.384 | Train Acc: 74.343
10 Train Loss: 75.599 | Train Acc: 77.445
11 Train Loss: 70.949 | Train Acc: 79.031
12 Train Loss: 61.018 | Train Acc: 82.172
13 Train Loss: 60.225 | Train Acc: 82.458
14 Train Loss: 53.347 | Train Acc: 84.662
15 Train Loss: 51.929 | Train Acc: 85.111
16 Train Loss: 43.372 | Train Acc: 88.218
17 Train Loss: 42.115 | Train Acc: 88.264
18 Train Loss: 38.564 | Train Acc: 89.376
19 Train Loss: 34.158 | Train Acc: 90.891
20 Train Loss: 28.958 | Train Acc: 92.874
21 Train Loss: 27.471 | Train Acc: 93.537
22 Train Loss: 25.650 | Train Acc: 94.077
23 Train Loss: 24.997 | Train Acc: 94.005
24 Train Loss: 24.569 | Train Acc: 94.285
25 Train Loss: 23.753 | Train Acc: 94.688
26 Train Loss: 22.951 | Train Acc: 94.844
27 Train Loss: 21.963 | Train Acc: 95.046
28 Train Loss: 21.052 | Train Acc: 95.572
29 Train Loss: 20.399 | Train Acc: 95.520
30 Train Loss: 19.735 | Train Acc: 95.644
31 Train Loss: 18.724 | Train Acc: 96.196
32 Train Loss: 18.201 | Train Acc: 96.092
33 Train Loss: 17.278 | Train Acc: 96.502
34 Train Loss: 16.579 | Train Acc: 96.691
35 Train Loss: 16.080 | Train Acc: 96.638
36 Train Loss: 15.456 | Train Acc: 97.094
37 Train Loss: 14.634 | Train Acc: 97.146
38 Train Loss: 14.173 | Train Acc: 97.276
39 Train Loss: 13.434 | Train Acc: 97.549
40 Train Loss: 12.123 | Train Acc: 98.140
41 Train Loss: 11.937 | Train Acc: 98.134
42 Train Loss: 11.527 | Train Acc: 98.212
43 Train Loss: 11.415 | Train Acc: 98.290
44 Train Loss: 11.274 | Train Acc: 98.322
45 Train Loss: 10.994 | Train Acc: 98.388
46 Train Loss: 10.825 | Train Acc: 98.388
47 Train Loss: 10.524 | Train Acc: 98.459
48 Train Loss: 10.396 | Train Acc: 98.498
49 Train Loss: 10.194 | Train Acc: 98.518
50 Train Loss: 10.018 | Train Acc: 98.641
51 Train Loss: 9.811 | Train Acc: 98.700
52 Train Loss: 9.649 | Train Acc: 98.700
53 Train Loss: 9.290 | Train Acc: 98.771
54 Train Loss: 9.261 | Train Acc: 98.739
55 Train Loss: 8.976 | Train Acc: 98.849
56 Train Loss: 8.823 | Train Acc: 98.804
57 Train Loss: 8.600 | Train Acc: 98.921
58 Train Loss: 8.445 | Train Acc: 98.953
59 Train Loss: 8.117 | Train Acc: 99.018
60 Train Loss: 7.737 | Train Acc: 99.103
61 Train Loss: 7.679 | Train Acc: 99.142
62 Train Loss: 7.573 | Train Acc: 99.168
63 Train Loss: 7.494 | Train Acc: 99.155
64 Train Loss: 7.450 | Train Acc: 99.174
65 Train Loss: 7.362 | Train Acc: 99.213
66 Train Loss: 7.280 | Train Acc: 99.200
67 Train Loss: 7.211 | Train Acc: 99.194
68 Train Loss: 7.172 | Train Acc: 99.239
69 Train Loss: 7.084 | Train Acc: 99.239
70 Train Loss: 7.028 | Train Acc: 99.324
71 Train Loss: 6.900 | Train Acc: 99.311
72 Train Loss: 6.843 | Train Acc: 99.317
73 Train Loss: 6.763 | Train Acc: 99.337
74 Train Loss: 6.745 | Train Acc: 99.363
75 Train Loss: 6.616 | Train Acc: 99.350
76 Train Loss: 6.596 | Train Acc: 99.337
77 Train Loss: 6.502 | Train Acc: 99.363
78 Train Loss: 6.411 | Train Acc: 99.395
79 Train Loss: 6.376 | Train Acc: 99.402
80 Train Loss: 6.161 | Train Acc: 99.486
81 Train Loss: 6.140 | Train Acc: 99.486
82 Train Loss: 6.116 | Train Acc: 99.454
83 Train Loss: 6.058 | Train Acc: 99.493
84 Train Loss: 6.038 | Train Acc: 99.493
85 Train Loss: 6.018 | Train Acc: 99.493
86 Train Loss: 5.984 | Train Acc: 99.493
87 Train Loss: 5.965 | Train Acc: 99.493
88 Train Loss: 5.925 | Train Acc: 99.519
89 Train Loss: 5.904 | Train Acc: 99.512
90 Train Loss: 5.881 | Train Acc: 99.545
91 Train Loss: 5.840 | Train Acc: 99.532
92 Train Loss: 5.815 | Train Acc: 99.545
93 Train Loss: 5.790 | Train Acc: 99.545
94 Train Loss: 5.765 | Train Acc: 99.525
95 Train Loss: 5.721 | Train Acc: 99.551
96 Train Loss: 5.710 | Train Acc: 99.564
97 Train Loss: 5.662 | Train Acc: 99.571
98 Train Loss: 5.644 | Train Acc: 99.558
99 Train Loss: 5.606 | Train Acc: 99.571
CNN trained successfully...
image_next_flat.shape :  torch.Size([15380, 6400])
printing expected split from k means
{1: 0, 9: 0, 3: 1, 2: 1, 4: 1, 7: 0, 6: 1, 5: 1, 0: 1, 8: 1}
Printing final_dict items...
{1: 0, 9: 0, 3: 1, 2: 1, 4: 1, 7: 0, 6: 1, 5: 1, 0: 1, 8: 1}
Image Statistics before MLP : L R :  5337 10043
expectedMlpLabels.shape :  torch.Size([15380])
0 Loss: 44.968 | Acc: 83.492
1 Loss: 29.493 | Acc: 89.909
2 Loss: 23.799 | Acc: 91.990
3 Loss: 20.181 | Acc: 93.238
4 Loss: 18.053 | Acc: 94.194
5 Loss: 15.825 | Acc: 94.798
6 Loss: 14.751 | Acc: 95.176
7 Loss: 14.430 | Acc: 95.208
8 Loss: 12.324 | Acc: 96.086
9 Loss: 10.526 | Acc: 96.612
10 Loss: 8.113 | Acc: 97.549
11 Loss: 6.358 | Acc: 98.023
12 Loss: 5.567 | Acc: 98.199
13 Loss: 5.542 | Acc: 98.427
14 Loss: 5.197 | Acc: 98.479
15 Loss: 5.168 | Acc: 98.433
16 Loss: 4.955 | Acc: 98.570
17 Loss: 4.528 | Acc: 98.609
18 Loss: 4.576 | Acc: 98.648
19 Loss: 4.753 | Acc: 98.596
20 Loss: 3.059 | Acc: 99.018
21 Loss: 2.496 | Acc: 99.324
22 Loss: 2.905 | Acc: 99.090
23 Loss: 2.435 | Acc: 99.311
24 Loss: 2.210 | Acc: 99.389
25 Loss: 2.545 | Acc: 99.259
26 Loss: 2.291 | Acc: 99.317
27 Loss: 2.539 | Acc: 99.239
28 Loss: 2.298 | Acc: 99.291
29 Loss: 2.388 | Acc: 99.285
30 Loss: 1.563 | Acc: 99.545
31 Loss: 2.102 | Acc: 99.376
32 Loss: 1.599 | Acc: 99.486
33 Loss: 1.774 | Acc: 99.506
34 Loss: 1.626 | Acc: 99.532
35 Loss: 1.646 | Acc: 99.473
36 Loss: 1.639 | Acc: 99.538
37 Loss: 1.614 | Acc: 99.577
38 Loss: 1.418 | Acc: 99.610
39 Loss: 1.758 | Acc: 99.493
40 Loss: 1.401 | Acc: 99.584
41 Loss: 1.256 | Acc: 99.610
42 Loss: 1.362 | Acc: 99.623
43 Loss: 1.392 | Acc: 99.512
44 Loss: 1.071 | Acc: 99.675
45 Loss: 1.342 | Acc: 99.649
46 Loss: 1.336 | Acc: 99.603
47 Loss: 1.189 | Acc: 99.668
48 Loss: 1.120 | Acc: 99.688
49 Loss: 1.453 | Acc: 99.597
50 Loss: 1.190 | Acc: 99.681
51 Loss: 1.350 | Acc: 99.629
52 Loss: 1.027 | Acc: 99.727
53 Loss: 1.273 | Acc: 99.623
54 Loss: 1.330 | Acc: 99.616
55 Loss: 1.189 | Acc: 99.649
56 Loss: 1.107 | Acc: 99.655
57 Loss: 1.088 | Acc: 99.681
58 Loss: 1.216 | Acc: 99.603
59 Loss: 0.979 | Acc: 99.720
MLP trained successfully...
# of Left images:  3642.0
# of Right images:  2431.0
giniRightRatio:  0.8572458344762166
giniLeftRatio:  0.8180391919159021
impurityDrop:  0.7985084456631086
giniGain:  0.04696488313152358
lclasses:  [121, 902, 120, 275, 132, 257, 221, 489, 67, 1058]
rclasses:  [276, 636, 166, 145, 118, 81, 254, 98, 284, 373]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([3642, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([3642])
rTrainDict[data].shape:  torch.Size([2431, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([2431])
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([3642, 16, 20, 20])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3642
nodeId:  13 , imgTensorShape :  torch.Size([2431, 16, 20, 20])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2431
Running nodeId:  7
trainInputDict[data].shape :  torch.Size([19705, 16, 24, 24])
copy.shape :  torch.Size([19705, 9216])
copyLabel.shape :  torch.Size([19705])
Class 0 has 3832 instances after oversampling
Class 1 has 3832 instances after oversampling
Class 2 has 3832 instances after oversampling
Class 3 has 3832 instances after oversampling
Class 4 has 3832 instances after oversampling
Class 5 has 3832 instances after oversampling
Class 6 has 3832 instances after oversampling
Class 7 has 3832 instances after oversampling
Class 8 has 3832 instances after oversampling
Class 9 has 3832 instances after oversampling
0 Train Loss: 211.442 | Train Acc: 23.656
1 Train Loss: 170.558 | Train Acc: 41.106
2 Train Loss: 149.699 | Train Acc: 47.894
3 Train Loss: 135.762 | Train Acc: 53.562
4 Train Loss: 132.062 | Train Acc: 54.079
5 Train Loss: 121.145 | Train Acc: 59.097
6 Train Loss: 111.993 | Train Acc: 61.939
7 Train Loss: 107.965 | Train Acc: 63.223
8 Train Loss: 102.772 | Train Acc: 65.232
9 Train Loss: 98.497 | Train Acc: 66.550
10 Train Loss: 93.182 | Train Acc: 68.210
11 Train Loss: 90.310 | Train Acc: 69.102
12 Train Loss: 85.351 | Train Acc: 70.877
13 Train Loss: 85.112 | Train Acc: 70.806
14 Train Loss: 81.049 | Train Acc: 72.424
15 Train Loss: 80.082 | Train Acc: 72.317
16 Train Loss: 77.142 | Train Acc: 73.442
17 Train Loss: 76.416 | Train Acc: 74.014
18 Train Loss: 74.837 | Train Acc: 74.653
19 Train Loss: 72.023 | Train Acc: 75.177
20 Train Loss: 67.254 | Train Acc: 77.242
21 Train Loss: 66.308 | Train Acc: 77.236
22 Train Loss: 65.132 | Train Acc: 77.792
23 Train Loss: 64.865 | Train Acc: 78.074
24 Train Loss: 64.261 | Train Acc: 77.991
25 Train Loss: 64.084 | Train Acc: 78.137
26 Train Loss: 63.527 | Train Acc: 78.121
27 Train Loss: 62.874 | Train Acc: 78.400
28 Train Loss: 62.514 | Train Acc: 78.599
29 Train Loss: 62.212 | Train Acc: 78.680
30 Train Loss: 61.139 | Train Acc: 79.139
31 Train Loss: 60.655 | Train Acc: 79.220
32 Train Loss: 61.678 | Train Acc: 78.499
33 Train Loss: 60.533 | Train Acc: 79.087
34 Train Loss: 59.879 | Train Acc: 79.452
35 Train Loss: 59.191 | Train Acc: 79.708
36 Train Loss: 59.320 | Train Acc: 79.645
37 Train Loss: 58.710 | Train Acc: 79.590
38 Train Loss: 57.873 | Train Acc: 79.956
39 Train Loss: 57.880 | Train Acc: 79.901
40 Train Loss: 55.558 | Train Acc: 81.153
41 Train Loss: 55.469 | Train Acc: 81.101
42 Train Loss: 55.814 | Train Acc: 80.994
43 Train Loss: 55.092 | Train Acc: 81.318
44 Train Loss: 55.104 | Train Acc: 81.326
45 Train Loss: 55.058 | Train Acc: 81.101
46 Train Loss: 54.726 | Train Acc: 81.407
47 Train Loss: 54.604 | Train Acc: 81.394
48 Train Loss: 54.316 | Train Acc: 81.386
49 Train Loss: 54.546 | Train Acc: 81.467
50 Train Loss: 54.089 | Train Acc: 81.501
51 Train Loss: 54.023 | Train Acc: 81.529
52 Train Loss: 53.930 | Train Acc: 81.631
53 Train Loss: 53.644 | Train Acc: 81.654
54 Train Loss: 53.376 | Train Acc: 81.835
55 Train Loss: 53.818 | Train Acc: 81.605
56 Train Loss: 53.154 | Train Acc: 81.892
57 Train Loss: 53.123 | Train Acc: 81.853
58 Train Loss: 52.943 | Train Acc: 82.017
59 Train Loss: 52.569 | Train Acc: 82.166
60 Train Loss: 51.962 | Train Acc: 82.555
61 Train Loss: 51.963 | Train Acc: 82.385
62 Train Loss: 51.812 | Train Acc: 82.508
63 Train Loss: 51.711 | Train Acc: 82.443
64 Train Loss: 51.639 | Train Acc: 82.534
65 Train Loss: 51.623 | Train Acc: 82.578
66 Train Loss: 51.705 | Train Acc: 82.568
67 Train Loss: 51.536 | Train Acc: 82.672
68 Train Loss: 51.611 | Train Acc: 82.537
69 Train Loss: 51.565 | Train Acc: 82.495
70 Train Loss: 51.377 | Train Acc: 82.683
71 Train Loss: 51.286 | Train Acc: 82.623
72 Train Loss: 51.360 | Train Acc: 82.677
73 Train Loss: 51.270 | Train Acc: 82.638
74 Train Loss: 51.159 | Train Acc: 82.730
75 Train Loss: 50.988 | Train Acc: 82.764
76 Train Loss: 51.055 | Train Acc: 82.641
77 Train Loss: 50.900 | Train Acc: 82.722
78 Train Loss: 51.012 | Train Acc: 82.771
79 Train Loss: 50.872 | Train Acc: 82.685
80 Train Loss: 50.502 | Train Acc: 83.064
81 Train Loss: 50.533 | Train Acc: 82.839
82 Train Loss: 50.439 | Train Acc: 82.988
83 Train Loss: 50.452 | Train Acc: 83.035
84 Train Loss: 50.467 | Train Acc: 82.907
85 Train Loss: 50.378 | Train Acc: 83.006
86 Train Loss: 50.433 | Train Acc: 82.983
87 Train Loss: 50.369 | Train Acc: 83.009
88 Train Loss: 50.306 | Train Acc: 83.066
89 Train Loss: 50.314 | Train Acc: 83.004
90 Train Loss: 50.308 | Train Acc: 83.038
91 Train Loss: 50.275 | Train Acc: 83.043
92 Train Loss: 50.202 | Train Acc: 82.980
93 Train Loss: 50.233 | Train Acc: 83.038
94 Train Loss: 50.216 | Train Acc: 83.027
95 Train Loss: 50.170 | Train Acc: 83.074
96 Train Loss: 50.155 | Train Acc: 83.113
97 Train Loss: 50.248 | Train Acc: 83.011
98 Train Loss: 50.104 | Train Acc: 83.077
99 Train Loss: 50.050 | Train Acc: 83.087
CNN trained successfully...
image_next_flat.shape :  torch.Size([38320, 6400])
printing expected split from k means
{4: 0, 2: 0, 6: 0, 0: 0, 3: 0, 5: 1, 7: 1, 1: 0, 8: 0, 9: 0}
Printing final_dict items...
{4: 0, 2: 0, 6: 0, 0: 0, 3: 0, 5: 1, 7: 1, 1: 0, 8: 0, 9: 0}
Image Statistics before MLP : L R :  22298 16022
expectedMlpLabels.shape :  torch.Size([38320])
0 Loss: 36.826 | Acc: 89.415
1 Loss: 25.373 | Acc: 93.017
2 Loss: 22.829 | Acc: 93.703
3 Loss: 20.383 | Acc: 94.415
4 Loss: 17.771 | Acc: 95.154
5 Loss: 17.137 | Acc: 95.394
6 Loss: 15.833 | Acc: 95.694
7 Loss: 13.561 | Acc: 96.341
8 Loss: 13.272 | Acc: 96.469
9 Loss: 12.588 | Acc: 96.621
10 Loss: 9.318 | Acc: 97.565
11 Loss: 8.658 | Acc: 97.743
12 Loss: 7.905 | Acc: 97.970
13 Loss: 7.312 | Acc: 98.103
14 Loss: 6.862 | Acc: 98.338
15 Loss: 7.030 | Acc: 98.259
16 Loss: 6.148 | Acc: 98.479
17 Loss: 6.091 | Acc: 98.466
18 Loss: 6.053 | Acc: 98.458
19 Loss: 5.632 | Acc: 98.575
20 Loss: 4.391 | Acc: 98.927
21 Loss: 4.128 | Acc: 99.034
22 Loss: 4.114 | Acc: 98.977
23 Loss: 3.548 | Acc: 99.141
24 Loss: 3.422 | Acc: 99.183
25 Loss: 3.220 | Acc: 99.212
26 Loss: 3.435 | Acc: 99.157
27 Loss: 3.261 | Acc: 99.209
28 Loss: 3.180 | Acc: 99.254
29 Loss: 3.101 | Acc: 99.225
30 Loss: 2.794 | Acc: 99.332
31 Loss: 2.718 | Acc: 99.358
32 Loss: 2.456 | Acc: 99.426
33 Loss: 2.276 | Acc: 99.483
34 Loss: 2.555 | Acc: 99.392
35 Loss: 2.486 | Acc: 99.465
36 Loss: 2.322 | Acc: 99.455
37 Loss: 2.373 | Acc: 99.494
38 Loss: 2.313 | Acc: 99.486
39 Loss: 2.413 | Acc: 99.452
40 Loss: 2.217 | Acc: 99.520
41 Loss: 2.253 | Acc: 99.522
42 Loss: 2.339 | Acc: 99.470
43 Loss: 2.191 | Acc: 99.512
44 Loss: 1.978 | Acc: 99.533
45 Loss: 2.118 | Acc: 99.533
46 Loss: 2.091 | Acc: 99.533
47 Loss: 1.949 | Acc: 99.572
48 Loss: 2.002 | Acc: 99.541
49 Loss: 1.938 | Acc: 99.564
50 Loss: 2.037 | Acc: 99.504
51 Loss: 1.803 | Acc: 99.603
52 Loss: 1.901 | Acc: 99.564
53 Loss: 1.855 | Acc: 99.543
54 Loss: 1.794 | Acc: 99.549
55 Loss: 1.825 | Acc: 99.564
56 Loss: 1.776 | Acc: 99.619
57 Loss: 1.823 | Acc: 99.541
58 Loss: 1.848 | Acc: 99.551
59 Loss: 1.859 | Acc: 99.549
MLP trained successfully...
# of Left images:  8845.0
# of Right images:  10860.0
giniRightRatio:  0.8331784235320452
giniLeftRatio:  0.8088662957070151
impurityDrop:  0.8133772476008858
giniGain:  0.029596982609356393
lclasses:  [200, 28, 1680, 1165, 1988, 818, 2437, 406, 69, 54]
rclasses:  [154, 72, 1171, 1684, 1483, 2250, 1395, 2493, 37, 121]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([8845, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([8845])
rTrainDict[data].shape:  torch.Size([10860, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([10860])
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([8845, 16, 20, 20])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 8845
nodeId:  15 , imgTensorShape :  torch.Size([10860, 16, 20, 20])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10860
Running nodeId:  8
trainInputDict[data].shape :  torch.Size([4052, 16, 20, 20])
copy.shape :  torch.Size([4052, 6400])
copyLabel.shape :  torch.Size([4052])
Class 0 has 1584 instances after oversampling
Class 1 has 1584 instances after oversampling
Class 2 has 1584 instances after oversampling
Class 3 has 1584 instances after oversampling
Class 4 has 1584 instances after oversampling
Class 5 has 1584 instances after oversampling
Class 6 has 1584 instances after oversampling
Class 7 has 1584 instances after oversampling
Class 8 has 1584 instances after oversampling
Class 9 has 1584 instances after oversampling
0 Train Loss: 222.797 | Train Acc: 14.047
1 Train Loss: 177.141 | Train Acc: 39.842
2 Train Loss: 132.165 | Train Acc: 55.663
3 Train Loss: 101.634 | Train Acc: 67.033
4 Train Loss: 75.219 | Train Acc: 76.092
5 Train Loss: 59.079 | Train Acc: 81.730
6 Train Loss: 54.813 | Train Acc: 82.494
7 Train Loss: 43.200 | Train Acc: 86.313
8 Train Loss: 35.734 | Train Acc: 88.674
9 Train Loss: 33.107 | Train Acc: 89.426
10 Train Loss: 30.161 | Train Acc: 90.133
11 Train Loss: 28.366 | Train Acc: 91.010
12 Train Loss: 23.584 | Train Acc: 92.285
13 Train Loss: 21.661 | Train Acc: 92.891
14 Train Loss: 17.413 | Train Acc: 94.646
15 Train Loss: 21.995 | Train Acc: 93.264
16 Train Loss: 16.116 | Train Acc: 95.107
17 Train Loss: 14.605 | Train Acc: 95.354
18 Train Loss: 12.243 | Train Acc: 96.237
19 Train Loss: 12.078 | Train Acc: 96.237
20 Train Loss: 9.401 | Train Acc: 97.418
21 Train Loss: 8.744 | Train Acc: 97.734
22 Train Loss: 8.627 | Train Acc: 97.563
23 Train Loss: 8.254 | Train Acc: 97.784
24 Train Loss: 8.279 | Train Acc: 97.721
25 Train Loss: 7.537 | Train Acc: 98.030
26 Train Loss: 7.335 | Train Acc: 98.157
27 Train Loss: 7.092 | Train Acc: 98.144
28 Train Loss: 7.061 | Train Acc: 98.194
29 Train Loss: 6.683 | Train Acc: 98.295
30 Train Loss: 7.222 | Train Acc: 98.030
31 Train Loss: 6.245 | Train Acc: 98.359
32 Train Loss: 5.919 | Train Acc: 98.592
33 Train Loss: 5.866 | Train Acc: 98.662
34 Train Loss: 5.759 | Train Acc: 98.472
35 Train Loss: 5.324 | Train Acc: 98.750
36 Train Loss: 5.219 | Train Acc: 98.699
37 Train Loss: 6.000 | Train Acc: 98.403
38 Train Loss: 4.979 | Train Acc: 98.845
39 Train Loss: 5.065 | Train Acc: 98.649
40 Train Loss: 4.294 | Train Acc: 99.116
41 Train Loss: 4.028 | Train Acc: 99.337
42 Train Loss: 3.935 | Train Acc: 99.242
43 Train Loss: 3.895 | Train Acc: 99.324
44 Train Loss: 3.801 | Train Acc: 99.375
45 Train Loss: 3.755 | Train Acc: 99.312
46 Train Loss: 3.801 | Train Acc: 99.312
47 Train Loss: 3.707 | Train Acc: 99.318
48 Train Loss: 3.590 | Train Acc: 99.419
49 Train Loss: 3.511 | Train Acc: 99.400
50 Train Loss: 3.408 | Train Acc: 99.394
51 Train Loss: 3.347 | Train Acc: 99.501
52 Train Loss: 3.324 | Train Acc: 99.501
53 Train Loss: 3.290 | Train Acc: 99.438
54 Train Loss: 3.173 | Train Acc: 99.527
55 Train Loss: 3.132 | Train Acc: 99.520
56 Train Loss: 3.035 | Train Acc: 99.609
57 Train Loss: 3.019 | Train Acc: 99.564
58 Train Loss: 2.874 | Train Acc: 99.602
59 Train Loss: 2.978 | Train Acc: 99.621
60 Train Loss: 2.687 | Train Acc: 99.684
61 Train Loss: 2.637 | Train Acc: 99.659
62 Train Loss: 2.599 | Train Acc: 99.716
63 Train Loss: 2.581 | Train Acc: 99.729
64 Train Loss: 2.587 | Train Acc: 99.741
65 Train Loss: 2.528 | Train Acc: 99.766
66 Train Loss: 2.508 | Train Acc: 99.735
67 Train Loss: 2.472 | Train Acc: 99.716
68 Train Loss: 2.518 | Train Acc: 99.716
69 Train Loss: 2.448 | Train Acc: 99.760
70 Train Loss: 2.412 | Train Acc: 99.773
71 Train Loss: 2.390 | Train Acc: 99.766
72 Train Loss: 2.358 | Train Acc: 99.754
73 Train Loss: 2.343 | Train Acc: 99.804
74 Train Loss: 2.317 | Train Acc: 99.804
75 Train Loss: 2.290 | Train Acc: 99.792
76 Train Loss: 2.295 | Train Acc: 99.766
77 Train Loss: 2.194 | Train Acc: 99.823
78 Train Loss: 2.256 | Train Acc: 99.792
79 Train Loss: 2.196 | Train Acc: 99.817
80 Train Loss: 2.123 | Train Acc: 99.830
81 Train Loss: 2.098 | Train Acc: 99.836
82 Train Loss: 2.097 | Train Acc: 99.830
83 Train Loss: 2.077 | Train Acc: 99.830
84 Train Loss: 2.070 | Train Acc: 99.842
85 Train Loss: 2.061 | Train Acc: 99.848
86 Train Loss: 2.059 | Train Acc: 99.848
87 Train Loss: 2.035 | Train Acc: 99.836
88 Train Loss: 2.034 | Train Acc: 99.830
89 Train Loss: 2.021 | Train Acc: 99.848
90 Train Loss: 2.017 | Train Acc: 99.842
91 Train Loss: 1.990 | Train Acc: 99.848
92 Train Loss: 1.995 | Train Acc: 99.861
93 Train Loss: 1.978 | Train Acc: 99.861
94 Train Loss: 1.960 | Train Acc: 99.842
95 Train Loss: 1.952 | Train Acc: 99.855
96 Train Loss: 1.943 | Train Acc: 99.867
97 Train Loss: 1.936 | Train Acc: 99.874
98 Train Loss: 1.925 | Train Acc: 99.867
99 Train Loss: 1.909 | Train Acc: 99.874
CNN trained successfully...
image_next_flat.shape :  torch.Size([15840, 4096])
printing expected split from k means
{9: 0, 8: 0, 0: 1, 3: 0, 6: 0, 2: 0, 4: 0, 5: 0, 7: 0, 1: 0}
Printing final_dict items...
{9: 0, 8: 0, 0: 1, 3: 0, 6: 0, 2: 0, 4: 0, 5: 0, 7: 0, 1: 0}
Image Statistics before MLP : L R :  11469 4371
expectedMlpLabels.shape :  torch.Size([15840])
0 Loss: 16.515 | Acc: 91.861
1 Loss: 10.665 | Acc: 95.297
2 Loss: 8.380 | Acc: 96.285
3 Loss: 7.079 | Acc: 96.797
4 Loss: 6.950 | Acc: 96.968
5 Loss: 6.117 | Acc: 97.285
6 Loss: 5.443 | Acc: 97.500
7 Loss: 5.317 | Acc: 97.684
8 Loss: 5.174 | Acc: 97.703
9 Loss: 4.636 | Acc: 97.987
10 Loss: 3.604 | Acc: 98.468
11 Loss: 2.779 | Acc: 98.835
12 Loss: 2.973 | Acc: 98.829
13 Loss: 2.775 | Acc: 98.823
14 Loss: 2.375 | Acc: 98.924
15 Loss: 2.478 | Acc: 98.930
16 Loss: 2.508 | Acc: 98.949
17 Loss: 2.446 | Acc: 99.006
18 Loss: 1.977 | Acc: 99.209
19 Loss: 2.309 | Acc: 99.082
20 Loss: 1.654 | Acc: 99.361
21 Loss: 1.496 | Acc: 99.405
22 Loss: 1.437 | Acc: 99.487
23 Loss: 1.567 | Acc: 99.456
24 Loss: 1.300 | Acc: 99.443
25 Loss: 1.149 | Acc: 99.513
26 Loss: 1.257 | Acc: 99.525
27 Loss: 1.349 | Acc: 99.538
28 Loss: 1.053 | Acc: 99.589
29 Loss: 1.065 | Acc: 99.620
30 Loss: 1.196 | Acc: 99.570
31 Loss: 0.885 | Acc: 99.696
32 Loss: 0.848 | Acc: 99.677
33 Loss: 0.759 | Acc: 99.709
34 Loss: 0.879 | Acc: 99.665
35 Loss: 0.966 | Acc: 99.671
36 Loss: 0.692 | Acc: 99.759
37 Loss: 0.667 | Acc: 99.741
38 Loss: 0.977 | Acc: 99.658
39 Loss: 0.858 | Acc: 99.677
40 Loss: 0.744 | Acc: 99.728
41 Loss: 0.748 | Acc: 99.652
42 Loss: 0.763 | Acc: 99.741
43 Loss: 0.647 | Acc: 99.753
44 Loss: 0.596 | Acc: 99.797
45 Loss: 0.587 | Acc: 99.778
46 Loss: 0.673 | Acc: 99.766
47 Loss: 0.697 | Acc: 99.741
48 Loss: 0.653 | Acc: 99.741
49 Loss: 0.477 | Acc: 99.804
50 Loss: 0.591 | Acc: 99.778
51 Loss: 0.556 | Acc: 99.816
52 Loss: 0.530 | Acc: 99.797
53 Loss: 0.530 | Acc: 99.785
54 Loss: 0.629 | Acc: 99.772
55 Loss: 0.552 | Acc: 99.785
56 Loss: 0.599 | Acc: 99.823
57 Loss: 0.649 | Acc: 99.778
58 Loss: 0.613 | Acc: 99.810
59 Loss: 0.516 | Acc: 99.785
MLP trained successfully...
# of Left images:  1979.0
# of Right images:  2073.0
giniRightRatio:  0.6316867989395273
giniLeftRatio:  0.7847267455324872
impurityDrop:  0.7777871628119188
giniGain:  -0.052497273914476006
lclasses:  [522, 45, 301, 55, 204, 32, 76, 27, 649, 68]
rclasses:  [1062, 56, 136, 12, 84, 12, 6, 9, 651, 45]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1979, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([1979])
rTrainDict[data].shape:  torch.Size([2073, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([2073])
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([1979, 16, 16, 16])
nodeId: 16 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1979
nodeId:  17 , imgTensorShape :  torch.Size([2073, 16, 16, 16])
nodeId: 17 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2073
Running nodeId:  9
trainInputDict[data].shape :  torch.Size([9785, 16, 20, 20])
copy.shape :  torch.Size([9785, 6400])
copyLabel.shape :  torch.Size([9785])
Class 0 has 2783 instances after oversampling
Class 1 has 2783 instances after oversampling
Class 2 has 2783 instances after oversampling
Class 3 has 2783 instances after oversampling
Class 4 has 2783 instances after oversampling
Class 5 has 2783 instances after oversampling
Class 6 has 2783 instances after oversampling
Class 7 has 2783 instances after oversampling
Class 8 has 2783 instances after oversampling
Class 9 has 2783 instances after oversampling
0 Train Loss: 231.594 | Train Acc: 8.954
1 Train Loss: 224.018 | Train Acc: 15.548
2 Train Loss: 208.480 | Train Acc: 22.605
3 Train Loss: 180.874 | Train Acc: 39.023
4 Train Loss: 152.952 | Train Acc: 49.651
5 Train Loss: 140.516 | Train Acc: 54.254
6 Train Loss: 123.973 | Train Acc: 60.083
7 Train Loss: 110.947 | Train Acc: 64.035
8 Train Loss: 100.982 | Train Acc: 67.312
9 Train Loss: 101.383 | Train Acc: 66.971
10 Train Loss: 89.794 | Train Acc: 71.200
11 Train Loss: 77.872 | Train Acc: 74.908
12 Train Loss: 67.597 | Train Acc: 78.160
13 Train Loss: 63.516 | Train Acc: 79.457
14 Train Loss: 62.945 | Train Acc: 79.421
15 Train Loss: 57.235 | Train Acc: 81.470
16 Train Loss: 55.212 | Train Acc: 81.656
17 Train Loss: 52.999 | Train Acc: 82.271
18 Train Loss: 50.623 | Train Acc: 83.151
19 Train Loss: 48.120 | Train Acc: 83.949
20 Train Loss: 44.882 | Train Acc: 85.138
21 Train Loss: 41.054 | Train Acc: 86.468
22 Train Loss: 40.816 | Train Acc: 86.385
23 Train Loss: 39.798 | Train Acc: 86.651
24 Train Loss: 38.030 | Train Acc: 87.251
25 Train Loss: 38.014 | Train Acc: 87.269
26 Train Loss: 36.529 | Train Acc: 87.805
27 Train Loss: 35.639 | Train Acc: 87.963
28 Train Loss: 35.670 | Train Acc: 87.891
29 Train Loss: 33.640 | Train Acc: 88.620
30 Train Loss: 33.000 | Train Acc: 88.843
31 Train Loss: 32.822 | Train Acc: 88.785
32 Train Loss: 31.141 | Train Acc: 89.353
33 Train Loss: 30.487 | Train Acc: 89.540
34 Train Loss: 30.009 | Train Acc: 89.878
35 Train Loss: 29.171 | Train Acc: 90.162
36 Train Loss: 28.095 | Train Acc: 90.561
37 Train Loss: 27.971 | Train Acc: 90.316
38 Train Loss: 26.980 | Train Acc: 90.791
39 Train Loss: 25.566 | Train Acc: 91.340
40 Train Loss: 25.469 | Train Acc: 91.283
41 Train Loss: 24.521 | Train Acc: 91.714
42 Train Loss: 24.150 | Train Acc: 91.890
43 Train Loss: 23.970 | Train Acc: 91.944
44 Train Loss: 23.706 | Train Acc: 91.983
45 Train Loss: 23.617 | Train Acc: 92.016
46 Train Loss: 23.434 | Train Acc: 92.156
47 Train Loss: 23.020 | Train Acc: 92.163
48 Train Loss: 23.052 | Train Acc: 92.267
49 Train Loss: 22.721 | Train Acc: 92.461
50 Train Loss: 22.681 | Train Acc: 92.332
51 Train Loss: 22.284 | Train Acc: 92.497
52 Train Loss: 22.460 | Train Acc: 92.275
53 Train Loss: 21.983 | Train Acc: 92.616
54 Train Loss: 22.059 | Train Acc: 92.627
55 Train Loss: 21.715 | Train Acc: 92.781
56 Train Loss: 21.468 | Train Acc: 92.727
57 Train Loss: 21.134 | Train Acc: 92.982
58 Train Loss: 21.001 | Train Acc: 93.036
59 Train Loss: 20.609 | Train Acc: 93.119
60 Train Loss: 20.265 | Train Acc: 93.238
61 Train Loss: 20.149 | Train Acc: 93.313
62 Train Loss: 20.115 | Train Acc: 93.288
63 Train Loss: 20.143 | Train Acc: 93.263
64 Train Loss: 19.998 | Train Acc: 93.378
65 Train Loss: 19.850 | Train Acc: 93.446
66 Train Loss: 19.785 | Train Acc: 93.471
67 Train Loss: 19.697 | Train Acc: 93.410
68 Train Loss: 19.670 | Train Acc: 93.424
69 Train Loss: 19.581 | Train Acc: 93.525
70 Train Loss: 19.405 | Train Acc: 93.518
71 Train Loss: 19.396 | Train Acc: 93.622
72 Train Loss: 19.307 | Train Acc: 93.600
73 Train Loss: 19.302 | Train Acc: 93.604
74 Train Loss: 19.116 | Train Acc: 93.715
75 Train Loss: 19.068 | Train Acc: 93.644
76 Train Loss: 19.028 | Train Acc: 93.748
77 Train Loss: 18.963 | Train Acc: 93.723
78 Train Loss: 18.843 | Train Acc: 93.830
79 Train Loss: 18.846 | Train Acc: 93.759
80 Train Loss: 18.593 | Train Acc: 93.906
81 Train Loss: 18.517 | Train Acc: 93.942
82 Train Loss: 18.456 | Train Acc: 94.028
83 Train Loss: 18.467 | Train Acc: 93.935
84 Train Loss: 18.432 | Train Acc: 94.003
85 Train Loss: 18.405 | Train Acc: 93.974
86 Train Loss: 18.402 | Train Acc: 94.006
87 Train Loss: 18.351 | Train Acc: 94.024
88 Train Loss: 18.283 | Train Acc: 94.021
89 Train Loss: 18.303 | Train Acc: 93.956
90 Train Loss: 18.280 | Train Acc: 93.949
91 Train Loss: 18.236 | Train Acc: 94.006
92 Train Loss: 18.220 | Train Acc: 94.071
93 Train Loss: 18.166 | Train Acc: 94.042
94 Train Loss: 18.141 | Train Acc: 94.057
95 Train Loss: 18.124 | Train Acc: 94.093
96 Train Loss: 18.065 | Train Acc: 94.100
97 Train Loss: 18.056 | Train Acc: 94.068
98 Train Loss: 18.047 | Train Acc: 94.118
99 Train Loss: 17.985 | Train Acc: 94.114
CNN trained successfully...
image_next_flat.shape :  torch.Size([27830, 4096])
printing expected split from k means
{9: 0, 1: 0, 7: 0, 6: 0, 3: 0, 2: 0, 0: 1, 8: 1, 4: 0, 5: 0}
Printing final_dict items...
{9: 0, 1: 0, 7: 0, 6: 0, 3: 0, 2: 0, 0: 1, 8: 1, 4: 0, 5: 0}
Image Statistics before MLP : L R :  18049 9781
expectedMlpLabels.shape :  torch.Size([27830])
0 Loss: 19.239 | Acc: 93.892
1 Loss: 11.088 | Acc: 96.482
2 Loss: 8.910 | Acc: 97.137
3 Loss: 7.992 | Acc: 97.295
4 Loss: 6.958 | Acc: 97.687
5 Loss: 6.753 | Acc: 97.809
6 Loss: 6.187 | Acc: 97.971
7 Loss: 5.408 | Acc: 98.212
8 Loss: 5.068 | Acc: 98.421
9 Loss: 5.124 | Acc: 98.392
10 Loss: 3.441 | Acc: 98.888
11 Loss: 2.918 | Acc: 99.076
12 Loss: 2.741 | Acc: 99.180
13 Loss: 2.579 | Acc: 99.162
14 Loss: 2.462 | Acc: 99.266
15 Loss: 2.641 | Acc: 99.245
16 Loss: 2.264 | Acc: 99.299
17 Loss: 2.217 | Acc: 99.331
18 Loss: 2.233 | Acc: 99.342
19 Loss: 2.065 | Acc: 99.335
20 Loss: 1.467 | Acc: 99.543
21 Loss: 1.296 | Acc: 99.647
22 Loss: 1.246 | Acc: 99.626
23 Loss: 1.443 | Acc: 99.547
24 Loss: 1.189 | Acc: 99.665
25 Loss: 1.206 | Acc: 99.633
26 Loss: 1.233 | Acc: 99.673
27 Loss: 1.044 | Acc: 99.698
28 Loss: 1.101 | Acc: 99.655
29 Loss: 1.112 | Acc: 99.658
30 Loss: 0.973 | Acc: 99.727
31 Loss: 0.987 | Acc: 99.745
32 Loss: 0.872 | Acc: 99.766
33 Loss: 0.762 | Acc: 99.741
34 Loss: 0.936 | Acc: 99.755
35 Loss: 0.835 | Acc: 99.777
36 Loss: 0.781 | Acc: 99.791
37 Loss: 0.780 | Acc: 99.770
38 Loss: 0.832 | Acc: 99.784
39 Loss: 0.853 | Acc: 99.777
40 Loss: 0.644 | Acc: 99.842
41 Loss: 0.699 | Acc: 99.820
42 Loss: 0.639 | Acc: 99.784
43 Loss: 0.586 | Acc: 99.845
44 Loss: 0.604 | Acc: 99.838
45 Loss: 0.607 | Acc: 99.820
46 Loss: 0.753 | Acc: 99.773
47 Loss: 0.747 | Acc: 99.791
48 Loss: 0.601 | Acc: 99.827
49 Loss: 0.636 | Acc: 99.817
50 Loss: 0.679 | Acc: 99.777
51 Loss: 0.574 | Acc: 99.860
52 Loss: 0.548 | Acc: 99.824
53 Loss: 0.541 | Acc: 99.842
54 Loss: 0.545 | Acc: 99.860
55 Loss: 0.564 | Acc: 99.824
56 Loss: 0.593 | Acc: 99.835
57 Loss: 0.529 | Acc: 99.863
58 Loss: 0.514 | Acc: 99.878
59 Loss: 0.539 | Acc: 99.863
MLP trained successfully...
# of Left images:  4636.0
# of Right images:  5149.0
giniRightRatio:  0.7470905942513033
giniLeftRatio:  0.7593105984525947
impurityDrop:  0.7580931072591082
giniGain:  0.012801870584665864
lclasses:  [406, 1400, 98, 57, 86, 31, 38, 109, 974, 1437]
rclasses:  [1265, 1383, 56, 13, 49, 8, 16, 41, 1658, 660]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([4636, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([4636])
rTrainDict[data].shape:  torch.Size([5149, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([5149])
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([4636, 16, 16, 16])
nodeId: 18 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 4636
nodeId:  19 , imgTensorShape :  torch.Size([5149, 16, 16, 16])
nodeId: 19 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 5149
Running nodeId:  10
trainInputDict[data].shape :  torch.Size([3983, 16, 20, 20])
copy.shape :  torch.Size([3983, 6400])
copyLabel.shape :  torch.Size([3983])
Class 0 has 752 instances after oversampling
Class 1 has 751 instances after oversampling
Class 2 has 752 instances after oversampling
Class 3 has 752 instances after oversampling
Class 4 has 751 instances after oversampling
Class 5 has 751 instances after oversampling
Class 6 has 751 instances after oversampling
Class 7 has 752 instances after oversampling
Class 8 has 751 instances after oversampling
Class 9 has 752 instances after oversampling
0 Train Loss: 210.096 | Train Acc: 23.227
1 Train Loss: 170.508 | Train Acc: 41.200
2 Train Loss: 141.392 | Train Acc: 53.120
3 Train Loss: 119.898 | Train Acc: 61.933
4 Train Loss: 104.208 | Train Acc: 67.000
5 Train Loss: 90.053 | Train Acc: 71.680
6 Train Loss: 81.852 | Train Acc: 74.547
7 Train Loss: 69.085 | Train Acc: 78.827
8 Train Loss: 61.755 | Train Acc: 80.773
9 Train Loss: 51.720 | Train Acc: 84.200
10 Train Loss: 42.132 | Train Acc: 88.053
11 Train Loss: 36.872 | Train Acc: 89.480
12 Train Loss: 31.060 | Train Acc: 91.520
13 Train Loss: 26.244 | Train Acc: 93.280
14 Train Loss: 21.332 | Train Acc: 95.200
15 Train Loss: 18.413 | Train Acc: 95.693
16 Train Loss: 17.149 | Train Acc: 96.373
17 Train Loss: 12.971 | Train Acc: 97.507
18 Train Loss: 10.400 | Train Acc: 98.333
19 Train Loss: 8.919 | Train Acc: 98.733
20 Train Loss: 6.213 | Train Acc: 99.720
21 Train Loss: 5.296 | Train Acc: 99.853
22 Train Loss: 4.813 | Train Acc: 99.880
23 Train Loss: 4.552 | Train Acc: 99.933
24 Train Loss: 4.227 | Train Acc: 99.933
25 Train Loss: 3.900 | Train Acc: 99.960
26 Train Loss: 3.601 | Train Acc: 99.973
27 Train Loss: 3.291 | Train Acc: 100.000
28 Train Loss: 3.160 | Train Acc: 100.000
29 Train Loss: 2.946 | Train Acc: 100.000
30 Train Loss: 2.709 | Train Acc: 100.000
31 Train Loss: 2.591 | Train Acc: 100.000
32 Train Loss: 2.369 | Train Acc: 100.000
33 Train Loss: 2.224 | Train Acc: 100.000
34 Train Loss: 2.092 | Train Acc: 100.000
35 Train Loss: 1.968 | Train Acc: 100.000
36 Train Loss: 1.834 | Train Acc: 100.000
37 Train Loss: 1.675 | Train Acc: 100.000
38 Train Loss: 1.581 | Train Acc: 100.000
39 Train Loss: 1.500 | Train Acc: 100.000
40 Train Loss: 1.303 | Train Acc: 100.000
41 Train Loss: 1.254 | Train Acc: 100.000
42 Train Loss: 1.215 | Train Acc: 100.000
43 Train Loss: 1.186 | Train Acc: 100.000
44 Train Loss: 1.155 | Train Acc: 100.000
45 Train Loss: 1.128 | Train Acc: 100.000
46 Train Loss: 1.090 | Train Acc: 100.000
47 Train Loss: 1.085 | Train Acc: 100.000
48 Train Loss: 1.034 | Train Acc: 100.000
49 Train Loss: 1.002 | Train Acc: 100.000
50 Train Loss: 0.974 | Train Acc: 100.000
51 Train Loss: 0.943 | Train Acc: 100.000
52 Train Loss: 0.921 | Train Acc: 100.000
53 Train Loss: 0.908 | Train Acc: 100.000
54 Train Loss: 0.857 | Train Acc: 100.000
55 Train Loss: 0.834 | Train Acc: 100.000
56 Train Loss: 0.807 | Train Acc: 100.000
57 Train Loss: 0.788 | Train Acc: 100.000
58 Train Loss: 0.755 | Train Acc: 100.000
59 Train Loss: 0.731 | Train Acc: 100.000
60 Train Loss: 0.676 | Train Acc: 100.000
61 Train Loss: 0.662 | Train Acc: 100.000
62 Train Loss: 0.653 | Train Acc: 100.000
63 Train Loss: 0.641 | Train Acc: 100.000
64 Train Loss: 0.635 | Train Acc: 100.000
65 Train Loss: 0.626 | Train Acc: 100.000
66 Train Loss: 0.615 | Train Acc: 100.000
67 Train Loss: 0.604 | Train Acc: 100.000
68 Train Loss: 0.590 | Train Acc: 100.000
69 Train Loss: 0.585 | Train Acc: 100.000
70 Train Loss: 0.571 | Train Acc: 100.000
71 Train Loss: 0.556 | Train Acc: 100.000
72 Train Loss: 0.552 | Train Acc: 100.000
73 Train Loss: 0.541 | Train Acc: 100.000
74 Train Loss: 0.531 | Train Acc: 100.000
75 Train Loss: 0.521 | Train Acc: 100.000
76 Train Loss: 0.511 | Train Acc: 100.000
77 Train Loss: 0.498 | Train Acc: 100.000
78 Train Loss: 0.493 | Train Acc: 100.000
79 Train Loss: 0.477 | Train Acc: 100.000
80 Train Loss: 0.457 | Train Acc: 100.000
81 Train Loss: 0.451 | Train Acc: 100.000
82 Train Loss: 0.446 | Train Acc: 100.000
83 Train Loss: 0.443 | Train Acc: 100.000
84 Train Loss: 0.440 | Train Acc: 100.000
85 Train Loss: 0.435 | Train Acc: 100.000
86 Train Loss: 0.430 | Train Acc: 100.000
87 Train Loss: 0.427 | Train Acc: 100.000
88 Train Loss: 0.421 | Train Acc: 100.000
89 Train Loss: 0.417 | Train Acc: 100.000
90 Train Loss: 0.412 | Train Acc: 100.000
91 Train Loss: 0.409 | Train Acc: 100.000
92 Train Loss: 0.402 | Train Acc: 100.000
93 Train Loss: 0.400 | Train Acc: 100.000
94 Train Loss: 0.394 | Train Acc: 100.000
95 Train Loss: 0.388 | Train Acc: 100.000
96 Train Loss: 0.384 | Train Acc: 100.000
97 Train Loss: 0.380 | Train Acc: 100.000
98 Train Loss: 0.376 | Train Acc: 100.000
99 Train Loss: 0.371 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([7515, 4096])
printing expected split from k means
{9: 0, 0: 1, 3: 0, 2: 0, 6: 0, 1: 0, 5: 0, 7: 0, 8: 0, 4: 0}
Printing final_dict items...
{9: 0, 0: 1, 3: 0, 2: 0, 6: 0, 1: 0, 5: 0, 7: 0, 8: 0, 4: 0}
Image Statistics before MLP : L R :  6003 1512
expectedMlpLabels.shape :  torch.Size([7515])
0 Loss: 20.102 | Acc: 88.122
1 Loss: 12.961 | Acc: 92.108
2 Loss: 11.330 | Acc: 93.081
3 Loss: 9.314 | Acc: 94.189
4 Loss: 8.221 | Acc: 94.878
5 Loss: 7.686 | Acc: 95.459
6 Loss: 6.842 | Acc: 95.486
7 Loss: 6.535 | Acc: 96.081
8 Loss: 5.500 | Acc: 96.541
9 Loss: 5.602 | Acc: 96.270
10 Loss: 4.139 | Acc: 97.419
11 Loss: 3.439 | Acc: 97.811
12 Loss: 3.379 | Acc: 97.716
13 Loss: 3.205 | Acc: 98.068
14 Loss: 2.612 | Acc: 98.257
15 Loss: 2.716 | Acc: 98.365
16 Loss: 2.604 | Acc: 98.405
17 Loss: 2.326 | Acc: 98.554
18 Loss: 2.121 | Acc: 98.568
19 Loss: 2.024 | Acc: 98.865
20 Loss: 1.911 | Acc: 98.811
21 Loss: 1.767 | Acc: 98.959
22 Loss: 1.513 | Acc: 98.986
23 Loss: 1.491 | Acc: 99.135
24 Loss: 1.259 | Acc: 99.162
25 Loss: 1.129 | Acc: 99.351
26 Loss: 1.315 | Acc: 99.216
27 Loss: 1.403 | Acc: 99.216
28 Loss: 1.226 | Acc: 99.203
29 Loss: 1.109 | Acc: 99.311
30 Loss: 1.233 | Acc: 99.230
31 Loss: 0.864 | Acc: 99.284
32 Loss: 0.814 | Acc: 99.541
33 Loss: 1.058 | Acc: 99.432
34 Loss: 0.878 | Acc: 99.500
35 Loss: 0.991 | Acc: 99.351
36 Loss: 0.687 | Acc: 99.527
37 Loss: 0.952 | Acc: 99.500
38 Loss: 0.823 | Acc: 99.432
39 Loss: 0.814 | Acc: 99.500
40 Loss: 0.753 | Acc: 99.486
41 Loss: 0.761 | Acc: 99.581
42 Loss: 0.830 | Acc: 99.568
43 Loss: 0.722 | Acc: 99.622
44 Loss: 0.710 | Acc: 99.622
45 Loss: 0.601 | Acc: 99.649
46 Loss: 0.588 | Acc: 99.662
47 Loss: 0.682 | Acc: 99.581
48 Loss: 0.753 | Acc: 99.554
49 Loss: 0.607 | Acc: 99.662
50 Loss: 0.705 | Acc: 99.649
51 Loss: 0.462 | Acc: 99.730
52 Loss: 0.795 | Acc: 99.527
53 Loss: 0.526 | Acc: 99.608
54 Loss: 0.543 | Acc: 99.662
55 Loss: 0.567 | Acc: 99.689
56 Loss: 0.583 | Acc: 99.676
57 Loss: 0.589 | Acc: 99.595
58 Loss: 0.540 | Acc: 99.716
59 Loss: 0.502 | Acc: 99.716
MLP trained successfully...
# of Left images:  3013.0
# of Right images:  970.0
giniRightRatio:  0.8154745456477841
giniLeftRatio:  0.8653617265772426
impurityDrop:  0.9704333870297002
giniGain:  -0.09490105148034145
lclasses:  [299, 225, 199, 302, 160, 220, 158, 529, 188, 733]
rclasses:  [324, 42, 164, 74, 88, 47, 21, 148, 43, 19]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([3013, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([3013])
rTrainDict[data].shape:  torch.Size([970, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([970])
RETURNING FROM WORK...
nodeId:  20 , imgTensorShape :  torch.Size([3013, 16, 16, 16])
nodeId: 20 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3013
nodeId:  21 , imgTensorShape :  torch.Size([970, 16, 16, 16])
nodeId: 21 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 970
Running nodeId:  11
trainInputDict[data].shape :  torch.Size([6402, 16, 20, 20])
copy.shape :  torch.Size([6402, 6400])
copyLabel.shape :  torch.Size([6402])
Class 0 has 1244 instances after oversampling
Class 1 has 1244 instances after oversampling
Class 2 has 1244 instances after oversampling
Class 3 has 1244 instances after oversampling
Class 4 has 1244 instances after oversampling
Class 5 has 1244 instances after oversampling
Class 6 has 1244 instances after oversampling
Class 7 has 1244 instances after oversampling
Class 8 has 1244 instances after oversampling
Class 9 has 1244 instances after oversampling
0 Train Loss: 219.104 | Train Acc: 19.437
1 Train Loss: 182.107 | Train Acc: 36.391
2 Train Loss: 162.029 | Train Acc: 45.965
3 Train Loss: 147.315 | Train Acc: 51.310
4 Train Loss: 131.952 | Train Acc: 56.768
5 Train Loss: 122.368 | Train Acc: 59.429
6 Train Loss: 113.020 | Train Acc: 63.312
7 Train Loss: 102.961 | Train Acc: 66.793
8 Train Loss: 94.086 | Train Acc: 69.373
9 Train Loss: 89.142 | Train Acc: 70.820
10 Train Loss: 82.099 | Train Acc: 73.963
11 Train Loss: 77.062 | Train Acc: 75.289
12 Train Loss: 75.302 | Train Acc: 75.836
13 Train Loss: 72.460 | Train Acc: 76.318
14 Train Loss: 65.229 | Train Acc: 79.180
15 Train Loss: 60.826 | Train Acc: 80.659
16 Train Loss: 58.514 | Train Acc: 81.447
17 Train Loss: 56.625 | Train Acc: 81.680
18 Train Loss: 54.060 | Train Acc: 82.749
19 Train Loss: 50.588 | Train Acc: 83.891
20 Train Loss: 43.837 | Train Acc: 86.624
21 Train Loss: 41.369 | Train Acc: 87.395
22 Train Loss: 40.621 | Train Acc: 87.789
23 Train Loss: 39.586 | Train Acc: 88.183
24 Train Loss: 38.627 | Train Acc: 88.320
25 Train Loss: 37.578 | Train Acc: 88.971
26 Train Loss: 37.594 | Train Acc: 88.939
27 Train Loss: 36.077 | Train Acc: 89.309
28 Train Loss: 35.230 | Train Acc: 89.638
29 Train Loss: 33.980 | Train Acc: 89.936
30 Train Loss: 33.025 | Train Acc: 90.450
31 Train Loss: 31.878 | Train Acc: 90.579
32 Train Loss: 30.996 | Train Acc: 91.286
33 Train Loss: 29.859 | Train Acc: 91.568
34 Train Loss: 28.706 | Train Acc: 91.833
35 Train Loss: 28.806 | Train Acc: 91.752
36 Train Loss: 27.432 | Train Acc: 92.323
37 Train Loss: 26.768 | Train Acc: 92.669
38 Train Loss: 26.481 | Train Acc: 92.621
39 Train Loss: 25.233 | Train Acc: 93.215
40 Train Loss: 22.543 | Train Acc: 94.574
41 Train Loss: 22.066 | Train Acc: 94.751
42 Train Loss: 21.862 | Train Acc: 94.912
43 Train Loss: 21.405 | Train Acc: 95.016
44 Train Loss: 21.278 | Train Acc: 94.928
45 Train Loss: 20.834 | Train Acc: 95.161
46 Train Loss: 20.657 | Train Acc: 95.217
47 Train Loss: 20.456 | Train Acc: 95.185
48 Train Loss: 20.116 | Train Acc: 95.386
49 Train Loss: 19.772 | Train Acc: 95.434
50 Train Loss: 19.616 | Train Acc: 95.466
51 Train Loss: 19.231 | Train Acc: 95.691
52 Train Loss: 18.964 | Train Acc: 95.683
53 Train Loss: 18.780 | Train Acc: 95.828
54 Train Loss: 18.507 | Train Acc: 95.788
55 Train Loss: 18.313 | Train Acc: 95.973
56 Train Loss: 17.941 | Train Acc: 96.174
57 Train Loss: 17.686 | Train Acc: 96.230
58 Train Loss: 17.370 | Train Acc: 96.334
59 Train Loss: 17.041 | Train Acc: 96.447
60 Train Loss: 16.202 | Train Acc: 96.777
61 Train Loss: 16.187 | Train Acc: 96.768
62 Train Loss: 16.018 | Train Acc: 96.841
63 Train Loss: 15.949 | Train Acc: 96.857
64 Train Loss: 15.828 | Train Acc: 96.929
65 Train Loss: 15.753 | Train Acc: 96.937
66 Train Loss: 15.659 | Train Acc: 96.929
67 Train Loss: 15.534 | Train Acc: 96.881
68 Train Loss: 15.460 | Train Acc: 97.042
69 Train Loss: 15.349 | Train Acc: 97.058
70 Train Loss: 15.183 | Train Acc: 97.074
71 Train Loss: 15.149 | Train Acc: 97.154
72 Train Loss: 14.993 | Train Acc: 97.146
73 Train Loss: 14.913 | Train Acc: 97.195
74 Train Loss: 14.808 | Train Acc: 97.195
75 Train Loss: 14.731 | Train Acc: 97.219
76 Train Loss: 14.655 | Train Acc: 97.323
77 Train Loss: 14.504 | Train Acc: 97.275
78 Train Loss: 14.424 | Train Acc: 97.291
79 Train Loss: 14.295 | Train Acc: 97.404
80 Train Loss: 13.986 | Train Acc: 97.524
81 Train Loss: 13.898 | Train Acc: 97.524
82 Train Loss: 13.886 | Train Acc: 97.500
83 Train Loss: 13.818 | Train Acc: 97.516
84 Train Loss: 13.784 | Train Acc: 97.508
85 Train Loss: 13.753 | Train Acc: 97.524
86 Train Loss: 13.688 | Train Acc: 97.621
87 Train Loss: 13.679 | Train Acc: 97.524
88 Train Loss: 13.621 | Train Acc: 97.588
89 Train Loss: 13.592 | Train Acc: 97.588
90 Train Loss: 13.574 | Train Acc: 97.621
91 Train Loss: 13.499 | Train Acc: 97.709
92 Train Loss: 13.469 | Train Acc: 97.621
93 Train Loss: 13.426 | Train Acc: 97.653
94 Train Loss: 13.381 | Train Acc: 97.669
95 Train Loss: 13.333 | Train Acc: 97.613
96 Train Loss: 13.291 | Train Acc: 97.677
97 Train Loss: 13.274 | Train Acc: 97.677
98 Train Loss: 13.214 | Train Acc: 97.717
99 Train Loss: 13.155 | Train Acc: 97.685
CNN trained successfully...
image_next_flat.shape :  torch.Size([12440, 4096])
printing expected split from k means
{9: 0, 3: 1, 6: 1, 1: 0, 4: 1, 2: 1, 0: 1, 7: 1, 5: 1, 8: 1}
Printing final_dict items...
{9: 0, 3: 1, 6: 1, 1: 0, 4: 1, 2: 1, 0: 1, 7: 1, 5: 1, 8: 1}
Image Statistics before MLP : L R :  4938 7502
expectedMlpLabels.shape :  torch.Size([12440])
0 Loss: 28.816 | Acc: 91.694
1 Loss: 20.046 | Acc: 94.435
2 Loss: 17.607 | Acc: 95.089
3 Loss: 14.403 | Acc: 96.089
4 Loss: 13.399 | Acc: 96.274
5 Loss: 10.557 | Acc: 96.895
6 Loss: 10.412 | Acc: 97.266
7 Loss: 9.340 | Acc: 97.476
8 Loss: 8.212 | Acc: 97.742
9 Loss: 7.997 | Acc: 97.750
10 Loss: 4.921 | Acc: 98.629
11 Loss: 3.648 | Acc: 98.960
12 Loss: 3.756 | Acc: 99.121
13 Loss: 3.619 | Acc: 98.976
14 Loss: 2.867 | Acc: 99.323
15 Loss: 3.223 | Acc: 99.177
16 Loss: 3.369 | Acc: 99.121
17 Loss: 2.693 | Acc: 99.355
18 Loss: 2.430 | Acc: 99.395
19 Loss: 2.849 | Acc: 99.258
20 Loss: 1.750 | Acc: 99.597
21 Loss: 1.781 | Acc: 99.629
22 Loss: 1.364 | Acc: 99.718
23 Loss: 1.404 | Acc: 99.661
24 Loss: 1.302 | Acc: 99.621
25 Loss: 1.384 | Acc: 99.677
26 Loss: 1.368 | Acc: 99.677
27 Loss: 1.323 | Acc: 99.653
28 Loss: 1.288 | Acc: 99.685
29 Loss: 1.114 | Acc: 99.710
30 Loss: 1.050 | Acc: 99.710
31 Loss: 1.154 | Acc: 99.661
32 Loss: 0.830 | Acc: 99.839
33 Loss: 0.757 | Acc: 99.839
34 Loss: 1.034 | Acc: 99.815
35 Loss: 1.048 | Acc: 99.758
36 Loss: 0.795 | Acc: 99.790
37 Loss: 1.092 | Acc: 99.758
38 Loss: 0.955 | Acc: 99.798
39 Loss: 0.719 | Acc: 99.831
40 Loss: 0.879 | Acc: 99.839
41 Loss: 0.623 | Acc: 99.863
42 Loss: 0.686 | Acc: 99.831
43 Loss: 0.799 | Acc: 99.815
44 Loss: 0.531 | Acc: 99.887
45 Loss: 0.627 | Acc: 99.863
46 Loss: 0.524 | Acc: 99.887
47 Loss: 0.586 | Acc: 99.863
48 Loss: 0.609 | Acc: 99.863
49 Loss: 0.641 | Acc: 99.831
50 Loss: 0.766 | Acc: 99.855
51 Loss: 0.729 | Acc: 99.823
52 Loss: 0.651 | Acc: 99.839
53 Loss: 0.473 | Acc: 99.903
54 Loss: 0.602 | Acc: 99.871
55 Loss: 0.539 | Acc: 99.847
56 Loss: 0.514 | Acc: 99.895
57 Loss: 0.540 | Acc: 99.831
58 Loss: 0.597 | Acc: 99.863
59 Loss: 0.517 | Acc: 99.919
MLP trained successfully...
# of Left images:  2355.0
# of Right images:  4047.0
giniRightRatio:  0.8391625726598065
giniLeftRatio:  0.8876645886017462
impurityDrop:  0.8673865033598975
giniGain:  0.0031320328558918087
lclasses:  [113, 189, 207, 333, 155, 305, 158, 292, 225, 378]
rclasses:  [258, 22, 702, 885, 453, 939, 220, 359, 155, 54]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2355, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([2355])
rTrainDict[data].shape:  torch.Size([4047, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([4047])
RETURNING FROM WORK...
nodeId:  22 , imgTensorShape :  torch.Size([2355, 16, 16, 16])
nodeId: 22 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2355
nodeId:  23 , imgTensorShape :  torch.Size([4047, 16, 16, 16])
nodeId: 23 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 4047
Running nodeId:  12
trainInputDict[data].shape :  torch.Size([3642, 16, 20, 20])
copy.shape :  torch.Size([3642, 6400])
copyLabel.shape :  torch.Size([3642])
Class 0 has 1057 instances after oversampling
Class 1 has 1058 instances after oversampling
Class 2 has 1057 instances after oversampling
Class 3 has 1058 instances after oversampling
Class 4 has 1057 instances after oversampling
Class 5 has 1058 instances after oversampling
Class 6 has 1058 instances after oversampling
Class 7 has 1058 instances after oversampling
Class 8 has 1057 instances after oversampling
Class 9 has 1058 instances after oversampling
0 Train Loss: 225.275 | Train Acc: 14.259
1 Train Loss: 195.434 | Train Acc: 30.304
2 Train Loss: 160.728 | Train Acc: 44.128
3 Train Loss: 141.122 | Train Acc: 53.820
4 Train Loss: 113.167 | Train Acc: 64.609
5 Train Loss: 92.488 | Train Acc: 71.596
6 Train Loss: 71.686 | Train Acc: 78.357
7 Train Loss: 61.655 | Train Acc: 81.430
8 Train Loss: 52.034 | Train Acc: 85.146
9 Train Loss: 44.901 | Train Acc: 87.273
10 Train Loss: 39.305 | Train Acc: 89.098
11 Train Loss: 32.716 | Train Acc: 91.027
12 Train Loss: 28.656 | Train Acc: 92.360
13 Train Loss: 26.157 | Train Acc: 93.050
14 Train Loss: 21.529 | Train Acc: 94.081
15 Train Loss: 18.395 | Train Acc: 95.197
16 Train Loss: 13.974 | Train Acc: 96.464
17 Train Loss: 12.405 | Train Acc: 96.776
18 Train Loss: 11.883 | Train Acc: 97.012
19 Train Loss: 8.521 | Train Acc: 97.995
20 Train Loss: 6.323 | Train Acc: 98.856
21 Train Loss: 5.596 | Train Acc: 99.206
22 Train Loss: 5.343 | Train Acc: 99.168
23 Train Loss: 5.080 | Train Acc: 99.319
24 Train Loss: 4.693 | Train Acc: 99.348
25 Train Loss: 4.448 | Train Acc: 99.433
26 Train Loss: 4.053 | Train Acc: 99.612
27 Train Loss: 3.814 | Train Acc: 99.622
28 Train Loss: 3.555 | Train Acc: 99.707
29 Train Loss: 3.422 | Train Acc: 99.716
30 Train Loss: 3.222 | Train Acc: 99.764
31 Train Loss: 3.011 | Train Acc: 99.745
32 Train Loss: 2.853 | Train Acc: 99.811
33 Train Loss: 2.608 | Train Acc: 99.849
34 Train Loss: 2.538 | Train Acc: 99.849
35 Train Loss: 2.323 | Train Acc: 99.896
36 Train Loss: 2.140 | Train Acc: 99.934
37 Train Loss: 2.256 | Train Acc: 99.792
38 Train Loss: 2.503 | Train Acc: 99.575
39 Train Loss: 1.913 | Train Acc: 99.924
40 Train Loss: 1.588 | Train Acc: 99.962
41 Train Loss: 1.530 | Train Acc: 99.981
42 Train Loss: 1.486 | Train Acc: 99.972
43 Train Loss: 1.433 | Train Acc: 99.972
44 Train Loss: 1.403 | Train Acc: 99.972
45 Train Loss: 1.358 | Train Acc: 99.981
46 Train Loss: 1.324 | Train Acc: 99.972
47 Train Loss: 1.290 | Train Acc: 99.972
48 Train Loss: 1.268 | Train Acc: 99.981
49 Train Loss: 1.227 | Train Acc: 99.972
50 Train Loss: 1.194 | Train Acc: 99.991
51 Train Loss: 1.166 | Train Acc: 99.991
52 Train Loss: 1.131 | Train Acc: 99.991
53 Train Loss: 1.086 | Train Acc: 100.000
54 Train Loss: 1.048 | Train Acc: 99.991
55 Train Loss: 1.025 | Train Acc: 99.991
56 Train Loss: 1.013 | Train Acc: 100.000
57 Train Loss: 0.961 | Train Acc: 100.000
58 Train Loss: 0.923 | Train Acc: 100.000
59 Train Loss: 0.912 | Train Acc: 100.000
60 Train Loss: 0.835 | Train Acc: 100.000
61 Train Loss: 0.816 | Train Acc: 100.000
62 Train Loss: 0.813 | Train Acc: 100.000
63 Train Loss: 0.803 | Train Acc: 100.000
64 Train Loss: 0.787 | Train Acc: 100.000
65 Train Loss: 0.773 | Train Acc: 100.000
66 Train Loss: 0.764 | Train Acc: 100.000
67 Train Loss: 0.754 | Train Acc: 100.000
68 Train Loss: 0.742 | Train Acc: 100.000
69 Train Loss: 0.728 | Train Acc: 100.000
70 Train Loss: 0.719 | Train Acc: 100.000
71 Train Loss: 0.708 | Train Acc: 100.000
72 Train Loss: 0.693 | Train Acc: 100.000
73 Train Loss: 0.680 | Train Acc: 100.000
74 Train Loss: 0.670 | Train Acc: 100.000
75 Train Loss: 0.659 | Train Acc: 100.000
76 Train Loss: 0.646 | Train Acc: 100.000
77 Train Loss: 0.632 | Train Acc: 100.000
78 Train Loss: 0.621 | Train Acc: 100.000
79 Train Loss: 0.610 | Train Acc: 100.000
80 Train Loss: 0.582 | Train Acc: 100.000
81 Train Loss: 0.576 | Train Acc: 100.000
82 Train Loss: 0.572 | Train Acc: 100.000
83 Train Loss: 0.567 | Train Acc: 100.000
84 Train Loss: 0.564 | Train Acc: 100.000
85 Train Loss: 0.558 | Train Acc: 100.000
86 Train Loss: 0.554 | Train Acc: 100.000
87 Train Loss: 0.547 | Train Acc: 100.000
88 Train Loss: 0.544 | Train Acc: 100.000
89 Train Loss: 0.539 | Train Acc: 100.000
90 Train Loss: 0.532 | Train Acc: 100.000
91 Train Loss: 0.527 | Train Acc: 100.000
92 Train Loss: 0.523 | Train Acc: 100.000
93 Train Loss: 0.517 | Train Acc: 100.000
94 Train Loss: 0.511 | Train Acc: 100.000
95 Train Loss: 0.506 | Train Acc: 100.000
96 Train Loss: 0.501 | Train Acc: 100.000
97 Train Loss: 0.494 | Train Acc: 100.000
98 Train Loss: 0.491 | Train Acc: 100.000
99 Train Loss: 0.485 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([10576, 4096])
printing expected split from k means
{9: 0, 3: 0, 2: 0, 4: 0, 7: 0, 1: 1, 6: 0, 5: 0, 8: 0, 0: 0}
Printing final_dict items...
{9: 0, 3: 0, 2: 0, 4: 0, 7: 0, 1: 1, 6: 0, 5: 0, 8: 0, 0: 0}
Image Statistics before MLP : L R :  8371 2205
expectedMlpLabels.shape :  torch.Size([10576])
0 Loss: 12.679 | Acc: 93.022
1 Loss: 6.758 | Acc: 96.284
2 Loss: 5.621 | Acc: 96.984
3 Loss: 4.810 | Acc: 97.277
4 Loss: 3.935 | Acc: 97.683
5 Loss: 3.563 | Acc: 97.769
6 Loss: 3.541 | Acc: 97.958
7 Loss: 3.078 | Acc: 98.232
8 Loss: 2.760 | Acc: 98.534
9 Loss: 2.814 | Acc: 98.449
10 Loss: 2.339 | Acc: 98.516
11 Loss: 1.946 | Acc: 98.941
12 Loss: 1.443 | Acc: 99.187
13 Loss: 1.252 | Acc: 99.348
14 Loss: 1.295 | Acc: 99.291
15 Loss: 1.271 | Acc: 99.272
16 Loss: 1.204 | Acc: 99.338
17 Loss: 1.163 | Acc: 99.414
18 Loss: 1.227 | Acc: 99.310
19 Loss: 0.909 | Acc: 99.499
20 Loss: 0.769 | Acc: 99.537
21 Loss: 0.708 | Acc: 99.660
22 Loss: 0.554 | Acc: 99.612
23 Loss: 0.556 | Acc: 99.697
24 Loss: 0.722 | Acc: 99.697
25 Loss: 0.513 | Acc: 99.707
26 Loss: 0.869 | Acc: 99.575
27 Loss: 0.719 | Acc: 99.622
28 Loss: 0.607 | Acc: 99.650
29 Loss: 0.628 | Acc: 99.622
30 Loss: 0.461 | Acc: 99.745
31 Loss: 0.499 | Acc: 99.697
32 Loss: 0.429 | Acc: 99.745
33 Loss: 0.526 | Acc: 99.754
34 Loss: 0.331 | Acc: 99.820
35 Loss: 0.327 | Acc: 99.830
36 Loss: 0.408 | Acc: 99.773
37 Loss: 0.367 | Acc: 99.783
38 Loss: 0.312 | Acc: 99.820
39 Loss: 0.318 | Acc: 99.849
40 Loss: 0.382 | Acc: 99.801
41 Loss: 0.343 | Acc: 99.764
42 Loss: 0.248 | Acc: 99.887
43 Loss: 0.346 | Acc: 99.792
44 Loss: 0.268 | Acc: 99.849
45 Loss: 0.337 | Acc: 99.820
46 Loss: 0.289 | Acc: 99.877
47 Loss: 0.310 | Acc: 99.868
48 Loss: 0.264 | Acc: 99.849
49 Loss: 0.259 | Acc: 99.877
50 Loss: 0.247 | Acc: 99.868
51 Loss: 0.385 | Acc: 99.858
52 Loss: 0.410 | Acc: 99.830
53 Loss: 0.279 | Acc: 99.905
54 Loss: 0.267 | Acc: 99.830
55 Loss: 0.237 | Acc: 99.915
56 Loss: 0.203 | Acc: 99.896
57 Loss: 0.278 | Acc: 99.839
58 Loss: 0.283 | Acc: 99.877
59 Loss: 0.258 | Acc: 99.868
MLP trained successfully...
# of Left images:  2393.0
# of Right images:  1249.0
giniRightRatio:  0.61188935135298
giniLeftRatio:  0.8538810002498931
impurityDrop:  1.0755290757807727
giniGain:  -0.2574898838648706
lclasses:  [91, 283, 112, 268, 117, 241, 188, 453, 49, 591]
rclasses:  [30, 619, 8, 7, 15, 16, 33, 36, 18, 467]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2393, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([2393])
rTrainDict[data].shape:  torch.Size([1249, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1249])
RETURNING FROM WORK...
nodeId:  24 , imgTensorShape :  torch.Size([2393, 16, 16, 16])
nodeId: 24 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2393
nodeId:  25 , imgTensorShape :  torch.Size([1249, 16, 16, 16])
nodeId: 25 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1249
Running nodeId:  13
trainInputDict[data].shape :  torch.Size([2431, 16, 20, 20])
copy.shape :  torch.Size([2431, 6400])
copyLabel.shape :  torch.Size([2431])
Class 0 has 636 instances after oversampling
Class 1 has 636 instances after oversampling
Class 2 has 636 instances after oversampling
Class 3 has 636 instances after oversampling
Class 4 has 636 instances after oversampling
Class 5 has 636 instances after oversampling
Class 6 has 636 instances after oversampling
Class 7 has 636 instances after oversampling
Class 8 has 636 instances after oversampling
Class 9 has 636 instances after oversampling
0 Train Loss: 225.367 | Train Acc: 15.881
1 Train Loss: 184.275 | Train Acc: 37.060
2 Train Loss: 143.632 | Train Acc: 53.176
3 Train Loss: 113.069 | Train Acc: 64.701
4 Train Loss: 89.269 | Train Acc: 72.343
5 Train Loss: 77.090 | Train Acc: 76.274
6 Train Loss: 63.360 | Train Acc: 80.818
7 Train Loss: 51.111 | Train Acc: 85.393
8 Train Loss: 43.075 | Train Acc: 87.453
9 Train Loss: 34.435 | Train Acc: 90.204
10 Train Loss: 32.082 | Train Acc: 90.896
11 Train Loss: 22.366 | Train Acc: 93.711
12 Train Loss: 16.937 | Train Acc: 95.865
13 Train Loss: 13.818 | Train Acc: 96.714
14 Train Loss: 11.224 | Train Acc: 97.610
15 Train Loss: 9.151 | Train Acc: 98.129
16 Train Loss: 7.042 | Train Acc: 98.726
17 Train Loss: 5.506 | Train Acc: 99.308
18 Train Loss: 4.740 | Train Acc: 99.387
19 Train Loss: 3.447 | Train Acc: 99.717
20 Train Loss: 2.368 | Train Acc: 99.906
21 Train Loss: 2.082 | Train Acc: 99.984
22 Train Loss: 1.900 | Train Acc: 99.984
23 Train Loss: 1.765 | Train Acc: 99.984
24 Train Loss: 1.650 | Train Acc: 99.984
25 Train Loss: 1.540 | Train Acc: 100.000
26 Train Loss: 1.441 | Train Acc: 100.000
27 Train Loss: 1.334 | Train Acc: 100.000
28 Train Loss: 1.298 | Train Acc: 100.000
29 Train Loss: 1.173 | Train Acc: 100.000
30 Train Loss: 1.125 | Train Acc: 100.000
31 Train Loss: 1.042 | Train Acc: 100.000
32 Train Loss: 0.971 | Train Acc: 100.000
33 Train Loss: 0.896 | Train Acc: 100.000
34 Train Loss: 0.870 | Train Acc: 100.000
35 Train Loss: 0.807 | Train Acc: 100.000
36 Train Loss: 0.754 | Train Acc: 100.000
37 Train Loss: 0.695 | Train Acc: 100.000
38 Train Loss: 0.656 | Train Acc: 100.000
39 Train Loss: 0.625 | Train Acc: 100.000
40 Train Loss: 0.557 | Train Acc: 100.000
41 Train Loss: 0.545 | Train Acc: 100.000
42 Train Loss: 0.530 | Train Acc: 100.000
43 Train Loss: 0.515 | Train Acc: 100.000
44 Train Loss: 0.502 | Train Acc: 100.000
45 Train Loss: 0.486 | Train Acc: 100.000
46 Train Loss: 0.473 | Train Acc: 100.000
47 Train Loss: 0.461 | Train Acc: 100.000
48 Train Loss: 0.449 | Train Acc: 100.000
49 Train Loss: 0.434 | Train Acc: 100.000
50 Train Loss: 0.423 | Train Acc: 100.000
51 Train Loss: 0.410 | Train Acc: 100.000
52 Train Loss: 0.401 | Train Acc: 100.000
53 Train Loss: 0.387 | Train Acc: 100.000
54 Train Loss: 0.380 | Train Acc: 100.000
55 Train Loss: 0.360 | Train Acc: 100.000
56 Train Loss: 0.352 | Train Acc: 100.000
57 Train Loss: 0.342 | Train Acc: 100.000
58 Train Loss: 0.323 | Train Acc: 100.000
59 Train Loss: 0.318 | Train Acc: 100.000
60 Train Loss: 0.297 | Train Acc: 100.000
61 Train Loss: 0.290 | Train Acc: 100.000
62 Train Loss: 0.287 | Train Acc: 100.000
63 Train Loss: 0.281 | Train Acc: 100.000
64 Train Loss: 0.278 | Train Acc: 100.000
65 Train Loss: 0.271 | Train Acc: 100.000
66 Train Loss: 0.269 | Train Acc: 100.000
67 Train Loss: 0.264 | Train Acc: 100.000
68 Train Loss: 0.259 | Train Acc: 100.000
69 Train Loss: 0.257 | Train Acc: 100.000
70 Train Loss: 0.251 | Train Acc: 100.000
71 Train Loss: 0.245 | Train Acc: 100.000
72 Train Loss: 0.241 | Train Acc: 100.000
73 Train Loss: 0.238 | Train Acc: 100.000
74 Train Loss: 0.235 | Train Acc: 100.000
75 Train Loss: 0.226 | Train Acc: 100.000
76 Train Loss: 0.222 | Train Acc: 100.000
77 Train Loss: 0.217 | Train Acc: 100.000
78 Train Loss: 0.211 | Train Acc: 100.000
79 Train Loss: 0.210 | Train Acc: 100.000
80 Train Loss: 0.200 | Train Acc: 100.000
81 Train Loss: 0.197 | Train Acc: 100.000
82 Train Loss: 0.195 | Train Acc: 100.000
83 Train Loss: 0.193 | Train Acc: 100.000
84 Train Loss: 0.192 | Train Acc: 100.000
85 Train Loss: 0.189 | Train Acc: 100.000
86 Train Loss: 0.188 | Train Acc: 100.000
87 Train Loss: 0.186 | Train Acc: 100.000
88 Train Loss: 0.183 | Train Acc: 100.000
89 Train Loss: 0.181 | Train Acc: 100.000
90 Train Loss: 0.179 | Train Acc: 100.000
91 Train Loss: 0.177 | Train Acc: 100.000
92 Train Loss: 0.174 | Train Acc: 100.000
93 Train Loss: 0.172 | Train Acc: 100.000
94 Train Loss: 0.170 | Train Acc: 100.000
95 Train Loss: 0.168 | Train Acc: 100.000
96 Train Loss: 0.166 | Train Acc: 100.000
97 Train Loss: 0.163 | Train Acc: 100.000
98 Train Loss: 0.162 | Train Acc: 100.000
99 Train Loss: 0.159 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([6360, 4096])
printing expected split from k means
{0: 0, 1: 0, 6: 1, 8: 0, 9: 1, 2: 1, 5: 1, 4: 1, 7: 1, 3: 1}
Printing final_dict items...
{0: 0, 1: 0, 6: 1, 8: 0, 9: 1, 2: 1, 5: 1, 4: 1, 7: 1, 3: 1}
Image Statistics before MLP : L R :  2004 4356
expectedMlpLabels.shape :  torch.Size([6360])
0 Loss: 30.643 | Acc: 89.500
1 Loss: 15.075 | Acc: 94.597
2 Loss: 11.745 | Acc: 95.984
3 Loss: 10.037 | Acc: 96.548
4 Loss: 8.955 | Acc: 96.871
5 Loss: 8.257 | Acc: 97.016
6 Loss: 6.264 | Acc: 97.726
7 Loss: 6.226 | Acc: 97.823
8 Loss: 5.418 | Acc: 98.113
9 Loss: 5.834 | Acc: 98.081
10 Loss: 3.848 | Acc: 98.694
11 Loss: 3.204 | Acc: 98.935
12 Loss: 2.799 | Acc: 99.000
13 Loss: 3.148 | Acc: 98.903
14 Loss: 2.922 | Acc: 98.984
15 Loss: 2.770 | Acc: 99.145
16 Loss: 2.804 | Acc: 98.919
17 Loss: 2.349 | Acc: 99.194
18 Loss: 2.686 | Acc: 99.081
19 Loss: 2.496 | Acc: 99.097
20 Loss: 1.540 | Acc: 99.468
21 Loss: 1.529 | Acc: 99.516
22 Loss: 1.485 | Acc: 99.500
23 Loss: 1.270 | Acc: 99.532
24 Loss: 1.237 | Acc: 99.548
25 Loss: 1.268 | Acc: 99.597
26 Loss: 1.242 | Acc: 99.500
27 Loss: 1.181 | Acc: 99.581
28 Loss: 1.143 | Acc: 99.629
29 Loss: 1.364 | Acc: 99.565
30 Loss: 1.137 | Acc: 99.710
31 Loss: 0.752 | Acc: 99.774
32 Loss: 0.781 | Acc: 99.823
33 Loss: 0.612 | Acc: 99.806
34 Loss: 0.752 | Acc: 99.790
35 Loss: 0.866 | Acc: 99.774
36 Loss: 0.712 | Acc: 99.790
37 Loss: 0.702 | Acc: 99.758
38 Loss: 0.700 | Acc: 99.758
39 Loss: 0.695 | Acc: 99.726
40 Loss: 0.716 | Acc: 99.758
41 Loss: 0.557 | Acc: 99.839
42 Loss: 0.820 | Acc: 99.806
43 Loss: 0.536 | Acc: 99.871
44 Loss: 0.474 | Acc: 99.871
45 Loss: 0.474 | Acc: 99.823
46 Loss: 0.678 | Acc: 99.758
47 Loss: 0.502 | Acc: 99.887
48 Loss: 0.525 | Acc: 99.823
49 Loss: 0.384 | Acc: 99.903
50 Loss: 0.531 | Acc: 99.806
51 Loss: 0.325 | Acc: 99.919
52 Loss: 0.657 | Acc: 99.823
53 Loss: 0.645 | Acc: 99.806
54 Loss: 0.488 | Acc: 99.871
55 Loss: 0.417 | Acc: 99.919
56 Loss: 0.467 | Acc: 99.903
57 Loss: 0.650 | Acc: 99.806
58 Loss: 0.555 | Acc: 99.823
59 Loss: 0.448 | Acc: 99.903
MLP trained successfully...
# of Left images:  1148.0
# of Right images:  1283.0
giniRightRatio:  0.8883541533902479
giniLeftRatio:  0.7642848037489831
impurityDrop:  0.7773396456831769
giniGain:  0.07990618879303968
lclasses:  [183, 462, 39, 10, 29, 4, 81, 10, 173, 157]
rclasses:  [93, 174, 127, 135, 89, 77, 173, 88, 111, 216]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1148, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([1148])
rTrainDict[data].shape:  torch.Size([1283, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1283])
RETURNING FROM WORK...
nodeId:  26 , imgTensorShape :  torch.Size([1148, 16, 16, 16])
nodeId: 26 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1148
nodeId:  27 , imgTensorShape :  torch.Size([1283, 16, 16, 16])
nodeId: 27 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1283
Running nodeId:  14
trainInputDict[data].shape :  torch.Size([8845, 16, 20, 20])
copy.shape :  torch.Size([8845, 6400])
copyLabel.shape :  torch.Size([8845])
Class 0 has 2437 instances after oversampling
Class 1 has 2437 instances after oversampling
Class 2 has 2437 instances after oversampling
Class 3 has 2437 instances after oversampling
Class 4 has 2437 instances after oversampling
Class 5 has 2437 instances after oversampling
Class 6 has 2437 instances after oversampling
Class 7 has 2437 instances after oversampling
Class 8 has 2437 instances after oversampling
Class 9 has 2437 instances after oversampling
0 Train Loss: 231.867 | Train Acc: 11.120
1 Train Loss: 213.079 | Train Acc: 19.754
2 Train Loss: 185.225 | Train Acc: 35.269
3 Train Loss: 160.243 | Train Acc: 44.711
4 Train Loss: 145.244 | Train Acc: 51.153
5 Train Loss: 136.562 | Train Acc: 53.619
6 Train Loss: 124.661 | Train Acc: 57.624
7 Train Loss: 115.298 | Train Acc: 59.327
8 Train Loss: 109.066 | Train Acc: 62.204
9 Train Loss: 104.994 | Train Acc: 63.451
10 Train Loss: 97.233 | Train Acc: 66.910
11 Train Loss: 90.634 | Train Acc: 69.089
12 Train Loss: 90.301 | Train Acc: 68.445
13 Train Loss: 82.549 | Train Acc: 71.498
14 Train Loss: 78.717 | Train Acc: 72.675
15 Train Loss: 76.354 | Train Acc: 73.233
16 Train Loss: 73.309 | Train Acc: 74.321
17 Train Loss: 73.453 | Train Acc: 74.391
18 Train Loss: 68.376 | Train Acc: 76.373
19 Train Loss: 73.850 | Train Acc: 74.218
20 Train Loss: 61.993 | Train Acc: 79.011
21 Train Loss: 59.969 | Train Acc: 79.192
22 Train Loss: 58.929 | Train Acc: 79.885
23 Train Loss: 58.042 | Train Acc: 80.386
24 Train Loss: 57.512 | Train Acc: 80.263
25 Train Loss: 56.517 | Train Acc: 80.730
26 Train Loss: 55.510 | Train Acc: 80.931
27 Train Loss: 55.590 | Train Acc: 80.767
28 Train Loss: 54.121 | Train Acc: 81.313
29 Train Loss: 53.913 | Train Acc: 81.399
30 Train Loss: 52.496 | Train Acc: 82.154
31 Train Loss: 51.819 | Train Acc: 82.052
32 Train Loss: 50.167 | Train Acc: 83.065
33 Train Loss: 50.185 | Train Acc: 82.831
34 Train Loss: 49.578 | Train Acc: 82.876
35 Train Loss: 49.340 | Train Acc: 82.991
36 Train Loss: 47.681 | Train Acc: 84.025
37 Train Loss: 47.246 | Train Acc: 83.668
38 Train Loss: 46.979 | Train Acc: 84.034
39 Train Loss: 46.069 | Train Acc: 84.432
40 Train Loss: 44.326 | Train Acc: 85.121
41 Train Loss: 43.664 | Train Acc: 85.581
42 Train Loss: 43.184 | Train Acc: 85.724
43 Train Loss: 43.069 | Train Acc: 85.581
44 Train Loss: 42.790 | Train Acc: 85.745
45 Train Loss: 42.518 | Train Acc: 85.905
46 Train Loss: 42.501 | Train Acc: 85.790
47 Train Loss: 41.972 | Train Acc: 85.909
48 Train Loss: 41.265 | Train Acc: 86.225
49 Train Loss: 41.531 | Train Acc: 86.241
50 Train Loss: 41.060 | Train Acc: 86.389
51 Train Loss: 40.693 | Train Acc: 86.520
52 Train Loss: 40.442 | Train Acc: 86.602
53 Train Loss: 40.251 | Train Acc: 86.631
54 Train Loss: 40.024 | Train Acc: 86.717
55 Train Loss: 39.995 | Train Acc: 86.668
56 Train Loss: 39.579 | Train Acc: 86.959
57 Train Loss: 39.557 | Train Acc: 87.041
58 Train Loss: 39.099 | Train Acc: 87.156
59 Train Loss: 39.048 | Train Acc: 87.107
60 Train Loss: 37.724 | Train Acc: 87.821
61 Train Loss: 37.990 | Train Acc: 87.760
62 Train Loss: 37.691 | Train Acc: 87.768
63 Train Loss: 37.694 | Train Acc: 87.776
64 Train Loss: 37.540 | Train Acc: 87.838
65 Train Loss: 37.459 | Train Acc: 87.866
66 Train Loss: 37.397 | Train Acc: 87.866
67 Train Loss: 37.158 | Train Acc: 87.895
68 Train Loss: 37.360 | Train Acc: 87.891
69 Train Loss: 37.164 | Train Acc: 87.764
70 Train Loss: 36.944 | Train Acc: 88.043
71 Train Loss: 36.908 | Train Acc: 88.010
72 Train Loss: 36.848 | Train Acc: 88.133
73 Train Loss: 36.730 | Train Acc: 88.145
74 Train Loss: 36.785 | Train Acc: 88.088
75 Train Loss: 36.653 | Train Acc: 88.149
76 Train Loss: 36.570 | Train Acc: 88.227
77 Train Loss: 36.297 | Train Acc: 88.252
78 Train Loss: 36.433 | Train Acc: 88.174
79 Train Loss: 36.219 | Train Acc: 88.322
80 Train Loss: 35.864 | Train Acc: 88.474
81 Train Loss: 35.876 | Train Acc: 88.391
82 Train Loss: 35.748 | Train Acc: 88.543
83 Train Loss: 35.795 | Train Acc: 88.437
84 Train Loss: 35.710 | Train Acc: 88.486
85 Train Loss: 35.779 | Train Acc: 88.441
86 Train Loss: 35.673 | Train Acc: 88.474
87 Train Loss: 35.590 | Train Acc: 88.613
88 Train Loss: 35.565 | Train Acc: 88.547
89 Train Loss: 35.516 | Train Acc: 88.584
90 Train Loss: 35.532 | Train Acc: 88.568
91 Train Loss: 35.493 | Train Acc: 88.547
92 Train Loss: 35.430 | Train Acc: 88.551
93 Train Loss: 35.401 | Train Acc: 88.621
94 Train Loss: 35.371 | Train Acc: 88.724
95 Train Loss: 35.356 | Train Acc: 88.543
96 Train Loss: 35.387 | Train Acc: 88.519
97 Train Loss: 35.321 | Train Acc: 88.642
98 Train Loss: 35.205 | Train Acc: 88.650
99 Train Loss: 35.281 | Train Acc: 88.699
CNN trained successfully...
image_next_flat.shape :  torch.Size([24370, 4096])
printing expected split from k means
{4: 0, 2: 0, 6: 0, 0: 1, 3: 0, 5: 0, 7: 0, 1: 0, 8: 1, 9: 0}
Printing final_dict items...
{4: 0, 2: 0, 6: 0, 0: 1, 3: 0, 5: 0, 7: 0, 1: 0, 8: 1, 9: 0}
Image Statistics before MLP : L R :  17717 6653
expectedMlpLabels.shape :  torch.Size([24370])
0 Loss: 16.267 | Acc: 93.697
1 Loss: 8.787 | Acc: 96.282
2 Loss: 7.039 | Acc: 97.033
3 Loss: 5.770 | Acc: 97.550
4 Loss: 5.273 | Acc: 97.796
5 Loss: 4.807 | Acc: 97.965
6 Loss: 4.372 | Acc: 98.149
7 Loss: 4.092 | Acc: 98.227
8 Loss: 3.735 | Acc: 98.416
9 Loss: 3.740 | Acc: 98.396
10 Loss: 2.405 | Acc: 99.003
11 Loss: 1.938 | Acc: 99.163
12 Loss: 2.060 | Acc: 99.163
13 Loss: 1.875 | Acc: 99.237
14 Loss: 1.758 | Acc: 99.311
15 Loss: 1.621 | Acc: 99.372
16 Loss: 1.450 | Acc: 99.446
17 Loss: 1.532 | Acc: 99.409
18 Loss: 1.503 | Acc: 99.442
19 Loss: 1.337 | Acc: 99.430
20 Loss: 1.183 | Acc: 99.577
21 Loss: 0.975 | Acc: 99.627
22 Loss: 0.797 | Acc: 99.709
23 Loss: 0.895 | Acc: 99.664
24 Loss: 0.793 | Acc: 99.696
25 Loss: 0.771 | Acc: 99.721
26 Loss: 0.804 | Acc: 99.700
27 Loss: 0.715 | Acc: 99.733
28 Loss: 0.670 | Acc: 99.721
29 Loss: 0.623 | Acc: 99.758
30 Loss: 0.623 | Acc: 99.762
31 Loss: 0.646 | Acc: 99.737
32 Loss: 0.529 | Acc: 99.832
33 Loss: 0.590 | Acc: 99.770
34 Loss: 0.451 | Acc: 99.836
35 Loss: 0.515 | Acc: 99.819
36 Loss: 0.569 | Acc: 99.783
37 Loss: 0.497 | Acc: 99.799
38 Loss: 0.472 | Acc: 99.807
39 Loss: 0.534 | Acc: 99.811
40 Loss: 0.508 | Acc: 99.840
41 Loss: 0.425 | Acc: 99.844
42 Loss: 0.508 | Acc: 99.795
43 Loss: 0.448 | Acc: 99.819
44 Loss: 0.381 | Acc: 99.836
45 Loss: 0.338 | Acc: 99.860
46 Loss: 0.315 | Acc: 99.902
47 Loss: 0.366 | Acc: 99.881
48 Loss: 0.452 | Acc: 99.811
49 Loss: 0.489 | Acc: 99.828
50 Loss: 0.508 | Acc: 99.824
51 Loss: 0.432 | Acc: 99.865
52 Loss: 0.361 | Acc: 99.865
53 Loss: 0.325 | Acc: 99.865
54 Loss: 0.412 | Acc: 99.852
55 Loss: 0.346 | Acc: 99.877
56 Loss: 0.413 | Acc: 99.848
57 Loss: 0.354 | Acc: 99.869
58 Loss: 0.407 | Acc: 99.865
59 Loss: 0.389 | Acc: 99.856
MLP trained successfully...
# of Left images:  6972.0
# of Right images:  1873.0
giniRightRatio:  0.7804695893452038
giniLeftRatio:  0.8058387553986128
impurityDrop:  0.8749030253966548
giniGain:  -0.0660367296896397
lclasses:  [110, 24, 1140, 1016, 1418, 713, 2106, 369, 34, 42]
rclasses:  [90, 4, 540, 149, 570, 105, 331, 37, 35, 12]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([6972, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([6972])
rTrainDict[data].shape:  torch.Size([1873, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1873])
RETURNING FROM WORK...
nodeId:  28 , imgTensorShape :  torch.Size([6972, 16, 16, 16])
nodeId: 28 ,  parentId: 14 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 6972
nodeId:  29 , imgTensorShape :  torch.Size([1873, 16, 16, 16])
nodeId: 29 ,  parentId: 14 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1873
Running nodeId:  15
trainInputDict[data].shape :  torch.Size([10860, 16, 20, 20])
copy.shape :  torch.Size([10860, 6400])
copyLabel.shape :  torch.Size([10860])
Class 0 has 2493 instances after oversampling
Class 1 has 2493 instances after oversampling
Class 2 has 2493 instances after oversampling
Class 3 has 2493 instances after oversampling
Class 4 has 2493 instances after oversampling
Class 5 has 2493 instances after oversampling
Class 6 has 2493 instances after oversampling
Class 7 has 2493 instances after oversampling
Class 8 has 2493 instances after oversampling
Class 9 has 2493 instances after oversampling
0 Train Loss: 219.296 | Train Acc: 17.898
1 Train Loss: 186.133 | Train Acc: 35.383
2 Train Loss: 150.535 | Train Acc: 49.904
3 Train Loss: 126.686 | Train Acc: 58.909
4 Train Loss: 109.692 | Train Acc: 63.273
5 Train Loss: 104.347 | Train Acc: 64.846
6 Train Loss: 95.019 | Train Acc: 67.601
7 Train Loss: 87.906 | Train Acc: 69.992
8 Train Loss: 81.865 | Train Acc: 71.925
9 Train Loss: 80.529 | Train Acc: 72.343
10 Train Loss: 78.809 | Train Acc: 73.000
11 Train Loss: 71.987 | Train Acc: 75.724
12 Train Loss: 71.231 | Train Acc: 75.884
13 Train Loss: 68.212 | Train Acc: 76.659
14 Train Loss: 65.190 | Train Acc: 77.597
15 Train Loss: 64.068 | Train Acc: 77.613
16 Train Loss: 61.451 | Train Acc: 78.712
17 Train Loss: 60.567 | Train Acc: 79.250
18 Train Loss: 56.165 | Train Acc: 80.878
19 Train Loss: 58.142 | Train Acc: 79.799
20 Train Loss: 51.644 | Train Acc: 82.631
21 Train Loss: 49.826 | Train Acc: 83.333
22 Train Loss: 48.807 | Train Acc: 83.646
23 Train Loss: 48.885 | Train Acc: 83.602
24 Train Loss: 49.247 | Train Acc: 83.357
25 Train Loss: 48.811 | Train Acc: 83.478
26 Train Loss: 47.522 | Train Acc: 83.995
27 Train Loss: 46.969 | Train Acc: 84.108
28 Train Loss: 45.603 | Train Acc: 84.974
29 Train Loss: 45.976 | Train Acc: 84.613
30 Train Loss: 45.280 | Train Acc: 84.854
31 Train Loss: 45.668 | Train Acc: 84.653
32 Train Loss: 43.803 | Train Acc: 85.540
33 Train Loss: 44.518 | Train Acc: 84.902
34 Train Loss: 44.025 | Train Acc: 85.162
35 Train Loss: 43.168 | Train Acc: 85.828
36 Train Loss: 43.383 | Train Acc: 85.600
37 Train Loss: 42.218 | Train Acc: 86.125
38 Train Loss: 41.066 | Train Acc: 86.478
39 Train Loss: 41.408 | Train Acc: 86.366
40 Train Loss: 39.334 | Train Acc: 87.320
41 Train Loss: 38.818 | Train Acc: 87.389
42 Train Loss: 38.905 | Train Acc: 87.244
43 Train Loss: 38.512 | Train Acc: 87.521
44 Train Loss: 38.874 | Train Acc: 87.361
45 Train Loss: 38.234 | Train Acc: 87.629
46 Train Loss: 37.939 | Train Acc: 87.653
47 Train Loss: 37.909 | Train Acc: 87.698
48 Train Loss: 38.244 | Train Acc: 87.617
49 Train Loss: 37.017 | Train Acc: 88.043
50 Train Loss: 37.563 | Train Acc: 87.886
51 Train Loss: 37.226 | Train Acc: 87.942
52 Train Loss: 36.453 | Train Acc: 88.227
53 Train Loss: 36.811 | Train Acc: 88.095
54 Train Loss: 36.393 | Train Acc: 88.327
55 Train Loss: 36.640 | Train Acc: 88.255
56 Train Loss: 36.047 | Train Acc: 88.444
57 Train Loss: 35.926 | Train Acc: 88.331
58 Train Loss: 35.782 | Train Acc: 88.524
59 Train Loss: 35.947 | Train Acc: 88.440
60 Train Loss: 34.553 | Train Acc: 89.150
61 Train Loss: 34.387 | Train Acc: 89.154
62 Train Loss: 34.301 | Train Acc: 89.166
63 Train Loss: 34.345 | Train Acc: 89.105
64 Train Loss: 34.285 | Train Acc: 89.166
65 Train Loss: 34.222 | Train Acc: 89.246
66 Train Loss: 34.041 | Train Acc: 89.266
67 Train Loss: 33.894 | Train Acc: 89.398
68 Train Loss: 33.843 | Train Acc: 89.330
69 Train Loss: 33.792 | Train Acc: 89.406
70 Train Loss: 33.996 | Train Acc: 89.358
71 Train Loss: 33.615 | Train Acc: 89.418
72 Train Loss: 33.439 | Train Acc: 89.643
73 Train Loss: 33.453 | Train Acc: 89.483
74 Train Loss: 33.469 | Train Acc: 89.523
75 Train Loss: 33.364 | Train Acc: 89.535
76 Train Loss: 33.263 | Train Acc: 89.683
77 Train Loss: 33.119 | Train Acc: 89.583
78 Train Loss: 33.101 | Train Acc: 89.623
79 Train Loss: 32.961 | Train Acc: 89.739
80 Train Loss: 32.691 | Train Acc: 89.775
81 Train Loss: 32.573 | Train Acc: 89.892
82 Train Loss: 32.522 | Train Acc: 89.896
83 Train Loss: 32.500 | Train Acc: 89.884
84 Train Loss: 32.545 | Train Acc: 89.832
85 Train Loss: 32.473 | Train Acc: 89.952
86 Train Loss: 32.439 | Train Acc: 89.944
87 Train Loss: 32.377 | Train Acc: 89.912
88 Train Loss: 32.354 | Train Acc: 90.004
89 Train Loss: 32.291 | Train Acc: 89.932
90 Train Loss: 32.367 | Train Acc: 89.988
91 Train Loss: 32.275 | Train Acc: 90.036
92 Train Loss: 32.207 | Train Acc: 90.016
93 Train Loss: 32.208 | Train Acc: 89.992
94 Train Loss: 32.158 | Train Acc: 90.072
95 Train Loss: 32.134 | Train Acc: 89.984
96 Train Loss: 32.174 | Train Acc: 90.012
97 Train Loss: 32.099 | Train Acc: 90.072
98 Train Loss: 31.969 | Train Acc: 90.168
99 Train Loss: 32.091 | Train Acc: 90.028
CNN trained successfully...
image_next_flat.shape :  torch.Size([24930, 4096])
printing expected split from k means
{2: 1, 3: 1, 7: 1, 5: 1, 4: 1, 6: 1, 0: 0, 1: 0, 9: 1, 8: 1}
Printing final_dict items...
{2: 1, 3: 1, 7: 1, 5: 1, 4: 1, 6: 1, 0: 0, 1: 0, 9: 1, 8: 1}
Image Statistics before MLP : L R :  6923 18007
expectedMlpLabels.shape :  torch.Size([24930])
0 Loss: 17.411 | Acc: 92.671
1 Loss: 10.807 | Acc: 95.415
2 Loss: 8.491 | Acc: 96.217
3 Loss: 7.578 | Acc: 96.795
4 Loss: 6.572 | Acc: 97.228
5 Loss: 5.745 | Acc: 97.445
6 Loss: 4.981 | Acc: 97.922
7 Loss: 4.796 | Acc: 98.014
8 Loss: 4.572 | Acc: 98.026
9 Loss: 4.399 | Acc: 98.155
10 Loss: 2.620 | Acc: 98.997
11 Loss: 2.026 | Acc: 99.194
12 Loss: 2.327 | Acc: 99.077
13 Loss: 2.073 | Acc: 99.226
14 Loss: 1.818 | Acc: 99.266
15 Loss: 1.778 | Acc: 99.334
16 Loss: 1.662 | Acc: 99.358
17 Loss: 1.720 | Acc: 99.370
18 Loss: 1.761 | Acc: 99.282
19 Loss: 1.459 | Acc: 99.454
20 Loss: 1.175 | Acc: 99.595
21 Loss: 0.981 | Acc: 99.627
22 Loss: 0.958 | Acc: 99.675
23 Loss: 0.920 | Acc: 99.663
24 Loss: 0.911 | Acc: 99.683
25 Loss: 0.992 | Acc: 99.671
26 Loss: 0.851 | Acc: 99.691
27 Loss: 0.901 | Acc: 99.695
28 Loss: 0.786 | Acc: 99.755
29 Loss: 0.878 | Acc: 99.659
30 Loss: 0.728 | Acc: 99.703
31 Loss: 0.688 | Acc: 99.763
32 Loss: 0.674 | Acc: 99.755
33 Loss: 0.723 | Acc: 99.767
34 Loss: 0.600 | Acc: 99.787
35 Loss: 0.575 | Acc: 99.787
36 Loss: 0.648 | Acc: 99.759
37 Loss: 0.622 | Acc: 99.779
38 Loss: 0.586 | Acc: 99.815
39 Loss: 0.557 | Acc: 99.783
40 Loss: 0.430 | Acc: 99.844
41 Loss: 0.490 | Acc: 99.828
42 Loss: 0.539 | Acc: 99.824
43 Loss: 0.442 | Acc: 99.852
44 Loss: 0.442 | Acc: 99.856
45 Loss: 0.443 | Acc: 99.828
46 Loss: 0.404 | Acc: 99.856
47 Loss: 0.453 | Acc: 99.844
48 Loss: 0.458 | Acc: 99.856
49 Loss: 0.399 | Acc: 99.852
50 Loss: 0.465 | Acc: 99.819
51 Loss: 0.361 | Acc: 99.872
52 Loss: 0.393 | Acc: 99.852
53 Loss: 0.386 | Acc: 99.860
54 Loss: 0.469 | Acc: 99.860
55 Loss: 0.357 | Acc: 99.872
56 Loss: 0.344 | Acc: 99.876
57 Loss: 0.356 | Acc: 99.880
58 Loss: 0.487 | Acc: 99.852
59 Loss: 0.414 | Acc: 99.872
MLP trained successfully...
# of Left images:  1829.0
# of Right images:  9031.0
giniRightRatio:  0.8246195289319589
giniLeftRatio:  0.8428654318179168
impurityDrop:  0.8283147737972469
giniGain:  0.004863649734798248
lclasses:  [97, 38, 418, 189, 246, 232, 163, 403, 14, 29]
rclasses:  [57, 34, 753, 1495, 1237, 2018, 1232, 2090, 23, 92]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1829, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([1829])
rTrainDict[data].shape:  torch.Size([9031, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([9031])
RETURNING FROM WORK...
nodeId:  30 , imgTensorShape :  torch.Size([1829, 16, 16, 16])
nodeId: 30 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1829
nodeId:  31 , imgTensorShape :  torch.Size([9031, 16, 16, 16])
nodeId: 31 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 9031
Running nodeId:  16
trainInputDict[data].shape :  torch.Size([1979, 16, 16, 16])
copy.shape :  torch.Size([1979, 4096])
copyLabel.shape :  torch.Size([1979])
Class 0 has 649 instances after oversampling
Class 1 has 649 instances after oversampling
Class 2 has 649 instances after oversampling
Class 3 has 649 instances after oversampling
Class 4 has 649 instances after oversampling
Class 5 has 649 instances after oversampling
Class 6 has 649 instances after oversampling
Class 7 has 649 instances after oversampling
Class 8 has 649 instances after oversampling
Class 9 has 649 instances after oversampling
0 Train Loss: 224.990 | Train Acc: 13.174
1 Train Loss: 209.519 | Train Acc: 22.604
2 Train Loss: 188.687 | Train Acc: 31.926
3 Train Loss: 155.992 | Train Acc: 48.398
4 Train Loss: 124.417 | Train Acc: 59.461
5 Train Loss: 106.169 | Train Acc: 65.023
6 Train Loss: 92.146 | Train Acc: 71.140
7 Train Loss: 76.330 | Train Acc: 75.331
8 Train Loss: 67.525 | Train Acc: 78.398
9 Train Loss: 57.990 | Train Acc: 81.387
10 Train Loss: 50.367 | Train Acc: 84.361
11 Train Loss: 44.425 | Train Acc: 85.716
12 Train Loss: 38.266 | Train Acc: 87.966
13 Train Loss: 31.633 | Train Acc: 90.354
14 Train Loss: 29.976 | Train Acc: 90.632
15 Train Loss: 24.131 | Train Acc: 92.512
16 Train Loss: 21.695 | Train Acc: 93.190
17 Train Loss: 19.528 | Train Acc: 93.898
18 Train Loss: 17.164 | Train Acc: 94.838
19 Train Loss: 17.340 | Train Acc: 94.268
20 Train Loss: 12.552 | Train Acc: 96.302
21 Train Loss: 10.809 | Train Acc: 97.026
22 Train Loss: 10.350 | Train Acc: 97.257
23 Train Loss: 10.045 | Train Acc: 97.273
24 Train Loss: 9.506 | Train Acc: 97.519
25 Train Loss: 8.631 | Train Acc: 97.920
26 Train Loss: 8.072 | Train Acc: 98.028
27 Train Loss: 8.372 | Train Acc: 97.781
28 Train Loss: 7.872 | Train Acc: 97.966
29 Train Loss: 7.109 | Train Acc: 98.274
30 Train Loss: 6.665 | Train Acc: 98.536
31 Train Loss: 6.355 | Train Acc: 98.767
32 Train Loss: 6.091 | Train Acc: 98.613
33 Train Loss: 5.735 | Train Acc: 98.844
34 Train Loss: 5.424 | Train Acc: 98.983
35 Train Loss: 5.108 | Train Acc: 99.153
36 Train Loss: 4.807 | Train Acc: 99.060
37 Train Loss: 4.620 | Train Acc: 99.260
38 Train Loss: 4.347 | Train Acc: 99.245
39 Train Loss: 4.354 | Train Acc: 99.353
40 Train Loss: 3.731 | Train Acc: 99.507
41 Train Loss: 3.504 | Train Acc: 99.569
42 Train Loss: 3.404 | Train Acc: 99.538
43 Train Loss: 3.275 | Train Acc: 99.615
44 Train Loss: 3.346 | Train Acc: 99.553
45 Train Loss: 3.170 | Train Acc: 99.599
46 Train Loss: 3.086 | Train Acc: 99.676
47 Train Loss: 3.099 | Train Acc: 99.661
48 Train Loss: 2.981 | Train Acc: 99.692
49 Train Loss: 2.852 | Train Acc: 99.707
50 Train Loss: 2.773 | Train Acc: 99.661
51 Train Loss: 2.744 | Train Acc: 99.692
52 Train Loss: 2.635 | Train Acc: 99.738
53 Train Loss: 2.618 | Train Acc: 99.707
54 Train Loss: 2.502 | Train Acc: 99.738
55 Train Loss: 2.520 | Train Acc: 99.753
56 Train Loss: 2.403 | Train Acc: 99.861
57 Train Loss: 2.299 | Train Acc: 99.815
58 Train Loss: 2.295 | Train Acc: 99.753
59 Train Loss: 2.239 | Train Acc: 99.815
60 Train Loss: 2.059 | Train Acc: 99.892
61 Train Loss: 2.001 | Train Acc: 99.908
62 Train Loss: 1.984 | Train Acc: 99.892
63 Train Loss: 1.953 | Train Acc: 99.877
64 Train Loss: 1.929 | Train Acc: 99.908
65 Train Loss: 1.907 | Train Acc: 99.892
66 Train Loss: 1.875 | Train Acc: 99.861
67 Train Loss: 1.848 | Train Acc: 99.908
68 Train Loss: 1.855 | Train Acc: 99.892
69 Train Loss: 1.819 | Train Acc: 99.877
70 Train Loss: 1.800 | Train Acc: 99.892
71 Train Loss: 1.768 | Train Acc: 99.923
72 Train Loss: 1.730 | Train Acc: 99.938
73 Train Loss: 1.705 | Train Acc: 99.923
74 Train Loss: 1.689 | Train Acc: 99.923
75 Train Loss: 1.675 | Train Acc: 99.923
76 Train Loss: 1.641 | Train Acc: 99.923
77 Train Loss: 1.630 | Train Acc: 99.908
78 Train Loss: 1.583 | Train Acc: 99.938
79 Train Loss: 1.579 | Train Acc: 99.908
80 Train Loss: 1.507 | Train Acc: 99.938
81 Train Loss: 1.488 | Train Acc: 99.938
82 Train Loss: 1.488 | Train Acc: 99.938
83 Train Loss: 1.472 | Train Acc: 99.938
84 Train Loss: 1.465 | Train Acc: 99.938
85 Train Loss: 1.458 | Train Acc: 99.954
86 Train Loss: 1.439 | Train Acc: 99.938
87 Train Loss: 1.433 | Train Acc: 99.954
88 Train Loss: 1.430 | Train Acc: 99.954
89 Train Loss: 1.413 | Train Acc: 99.954
90 Train Loss: 1.408 | Train Acc: 99.938
91 Train Loss: 1.394 | Train Acc: 99.954
92 Train Loss: 1.393 | Train Acc: 99.954
93 Train Loss: 1.376 | Train Acc: 99.938
94 Train Loss: 1.367 | Train Acc: 99.954
95 Train Loss: 1.368 | Train Acc: 99.969
96 Train Loss: 1.351 | Train Acc: 99.954
97 Train Loss: 1.347 | Train Acc: 99.969
98 Train Loss: 1.329 | Train Acc: 99.969
99 Train Loss: 1.317 | Train Acc: 99.969
CNN trained successfully...
image_next_flat.shape :  torch.Size([6490, 2304])
printing expected split from k means
{9: 0, 8: 0, 0: 0, 2: 1, 4: 1, 6: 1, 5: 0, 7: 0, 3: 0, 1: 0}
Printing final_dict items...
{9: 0, 8: 0, 0: 0, 2: 1, 4: 1, 6: 1, 5: 0, 7: 0, 3: 0, 1: 0}
Image Statistics before MLP : L R :  4326 2164
expectedMlpLabels.shape :  torch.Size([6490])
0 Loss: 26.953 | Acc: 90.562
1 Loss: 14.734 | Acc: 94.547
2 Loss: 12.419 | Acc: 95.750
3 Loss: 10.764 | Acc: 96.375
4 Loss: 9.119 | Acc: 96.469
5 Loss: 9.172 | Acc: 96.812
6 Loss: 7.814 | Acc: 97.391
7 Loss: 8.567 | Acc: 97.188
8 Loss: 6.687 | Acc: 97.672
9 Loss: 6.052 | Acc: 97.828
10 Loss: 5.146 | Acc: 98.281
11 Loss: 4.302 | Acc: 98.641
12 Loss: 3.954 | Acc: 98.609
13 Loss: 3.865 | Acc: 98.672
14 Loss: 2.920 | Acc: 98.969
15 Loss: 2.978 | Acc: 99.062
16 Loss: 3.114 | Acc: 99.109
17 Loss: 3.209 | Acc: 98.953
18 Loss: 2.111 | Acc: 99.359
19 Loss: 3.171 | Acc: 98.906
20 Loss: 2.043 | Acc: 99.469
21 Loss: 1.845 | Acc: 99.438
22 Loss: 1.969 | Acc: 99.375
23 Loss: 1.600 | Acc: 99.547
24 Loss: 1.525 | Acc: 99.500
25 Loss: 1.596 | Acc: 99.531
26 Loss: 1.566 | Acc: 99.531
27 Loss: 1.301 | Acc: 99.578
28 Loss: 1.150 | Acc: 99.719
29 Loss: 1.160 | Acc: 99.641
30 Loss: 1.448 | Acc: 99.578
31 Loss: 1.459 | Acc: 99.562
32 Loss: 1.135 | Acc: 99.641
33 Loss: 0.983 | Acc: 99.641
34 Loss: 0.691 | Acc: 99.812
35 Loss: 1.030 | Acc: 99.719
36 Loss: 1.015 | Acc: 99.703
37 Loss: 0.650 | Acc: 99.844
38 Loss: 0.632 | Acc: 99.797
39 Loss: 0.747 | Acc: 99.750
40 Loss: 0.764 | Acc: 99.812
41 Loss: 0.563 | Acc: 99.812
42 Loss: 0.706 | Acc: 99.750
43 Loss: 0.850 | Acc: 99.781
44 Loss: 0.649 | Acc: 99.859
45 Loss: 0.548 | Acc: 99.844
46 Loss: 0.754 | Acc: 99.828
47 Loss: 0.613 | Acc: 99.844
48 Loss: 0.766 | Acc: 99.734
49 Loss: 0.805 | Acc: 99.797
50 Loss: 0.539 | Acc: 99.859
51 Loss: 0.731 | Acc: 99.750
52 Loss: 0.560 | Acc: 99.844
53 Loss: 0.580 | Acc: 99.844
54 Loss: 0.481 | Acc: 99.828
55 Loss: 0.809 | Acc: 99.781
56 Loss: 0.567 | Acc: 99.891
57 Loss: 0.503 | Acc: 99.891
58 Loss: 0.545 | Acc: 99.906
59 Loss: 0.657 | Acc: 99.797
MLP trained successfully...
# of Left images:  1458.0
# of Right images:  521.0
giniRightRatio:  0.82238129096194
giniLeftRatio:  0.7324416068763984
impurityDrop:  0.5706882786841669
giniGain:  0.21403846684832029
lclasses:  [457, 39, 155, 37, 93, 16, 26, 16, 566, 53]
rclasses:  [65, 6, 146, 18, 111, 16, 50, 11, 83, 15]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1458, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([1458])
rTrainDict[data].shape:  torch.Size([521, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([521])
RETURNING FROM WORK...
nodeId:  32 , imgTensorShape :  torch.Size([1458, 16, 12, 12])
nodeId: 32 ,  parentId: 16 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1458
nodeId:  33 , imgTensorShape :  torch.Size([521, 16, 12, 12])
nodeId: 33 ,  parentId: 16 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 521
Running nodeId:  17
trainInputDict[data].shape :  torch.Size([2073, 16, 16, 16])
copy.shape :  torch.Size([2073, 4096])
copyLabel.shape :  torch.Size([2073])
Class 0 has 1062 instances after oversampling
Class 1 has 1062 instances after oversampling
Class 2 has 1062 instances after oversampling
Class 3 has 1062 instances after oversampling
Class 4 has 1062 instances after oversampling
Class 5 has 1062 instances after oversampling
Class 6 has 1062 instances after oversampling
Class 7 has 1062 instances after oversampling
Class 8 has 1062 instances after oversampling
Class 9 has 1062 instances after oversampling
0 Train Loss: 233.172 | Train Acc: 7.580
1 Train Loss: 216.989 | Train Acc: 21.073
2 Train Loss: 161.822 | Train Acc: 45.452
3 Train Loss: 118.675 | Train Acc: 60.179
4 Train Loss: 87.452 | Train Acc: 71.535
5 Train Loss: 73.626 | Train Acc: 75.480
6 Train Loss: 59.910 | Train Acc: 79.190
7 Train Loss: 55.938 | Train Acc: 81.573
8 Train Loss: 46.029 | Train Acc: 84.567
9 Train Loss: 46.508 | Train Acc: 84.736
10 Train Loss: 33.948 | Train Acc: 88.861
11 Train Loss: 35.942 | Train Acc: 87.448
12 Train Loss: 35.489 | Train Acc: 88.126
13 Train Loss: 29.328 | Train Acc: 89.831
14 Train Loss: 27.861 | Train Acc: 90.603
15 Train Loss: 24.149 | Train Acc: 92.090
16 Train Loss: 22.557 | Train Acc: 92.514
17 Train Loss: 20.926 | Train Acc: 93.060
18 Train Loss: 17.893 | Train Acc: 94.134
19 Train Loss: 17.346 | Train Acc: 94.049
20 Train Loss: 14.077 | Train Acc: 95.537
21 Train Loss: 12.666 | Train Acc: 96.299
22 Train Loss: 12.047 | Train Acc: 96.196
23 Train Loss: 11.087 | Train Acc: 96.714
24 Train Loss: 10.958 | Train Acc: 96.638
25 Train Loss: 10.771 | Train Acc: 96.695
26 Train Loss: 9.770 | Train Acc: 97.288
27 Train Loss: 9.180 | Train Acc: 97.222
28 Train Loss: 9.049 | Train Acc: 97.307
29 Train Loss: 8.338 | Train Acc: 97.542
30 Train Loss: 7.841 | Train Acc: 97.787
31 Train Loss: 7.929 | Train Acc: 97.684
32 Train Loss: 7.205 | Train Acc: 97.919
33 Train Loss: 7.065 | Train Acc: 97.985
34 Train Loss: 6.648 | Train Acc: 98.013
35 Train Loss: 6.492 | Train Acc: 98.183
36 Train Loss: 6.164 | Train Acc: 98.202
37 Train Loss: 5.883 | Train Acc: 98.399
38 Train Loss: 5.688 | Train Acc: 98.531
39 Train Loss: 5.170 | Train Acc: 98.625
40 Train Loss: 4.592 | Train Acc: 98.870
41 Train Loss: 4.559 | Train Acc: 98.795
42 Train Loss: 4.487 | Train Acc: 98.927
43 Train Loss: 4.344 | Train Acc: 98.917
44 Train Loss: 4.194 | Train Acc: 99.040
45 Train Loss: 4.207 | Train Acc: 98.974
46 Train Loss: 4.062 | Train Acc: 99.077
47 Train Loss: 4.031 | Train Acc: 99.011
48 Train Loss: 3.939 | Train Acc: 99.134
49 Train Loss: 3.949 | Train Acc: 99.105
50 Train Loss: 3.792 | Train Acc: 99.171
51 Train Loss: 3.715 | Train Acc: 99.143
52 Train Loss: 3.746 | Train Acc: 99.143
53 Train Loss: 3.520 | Train Acc: 99.218
54 Train Loss: 3.587 | Train Acc: 99.237
55 Train Loss: 3.451 | Train Acc: 99.275
56 Train Loss: 3.480 | Train Acc: 99.209
57 Train Loss: 3.319 | Train Acc: 99.275
58 Train Loss: 3.220 | Train Acc: 99.322
59 Train Loss: 3.146 | Train Acc: 99.379
60 Train Loss: 3.030 | Train Acc: 99.426
61 Train Loss: 2.931 | Train Acc: 99.454
62 Train Loss: 2.920 | Train Acc: 99.454
63 Train Loss: 2.897 | Train Acc: 99.454
64 Train Loss: 2.886 | Train Acc: 99.492
65 Train Loss: 2.847 | Train Acc: 99.473
66 Train Loss: 2.829 | Train Acc: 99.520
67 Train Loss: 2.787 | Train Acc: 99.473
68 Train Loss: 2.765 | Train Acc: 99.539
69 Train Loss: 2.760 | Train Acc: 99.473
70 Train Loss: 2.695 | Train Acc: 99.529
71 Train Loss: 2.665 | Train Acc: 99.529
72 Train Loss: 2.685 | Train Acc: 99.539
73 Train Loss: 2.651 | Train Acc: 99.539
74 Train Loss: 2.591 | Train Acc: 99.510
75 Train Loss: 2.579 | Train Acc: 99.586
76 Train Loss: 2.567 | Train Acc: 99.567
77 Train Loss: 2.548 | Train Acc: 99.576
78 Train Loss: 2.495 | Train Acc: 99.605
79 Train Loss: 2.480 | Train Acc: 99.623
80 Train Loss: 2.396 | Train Acc: 99.595
81 Train Loss: 2.381 | Train Acc: 99.633
82 Train Loss: 2.364 | Train Acc: 99.595
83 Train Loss: 2.369 | Train Acc: 99.642
84 Train Loss: 2.354 | Train Acc: 99.652
85 Train Loss: 2.337 | Train Acc: 99.652
86 Train Loss: 2.318 | Train Acc: 99.642
87 Train Loss: 2.326 | Train Acc: 99.661
88 Train Loss: 2.293 | Train Acc: 99.689
89 Train Loss: 2.303 | Train Acc: 99.661
90 Train Loss: 2.275 | Train Acc: 99.670
91 Train Loss: 2.289 | Train Acc: 99.633
92 Train Loss: 2.247 | Train Acc: 99.689
93 Train Loss: 2.259 | Train Acc: 99.689
94 Train Loss: 2.231 | Train Acc: 99.670
95 Train Loss: 2.221 | Train Acc: 99.689
96 Train Loss: 2.226 | Train Acc: 99.680
97 Train Loss: 2.181 | Train Acc: 99.699
98 Train Loss: 2.199 | Train Acc: 99.680
99 Train Loss: 2.182 | Train Acc: 99.708
CNN trained successfully...
image_next_flat.shape :  torch.Size([10620, 2304])
printing expected split from k means
{2: 1, 8: 1, 0: 0, 1: 1, 4: 1, 7: 0, 9: 1, 3: 1, 5: 1, 6: 1}
Printing final_dict items...
{2: 1, 8: 1, 0: 0, 1: 1, 4: 1, 7: 0, 9: 1, 3: 1, 5: 1, 6: 1}
Image Statistics before MLP : L R :  2821 7799
expectedMlpLabels.shape :  torch.Size([10620])
0 Loss: 25.163 | Acc: 88.340
1 Loss: 13.214 | Acc: 94.660
2 Loss: 10.776 | Acc: 95.387
3 Loss: 8.898 | Acc: 96.274
4 Loss: 9.822 | Acc: 95.604
5 Loss: 8.058 | Acc: 96.123
6 Loss: 7.637 | Acc: 96.425
7 Loss: 7.244 | Acc: 96.736
8 Loss: 6.562 | Acc: 97.179
9 Loss: 6.397 | Acc: 97.028
10 Loss: 5.001 | Acc: 97.623
11 Loss: 4.428 | Acc: 98.057
12 Loss: 4.037 | Acc: 98.217
13 Loss: 3.846 | Acc: 98.311
14 Loss: 3.735 | Acc: 98.208
15 Loss: 3.548 | Acc: 98.321
16 Loss: 3.245 | Acc: 98.566
17 Loss: 3.449 | Acc: 98.481
18 Loss: 3.666 | Acc: 98.349
19 Loss: 3.290 | Acc: 98.538
20 Loss: 2.443 | Acc: 98.934
21 Loss: 2.547 | Acc: 98.915
22 Loss: 2.463 | Acc: 98.972
23 Loss: 2.401 | Acc: 98.934
24 Loss: 2.176 | Acc: 98.991
25 Loss: 2.228 | Acc: 98.906
26 Loss: 1.918 | Acc: 99.160
27 Loss: 1.995 | Acc: 99.198
28 Loss: 1.755 | Acc: 99.245
29 Loss: 1.948 | Acc: 99.160
30 Loss: 1.679 | Acc: 99.274
31 Loss: 1.839 | Acc: 99.160
32 Loss: 1.566 | Acc: 99.302
33 Loss: 1.568 | Acc: 99.358
34 Loss: 1.638 | Acc: 99.292
35 Loss: 1.374 | Acc: 99.368
36 Loss: 1.272 | Acc: 99.509
37 Loss: 1.309 | Acc: 99.425
38 Loss: 1.334 | Acc: 99.387
39 Loss: 1.288 | Acc: 99.500
40 Loss: 1.475 | Acc: 99.415
41 Loss: 1.319 | Acc: 99.509
42 Loss: 1.435 | Acc: 99.406
43 Loss: 1.370 | Acc: 99.443
44 Loss: 1.392 | Acc: 99.472
45 Loss: 1.268 | Acc: 99.500
46 Loss: 1.288 | Acc: 99.472
47 Loss: 1.262 | Acc: 99.462
48 Loss: 1.341 | Acc: 99.443
49 Loss: 1.290 | Acc: 99.453
50 Loss: 1.155 | Acc: 99.425
51 Loss: 1.038 | Acc: 99.557
52 Loss: 0.934 | Acc: 99.623
53 Loss: 1.211 | Acc: 99.481
54 Loss: 1.325 | Acc: 99.377
55 Loss: 1.168 | Acc: 99.528
56 Loss: 1.188 | Acc: 99.528
57 Loss: 1.183 | Acc: 99.509
58 Loss: 1.049 | Acc: 99.528
59 Loss: 1.112 | Acc: 99.557
MLP trained successfully...
# of Left images:  956.0
# of Right images:  1117.0
giniRightRatio:  0.6728856309545087
giniLeftRatio:  0.5752087673535128
impurityDrop:  0.5892875274607289
giniGain:  0.042399271478798406
lclasses:  [548, 8, 63, 3, 28, 1, 0, 6, 288, 11]
rclasses:  [514, 48, 73, 9, 56, 11, 6, 3, 363, 34]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([956, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([956])
rTrainDict[data].shape:  torch.Size([1117, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([1117])
RETURNING FROM WORK...
nodeId:  34 , imgTensorShape :  torch.Size([956, 16, 12, 12])
nodeId: 34 ,  parentId: 17 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 9 ,  numData: 956
nodeId:  35 , imgTensorShape :  torch.Size([1117, 16, 12, 12])
nodeId: 35 ,  parentId: 17 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1117
Running nodeId:  18
trainInputDict[data].shape :  torch.Size([4636, 16, 16, 16])
copy.shape :  torch.Size([4636, 4096])
copyLabel.shape :  torch.Size([4636])
Class 0 has 1437 instances after oversampling
Class 1 has 1437 instances after oversampling
Class 2 has 1437 instances after oversampling
Class 3 has 1437 instances after oversampling
Class 4 has 1437 instances after oversampling
Class 5 has 1437 instances after oversampling
Class 6 has 1437 instances after oversampling
Class 7 has 1437 instances after oversampling
Class 8 has 1437 instances after oversampling
Class 9 has 1437 instances after oversampling
0 Train Loss: 227.970 | Train Acc: 16.235
1 Train Loss: 186.395 | Train Acc: 35.560
2 Train Loss: 132.228 | Train Acc: 58.156
3 Train Loss: 100.876 | Train Acc: 68.671
4 Train Loss: 73.492 | Train Acc: 77.425
5 Train Loss: 66.627 | Train Acc: 79.520
6 Train Loss: 47.777 | Train Acc: 85.059
7 Train Loss: 43.381 | Train Acc: 86.444
8 Train Loss: 40.201 | Train Acc: 87.237
9 Train Loss: 37.026 | Train Acc: 87.947
10 Train Loss: 32.851 | Train Acc: 89.555
11 Train Loss: 28.998 | Train Acc: 90.786
12 Train Loss: 24.619 | Train Acc: 92.234
13 Train Loss: 28.811 | Train Acc: 90.501
14 Train Loss: 24.158 | Train Acc: 92.248
15 Train Loss: 23.866 | Train Acc: 92.248
16 Train Loss: 20.706 | Train Acc: 93.250
17 Train Loss: 18.332 | Train Acc: 94.203
18 Train Loss: 16.859 | Train Acc: 94.628
19 Train Loss: 15.306 | Train Acc: 95.351
20 Train Loss: 12.637 | Train Acc: 96.347
21 Train Loss: 12.223 | Train Acc: 96.604
22 Train Loss: 11.765 | Train Acc: 96.667
23 Train Loss: 11.408 | Train Acc: 96.695
24 Train Loss: 11.015 | Train Acc: 96.945
25 Train Loss: 11.126 | Train Acc: 96.855
26 Train Loss: 10.378 | Train Acc: 97.189
27 Train Loss: 10.145 | Train Acc: 97.237
28 Train Loss: 10.276 | Train Acc: 97.084
29 Train Loss: 9.397 | Train Acc: 97.585
30 Train Loss: 8.976 | Train Acc: 97.648
31 Train Loss: 9.174 | Train Acc: 97.585
32 Train Loss: 8.530 | Train Acc: 97.794
33 Train Loss: 8.305 | Train Acc: 97.850
34 Train Loss: 7.915 | Train Acc: 98.038
35 Train Loss: 7.928 | Train Acc: 98.079
36 Train Loss: 7.589 | Train Acc: 98.156
37 Train Loss: 7.320 | Train Acc: 98.149
38 Train Loss: 7.162 | Train Acc: 98.239
39 Train Loss: 7.224 | Train Acc: 98.246
40 Train Loss: 6.026 | Train Acc: 98.733
41 Train Loss: 5.951 | Train Acc: 98.817
42 Train Loss: 5.819 | Train Acc: 98.935
43 Train Loss: 5.755 | Train Acc: 98.900
44 Train Loss: 5.664 | Train Acc: 98.935
45 Train Loss: 5.531 | Train Acc: 98.991
46 Train Loss: 5.461 | Train Acc: 99.026
47 Train Loss: 5.405 | Train Acc: 99.054
48 Train Loss: 5.297 | Train Acc: 99.081
49 Train Loss: 5.161 | Train Acc: 99.061
50 Train Loss: 5.190 | Train Acc: 99.019
51 Train Loss: 5.005 | Train Acc: 99.179
52 Train Loss: 4.994 | Train Acc: 99.200
53 Train Loss: 4.914 | Train Acc: 99.179
54 Train Loss: 4.746 | Train Acc: 99.283
55 Train Loss: 4.760 | Train Acc: 99.158
56 Train Loss: 4.601 | Train Acc: 99.304
57 Train Loss: 4.522 | Train Acc: 99.269
58 Train Loss: 4.528 | Train Acc: 99.207
59 Train Loss: 4.374 | Train Acc: 99.318
60 Train Loss: 4.088 | Train Acc: 99.395
61 Train Loss: 4.039 | Train Acc: 99.395
62 Train Loss: 3.987 | Train Acc: 99.450
63 Train Loss: 3.959 | Train Acc: 99.464
64 Train Loss: 3.934 | Train Acc: 99.506
65 Train Loss: 3.926 | Train Acc: 99.457
66 Train Loss: 3.881 | Train Acc: 99.478
67 Train Loss: 3.838 | Train Acc: 99.464
68 Train Loss: 3.751 | Train Acc: 99.506
69 Train Loss: 3.794 | Train Acc: 99.527
70 Train Loss: 3.737 | Train Acc: 99.534
71 Train Loss: 3.707 | Train Acc: 99.520
72 Train Loss: 3.691 | Train Acc: 99.534
73 Train Loss: 3.625 | Train Acc: 99.562
74 Train Loss: 3.620 | Train Acc: 99.548
75 Train Loss: 3.540 | Train Acc: 99.541
76 Train Loss: 3.542 | Train Acc: 99.548
77 Train Loss: 3.510 | Train Acc: 99.576
78 Train Loss: 3.432 | Train Acc: 99.562
79 Train Loss: 3.458 | Train Acc: 99.610
80 Train Loss: 3.326 | Train Acc: 99.638
81 Train Loss: 3.309 | Train Acc: 99.638
82 Train Loss: 3.297 | Train Acc: 99.624
83 Train Loss: 3.289 | Train Acc: 99.631
84 Train Loss: 3.272 | Train Acc: 99.631
85 Train Loss: 3.259 | Train Acc: 99.645
86 Train Loss: 3.246 | Train Acc: 99.631
87 Train Loss: 3.234 | Train Acc: 99.638
88 Train Loss: 3.224 | Train Acc: 99.666
89 Train Loss: 3.201 | Train Acc: 99.652
90 Train Loss: 3.197 | Train Acc: 99.680
91 Train Loss: 3.174 | Train Acc: 99.659
92 Train Loss: 3.165 | Train Acc: 99.673
93 Train Loss: 3.143 | Train Acc: 99.680
94 Train Loss: 3.137 | Train Acc: 99.673
95 Train Loss: 3.114 | Train Acc: 99.694
96 Train Loss: 3.109 | Train Acc: 99.659
97 Train Loss: 3.101 | Train Acc: 99.666
98 Train Loss: 3.083 | Train Acc: 99.673
99 Train Loss: 3.070 | Train Acc: 99.687
CNN trained successfully...
image_next_flat.shape :  torch.Size([14370, 2304])
printing expected split from k means
{7: 0, 6: 0, 1: 1, 2: 0, 0: 0, 8: 0, 9: 0, 4: 0, 5: 0, 3: 0}
Printing final_dict items...
{7: 0, 6: 0, 1: 1, 2: 0, 0: 0, 8: 0, 9: 0, 4: 0, 5: 0, 3: 0}
Image Statistics before MLP : L R :  10915 3455
expectedMlpLabels.shape :  torch.Size([14370])
0 Loss: 39.892 | Acc: 76.451
1 Loss: 24.404 | Acc: 87.015
2 Loss: 20.232 | Acc: 89.158
3 Loss: 19.083 | Acc: 89.979
4 Loss: 16.361 | Acc: 91.197
5 Loss: 14.794 | Acc: 91.781
6 Loss: 15.046 | Acc: 91.844
7 Loss: 13.656 | Acc: 92.422
8 Loss: 12.120 | Acc: 93.556
9 Loss: 12.112 | Acc: 93.674
10 Loss: 9.264 | Acc: 94.843
11 Loss: 8.295 | Acc: 95.818
12 Loss: 8.209 | Acc: 95.797
13 Loss: 8.038 | Acc: 96.013
14 Loss: 7.610 | Acc: 95.859
15 Loss: 7.076 | Acc: 96.374
16 Loss: 6.865 | Acc: 96.409
17 Loss: 6.885 | Acc: 96.681
18 Loss: 6.681 | Acc: 96.827
19 Loss: 6.793 | Acc: 96.347
20 Loss: 5.285 | Acc: 97.349
21 Loss: 4.954 | Acc: 97.523
22 Loss: 4.801 | Acc: 97.690
23 Loss: 4.724 | Acc: 97.641
24 Loss: 4.994 | Acc: 97.404
25 Loss: 4.325 | Acc: 97.829
26 Loss: 4.345 | Acc: 97.766
27 Loss: 4.166 | Acc: 97.954
28 Loss: 4.343 | Acc: 98.010
29 Loss: 3.966 | Acc: 98.051
30 Loss: 3.648 | Acc: 98.309
31 Loss: 4.046 | Acc: 98.156
32 Loss: 3.669 | Acc: 98.274
33 Loss: 3.431 | Acc: 98.365
34 Loss: 3.396 | Acc: 98.309
35 Loss: 3.502 | Acc: 98.323
36 Loss: 3.501 | Acc: 98.302
37 Loss: 3.101 | Acc: 98.608
38 Loss: 3.294 | Acc: 98.351
39 Loss: 3.115 | Acc: 98.525
40 Loss: 3.191 | Acc: 98.497
41 Loss: 2.955 | Acc: 98.587
42 Loss: 2.896 | Acc: 98.629
43 Loss: 2.694 | Acc: 98.775
44 Loss: 2.822 | Acc: 98.740
45 Loss: 2.786 | Acc: 98.720
46 Loss: 2.618 | Acc: 98.824
47 Loss: 2.641 | Acc: 98.761
48 Loss: 2.743 | Acc: 98.699
49 Loss: 2.997 | Acc: 98.566
50 Loss: 2.563 | Acc: 98.775
51 Loss: 2.622 | Acc: 98.664
52 Loss: 2.813 | Acc: 98.685
53 Loss: 2.433 | Acc: 98.831
54 Loss: 2.690 | Acc: 98.768
55 Loss: 2.840 | Acc: 98.587
56 Loss: 2.851 | Acc: 98.775
57 Loss: 2.670 | Acc: 98.733
58 Loss: 2.606 | Acc: 98.761
59 Loss: 2.741 | Acc: 98.727
MLP trained successfully...
# of Left images:  2560.0
# of Right images:  2076.0
giniRightRatio:  0.7115423168164656
giniLeftRatio:  0.7386343383789062
impurityDrop:  0.7449505900341188
giniGain:  0.014360008418475956
lclasses:  [210, 468, 59, 38, 63, 19, 31, 71, 524, 1077]
rclasses:  [196, 932, 39, 19, 23, 12, 7, 38, 450, 360]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2560, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([2560])
rTrainDict[data].shape:  torch.Size([2076, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([2076])
RETURNING FROM WORK...
nodeId:  36 , imgTensorShape :  torch.Size([2560, 16, 12, 12])
nodeId: 36 ,  parentId: 18 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2560
nodeId:  37 , imgTensorShape :  torch.Size([2076, 16, 12, 12])
nodeId: 37 ,  parentId: 18 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2076
Running nodeId:  19
trainInputDict[data].shape :  torch.Size([5149, 16, 16, 16])
copy.shape :  torch.Size([5149, 4096])
copyLabel.shape :  torch.Size([5149])
Class 0 has 1658 instances after oversampling
Class 1 has 1658 instances after oversampling
Class 2 has 1658 instances after oversampling
Class 3 has 1658 instances after oversampling
Class 4 has 1658 instances after oversampling
Class 5 has 1658 instances after oversampling
Class 6 has 1658 instances after oversampling
Class 7 has 1658 instances after oversampling
Class 8 has 1658 instances after oversampling
Class 9 has 1658 instances after oversampling
0 Train Loss: 233.852 | Train Acc: 12.666
1 Train Loss: 202.323 | Train Acc: 27.461
2 Train Loss: 153.532 | Train Acc: 49.162
3 Train Loss: 111.318 | Train Acc: 63.414
4 Train Loss: 95.344 | Train Acc: 67.600
5 Train Loss: 78.315 | Train Acc: 73.378
6 Train Loss: 70.969 | Train Acc: 75.103
7 Train Loss: 63.178 | Train Acc: 77.780
8 Train Loss: 56.167 | Train Acc: 80.133
9 Train Loss: 48.186 | Train Acc: 83.046
10 Train Loss: 47.636 | Train Acc: 83.082
11 Train Loss: 44.094 | Train Acc: 84.138
12 Train Loss: 39.053 | Train Acc: 86.496
13 Train Loss: 37.889 | Train Acc: 86.616
14 Train Loss: 32.881 | Train Acc: 88.124
15 Train Loss: 36.903 | Train Acc: 86.568
16 Train Loss: 32.257 | Train Acc: 88.299
17 Train Loss: 28.226 | Train Acc: 90.199
18 Train Loss: 26.773 | Train Acc: 90.476
19 Train Loss: 25.765 | Train Acc: 90.953
20 Train Loss: 22.054 | Train Acc: 92.400
21 Train Loss: 21.080 | Train Acc: 92.762
22 Train Loss: 20.157 | Train Acc: 92.986
23 Train Loss: 19.458 | Train Acc: 93.438
24 Train Loss: 18.934 | Train Acc: 93.727
25 Train Loss: 18.660 | Train Acc: 93.794
26 Train Loss: 18.113 | Train Acc: 93.866
27 Train Loss: 17.498 | Train Acc: 94.192
28 Train Loss: 17.568 | Train Acc: 94.288
29 Train Loss: 16.730 | Train Acc: 94.698
30 Train Loss: 16.241 | Train Acc: 94.789
31 Train Loss: 16.117 | Train Acc: 94.735
32 Train Loss: 15.576 | Train Acc: 95.006
33 Train Loss: 15.430 | Train Acc: 95.006
34 Train Loss: 14.770 | Train Acc: 95.446
35 Train Loss: 15.300 | Train Acc: 94.825
36 Train Loss: 14.477 | Train Acc: 95.386
37 Train Loss: 14.042 | Train Acc: 95.585
38 Train Loss: 13.607 | Train Acc: 95.832
39 Train Loss: 13.182 | Train Acc: 95.796
40 Train Loss: 12.100 | Train Acc: 96.435
41 Train Loss: 11.934 | Train Acc: 96.454
42 Train Loss: 11.705 | Train Acc: 96.496
43 Train Loss: 11.666 | Train Acc: 96.616
44 Train Loss: 11.459 | Train Acc: 96.701
45 Train Loss: 11.436 | Train Acc: 96.755
46 Train Loss: 11.277 | Train Acc: 96.731
47 Train Loss: 11.227 | Train Acc: 96.779
48 Train Loss: 11.056 | Train Acc: 96.900
49 Train Loss: 10.846 | Train Acc: 96.870
50 Train Loss: 10.773 | Train Acc: 96.900
51 Train Loss: 10.818 | Train Acc: 96.984
52 Train Loss: 10.565 | Train Acc: 97.039
53 Train Loss: 10.398 | Train Acc: 97.075
54 Train Loss: 10.341 | Train Acc: 97.177
55 Train Loss: 10.174 | Train Acc: 97.093
56 Train Loss: 10.136 | Train Acc: 97.159
57 Train Loss: 10.026 | Train Acc: 97.153
58 Train Loss: 9.973 | Train Acc: 97.310
59 Train Loss: 9.937 | Train Acc: 97.334
60 Train Loss: 9.305 | Train Acc: 97.575
61 Train Loss: 9.231 | Train Acc: 97.527
62 Train Loss: 9.224 | Train Acc: 97.636
63 Train Loss: 9.128 | Train Acc: 97.581
64 Train Loss: 9.133 | Train Acc: 97.714
65 Train Loss: 9.020 | Train Acc: 97.684
66 Train Loss: 8.983 | Train Acc: 97.672
67 Train Loss: 8.976 | Train Acc: 97.636
68 Train Loss: 8.926 | Train Acc: 97.708
69 Train Loss: 8.869 | Train Acc: 97.702
70 Train Loss: 8.795 | Train Acc: 97.780
71 Train Loss: 8.818 | Train Acc: 97.690
72 Train Loss: 8.674 | Train Acc: 97.714
73 Train Loss: 8.651 | Train Acc: 97.865
74 Train Loss: 8.589 | Train Acc: 97.859
75 Train Loss: 8.562 | Train Acc: 97.883
76 Train Loss: 8.502 | Train Acc: 97.865
77 Train Loss: 8.461 | Train Acc: 97.865
78 Train Loss: 8.439 | Train Acc: 97.889
79 Train Loss: 8.366 | Train Acc: 97.877
80 Train Loss: 8.192 | Train Acc: 97.919
81 Train Loss: 8.165 | Train Acc: 97.992
82 Train Loss: 8.146 | Train Acc: 98.010
83 Train Loss: 8.138 | Train Acc: 97.919
84 Train Loss: 8.124 | Train Acc: 97.955
85 Train Loss: 8.110 | Train Acc: 98.004
86 Train Loss: 8.069 | Train Acc: 98.028
87 Train Loss: 8.049 | Train Acc: 97.998
88 Train Loss: 8.035 | Train Acc: 98.022
89 Train Loss: 8.008 | Train Acc: 98.022
90 Train Loss: 8.006 | Train Acc: 98.022
91 Train Loss: 7.975 | Train Acc: 98.046
92 Train Loss: 7.971 | Train Acc: 98.016
93 Train Loss: 7.938 | Train Acc: 98.034
94 Train Loss: 7.926 | Train Acc: 98.058
95 Train Loss: 7.900 | Train Acc: 98.028
96 Train Loss: 7.886 | Train Acc: 98.034
97 Train Loss: 7.846 | Train Acc: 98.106
98 Train Loss: 7.839 | Train Acc: 98.064
99 Train Loss: 7.818 | Train Acc: 98.076
CNN trained successfully...
image_next_flat.shape :  torch.Size([16580, 2304])
printing expected split from k means
{8: 0, 9: 1, 0: 0, 1: 1, 4: 1, 2: 1, 5: 0, 3: 1, 7: 1, 6: 1}
Printing final_dict items...
{8: 0, 9: 1, 0: 0, 1: 1, 4: 1, 2: 1, 5: 0, 3: 1, 7: 1, 6: 1}
Image Statistics before MLP : L R :  6400 10180
expectedMlpLabels.shape :  torch.Size([16580])
0 Loss: 18.870 | Acc: 94.686
1 Loss: 8.347 | Acc: 97.690
2 Loss: 7.210 | Acc: 98.016
3 Loss: 6.597 | Acc: 98.076
4 Loss: 5.647 | Acc: 98.372
5 Loss: 4.550 | Acc: 98.583
6 Loss: 4.953 | Acc: 98.709
7 Loss: 4.649 | Acc: 98.739
8 Loss: 4.008 | Acc: 98.920
9 Loss: 3.562 | Acc: 98.999
10 Loss: 2.352 | Acc: 99.343
11 Loss: 2.023 | Acc: 99.445
12 Loss: 1.989 | Acc: 99.469
13 Loss: 1.852 | Acc: 99.469
14 Loss: 1.468 | Acc: 99.554
15 Loss: 1.770 | Acc: 99.499
16 Loss: 1.489 | Acc: 99.626
17 Loss: 1.596 | Acc: 99.578
18 Loss: 1.406 | Acc: 99.584
19 Loss: 1.572 | Acc: 99.620
20 Loss: 1.115 | Acc: 99.783
21 Loss: 1.021 | Acc: 99.759
22 Loss: 0.782 | Acc: 99.813
23 Loss: 0.831 | Acc: 99.795
24 Loss: 0.779 | Acc: 99.813
25 Loss: 0.686 | Acc: 99.783
26 Loss: 0.692 | Acc: 99.807
27 Loss: 0.529 | Acc: 99.855
28 Loss: 0.879 | Acc: 99.777
29 Loss: 0.826 | Acc: 99.783
30 Loss: 0.588 | Acc: 99.849
31 Loss: 0.639 | Acc: 99.831
32 Loss: 0.523 | Acc: 99.910
33 Loss: 0.430 | Acc: 99.885
34 Loss: 0.428 | Acc: 99.867
35 Loss: 0.394 | Acc: 99.897
36 Loss: 0.481 | Acc: 99.885
37 Loss: 0.559 | Acc: 99.861
38 Loss: 0.516 | Acc: 99.831
39 Loss: 0.390 | Acc: 99.910
40 Loss: 0.395 | Acc: 99.922
41 Loss: 0.379 | Acc: 99.897
42 Loss: 0.410 | Acc: 99.891
43 Loss: 0.248 | Acc: 99.946
44 Loss: 0.346 | Acc: 99.940
45 Loss: 0.465 | Acc: 99.897
46 Loss: 0.422 | Acc: 99.934
47 Loss: 0.298 | Acc: 99.946
48 Loss: 0.490 | Acc: 99.873
49 Loss: 0.317 | Acc: 99.922
50 Loss: 0.322 | Acc: 99.922
51 Loss: 0.372 | Acc: 99.903
52 Loss: 0.267 | Acc: 99.940
53 Loss: 0.360 | Acc: 99.903
54 Loss: 0.372 | Acc: 99.903
55 Loss: 0.252 | Acc: 99.922
56 Loss: 0.308 | Acc: 99.940
57 Loss: 0.248 | Acc: 99.952
58 Loss: 0.375 | Acc: 99.903
59 Loss: 0.356 | Acc: 99.922
MLP trained successfully...
# of Left images:  2667.0
# of Right images:  2482.0
giniRightRatio:  0.766623963285048
giniLeftRatio:  0.6948169724003846
impurityDrop:  0.6894647188493521
giniGain:  0.05762587540195119
lclasses:  [678, 626, 26, 5, 19, 7, 1, 3, 1136, 166]
rclasses:  [587, 757, 30, 8, 30, 1, 15, 38, 522, 494]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2667, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([2667])
rTrainDict[data].shape:  torch.Size([2482, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([2482])
RETURNING FROM WORK...
nodeId:  38 , imgTensorShape :  torch.Size([2667, 16, 12, 12])
nodeId: 38 ,  parentId: 19 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2667
nodeId:  39 , imgTensorShape :  torch.Size([2482, 16, 12, 12])
nodeId: 39 ,  parentId: 19 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2482
Running nodeId:  20
trainInputDict[data].shape :  torch.Size([3013, 16, 16, 16])
copy.shape :  torch.Size([3013, 4096])
copyLabel.shape :  torch.Size([3013])
Class 0 has 733 instances after oversampling
Class 1 has 732 instances after oversampling
Class 2 has 732 instances after oversampling
Class 3 has 733 instances after oversampling
Class 4 has 732 instances after oversampling
Class 5 has 732 instances after oversampling
Class 6 has 732 instances after oversampling
Class 7 has 733 instances after oversampling
Class 8 has 732 instances after oversampling
Class 9 has 733 instances after oversampling
0 Train Loss: 228.771 | Train Acc: 13.192
1 Train Loss: 207.638 | Train Acc: 24.658
2 Train Loss: 190.279 | Train Acc: 33.589
3 Train Loss: 173.212 | Train Acc: 40.616
4 Train Loss: 156.497 | Train Acc: 48.123
5 Train Loss: 145.311 | Train Acc: 51.123
6 Train Loss: 133.133 | Train Acc: 56.685
7 Train Loss: 112.344 | Train Acc: 63.795
8 Train Loss: 101.239 | Train Acc: 67.849
9 Train Loss: 92.064 | Train Acc: 70.685
10 Train Loss: 77.217 | Train Acc: 76.370
11 Train Loss: 66.214 | Train Acc: 80.753
12 Train Loss: 58.292 | Train Acc: 82.849
13 Train Loss: 49.175 | Train Acc: 86.041
14 Train Loss: 39.299 | Train Acc: 88.959
15 Train Loss: 33.544 | Train Acc: 90.575
16 Train Loss: 30.241 | Train Acc: 91.767
17 Train Loss: 22.206 | Train Acc: 94.753
18 Train Loss: 17.166 | Train Acc: 96.178
19 Train Loss: 14.682 | Train Acc: 96.767
20 Train Loss: 9.543 | Train Acc: 98.904
21 Train Loss: 8.006 | Train Acc: 99.178
22 Train Loss: 7.274 | Train Acc: 99.521
23 Train Loss: 6.407 | Train Acc: 99.521
24 Train Loss: 5.782 | Train Acc: 99.616
25 Train Loss: 5.305 | Train Acc: 99.767
26 Train Loss: 4.934 | Train Acc: 99.849
27 Train Loss: 4.619 | Train Acc: 99.822
28 Train Loss: 4.073 | Train Acc: 99.918
29 Train Loss: 3.784 | Train Acc: 99.918
30 Train Loss: 3.472 | Train Acc: 99.945
31 Train Loss: 3.165 | Train Acc: 99.918
32 Train Loss: 2.984 | Train Acc: 99.959
33 Train Loss: 2.689 | Train Acc: 99.973
34 Train Loss: 2.463 | Train Acc: 99.973
35 Train Loss: 2.302 | Train Acc: 99.973
36 Train Loss: 2.126 | Train Acc: 99.973
37 Train Loss: 1.974 | Train Acc: 100.000
38 Train Loss: 1.788 | Train Acc: 100.000
39 Train Loss: 1.719 | Train Acc: 100.000
40 Train Loss: 1.485 | Train Acc: 100.000
41 Train Loss: 1.418 | Train Acc: 100.000
42 Train Loss: 1.371 | Train Acc: 100.000
43 Train Loss: 1.334 | Train Acc: 100.000
44 Train Loss: 1.310 | Train Acc: 100.000
45 Train Loss: 1.267 | Train Acc: 100.000
46 Train Loss: 1.231 | Train Acc: 100.000
47 Train Loss: 1.193 | Train Acc: 100.000
48 Train Loss: 1.145 | Train Acc: 100.000
49 Train Loss: 1.122 | Train Acc: 100.000
50 Train Loss: 1.076 | Train Acc: 100.000
51 Train Loss: 1.047 | Train Acc: 100.000
52 Train Loss: 1.012 | Train Acc: 100.000
53 Train Loss: 0.969 | Train Acc: 100.000
54 Train Loss: 0.935 | Train Acc: 100.000
55 Train Loss: 0.910 | Train Acc: 100.000
56 Train Loss: 0.874 | Train Acc: 100.000
57 Train Loss: 0.844 | Train Acc: 100.000
58 Train Loss: 0.825 | Train Acc: 100.000
59 Train Loss: 0.794 | Train Acc: 100.000
60 Train Loss: 0.729 | Train Acc: 100.000
61 Train Loss: 0.717 | Train Acc: 100.000
62 Train Loss: 0.707 | Train Acc: 100.000
63 Train Loss: 0.696 | Train Acc: 100.000
64 Train Loss: 0.686 | Train Acc: 100.000
65 Train Loss: 0.673 | Train Acc: 100.000
66 Train Loss: 0.665 | Train Acc: 100.000
67 Train Loss: 0.651 | Train Acc: 100.000
68 Train Loss: 0.639 | Train Acc: 100.000
69 Train Loss: 0.632 | Train Acc: 100.000
70 Train Loss: 0.619 | Train Acc: 100.000
71 Train Loss: 0.603 | Train Acc: 100.000
72 Train Loss: 0.596 | Train Acc: 100.000
73 Train Loss: 0.585 | Train Acc: 100.000
74 Train Loss: 0.570 | Train Acc: 100.000
75 Train Loss: 0.559 | Train Acc: 100.000
76 Train Loss: 0.547 | Train Acc: 100.000
77 Train Loss: 0.536 | Train Acc: 100.000
78 Train Loss: 0.528 | Train Acc: 100.000
79 Train Loss: 0.515 | Train Acc: 100.000
80 Train Loss: 0.494 | Train Acc: 100.000
81 Train Loss: 0.487 | Train Acc: 100.000
82 Train Loss: 0.481 | Train Acc: 100.000
83 Train Loss: 0.475 | Train Acc: 100.000
84 Train Loss: 0.473 | Train Acc: 100.000
85 Train Loss: 0.467 | Train Acc: 100.000
86 Train Loss: 0.464 | Train Acc: 100.000
87 Train Loss: 0.458 | Train Acc: 100.000
88 Train Loss: 0.454 | Train Acc: 100.000
89 Train Loss: 0.450 | Train Acc: 100.000
90 Train Loss: 0.444 | Train Acc: 100.000
91 Train Loss: 0.440 | Train Acc: 100.000
92 Train Loss: 0.434 | Train Acc: 100.000
93 Train Loss: 0.429 | Train Acc: 100.000
94 Train Loss: 0.423 | Train Acc: 100.000
95 Train Loss: 0.419 | Train Acc: 100.000
96 Train Loss: 0.414 | Train Acc: 100.000
97 Train Loss: 0.409 | Train Acc: 100.000
98 Train Loss: 0.404 | Train Acc: 100.000
99 Train Loss: 0.399 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([7324, 2304])
printing expected split from k means
{9: 0, 3: 1, 1: 0, 0: 1, 8: 0, 7: 1, 2: 1, 4: 1, 6: 1, 5: 1}
Printing final_dict items...
{9: 0, 3: 1, 1: 0, 0: 1, 8: 0, 7: 1, 2: 1, 4: 1, 6: 1, 5: 1}
Image Statistics before MLP : L R :  3316 4008
expectedMlpLabels.shape :  torch.Size([7324])
0 Loss: 24.583 | Acc: 93.958
1 Loss: 15.274 | Acc: 96.556
2 Loss: 10.967 | Acc: 97.417
3 Loss: 10.406 | Acc: 97.819
4 Loss: 7.791 | Acc: 98.250
5 Loss: 8.716 | Acc: 98.167
6 Loss: 6.588 | Acc: 98.583
7 Loss: 6.858 | Acc: 98.486
8 Loss: 5.432 | Acc: 98.681
9 Loss: 5.768 | Acc: 98.847
10 Loss: 3.215 | Acc: 99.361
11 Loss: 2.359 | Acc: 99.486
12 Loss: 2.111 | Acc: 99.542
13 Loss: 1.862 | Acc: 99.556
14 Loss: 2.051 | Acc: 99.583
15 Loss: 1.676 | Acc: 99.681
16 Loss: 2.222 | Acc: 99.542
17 Loss: 1.481 | Acc: 99.722
18 Loss: 1.956 | Acc: 99.583
19 Loss: 1.773 | Acc: 99.694
20 Loss: 1.449 | Acc: 99.681
21 Loss: 1.012 | Acc: 99.792
22 Loss: 1.145 | Acc: 99.750
23 Loss: 0.752 | Acc: 99.875
24 Loss: 0.980 | Acc: 99.792
25 Loss: 0.452 | Acc: 99.903
26 Loss: 0.633 | Acc: 99.847
27 Loss: 0.694 | Acc: 99.833
28 Loss: 1.104 | Acc: 99.847
29 Loss: 0.650 | Acc: 99.917
30 Loss: 0.616 | Acc: 99.875
31 Loss: 0.509 | Acc: 99.875
32 Loss: 0.483 | Acc: 99.903
33 Loss: 0.438 | Acc: 99.889
34 Loss: 0.617 | Acc: 99.903
35 Loss: 0.433 | Acc: 99.903
36 Loss: 0.394 | Acc: 99.931
37 Loss: 0.727 | Acc: 99.875
38 Loss: 0.277 | Acc: 99.958
39 Loss: 0.433 | Acc: 99.875
40 Loss: 0.242 | Acc: 99.986
41 Loss: 0.349 | Acc: 99.972
42 Loss: 0.406 | Acc: 99.931
43 Loss: 0.278 | Acc: 99.944
44 Loss: 0.346 | Acc: 99.944
45 Loss: 0.373 | Acc: 99.903
46 Loss: 0.370 | Acc: 99.903
47 Loss: 0.391 | Acc: 99.903
48 Loss: 0.288 | Acc: 99.958
49 Loss: 0.378 | Acc: 99.903
50 Loss: 0.377 | Acc: 99.944
51 Loss: 0.481 | Acc: 99.903
52 Loss: 0.286 | Acc: 99.944
53 Loss: 0.368 | Acc: 99.944
54 Loss: 0.331 | Acc: 99.958
55 Loss: 0.187 | Acc: 99.986
56 Loss: 0.282 | Acc: 99.917
57 Loss: 0.373 | Acc: 99.917
58 Loss: 0.177 | Acc: 99.986
59 Loss: 0.457 | Acc: 99.875
MLP trained successfully...
# of Left images:  1583.0
# of Right images:  1430.0
giniRightRatio:  0.8648462027483006
giniLeftRatio:  0.8020706423947748
impurityDrop:  0.79535409642688
giniGain:  0.0700076301503626
lclasses:  [141, 206, 65, 71, 60, 64, 37, 197, 146, 596]
rclasses:  [158, 19, 134, 231, 100, 156, 121, 332, 42, 137]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1583, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([1583])
rTrainDict[data].shape:  torch.Size([1430, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([1430])
RETURNING FROM WORK...
nodeId:  40 , imgTensorShape :  torch.Size([1583, 16, 12, 12])
nodeId: 40 ,  parentId: 20 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1583
nodeId:  41 , imgTensorShape :  torch.Size([1430, 16, 12, 12])
nodeId: 41 ,  parentId: 20 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1430
Running nodeId:  21
trainInputDict[data].shape :  torch.Size([970, 16, 16, 16])
copy.shape :  torch.Size([970, 4096])
copyLabel.shape :  torch.Size([970])
Class 0 has 324 instances after oversampling
Class 1 has 324 instances after oversampling
Class 2 has 324 instances after oversampling
Class 3 has 324 instances after oversampling
Class 4 has 324 instances after oversampling
Class 5 has 324 instances after oversampling
Class 6 has 324 instances after oversampling
Class 7 has 324 instances after oversampling
Class 8 has 324 instances after oversampling
Class 9 has 324 instances after oversampling
0 Train Loss: 224.830 | Train Acc: 19.688
1 Train Loss: 162.217 | Train Acc: 47.344
2 Train Loss: 97.895 | Train Acc: 69.469
3 Train Loss: 63.547 | Train Acc: 81.594
4 Train Loss: 41.991 | Train Acc: 88.781
5 Train Loss: 30.213 | Train Acc: 91.562
6 Train Loss: 21.494 | Train Acc: 94.219
7 Train Loss: 15.458 | Train Acc: 95.969
8 Train Loss: 9.110 | Train Acc: 98.188
9 Train Loss: 7.041 | Train Acc: 98.344
10 Train Loss: 4.958 | Train Acc: 99.000
11 Train Loss: 3.767 | Train Acc: 99.562
12 Train Loss: 2.176 | Train Acc: 99.875
13 Train Loss: 1.726 | Train Acc: 99.938
14 Train Loss: 1.109 | Train Acc: 100.000
15 Train Loss: 0.822 | Train Acc: 100.000
16 Train Loss: 0.721 | Train Acc: 100.000
17 Train Loss: 0.735 | Train Acc: 99.969
18 Train Loss: 0.518 | Train Acc: 100.000
19 Train Loss: 0.427 | Train Acc: 100.000
20 Train Loss: 0.333 | Train Acc: 100.000
21 Train Loss: 0.307 | Train Acc: 100.000
22 Train Loss: 0.285 | Train Acc: 100.000
23 Train Loss: 0.270 | Train Acc: 100.000
24 Train Loss: 0.257 | Train Acc: 100.000
25 Train Loss: 0.242 | Train Acc: 100.000
26 Train Loss: 0.227 | Train Acc: 100.000
27 Train Loss: 0.214 | Train Acc: 100.000
28 Train Loss: 0.203 | Train Acc: 100.000
29 Train Loss: 0.193 | Train Acc: 100.000
30 Train Loss: 0.184 | Train Acc: 100.000
31 Train Loss: 0.172 | Train Acc: 100.000
32 Train Loss: 0.161 | Train Acc: 100.000
33 Train Loss: 0.152 | Train Acc: 100.000
34 Train Loss: 0.144 | Train Acc: 100.000
35 Train Loss: 0.134 | Train Acc: 100.000
36 Train Loss: 0.128 | Train Acc: 100.000
37 Train Loss: 0.119 | Train Acc: 100.000
38 Train Loss: 0.112 | Train Acc: 100.000
39 Train Loss: 0.107 | Train Acc: 100.000
40 Train Loss: 0.098 | Train Acc: 100.000
41 Train Loss: 0.095 | Train Acc: 100.000
42 Train Loss: 0.093 | Train Acc: 100.000
43 Train Loss: 0.091 | Train Acc: 100.000
44 Train Loss: 0.088 | Train Acc: 100.000
45 Train Loss: 0.086 | Train Acc: 100.000
46 Train Loss: 0.084 | Train Acc: 100.000
47 Train Loss: 0.081 | Train Acc: 100.000
48 Train Loss: 0.079 | Train Acc: 100.000
49 Train Loss: 0.077 | Train Acc: 100.000
50 Train Loss: 0.075 | Train Acc: 100.000
51 Train Loss: 0.072 | Train Acc: 100.000
52 Train Loss: 0.070 | Train Acc: 100.000
53 Train Loss: 0.068 | Train Acc: 100.000
54 Train Loss: 0.066 | Train Acc: 100.000
55 Train Loss: 0.063 | Train Acc: 100.000
56 Train Loss: 0.061 | Train Acc: 100.000
57 Train Loss: 0.059 | Train Acc: 100.000
58 Train Loss: 0.057 | Train Acc: 100.000
59 Train Loss: 0.055 | Train Acc: 100.000
60 Train Loss: 0.052 | Train Acc: 100.000
61 Train Loss: 0.051 | Train Acc: 100.000
62 Train Loss: 0.050 | Train Acc: 100.000
63 Train Loss: 0.049 | Train Acc: 100.000
64 Train Loss: 0.049 | Train Acc: 100.000
65 Train Loss: 0.048 | Train Acc: 100.000
66 Train Loss: 0.047 | Train Acc: 100.000
67 Train Loss: 0.046 | Train Acc: 100.000
68 Train Loss: 0.045 | Train Acc: 100.000
69 Train Loss: 0.044 | Train Acc: 100.000
70 Train Loss: 0.043 | Train Acc: 100.000
71 Train Loss: 0.043 | Train Acc: 100.000
72 Train Loss: 0.042 | Train Acc: 100.000
73 Train Loss: 0.041 | Train Acc: 100.000
74 Train Loss: 0.040 | Train Acc: 100.000
75 Train Loss: 0.039 | Train Acc: 100.000
76 Train Loss: 0.038 | Train Acc: 100.000
77 Train Loss: 0.037 | Train Acc: 100.000
78 Train Loss: 0.036 | Train Acc: 100.000
79 Train Loss: 0.035 | Train Acc: 100.000
80 Train Loss: 0.034 | Train Acc: 100.000
81 Train Loss: 0.034 | Train Acc: 100.000
82 Train Loss: 0.033 | Train Acc: 100.000
83 Train Loss: 0.033 | Train Acc: 100.000
84 Train Loss: 0.032 | Train Acc: 100.000
85 Train Loss: 0.032 | Train Acc: 100.000
86 Train Loss: 0.032 | Train Acc: 100.000
87 Train Loss: 0.031 | Train Acc: 100.000
88 Train Loss: 0.031 | Train Acc: 100.000
89 Train Loss: 0.030 | Train Acc: 100.000
90 Train Loss: 0.030 | Train Acc: 100.000
91 Train Loss: 0.030 | Train Acc: 100.000
92 Train Loss: 0.029 | Train Acc: 100.000
93 Train Loss: 0.029 | Train Acc: 100.000
94 Train Loss: 0.028 | Train Acc: 100.000
95 Train Loss: 0.028 | Train Acc: 100.000
96 Train Loss: 0.027 | Train Acc: 100.000
97 Train Loss: 0.027 | Train Acc: 100.000
98 Train Loss: 0.026 | Train Acc: 100.000
99 Train Loss: 0.026 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([3240, 2304])
printing expected split from k means
{4: 0, 7: 0, 0: 1, 2: 0, 9: 1, 5: 0, 8: 1, 6: 1, 3: 0, 1: 1}
Printing final_dict items...
{4: 0, 7: 0, 0: 1, 2: 0, 9: 1, 5: 0, 8: 1, 6: 1, 3: 0, 1: 1}
Image Statistics before MLP : L R :  1433 1807
expectedMlpLabels.shape :  torch.Size([3240])
0 Loss: 31.446 | Acc: 92.094
1 Loss: 20.734 | Acc: 95.500
2 Loss: 13.161 | Acc: 97.125
3 Loss: 13.647 | Acc: 96.781
4 Loss: 14.018 | Acc: 97.250
5 Loss: 8.822 | Acc: 97.969
6 Loss: 8.723 | Acc: 98.094
7 Loss: 8.180 | Acc: 98.344
8 Loss: 7.340 | Acc: 98.438
9 Loss: 9.825 | Acc: 98.219
10 Loss: 7.014 | Acc: 98.469
11 Loss: 3.858 | Acc: 99.094
12 Loss: 3.266 | Acc: 99.344
13 Loss: 3.699 | Acc: 99.156
14 Loss: 2.341 | Acc: 99.594
15 Loss: 3.319 | Acc: 99.250
16 Loss: 4.048 | Acc: 99.250
17 Loss: 2.354 | Acc: 99.375
18 Loss: 2.477 | Acc: 99.531
19 Loss: 2.344 | Acc: 99.562
20 Loss: 1.759 | Acc: 99.688
21 Loss: 1.340 | Acc: 99.688
22 Loss: 1.047 | Acc: 99.781
23 Loss: 1.262 | Acc: 99.688
24 Loss: 1.006 | Acc: 99.750
25 Loss: 1.252 | Acc: 99.688
26 Loss: 0.960 | Acc: 99.812
27 Loss: 1.414 | Acc: 99.625
28 Loss: 1.834 | Acc: 99.656
29 Loss: 1.312 | Acc: 99.781
30 Loss: 0.890 | Acc: 99.844
31 Loss: 0.676 | Acc: 99.844
32 Loss: 0.697 | Acc: 99.844
33 Loss: 0.758 | Acc: 99.812
34 Loss: 0.592 | Acc: 99.938
35 Loss: 0.636 | Acc: 99.875
36 Loss: 0.488 | Acc: 99.938
37 Loss: 0.810 | Acc: 99.750
38 Loss: 0.917 | Acc: 99.875
39 Loss: 0.561 | Acc: 99.844
40 Loss: 0.556 | Acc: 99.812
41 Loss: 1.295 | Acc: 99.812
42 Loss: 0.695 | Acc: 99.812
43 Loss: 0.366 | Acc: 99.906
44 Loss: 0.515 | Acc: 99.875
45 Loss: 0.708 | Acc: 99.844
46 Loss: 0.771 | Acc: 99.812
47 Loss: 0.648 | Acc: 99.812
48 Loss: 0.563 | Acc: 99.875
49 Loss: 0.519 | Acc: 99.875
50 Loss: 0.462 | Acc: 99.875
51 Loss: 0.477 | Acc: 99.875
52 Loss: 0.496 | Acc: 99.875
53 Loss: 0.547 | Acc: 99.875
54 Loss: 0.536 | Acc: 99.844
55 Loss: 0.468 | Acc: 99.875
56 Loss: 0.448 | Acc: 99.906
57 Loss: 0.593 | Acc: 99.844
58 Loss: 0.574 | Acc: 99.875
59 Loss: 0.565 | Acc: 99.781
MLP trained successfully...
# of Left images:  497.0
# of Right images:  473.0
giniRightRatio:  0.7775478368919541
giniLeftRatio:  0.8211360719649892
impurityDrop:  0.8233477371695406
giniGain:  -0.007873191521756473
lclasses:  [127, 2, 99, 43, 67, 33, 11, 103, 9, 3]
rclasses:  [197, 40, 65, 31, 21, 14, 10, 45, 34, 16]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([497, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([497])
rTrainDict[data].shape:  torch.Size([473, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([473])
RETURNING FROM WORK...
nodeId:  42 , imgTensorShape :  torch.Size([497, 16, 12, 12])
nodeId: 42 ,  parentId: 21 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 497
nodeId:  43 , imgTensorShape :  torch.Size([473, 16, 12, 12])
nodeId: 43 ,  parentId: 21 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 473
Running nodeId:  22
trainInputDict[data].shape :  torch.Size([2355, 16, 16, 16])
copy.shape :  torch.Size([2355, 4096])
copyLabel.shape :  torch.Size([2355])
Class 0 has 378 instances after oversampling
Class 1 has 378 instances after oversampling
Class 2 has 378 instances after oversampling
Class 3 has 378 instances after oversampling
Class 4 has 378 instances after oversampling
Class 5 has 378 instances after oversampling
Class 6 has 378 instances after oversampling
Class 7 has 378 instances after oversampling
Class 8 has 378 instances after oversampling
Class 9 has 378 instances after oversampling
0 Train Loss: 226.960 | Train Acc: 12.222
1 Train Loss: 199.473 | Train Acc: 30.000
2 Train Loss: 162.225 | Train Acc: 47.222
3 Train Loss: 139.959 | Train Acc: 55.159
4 Train Loss: 112.077 | Train Acc: 65.503
5 Train Loss: 88.154 | Train Acc: 72.857
6 Train Loss: 72.059 | Train Acc: 77.460
7 Train Loss: 60.206 | Train Acc: 81.534
8 Train Loss: 46.428 | Train Acc: 86.772
9 Train Loss: 37.878 | Train Acc: 89.577
10 Train Loss: 29.449 | Train Acc: 92.249
11 Train Loss: 23.528 | Train Acc: 94.286
12 Train Loss: 18.902 | Train Acc: 95.635
13 Train Loss: 15.118 | Train Acc: 97.169
14 Train Loss: 10.895 | Train Acc: 98.545
15 Train Loss: 8.497 | Train Acc: 99.233
16 Train Loss: 6.742 | Train Acc: 99.577
17 Train Loss: 5.648 | Train Acc: 99.709
18 Train Loss: 4.071 | Train Acc: 99.788
19 Train Loss: 3.283 | Train Acc: 100.000
20 Train Loss: 2.429 | Train Acc: 100.000
21 Train Loss: 2.205 | Train Acc: 100.000
22 Train Loss: 2.032 | Train Acc: 100.000
23 Train Loss: 1.921 | Train Acc: 100.000
24 Train Loss: 1.854 | Train Acc: 100.000
25 Train Loss: 1.703 | Train Acc: 100.000
26 Train Loss: 1.613 | Train Acc: 100.000
27 Train Loss: 1.514 | Train Acc: 100.000
28 Train Loss: 1.443 | Train Acc: 100.000
29 Train Loss: 1.394 | Train Acc: 100.000
30 Train Loss: 1.285 | Train Acc: 100.000
31 Train Loss: 1.226 | Train Acc: 100.000
32 Train Loss: 1.161 | Train Acc: 100.000
33 Train Loss: 1.096 | Train Acc: 100.000
34 Train Loss: 1.034 | Train Acc: 100.000
35 Train Loss: 0.969 | Train Acc: 100.000
36 Train Loss: 0.908 | Train Acc: 100.000
37 Train Loss: 0.858 | Train Acc: 100.000
38 Train Loss: 0.816 | Train Acc: 100.000
39 Train Loss: 0.777 | Train Acc: 100.000
40 Train Loss: 0.692 | Train Acc: 100.000
41 Train Loss: 0.670 | Train Acc: 100.000
42 Train Loss: 0.656 | Train Acc: 100.000
43 Train Loss: 0.643 | Train Acc: 100.000
44 Train Loss: 0.628 | Train Acc: 100.000
45 Train Loss: 0.610 | Train Acc: 100.000
46 Train Loss: 0.597 | Train Acc: 100.000
47 Train Loss: 0.580 | Train Acc: 100.000
48 Train Loss: 0.569 | Train Acc: 100.000
49 Train Loss: 0.549 | Train Acc: 100.000
50 Train Loss: 0.533 | Train Acc: 100.000
51 Train Loss: 0.518 | Train Acc: 100.000
52 Train Loss: 0.501 | Train Acc: 100.000
53 Train Loss: 0.489 | Train Acc: 100.000
54 Train Loss: 0.474 | Train Acc: 100.000
55 Train Loss: 0.462 | Train Acc: 100.000
56 Train Loss: 0.442 | Train Acc: 100.000
57 Train Loss: 0.430 | Train Acc: 100.000
58 Train Loss: 0.416 | Train Acc: 100.000
59 Train Loss: 0.400 | Train Acc: 100.000
60 Train Loss: 0.376 | Train Acc: 100.000
61 Train Loss: 0.370 | Train Acc: 100.000
62 Train Loss: 0.366 | Train Acc: 100.000
63 Train Loss: 0.360 | Train Acc: 100.000
64 Train Loss: 0.355 | Train Acc: 100.000
65 Train Loss: 0.350 | Train Acc: 100.000
66 Train Loss: 0.344 | Train Acc: 100.000
67 Train Loss: 0.338 | Train Acc: 100.000
68 Train Loss: 0.333 | Train Acc: 100.000
69 Train Loss: 0.327 | Train Acc: 100.000
70 Train Loss: 0.321 | Train Acc: 100.000
71 Train Loss: 0.314 | Train Acc: 100.000
72 Train Loss: 0.310 | Train Acc: 100.000
73 Train Loss: 0.302 | Train Acc: 100.000
74 Train Loss: 0.298 | Train Acc: 100.000
75 Train Loss: 0.290 | Train Acc: 100.000
76 Train Loss: 0.285 | Train Acc: 100.000
77 Train Loss: 0.277 | Train Acc: 100.000
78 Train Loss: 0.272 | Train Acc: 100.000
79 Train Loss: 0.266 | Train Acc: 100.000
80 Train Loss: 0.254 | Train Acc: 100.000
81 Train Loss: 0.252 | Train Acc: 100.000
82 Train Loss: 0.249 | Train Acc: 100.000
83 Train Loss: 0.247 | Train Acc: 100.000
84 Train Loss: 0.245 | Train Acc: 100.000
85 Train Loss: 0.242 | Train Acc: 100.000
86 Train Loss: 0.239 | Train Acc: 100.000
87 Train Loss: 0.237 | Train Acc: 100.000
88 Train Loss: 0.234 | Train Acc: 100.000
89 Train Loss: 0.231 | Train Acc: 100.000
90 Train Loss: 0.228 | Train Acc: 100.000
91 Train Loss: 0.226 | Train Acc: 100.000
92 Train Loss: 0.223 | Train Acc: 100.000
93 Train Loss: 0.220 | Train Acc: 100.000
94 Train Loss: 0.217 | Train Acc: 100.000
95 Train Loss: 0.214 | Train Acc: 100.000
96 Train Loss: 0.213 | Train Acc: 100.000
97 Train Loss: 0.209 | Train Acc: 100.000
98 Train Loss: 0.206 | Train Acc: 100.000
99 Train Loss: 0.203 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([3780, 2304])
printing expected split from k means
{3: 0, 4: 1, 5: 0, 9: 0, 6: 1, 7: 1, 2: 0, 8: 0, 0: 1, 1: 1}
Printing final_dict items...
{3: 0, 4: 1, 5: 0, 9: 0, 6: 1, 7: 1, 2: 0, 8: 0, 0: 1, 1: 1}
Image Statistics before MLP : L R :  1753 2027
expectedMlpLabels.shape :  torch.Size([3780])
0 Loss: 44.560 | Acc: 88.861
1 Loss: 28.301 | Acc: 93.417
2 Loss: 23.504 | Acc: 94.722
3 Loss: 20.363 | Acc: 95.194
4 Loss: 16.203 | Acc: 96.389
5 Loss: 15.746 | Acc: 96.417
6 Loss: 17.029 | Acc: 96.250
7 Loss: 11.760 | Acc: 97.139
8 Loss: 10.931 | Acc: 97.389
9 Loss: 11.457 | Acc: 97.639
10 Loss: 6.551 | Acc: 98.556
11 Loss: 4.948 | Acc: 98.944
12 Loss: 4.410 | Acc: 99.000
13 Loss: 4.087 | Acc: 99.111
14 Loss: 3.847 | Acc: 99.250
15 Loss: 4.082 | Acc: 99.250
16 Loss: 4.185 | Acc: 99.028
17 Loss: 3.199 | Acc: 99.361
18 Loss: 4.723 | Acc: 99.000
19 Loss: 4.165 | Acc: 99.139
20 Loss: 2.464 | Acc: 99.528
21 Loss: 2.037 | Acc: 99.528
22 Loss: 1.658 | Acc: 99.583
23 Loss: 1.803 | Acc: 99.611
24 Loss: 1.717 | Acc: 99.583
25 Loss: 2.162 | Acc: 99.528
26 Loss: 1.283 | Acc: 99.667
27 Loss: 2.330 | Acc: 99.556
28 Loss: 1.832 | Acc: 99.500
29 Loss: 1.549 | Acc: 99.694
30 Loss: 1.352 | Acc: 99.667
31 Loss: 1.525 | Acc: 99.722
32 Loss: 1.044 | Acc: 99.806
33 Loss: 1.211 | Acc: 99.667
34 Loss: 1.246 | Acc: 99.722
35 Loss: 0.897 | Acc: 99.778
36 Loss: 1.279 | Acc: 99.667
37 Loss: 1.119 | Acc: 99.722
38 Loss: 1.068 | Acc: 99.667
39 Loss: 0.933 | Acc: 99.722
40 Loss: 1.150 | Acc: 99.722
41 Loss: 1.261 | Acc: 99.750
42 Loss: 0.896 | Acc: 99.833
43 Loss: 0.778 | Acc: 99.833
44 Loss: 0.712 | Acc: 99.861
45 Loss: 0.680 | Acc: 99.917
46 Loss: 0.664 | Acc: 99.833
47 Loss: 0.533 | Acc: 99.917
48 Loss: 0.600 | Acc: 99.889
49 Loss: 1.294 | Acc: 99.722
50 Loss: 0.883 | Acc: 99.806
51 Loss: 0.651 | Acc: 99.861
52 Loss: 0.906 | Acc: 99.833
53 Loss: 0.620 | Acc: 99.833
54 Loss: 1.141 | Acc: 99.750
55 Loss: 0.485 | Acc: 99.917
56 Loss: 0.573 | Acc: 99.889
57 Loss: 0.761 | Acc: 99.861
58 Loss: 0.671 | Acc: 99.833
59 Loss: 0.714 | Acc: 99.806
MLP trained successfully...
# of Left images:  1296.0
# of Right images:  1059.0
giniRightRatio:  0.891176934785342
giniLeftRatio:  0.8775672534674592
impurityDrop:  0.8745214607645904
giniGain:  0.013143127837155877
lclasses:  [43, 80, 121, 230, 60, 204, 85, 145, 128, 200]
rclasses:  [70, 109, 86, 103, 95, 101, 73, 147, 97, 178]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1296, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([1296])
rTrainDict[data].shape:  torch.Size([1059, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([1059])
RETURNING FROM WORK...
nodeId:  44 , imgTensorShape :  torch.Size([1296, 16, 12, 12])
nodeId: 44 ,  parentId: 22 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1296
nodeId:  45 , imgTensorShape :  torch.Size([1059, 16, 12, 12])
nodeId: 45 ,  parentId: 22 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1059
Running nodeId:  23
trainInputDict[data].shape :  torch.Size([4047, 16, 16, 16])
copy.shape :  torch.Size([4047, 4096])
copyLabel.shape :  torch.Size([4047])
Class 0 has 939 instances after oversampling
Class 1 has 939 instances after oversampling
Class 2 has 939 instances after oversampling
Class 3 has 939 instances after oversampling
Class 4 has 939 instances after oversampling
Class 5 has 939 instances after oversampling
Class 6 has 939 instances after oversampling
Class 7 has 939 instances after oversampling
Class 8 has 939 instances after oversampling
Class 9 has 939 instances after oversampling
0 Train Loss: 218.375 | Train Acc: 18.190
1 Train Loss: 182.427 | Train Acc: 37.902
2 Train Loss: 143.751 | Train Acc: 53.823
3 Train Loss: 122.187 | Train Acc: 60.266
4 Train Loss: 104.761 | Train Acc: 66.092
5 Train Loss: 97.721 | Train Acc: 68.360
6 Train Loss: 82.211 | Train Acc: 73.195
7 Train Loss: 76.973 | Train Acc: 75.495
8 Train Loss: 66.924 | Train Acc: 78.530
9 Train Loss: 60.761 | Train Acc: 80.181
10 Train Loss: 55.305 | Train Acc: 82.013
11 Train Loss: 53.035 | Train Acc: 82.386
12 Train Loss: 47.433 | Train Acc: 84.909
13 Train Loss: 44.167 | Train Acc: 85.719
14 Train Loss: 41.028 | Train Acc: 86.965
15 Train Loss: 36.752 | Train Acc: 88.253
16 Train Loss: 34.972 | Train Acc: 89.010
17 Train Loss: 33.498 | Train Acc: 89.457
18 Train Loss: 30.562 | Train Acc: 90.234
19 Train Loss: 27.823 | Train Acc: 91.118
20 Train Loss: 22.709 | Train Acc: 93.855
21 Train Loss: 21.103 | Train Acc: 94.547
22 Train Loss: 20.087 | Train Acc: 94.920
23 Train Loss: 19.120 | Train Acc: 95.399
24 Train Loss: 18.529 | Train Acc: 95.410
25 Train Loss: 17.845 | Train Acc: 95.698
26 Train Loss: 17.292 | Train Acc: 95.889
27 Train Loss: 17.168 | Train Acc: 96.028
28 Train Loss: 16.021 | Train Acc: 96.283
29 Train Loss: 15.483 | Train Acc: 96.518
30 Train Loss: 15.106 | Train Acc: 96.624
31 Train Loss: 14.677 | Train Acc: 96.763
32 Train Loss: 13.945 | Train Acc: 97.071
33 Train Loss: 13.463 | Train Acc: 97.252
34 Train Loss: 12.787 | Train Acc: 97.188
35 Train Loss: 12.454 | Train Acc: 97.306
36 Train Loss: 11.946 | Train Acc: 97.625
37 Train Loss: 11.330 | Train Acc: 97.785
38 Train Loss: 10.810 | Train Acc: 97.902
39 Train Loss: 10.684 | Train Acc: 98.030
40 Train Loss: 9.118 | Train Acc: 98.711
41 Train Loss: 8.930 | Train Acc: 98.733
42 Train Loss: 8.666 | Train Acc: 98.839
43 Train Loss: 8.644 | Train Acc: 98.807
44 Train Loss: 8.446 | Train Acc: 98.871
45 Train Loss: 8.321 | Train Acc: 98.967
46 Train Loss: 8.114 | Train Acc: 98.999
47 Train Loss: 7.964 | Train Acc: 98.988
48 Train Loss: 7.759 | Train Acc: 99.031
49 Train Loss: 7.642 | Train Acc: 99.042
50 Train Loss: 7.626 | Train Acc: 99.105
51 Train Loss: 7.384 | Train Acc: 99.116
52 Train Loss: 7.192 | Train Acc: 99.223
53 Train Loss: 7.178 | Train Acc: 99.212
54 Train Loss: 6.996 | Train Acc: 99.265
55 Train Loss: 6.782 | Train Acc: 99.382
56 Train Loss: 6.629 | Train Acc: 99.286
57 Train Loss: 6.506 | Train Acc: 99.446
58 Train Loss: 6.382 | Train Acc: 99.404
59 Train Loss: 6.171 | Train Acc: 99.457
60 Train Loss: 5.835 | Train Acc: 99.574
61 Train Loss: 5.710 | Train Acc: 99.574
62 Train Loss: 5.665 | Train Acc: 99.585
63 Train Loss: 5.573 | Train Acc: 99.595
64 Train Loss: 5.536 | Train Acc: 99.606
65 Train Loss: 5.496 | Train Acc: 99.638
66 Train Loss: 5.447 | Train Acc: 99.659
67 Train Loss: 5.390 | Train Acc: 99.617
68 Train Loss: 5.324 | Train Acc: 99.659
69 Train Loss: 5.284 | Train Acc: 99.617
70 Train Loss: 5.255 | Train Acc: 99.638
71 Train Loss: 5.212 | Train Acc: 99.691
72 Train Loss: 5.142 | Train Acc: 99.681
73 Train Loss: 5.069 | Train Acc: 99.691
74 Train Loss: 5.009 | Train Acc: 99.659
75 Train Loss: 4.977 | Train Acc: 99.659
76 Train Loss: 4.935 | Train Acc: 99.702
77 Train Loss: 4.858 | Train Acc: 99.702
78 Train Loss: 4.813 | Train Acc: 99.702
79 Train Loss: 4.755 | Train Acc: 99.712
80 Train Loss: 4.588 | Train Acc: 99.766
81 Train Loss: 4.561 | Train Acc: 99.766
82 Train Loss: 4.530 | Train Acc: 99.766
83 Train Loss: 4.523 | Train Acc: 99.755
84 Train Loss: 4.490 | Train Acc: 99.744
85 Train Loss: 4.495 | Train Acc: 99.766
86 Train Loss: 4.446 | Train Acc: 99.766
87 Train Loss: 4.437 | Train Acc: 99.755
88 Train Loss: 4.409 | Train Acc: 99.755
89 Train Loss: 4.390 | Train Acc: 99.776
90 Train Loss: 4.375 | Train Acc: 99.755
91 Train Loss: 4.344 | Train Acc: 99.755
92 Train Loss: 4.321 | Train Acc: 99.766
93 Train Loss: 4.303 | Train Acc: 99.766
94 Train Loss: 4.286 | Train Acc: 99.776
95 Train Loss: 4.262 | Train Acc: 99.776
96 Train Loss: 4.234 | Train Acc: 99.766
97 Train Loss: 4.216 | Train Acc: 99.766
98 Train Loss: 4.195 | Train Acc: 99.776
99 Train Loss: 4.172 | Train Acc: 99.766
CNN trained successfully...
image_next_flat.shape :  torch.Size([9390, 2304])
printing expected split from k means
{3: 1, 2: 1, 4: 1, 0: 1, 6: 0, 9: 1, 5: 1, 7: 1, 8: 1, 1: 1}
Printing final_dict items...
{3: 1, 2: 1, 4: 1, 0: 1, 6: 0, 9: 1, 5: 1, 7: 1, 8: 1, 1: 1}
Image Statistics before MLP : L R :  1557 7833
expectedMlpLabels.shape :  torch.Size([9390])
0 Loss: 17.831 | Acc: 87.519
1 Loss: 10.610 | Acc: 91.917
2 Loss: 9.575 | Acc: 92.662
3 Loss: 7.996 | Acc: 93.546
4 Loss: 7.412 | Acc: 93.802
5 Loss: 6.445 | Acc: 94.643
6 Loss: 6.436 | Acc: 95.080
7 Loss: 5.431 | Acc: 95.655
8 Loss: 4.880 | Acc: 96.038
9 Loss: 4.894 | Acc: 95.921
10 Loss: 3.481 | Acc: 97.167
11 Loss: 2.982 | Acc: 97.551
12 Loss: 2.757 | Acc: 97.561
13 Loss: 2.632 | Acc: 97.945
14 Loss: 2.429 | Acc: 98.168
15 Loss: 2.676 | Acc: 98.051
16 Loss: 2.455 | Acc: 97.987
17 Loss: 2.200 | Acc: 98.232
18 Loss: 2.110 | Acc: 98.392
19 Loss: 2.075 | Acc: 98.445
20 Loss: 1.823 | Acc: 98.637
21 Loss: 1.552 | Acc: 98.807
22 Loss: 1.500 | Acc: 98.860
23 Loss: 1.418 | Acc: 98.829
24 Loss: 1.300 | Acc: 98.935
25 Loss: 1.232 | Acc: 98.978
26 Loss: 1.245 | Acc: 99.063
27 Loss: 1.210 | Acc: 98.914
28 Loss: 1.152 | Acc: 99.084
29 Loss: 1.355 | Acc: 99.063
30 Loss: 1.174 | Acc: 99.191
31 Loss: 1.028 | Acc: 99.212
32 Loss: 0.850 | Acc: 99.308
33 Loss: 0.860 | Acc: 99.329
34 Loss: 1.058 | Acc: 99.159
35 Loss: 0.984 | Acc: 99.191
36 Loss: 0.762 | Acc: 99.404
37 Loss: 0.979 | Acc: 99.329
38 Loss: 0.879 | Acc: 99.329
39 Loss: 0.795 | Acc: 99.393
40 Loss: 0.749 | Acc: 99.393
41 Loss: 0.872 | Acc: 99.329
42 Loss: 0.789 | Acc: 99.372
43 Loss: 0.920 | Acc: 99.372
44 Loss: 0.750 | Acc: 99.478
45 Loss: 0.717 | Acc: 99.489
46 Loss: 0.778 | Acc: 99.329
47 Loss: 0.804 | Acc: 99.350
48 Loss: 0.813 | Acc: 99.425
49 Loss: 0.759 | Acc: 99.382
50 Loss: 0.767 | Acc: 99.436
51 Loss: 0.843 | Acc: 99.446
52 Loss: 0.677 | Acc: 99.404
53 Loss: 0.639 | Acc: 99.510
54 Loss: 0.629 | Acc: 99.553
55 Loss: 0.738 | Acc: 99.436
56 Loss: 0.807 | Acc: 99.404
57 Loss: 0.633 | Acc: 99.425
58 Loss: 0.699 | Acc: 99.478
59 Loss: 0.656 | Acc: 99.478
MLP trained successfully...
# of Left images:  795.0
# of Right images:  3252.0
giniRightRatio:  0.8319839886590747
giniLeftRatio:  0.8144519599699379
impurityDrop:  0.8276980222359924
giniGain:  0.011464550423814113
lclasses:  [23, 1, 203, 189, 86, 93, 151, 26, 15, 8]
rclasses:  [235, 21, 499, 696, 367, 846, 69, 333, 140, 46]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([795, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([795])
rTrainDict[data].shape:  torch.Size([3252, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([3252])
RETURNING FROM WORK...
nodeId:  46 , imgTensorShape :  torch.Size([795, 16, 12, 12])
nodeId: 46 ,  parentId: 23 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 795
nodeId:  47 , imgTensorShape :  torch.Size([3252, 16, 12, 12])
nodeId: 47 ,  parentId: 23 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3252
Running nodeId:  24
trainInputDict[data].shape :  torch.Size([2393, 16, 16, 16])
copy.shape :  torch.Size([2393, 4096])
copyLabel.shape :  torch.Size([2393])
Class 0 has 590 instances after oversampling
Class 1 has 591 instances after oversampling
Class 2 has 590 instances after oversampling
Class 3 has 591 instances after oversampling
Class 4 has 590 instances after oversampling
Class 5 has 591 instances after oversampling
Class 6 has 591 instances after oversampling
Class 7 has 591 instances after oversampling
Class 8 has 590 instances after oversampling
Class 9 has 591 instances after oversampling
0 Train Loss: 229.008 | Train Acc: 11.763
1 Train Loss: 195.537 | Train Acc: 31.305
2 Train Loss: 161.840 | Train Acc: 47.288
3 Train Loss: 124.410 | Train Acc: 61.373
4 Train Loss: 100.794 | Train Acc: 69.881
5 Train Loss: 78.171 | Train Acc: 76.881
6 Train Loss: 60.710 | Train Acc: 82.542
7 Train Loss: 48.514 | Train Acc: 86.475
8 Train Loss: 39.926 | Train Acc: 89.153
9 Train Loss: 31.512 | Train Acc: 91.661
10 Train Loss: 25.633 | Train Acc: 93.559
11 Train Loss: 22.379 | Train Acc: 94.085
12 Train Loss: 17.263 | Train Acc: 95.644
13 Train Loss: 14.228 | Train Acc: 96.847
14 Train Loss: 11.077 | Train Acc: 97.831
15 Train Loss: 8.461 | Train Acc: 98.780
16 Train Loss: 6.911 | Train Acc: 99.136
17 Train Loss: 5.679 | Train Acc: 99.492
18 Train Loss: 5.404 | Train Acc: 99.407
19 Train Loss: 4.331 | Train Acc: 99.576
20 Train Loss: 2.620 | Train Acc: 99.983
21 Train Loss: 2.322 | Train Acc: 99.966
22 Train Loss: 2.081 | Train Acc: 100.000
23 Train Loss: 1.928 | Train Acc: 100.000
24 Train Loss: 1.789 | Train Acc: 100.000
25 Train Loss: 1.685 | Train Acc: 100.000
26 Train Loss: 1.581 | Train Acc: 100.000
27 Train Loss: 1.463 | Train Acc: 100.000
28 Train Loss: 1.370 | Train Acc: 100.000
29 Train Loss: 1.281 | Train Acc: 100.000
30 Train Loss: 1.169 | Train Acc: 100.000
31 Train Loss: 1.106 | Train Acc: 100.000
32 Train Loss: 1.032 | Train Acc: 100.000
33 Train Loss: 0.968 | Train Acc: 100.000
34 Train Loss: 0.903 | Train Acc: 100.000
35 Train Loss: 0.859 | Train Acc: 100.000
36 Train Loss: 0.787 | Train Acc: 100.000
37 Train Loss: 0.741 | Train Acc: 100.000
38 Train Loss: 0.691 | Train Acc: 100.000
39 Train Loss: 0.656 | Train Acc: 100.000
40 Train Loss: 0.583 | Train Acc: 100.000
41 Train Loss: 0.560 | Train Acc: 100.000
42 Train Loss: 0.548 | Train Acc: 100.000
43 Train Loss: 0.531 | Train Acc: 100.000
44 Train Loss: 0.519 | Train Acc: 100.000
45 Train Loss: 0.501 | Train Acc: 100.000
46 Train Loss: 0.487 | Train Acc: 100.000
47 Train Loss: 0.474 | Train Acc: 100.000
48 Train Loss: 0.465 | Train Acc: 100.000
49 Train Loss: 0.448 | Train Acc: 100.000
50 Train Loss: 0.435 | Train Acc: 100.000
51 Train Loss: 0.422 | Train Acc: 100.000
52 Train Loss: 0.407 | Train Acc: 100.000
53 Train Loss: 0.397 | Train Acc: 100.000
54 Train Loss: 0.385 | Train Acc: 100.000
55 Train Loss: 0.369 | Train Acc: 100.000
56 Train Loss: 0.358 | Train Acc: 100.000
57 Train Loss: 0.345 | Train Acc: 100.000
58 Train Loss: 0.334 | Train Acc: 100.000
59 Train Loss: 0.322 | Train Acc: 100.000
60 Train Loss: 0.299 | Train Acc: 100.000
61 Train Loss: 0.296 | Train Acc: 100.000
62 Train Loss: 0.290 | Train Acc: 100.000
63 Train Loss: 0.287 | Train Acc: 100.000
64 Train Loss: 0.281 | Train Acc: 100.000
65 Train Loss: 0.279 | Train Acc: 100.000
66 Train Loss: 0.273 | Train Acc: 100.000
67 Train Loss: 0.268 | Train Acc: 100.000
68 Train Loss: 0.264 | Train Acc: 100.000
69 Train Loss: 0.259 | Train Acc: 100.000
70 Train Loss: 0.254 | Train Acc: 100.000
71 Train Loss: 0.248 | Train Acc: 100.000
72 Train Loss: 0.245 | Train Acc: 100.000
73 Train Loss: 0.239 | Train Acc: 100.000
74 Train Loss: 0.235 | Train Acc: 100.000
75 Train Loss: 0.229 | Train Acc: 100.000
76 Train Loss: 0.225 | Train Acc: 100.000
77 Train Loss: 0.219 | Train Acc: 100.000
78 Train Loss: 0.214 | Train Acc: 100.000
79 Train Loss: 0.209 | Train Acc: 100.000
80 Train Loss: 0.202 | Train Acc: 100.000
81 Train Loss: 0.199 | Train Acc: 100.000
82 Train Loss: 0.197 | Train Acc: 100.000
83 Train Loss: 0.195 | Train Acc: 100.000
84 Train Loss: 0.193 | Train Acc: 100.000
85 Train Loss: 0.190 | Train Acc: 100.000
86 Train Loss: 0.189 | Train Acc: 100.000
87 Train Loss: 0.187 | Train Acc: 100.000
88 Train Loss: 0.185 | Train Acc: 100.000
89 Train Loss: 0.182 | Train Acc: 100.000
90 Train Loss: 0.180 | Train Acc: 100.000
91 Train Loss: 0.178 | Train Acc: 100.000
92 Train Loss: 0.176 | Train Acc: 100.000
93 Train Loss: 0.173 | Train Acc: 100.000
94 Train Loss: 0.171 | Train Acc: 100.000
95 Train Loss: 0.169 | Train Acc: 100.000
96 Train Loss: 0.167 | Train Acc: 100.000
97 Train Loss: 0.164 | Train Acc: 100.000
98 Train Loss: 0.162 | Train Acc: 100.000
99 Train Loss: 0.159 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([5906, 2304])
printing expected split from k means
{3: 0, 2: 0, 4: 0, 9: 1, 7: 0, 1: 0, 6: 0, 5: 0, 0: 0, 8: 1}
Printing final_dict items...
{3: 0, 2: 0, 4: 0, 9: 1, 7: 0, 1: 0, 6: 0, 5: 0, 0: 0, 8: 1}
Image Statistics before MLP : L R :  4082 1824
expectedMlpLabels.shape :  torch.Size([5906])
0 Loss: 45.746 | Acc: 82.759
1 Loss: 30.198 | Acc: 89.500
2 Loss: 25.392 | Acc: 90.707
3 Loss: 21.009 | Acc: 92.155
4 Loss: 19.252 | Acc: 92.897
5 Loss: 15.270 | Acc: 94.483
6 Loss: 15.729 | Acc: 94.172
7 Loss: 13.261 | Acc: 95.552
8 Loss: 12.848 | Acc: 95.603
9 Loss: 12.220 | Acc: 95.948
10 Loss: 8.537 | Acc: 97.052
11 Loss: 6.741 | Acc: 97.690
12 Loss: 6.575 | Acc: 97.690
13 Loss: 5.982 | Acc: 98.034
14 Loss: 5.468 | Acc: 98.069
15 Loss: 4.810 | Acc: 98.276
16 Loss: 5.059 | Acc: 98.362
17 Loss: 4.510 | Acc: 98.345
18 Loss: 4.978 | Acc: 98.259
19 Loss: 5.705 | Acc: 98.052
20 Loss: 3.835 | Acc: 98.776
21 Loss: 3.076 | Acc: 99.000
22 Loss: 2.472 | Acc: 99.224
23 Loss: 2.525 | Acc: 99.224
24 Loss: 2.713 | Acc: 99.052
25 Loss: 2.604 | Acc: 99.207
26 Loss: 2.700 | Acc: 99.172
27 Loss: 2.765 | Acc: 99.172
28 Loss: 2.305 | Acc: 99.345
29 Loss: 2.187 | Acc: 99.310
30 Loss: 1.956 | Acc: 99.397
31 Loss: 1.359 | Acc: 99.672
32 Loss: 1.526 | Acc: 99.448
33 Loss: 1.615 | Acc: 99.500
34 Loss: 1.560 | Acc: 99.569
35 Loss: 2.122 | Acc: 99.259
36 Loss: 1.542 | Acc: 99.603
37 Loss: 1.478 | Acc: 99.552
38 Loss: 1.454 | Acc: 99.534
39 Loss: 1.617 | Acc: 99.517
40 Loss: 1.529 | Acc: 99.500
41 Loss: 1.319 | Acc: 99.638
42 Loss: 1.414 | Acc: 99.569
43 Loss: 1.211 | Acc: 99.690
44 Loss: 1.471 | Acc: 99.603
45 Loss: 1.019 | Acc: 99.655
46 Loss: 1.212 | Acc: 99.655
47 Loss: 1.236 | Acc: 99.603
48 Loss: 0.904 | Acc: 99.793
49 Loss: 1.461 | Acc: 99.586
50 Loss: 1.250 | Acc: 99.603
51 Loss: 0.889 | Acc: 99.724
52 Loss: 1.389 | Acc: 99.586
53 Loss: 1.190 | Acc: 99.672
54 Loss: 1.036 | Acc: 99.672
55 Loss: 1.227 | Acc: 99.672
56 Loss: 0.987 | Acc: 99.707
57 Loss: 1.003 | Acc: 99.690
58 Loss: 0.896 | Acc: 99.793
59 Loss: 1.399 | Acc: 99.569
MLP trained successfully...
# of Left images:  1419.0
# of Right images:  974.0
giniRightRatio:  0.8085795361113806
giniLeftRatio:  0.8705790388272319
impurityDrop:  0.8989053003349874
giniGain:  -0.04502430008509428
lclasses:  [75, 167, 81, 200, 86, 153, 126, 259, 14, 258]
rclasses:  [16, 116, 31, 68, 31, 88, 62, 194, 35, 333]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1419, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([1419])
rTrainDict[data].shape:  torch.Size([974, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([974])
RETURNING FROM WORK...
nodeId:  48 , imgTensorShape :  torch.Size([1419, 16, 12, 12])
nodeId: 48 ,  parentId: 24 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1419
nodeId:  49 , imgTensorShape :  torch.Size([974, 16, 12, 12])
nodeId: 49 ,  parentId: 24 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 974
Running nodeId:  25
trainInputDict[data].shape :  torch.Size([1249, 16, 16, 16])
copy.shape :  torch.Size([1249, 4096])
copyLabel.shape :  torch.Size([1249])
Class 0 has 619 instances after oversampling
Class 1 has 619 instances after oversampling
Class 2 has 619 instances after oversampling
Class 3 has 619 instances after oversampling
Class 4 has 619 instances after oversampling
Class 5 has 619 instances after oversampling
Class 6 has 619 instances after oversampling
Class 7 has 619 instances after oversampling
Class 8 has 619 instances after oversampling
Class 9 has 619 instances after oversampling
0 Train Loss: 209.203 | Train Acc: 31.115
1 Train Loss: 76.119 | Train Acc: 78.627
2 Train Loss: 27.138 | Train Acc: 92.246
3 Train Loss: 19.692 | Train Acc: 93.990
4 Train Loss: 11.575 | Train Acc: 96.381
5 Train Loss: 9.733 | Train Acc: 96.785
6 Train Loss: 12.241 | Train Acc: 96.187
7 Train Loss: 8.009 | Train Acc: 97.237
8 Train Loss: 5.224 | Train Acc: 98.288
9 Train Loss: 4.102 | Train Acc: 98.627
10 Train Loss: 6.196 | Train Acc: 97.641
11 Train Loss: 4.386 | Train Acc: 98.530
12 Train Loss: 3.288 | Train Acc: 98.934
13 Train Loss: 3.418 | Train Acc: 98.869
14 Train Loss: 1.838 | Train Acc: 99.564
15 Train Loss: 2.046 | Train Acc: 99.499
16 Train Loss: 1.577 | Train Acc: 99.580
17 Train Loss: 2.939 | Train Acc: 99.047
18 Train Loss: 1.655 | Train Acc: 99.628
19 Train Loss: 0.921 | Train Acc: 99.887
20 Train Loss: 0.601 | Train Acc: 99.968
21 Train Loss: 0.470 | Train Acc: 100.000
22 Train Loss: 0.433 | Train Acc: 100.000
23 Train Loss: 0.405 | Train Acc: 100.000
24 Train Loss: 0.377 | Train Acc: 100.000
25 Train Loss: 0.351 | Train Acc: 100.000
26 Train Loss: 0.344 | Train Acc: 100.000
27 Train Loss: 0.315 | Train Acc: 100.000
28 Train Loss: 0.290 | Train Acc: 100.000
29 Train Loss: 0.272 | Train Acc: 100.000
30 Train Loss: 0.257 | Train Acc: 100.000
31 Train Loss: 0.242 | Train Acc: 100.000
32 Train Loss: 0.245 | Train Acc: 100.000
33 Train Loss: 0.217 | Train Acc: 100.000
34 Train Loss: 0.207 | Train Acc: 100.000
35 Train Loss: 0.190 | Train Acc: 100.000
36 Train Loss: 0.186 | Train Acc: 100.000
37 Train Loss: 0.168 | Train Acc: 100.000
38 Train Loss: 0.164 | Train Acc: 100.000
39 Train Loss: 0.155 | Train Acc: 100.000
40 Train Loss: 0.137 | Train Acc: 100.000
41 Train Loss: 0.133 | Train Acc: 100.000
42 Train Loss: 0.130 | Train Acc: 100.000
43 Train Loss: 0.126 | Train Acc: 100.000
44 Train Loss: 0.124 | Train Acc: 100.000
45 Train Loss: 0.120 | Train Acc: 100.000
46 Train Loss: 0.117 | Train Acc: 100.000
47 Train Loss: 0.114 | Train Acc: 100.000
48 Train Loss: 0.112 | Train Acc: 100.000
49 Train Loss: 0.108 | Train Acc: 100.000
50 Train Loss: 0.105 | Train Acc: 100.000
51 Train Loss: 0.104 | Train Acc: 100.000
52 Train Loss: 0.100 | Train Acc: 100.000
53 Train Loss: 0.094 | Train Acc: 100.000
54 Train Loss: 0.093 | Train Acc: 100.000
55 Train Loss: 0.091 | Train Acc: 100.000
56 Train Loss: 0.086 | Train Acc: 100.000
57 Train Loss: 0.084 | Train Acc: 100.000
58 Train Loss: 0.081 | Train Acc: 100.000
59 Train Loss: 0.078 | Train Acc: 100.000
60 Train Loss: 0.073 | Train Acc: 100.000
61 Train Loss: 0.073 | Train Acc: 100.000
62 Train Loss: 0.071 | Train Acc: 100.000
63 Train Loss: 0.070 | Train Acc: 100.000
64 Train Loss: 0.069 | Train Acc: 100.000
65 Train Loss: 0.068 | Train Acc: 100.000
66 Train Loss: 0.067 | Train Acc: 100.000
67 Train Loss: 0.066 | Train Acc: 100.000
68 Train Loss: 0.064 | Train Acc: 100.000
69 Train Loss: 0.064 | Train Acc: 100.000
70 Train Loss: 0.062 | Train Acc: 100.000
71 Train Loss: 0.060 | Train Acc: 100.000
72 Train Loss: 0.060 | Train Acc: 100.000
73 Train Loss: 0.059 | Train Acc: 100.000
74 Train Loss: 0.057 | Train Acc: 100.000
75 Train Loss: 0.056 | Train Acc: 100.000
76 Train Loss: 0.055 | Train Acc: 100.000
77 Train Loss: 0.053 | Train Acc: 100.000
78 Train Loss: 0.052 | Train Acc: 100.000
79 Train Loss: 0.051 | Train Acc: 100.000
80 Train Loss: 0.049 | Train Acc: 100.000
81 Train Loss: 0.048 | Train Acc: 100.000
82 Train Loss: 0.047 | Train Acc: 100.000
83 Train Loss: 0.047 | Train Acc: 100.000
84 Train Loss: 0.047 | Train Acc: 100.000
85 Train Loss: 0.046 | Train Acc: 100.000
86 Train Loss: 0.046 | Train Acc: 100.000
87 Train Loss: 0.045 | Train Acc: 100.000
88 Train Loss: 0.044 | Train Acc: 100.000
89 Train Loss: 0.044 | Train Acc: 100.000
90 Train Loss: 0.044 | Train Acc: 100.000
91 Train Loss: 0.042 | Train Acc: 100.000
92 Train Loss: 0.042 | Train Acc: 100.000
93 Train Loss: 0.042 | Train Acc: 100.000
94 Train Loss: 0.041 | Train Acc: 100.000
95 Train Loss: 0.040 | Train Acc: 100.000
96 Train Loss: 0.039 | Train Acc: 100.000
97 Train Loss: 0.039 | Train Acc: 100.000
98 Train Loss: 0.039 | Train Acc: 100.000
99 Train Loss: 0.038 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([6190, 2304])
printing expected split from k means
{1: 0, 9: 1, 7: 0, 0: 0, 6: 0, 8: 1, 2: 0, 4: 0, 5: 1, 3: 1}
Printing final_dict items...
{1: 0, 9: 1, 7: 0, 0: 0, 6: 0, 8: 1, 2: 0, 4: 0, 5: 1, 3: 1}
Image Statistics before MLP : L R :  3456 2734
expectedMlpLabels.shape :  torch.Size([6190])
0 Loss: 28.994 | Acc: 93.021
1 Loss: 13.613 | Acc: 97.076
2 Loss: 11.871 | Acc: 97.383
3 Loss: 9.231 | Acc: 97.803
4 Loss: 8.452 | Acc: 97.900
5 Loss: 9.688 | Acc: 97.819
6 Loss: 8.248 | Acc: 98.288
7 Loss: 6.937 | Acc: 98.401
8 Loss: 5.024 | Acc: 98.740
9 Loss: 5.501 | Acc: 98.627
10 Loss: 3.635 | Acc: 99.128
11 Loss: 3.652 | Acc: 99.225
12 Loss: 2.736 | Acc: 99.386
13 Loss: 3.379 | Acc: 99.273
14 Loss: 2.132 | Acc: 99.499
15 Loss: 2.853 | Acc: 99.435
16 Loss: 2.516 | Acc: 99.386
17 Loss: 2.230 | Acc: 99.515
18 Loss: 3.023 | Acc: 99.386
19 Loss: 2.303 | Acc: 99.402
20 Loss: 2.106 | Acc: 99.580
21 Loss: 1.410 | Acc: 99.693
22 Loss: 1.456 | Acc: 99.645
23 Loss: 1.128 | Acc: 99.790
24 Loss: 1.335 | Acc: 99.645
25 Loss: 1.354 | Acc: 99.677
26 Loss: 1.420 | Acc: 99.758
27 Loss: 1.461 | Acc: 99.709
28 Loss: 1.029 | Acc: 99.758
29 Loss: 1.369 | Acc: 99.677
30 Loss: 0.917 | Acc: 99.774
31 Loss: 1.212 | Acc: 99.742
32 Loss: 0.683 | Acc: 99.871
33 Loss: 0.833 | Acc: 99.790
34 Loss: 0.775 | Acc: 99.806
35 Loss: 0.725 | Acc: 99.838
36 Loss: 0.829 | Acc: 99.790
37 Loss: 0.724 | Acc: 99.838
38 Loss: 1.142 | Acc: 99.693
39 Loss: 0.836 | Acc: 99.806
40 Loss: 0.682 | Acc: 99.838
41 Loss: 0.507 | Acc: 99.855
42 Loss: 0.434 | Acc: 99.887
43 Loss: 0.572 | Acc: 99.855
44 Loss: 0.440 | Acc: 99.903
45 Loss: 0.506 | Acc: 99.935
46 Loss: 0.589 | Acc: 99.903
47 Loss: 0.607 | Acc: 99.855
48 Loss: 0.562 | Acc: 99.887
49 Loss: 0.600 | Acc: 99.838
50 Loss: 0.546 | Acc: 99.855
51 Loss: 0.591 | Acc: 99.887
52 Loss: 0.567 | Acc: 99.871
53 Loss: 0.585 | Acc: 99.855
54 Loss: 0.581 | Acc: 99.903
55 Loss: 0.482 | Acc: 99.903
56 Loss: 0.523 | Acc: 99.855
57 Loss: 0.536 | Acc: 99.887
58 Loss: 0.731 | Acc: 99.871
59 Loss: 0.718 | Acc: 99.806
MLP trained successfully...
# of Left images:  690.0
# of Right images:  559.0
giniRightRatio:  0.6179575718203666
giniLeftRatio:  0.595059861373661
impurityDrop:  0.5896938505176351
giniGain:  0.022195500835344828
lclasses:  [14, 376, 7, 0, 8, 7, 23, 28, 4, 223]
rclasses:  [16, 243, 1, 7, 7, 9, 10, 8, 14, 244]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([690, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([690])
rTrainDict[data].shape:  torch.Size([559, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([559])
RETURNING FROM WORK...
nodeId:  50 , imgTensorShape :  torch.Size([690, 16, 12, 12])
nodeId: 50 ,  parentId: 25 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 9 ,  numData: 690
nodeId:  51 , imgTensorShape :  torch.Size([559, 16, 12, 12])
nodeId: 51 ,  parentId: 25 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 559
Running nodeId:  26
trainInputDict[data].shape :  torch.Size([1148, 16, 16, 16])
copy.shape :  torch.Size([1148, 4096])
copyLabel.shape :  torch.Size([1148])
Class 0 has 462 instances after oversampling
Class 1 has 462 instances after oversampling
Class 2 has 462 instances after oversampling
Class 3 has 461 instances after oversampling
Class 4 has 462 instances after oversampling
Class 5 has 461 instances after oversampling
Class 6 has 462 instances after oversampling
Class 7 has 461 instances after oversampling
Class 8 has 462 instances after oversampling
Class 9 has 462 instances after oversampling
0 Train Loss: 214.927 | Train Acc: 23.957
1 Train Loss: 138.323 | Train Acc: 56.978
2 Train Loss: 85.982 | Train Acc: 73.217
3 Train Loss: 62.570 | Train Acc: 80.630
4 Train Loss: 43.591 | Train Acc: 86.696
5 Train Loss: 33.039 | Train Acc: 89.674
6 Train Loss: 23.733 | Train Acc: 92.978
7 Train Loss: 19.191 | Train Acc: 94.348
8 Train Loss: 12.909 | Train Acc: 96.652
9 Train Loss: 11.115 | Train Acc: 96.804
10 Train Loss: 9.123 | Train Acc: 97.761
11 Train Loss: 6.333 | Train Acc: 98.630
12 Train Loss: 4.507 | Train Acc: 99.065
13 Train Loss: 3.192 | Train Acc: 99.500
14 Train Loss: 2.792 | Train Acc: 99.609
15 Train Loss: 1.777 | Train Acc: 99.848
16 Train Loss: 1.313 | Train Acc: 99.935
17 Train Loss: 1.163 | Train Acc: 99.957
18 Train Loss: 0.889 | Train Acc: 100.000
19 Train Loss: 0.678 | Train Acc: 100.000
20 Train Loss: 0.527 | Train Acc: 100.000
21 Train Loss: 0.490 | Train Acc: 100.000
22 Train Loss: 0.457 | Train Acc: 100.000
23 Train Loss: 0.426 | Train Acc: 100.000
24 Train Loss: 0.408 | Train Acc: 100.000
25 Train Loss: 0.387 | Train Acc: 100.000
26 Train Loss: 0.363 | Train Acc: 100.000
27 Train Loss: 0.343 | Train Acc: 100.000
28 Train Loss: 0.323 | Train Acc: 100.000
29 Train Loss: 0.310 | Train Acc: 100.000
30 Train Loss: 0.292 | Train Acc: 100.000
31 Train Loss: 0.271 | Train Acc: 100.000
32 Train Loss: 0.260 | Train Acc: 100.000
33 Train Loss: 0.245 | Train Acc: 100.000
34 Train Loss: 0.233 | Train Acc: 100.000
35 Train Loss: 0.217 | Train Acc: 100.000
36 Train Loss: 0.206 | Train Acc: 100.000
37 Train Loss: 0.195 | Train Acc: 100.000
38 Train Loss: 0.183 | Train Acc: 100.000
39 Train Loss: 0.173 | Train Acc: 100.000
40 Train Loss: 0.159 | Train Acc: 100.000
41 Train Loss: 0.154 | Train Acc: 100.000
42 Train Loss: 0.150 | Train Acc: 100.000
43 Train Loss: 0.146 | Train Acc: 100.000
44 Train Loss: 0.143 | Train Acc: 100.000
45 Train Loss: 0.140 | Train Acc: 100.000
46 Train Loss: 0.136 | Train Acc: 100.000
47 Train Loss: 0.131 | Train Acc: 100.000
48 Train Loss: 0.130 | Train Acc: 100.000
49 Train Loss: 0.126 | Train Acc: 100.000
50 Train Loss: 0.122 | Train Acc: 100.000
51 Train Loss: 0.118 | Train Acc: 100.000
52 Train Loss: 0.115 | Train Acc: 100.000
53 Train Loss: 0.111 | Train Acc: 100.000
54 Train Loss: 0.107 | Train Acc: 100.000
55 Train Loss: 0.104 | Train Acc: 100.000
56 Train Loss: 0.101 | Train Acc: 100.000
57 Train Loss: 0.097 | Train Acc: 100.000
58 Train Loss: 0.095 | Train Acc: 100.000
59 Train Loss: 0.092 | Train Acc: 100.000
60 Train Loss: 0.086 | Train Acc: 100.000
61 Train Loss: 0.085 | Train Acc: 100.000
62 Train Loss: 0.083 | Train Acc: 100.000
63 Train Loss: 0.082 | Train Acc: 100.000
64 Train Loss: 0.081 | Train Acc: 100.000
65 Train Loss: 0.079 | Train Acc: 100.000
66 Train Loss: 0.078 | Train Acc: 100.000
67 Train Loss: 0.077 | Train Acc: 100.000
68 Train Loss: 0.075 | Train Acc: 100.000
69 Train Loss: 0.074 | Train Acc: 100.000
70 Train Loss: 0.073 | Train Acc: 100.000
71 Train Loss: 0.071 | Train Acc: 100.000
72 Train Loss: 0.070 | Train Acc: 100.000
73 Train Loss: 0.069 | Train Acc: 100.000
74 Train Loss: 0.067 | Train Acc: 100.000
75 Train Loss: 0.065 | Train Acc: 100.000
76 Train Loss: 0.064 | Train Acc: 100.000
77 Train Loss: 0.063 | Train Acc: 100.000
78 Train Loss: 0.061 | Train Acc: 100.000
79 Train Loss: 0.059 | Train Acc: 100.000
80 Train Loss: 0.057 | Train Acc: 100.000
81 Train Loss: 0.057 | Train Acc: 100.000
82 Train Loss: 0.056 | Train Acc: 100.000
83 Train Loss: 0.055 | Train Acc: 100.000
84 Train Loss: 0.055 | Train Acc: 100.000
85 Train Loss: 0.054 | Train Acc: 100.000
86 Train Loss: 0.054 | Train Acc: 100.000
87 Train Loss: 0.053 | Train Acc: 100.000
88 Train Loss: 0.052 | Train Acc: 100.000
89 Train Loss: 0.052 | Train Acc: 100.000
90 Train Loss: 0.051 | Train Acc: 100.000
91 Train Loss: 0.050 | Train Acc: 100.000
92 Train Loss: 0.050 | Train Acc: 100.000
93 Train Loss: 0.049 | Train Acc: 100.000
94 Train Loss: 0.048 | Train Acc: 100.000
95 Train Loss: 0.047 | Train Acc: 100.000
96 Train Loss: 0.047 | Train Acc: 100.000
97 Train Loss: 0.046 | Train Acc: 100.000
98 Train Loss: 0.045 | Train Acc: 100.000
99 Train Loss: 0.044 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([4617, 2304])
printing expected split from k means
{0: 0, 1: 0, 6: 0, 8: 0, 9: 0, 2: 0, 5: 0, 4: 0, 3: 0, 7: 1}
Printing final_dict items...
{0: 0, 1: 0, 6: 0, 8: 0, 9: 0, 2: 0, 5: 0, 4: 0, 3: 0, 7: 1}
Image Statistics before MLP : L R :  4228 389
expectedMlpLabels.shape :  torch.Size([4617])
0 Loss: 12.182 | Acc: 89.891
1 Loss: 7.274 | Acc: 93.391
2 Loss: 4.418 | Acc: 94.217
3 Loss: 2.853 | Acc: 96.348
4 Loss: 3.995 | Acc: 95.630
5 Loss: 2.547 | Acc: 96.652
6 Loss: 1.739 | Acc: 97.674
7 Loss: 1.944 | Acc: 97.478
8 Loss: 3.013 | Acc: 96.870
9 Loss: 1.615 | Acc: 97.826
10 Loss: 1.307 | Acc: 97.891
11 Loss: 1.054 | Acc: 98.413
12 Loss: 0.878 | Acc: 98.826
13 Loss: 0.871 | Acc: 98.761
14 Loss: 0.835 | Acc: 98.783
15 Loss: 0.922 | Acc: 98.804
16 Loss: 0.931 | Acc: 98.783
17 Loss: 0.716 | Acc: 99.000
18 Loss: 0.520 | Acc: 99.196
19 Loss: 0.945 | Acc: 98.804
20 Loss: 0.530 | Acc: 99.065
21 Loss: 0.514 | Acc: 99.109
22 Loss: 0.474 | Acc: 99.152
23 Loss: 0.407 | Acc: 99.196
24 Loss: 0.714 | Acc: 99.152
25 Loss: 0.515 | Acc: 99.239
26 Loss: 0.475 | Acc: 99.370
27 Loss: 0.377 | Acc: 99.478
28 Loss: 0.469 | Acc: 99.239
29 Loss: 0.436 | Acc: 99.261
30 Loss: 0.434 | Acc: 99.304
31 Loss: 0.444 | Acc: 99.261
32 Loss: 0.355 | Acc: 99.457
33 Loss: 0.283 | Acc: 99.500
34 Loss: 0.445 | Acc: 99.435
35 Loss: 0.283 | Acc: 99.587
36 Loss: 0.337 | Acc: 99.522
37 Loss: 0.313 | Acc: 99.500
38 Loss: 0.376 | Acc: 99.457
39 Loss: 0.264 | Acc: 99.565
40 Loss: 0.174 | Acc: 99.696
41 Loss: 0.240 | Acc: 99.696
42 Loss: 0.213 | Acc: 99.609
43 Loss: 0.216 | Acc: 99.674
44 Loss: 0.260 | Acc: 99.543
45 Loss: 0.252 | Acc: 99.587
46 Loss: 0.258 | Acc: 99.674
47 Loss: 0.219 | Acc: 99.674
48 Loss: 0.202 | Acc: 99.630
49 Loss: 0.186 | Acc: 99.652
50 Loss: 0.210 | Acc: 99.630
51 Loss: 0.203 | Acc: 99.630
52 Loss: 0.241 | Acc: 99.587
53 Loss: 0.170 | Acc: 99.674
54 Loss: 0.207 | Acc: 99.696
55 Loss: 0.171 | Acc: 99.696
56 Loss: 0.183 | Acc: 99.674
57 Loss: 0.149 | Acc: 99.674
58 Loss: 0.161 | Acc: 99.739
59 Loss: 0.130 | Acc: 99.783
MLP trained successfully...
# of Left images:  1005.0
# of Right images:  143.0
giniRightRatio:  0.716807667856619
giniLeftRatio:  0.7663453874904086
impurityDrop:  1.064957375772413
giniGain:  -0.3006725720234298
lclasses:  [140, 403, 32, 10, 29, 4, 79, 6, 159, 143]
rclasses:  [43, 59, 7, 0, 0, 0, 2, 4, 14, 14]
noOfLeftClasses:  10
noOfRightClasses:  7
lTrainDict[data].shape:  torch.Size([1005, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([1005])
rTrainDict[data].shape:  torch.Size([143, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([143])
RETURNING FROM WORK...
nodeId:  52 , imgTensorShape :  torch.Size([1005, 16, 12, 12])
nodeId: 52 ,  parentId: 26 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1005
nodeId:  53 , imgTensorShape :  torch.Size([143, 16, 12, 12])
nodeId: 53 ,  parentId: 26 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 7 ,  numData: 143
Running nodeId:  27
trainInputDict[data].shape :  torch.Size([1283, 16, 16, 16])
copy.shape :  torch.Size([1283, 4096])
copyLabel.shape :  torch.Size([1283])
Class 0 has 216 instances after oversampling
Class 1 has 216 instances after oversampling
Class 2 has 216 instances after oversampling
Class 3 has 216 instances after oversampling
Class 4 has 216 instances after oversampling
Class 5 has 216 instances after oversampling
Class 6 has 216 instances after oversampling
Class 7 has 216 instances after oversampling
Class 8 has 216 instances after oversampling
Class 9 has 216 instances after oversampling
0 Train Loss: 230.754 | Train Acc: 12.238
1 Train Loss: 211.593 | Train Acc: 24.381
2 Train Loss: 166.775 | Train Acc: 46.190
3 Train Loss: 125.944 | Train Acc: 60.238
4 Train Loss: 94.850 | Train Acc: 71.524
5 Train Loss: 68.423 | Train Acc: 79.000
6 Train Loss: 47.423 | Train Acc: 86.667
7 Train Loss: 31.368 | Train Acc: 92.095
8 Train Loss: 18.730 | Train Acc: 95.762
9 Train Loss: 11.581 | Train Acc: 98.238
10 Train Loss: 6.906 | Train Acc: 99.286
11 Train Loss: 4.542 | Train Acc: 99.714
12 Train Loss: 2.777 | Train Acc: 100.000
13 Train Loss: 2.010 | Train Acc: 100.000
14 Train Loss: 1.472 | Train Acc: 100.000
15 Train Loss: 1.202 | Train Acc: 100.000
16 Train Loss: 0.989 | Train Acc: 100.000
17 Train Loss: 0.837 | Train Acc: 100.000
18 Train Loss: 0.710 | Train Acc: 100.000
19 Train Loss: 0.613 | Train Acc: 100.000
20 Train Loss: 0.516 | Train Acc: 100.000
21 Train Loss: 0.487 | Train Acc: 100.000
22 Train Loss: 0.466 | Train Acc: 100.000
23 Train Loss: 0.444 | Train Acc: 100.000
24 Train Loss: 0.422 | Train Acc: 100.000
25 Train Loss: 0.404 | Train Acc: 100.000
26 Train Loss: 0.381 | Train Acc: 100.000
27 Train Loss: 0.363 | Train Acc: 100.000
28 Train Loss: 0.344 | Train Acc: 100.000
29 Train Loss: 0.327 | Train Acc: 100.000
30 Train Loss: 0.311 | Train Acc: 100.000
31 Train Loss: 0.295 | Train Acc: 100.000
32 Train Loss: 0.279 | Train Acc: 100.000
33 Train Loss: 0.265 | Train Acc: 100.000
34 Train Loss: 0.253 | Train Acc: 100.000
35 Train Loss: 0.237 | Train Acc: 100.000
36 Train Loss: 0.226 | Train Acc: 100.000
37 Train Loss: 0.213 | Train Acc: 100.000
38 Train Loss: 0.203 | Train Acc: 100.000
39 Train Loss: 0.190 | Train Acc: 100.000
40 Train Loss: 0.177 | Train Acc: 100.000
41 Train Loss: 0.172 | Train Acc: 100.000
42 Train Loss: 0.169 | Train Acc: 100.000
43 Train Loss: 0.165 | Train Acc: 100.000
44 Train Loss: 0.161 | Train Acc: 100.000
45 Train Loss: 0.157 | Train Acc: 100.000
46 Train Loss: 0.153 | Train Acc: 100.000
47 Train Loss: 0.149 | Train Acc: 100.000
48 Train Loss: 0.146 | Train Acc: 100.000
49 Train Loss: 0.141 | Train Acc: 100.000
50 Train Loss: 0.138 | Train Acc: 100.000
51 Train Loss: 0.134 | Train Acc: 100.000
52 Train Loss: 0.130 | Train Acc: 100.000
53 Train Loss: 0.126 | Train Acc: 100.000
54 Train Loss: 0.123 | Train Acc: 100.000
55 Train Loss: 0.118 | Train Acc: 100.000
56 Train Loss: 0.115 | Train Acc: 100.000
57 Train Loss: 0.111 | Train Acc: 100.000
58 Train Loss: 0.107 | Train Acc: 100.000
59 Train Loss: 0.104 | Train Acc: 100.000
60 Train Loss: 0.099 | Train Acc: 100.000
61 Train Loss: 0.097 | Train Acc: 100.000
62 Train Loss: 0.096 | Train Acc: 100.000
63 Train Loss: 0.094 | Train Acc: 100.000
64 Train Loss: 0.093 | Train Acc: 100.000
65 Train Loss: 0.092 | Train Acc: 100.000
66 Train Loss: 0.090 | Train Acc: 100.000
67 Train Loss: 0.088 | Train Acc: 100.000
68 Train Loss: 0.087 | Train Acc: 100.000
69 Train Loss: 0.085 | Train Acc: 100.000
70 Train Loss: 0.084 | Train Acc: 100.000
71 Train Loss: 0.082 | Train Acc: 100.000
72 Train Loss: 0.080 | Train Acc: 100.000
73 Train Loss: 0.079 | Train Acc: 100.000
74 Train Loss: 0.077 | Train Acc: 100.000
75 Train Loss: 0.075 | Train Acc: 100.000
76 Train Loss: 0.074 | Train Acc: 100.000
77 Train Loss: 0.072 | Train Acc: 100.000
78 Train Loss: 0.070 | Train Acc: 100.000
79 Train Loss: 0.069 | Train Acc: 100.000
80 Train Loss: 0.066 | Train Acc: 100.000
81 Train Loss: 0.065 | Train Acc: 100.000
82 Train Loss: 0.065 | Train Acc: 100.000
83 Train Loss: 0.064 | Train Acc: 100.000
84 Train Loss: 0.063 | Train Acc: 100.000
85 Train Loss: 0.063 | Train Acc: 100.000
86 Train Loss: 0.062 | Train Acc: 100.000
87 Train Loss: 0.061 | Train Acc: 100.000
88 Train Loss: 0.060 | Train Acc: 100.000
89 Train Loss: 0.059 | Train Acc: 100.000
90 Train Loss: 0.059 | Train Acc: 100.000
91 Train Loss: 0.058 | Train Acc: 100.000
92 Train Loss: 0.057 | Train Acc: 100.000
93 Train Loss: 0.056 | Train Acc: 100.000
94 Train Loss: 0.055 | Train Acc: 100.000
95 Train Loss: 0.054 | Train Acc: 100.000
96 Train Loss: 0.053 | Train Acc: 100.000
97 Train Loss: 0.053 | Train Acc: 100.000
98 Train Loss: 0.052 | Train Acc: 100.000
99 Train Loss: 0.051 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([2160, 2304])
printing expected split from k means
{1: 0, 4: 0, 6: 0, 8: 0, 2: 0, 7: 0, 3: 0, 0: 1, 9: 0, 5: 0}
Printing final_dict items...
{1: 0, 4: 0, 6: 0, 8: 0, 2: 0, 7: 0, 3: 0, 0: 1, 9: 0, 5: 0}
Image Statistics before MLP : L R :  1619 541
expectedMlpLabels.shape :  torch.Size([2160])
0 Loss: 30.217 | Acc: 86.300
1 Loss: 17.209 | Acc: 92.600
2 Loss: 14.206 | Acc: 94.600
3 Loss: 13.606 | Acc: 94.650
4 Loss: 11.315 | Acc: 94.900
5 Loss: 7.838 | Acc: 96.350
6 Loss: 8.780 | Acc: 95.850
7 Loss: 8.961 | Acc: 96.350
8 Loss: 8.330 | Acc: 96.750
9 Loss: 6.832 | Acc: 97.050
10 Loss: 5.096 | Acc: 97.650
11 Loss: 3.967 | Acc: 97.950
12 Loss: 3.012 | Acc: 98.850
13 Loss: 2.587 | Acc: 98.900
14 Loss: 2.777 | Acc: 98.800
15 Loss: 2.861 | Acc: 98.750
16 Loss: 2.631 | Acc: 98.850
17 Loss: 3.004 | Acc: 98.900
18 Loss: 3.395 | Acc: 98.450
19 Loss: 3.246 | Acc: 98.550
20 Loss: 2.336 | Acc: 98.900
21 Loss: 2.036 | Acc: 99.000
22 Loss: 1.736 | Acc: 99.150
23 Loss: 1.555 | Acc: 99.200
24 Loss: 1.258 | Acc: 99.400
25 Loss: 1.346 | Acc: 99.400
26 Loss: 1.401 | Acc: 99.550
27 Loss: 1.505 | Acc: 99.150
28 Loss: 1.946 | Acc: 99.000
29 Loss: 1.491 | Acc: 99.250
30 Loss: 1.231 | Acc: 99.400
31 Loss: 1.392 | Acc: 99.150
32 Loss: 1.049 | Acc: 99.400
33 Loss: 0.963 | Acc: 99.450
34 Loss: 1.414 | Acc: 99.300
35 Loss: 0.846 | Acc: 99.650
36 Loss: 1.196 | Acc: 99.400
37 Loss: 1.002 | Acc: 99.450
38 Loss: 0.869 | Acc: 99.550
39 Loss: 1.435 | Acc: 99.300
40 Loss: 0.898 | Acc: 99.500
41 Loss: 0.773 | Acc: 99.700
42 Loss: 1.096 | Acc: 99.400
43 Loss: 1.118 | Acc: 99.300
44 Loss: 0.843 | Acc: 99.500
45 Loss: 1.004 | Acc: 99.450
46 Loss: 0.694 | Acc: 99.700
47 Loss: 0.862 | Acc: 99.500
48 Loss: 1.239 | Acc: 99.300
49 Loss: 0.681 | Acc: 99.750
50 Loss: 0.950 | Acc: 99.350
51 Loss: 0.497 | Acc: 99.750
52 Loss: 0.590 | Acc: 99.700
53 Loss: 1.307 | Acc: 99.500
54 Loss: 0.737 | Acc: 99.650
55 Loss: 0.803 | Acc: 99.550
56 Loss: 0.769 | Acc: 99.500
57 Loss: 0.756 | Acc: 99.650
58 Loss: 0.873 | Acc: 99.450
59 Loss: 0.792 | Acc: 99.600
MLP trained successfully...
# of Left images:  904.0
# of Right images:  379.0
giniRightRatio:  0.8763653831426961
giniLeftRatio:  0.8853840355548594
impurityDrop:  0.8978768917986213
giniGain:  -0.009522738408373366
lclasses:  [46, 112, 99, 116, 54, 62, 144, 53, 80, 138]
rclasses:  [47, 62, 28, 19, 35, 15, 29, 35, 31, 78]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([904, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([904])
rTrainDict[data].shape:  torch.Size([379, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([379])
RETURNING FROM WORK...
nodeId:  54 , imgTensorShape :  torch.Size([904, 16, 12, 12])
nodeId: 54 ,  parentId: 27 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 904
nodeId:  55 , imgTensorShape :  torch.Size([379, 16, 12, 12])
nodeId: 55 ,  parentId: 27 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 379
Running nodeId:  28
trainInputDict[data].shape :  torch.Size([6972, 16, 16, 16])
copy.shape :  torch.Size([6972, 4096])
copyLabel.shape :  torch.Size([6972])
Class 0 has 2105 instances after oversampling
Class 1 has 2105 instances after oversampling
Class 2 has 2106 instances after oversampling
Class 3 has 2106 instances after oversampling
Class 4 has 2106 instances after oversampling
Class 5 has 2106 instances after oversampling
Class 6 has 2106 instances after oversampling
Class 7 has 2106 instances after oversampling
Class 8 has 2105 instances after oversampling
Class 9 has 2105 instances after oversampling
0 Train Loss: 228.125 | Train Acc: 12.908
1 Train Loss: 197.270 | Train Acc: 28.548
2 Train Loss: 154.974 | Train Acc: 46.941
3 Train Loss: 123.654 | Train Acc: 59.024
4 Train Loss: 104.809 | Train Acc: 64.818
5 Train Loss: 91.710 | Train Acc: 69.234
6 Train Loss: 88.702 | Train Acc: 69.586
7 Train Loss: 81.361 | Train Acc: 71.780
8 Train Loss: 78.057 | Train Acc: 73.134
9 Train Loss: 71.459 | Train Acc: 74.972
10 Train Loss: 67.378 | Train Acc: 76.743
11 Train Loss: 69.016 | Train Acc: 75.831
12 Train Loss: 63.805 | Train Acc: 77.859
13 Train Loss: 60.755 | Train Acc: 79.160
14 Train Loss: 59.146 | Train Acc: 79.702
15 Train Loss: 57.623 | Train Acc: 80.224
16 Train Loss: 57.008 | Train Acc: 80.338
17 Train Loss: 56.666 | Train Acc: 80.381
18 Train Loss: 53.519 | Train Acc: 81.549
19 Train Loss: 52.825 | Train Acc: 81.910
20 Train Loss: 45.907 | Train Acc: 85.064
21 Train Loss: 45.445 | Train Acc: 84.688
22 Train Loss: 43.992 | Train Acc: 85.586
23 Train Loss: 43.464 | Train Acc: 85.567
24 Train Loss: 43.316 | Train Acc: 85.781
25 Train Loss: 42.896 | Train Acc: 85.653
26 Train Loss: 41.848 | Train Acc: 86.146
27 Train Loss: 41.767 | Train Acc: 86.379
28 Train Loss: 40.911 | Train Acc: 86.674
29 Train Loss: 40.041 | Train Acc: 86.807
30 Train Loss: 41.599 | Train Acc: 86.327
31 Train Loss: 39.469 | Train Acc: 87.073
32 Train Loss: 38.900 | Train Acc: 87.225
33 Train Loss: 38.794 | Train Acc: 87.025
34 Train Loss: 37.537 | Train Acc: 87.704
35 Train Loss: 38.496 | Train Acc: 87.172
36 Train Loss: 37.169 | Train Acc: 87.761
37 Train Loss: 36.853 | Train Acc: 88.165
38 Train Loss: 36.784 | Train Acc: 88.018
39 Train Loss: 35.653 | Train Acc: 88.355
40 Train Loss: 33.710 | Train Acc: 89.195
41 Train Loss: 33.048 | Train Acc: 89.409
42 Train Loss: 33.222 | Train Acc: 89.504
43 Train Loss: 32.871 | Train Acc: 89.661
44 Train Loss: 32.647 | Train Acc: 89.699
45 Train Loss: 32.509 | Train Acc: 89.827
46 Train Loss: 32.697 | Train Acc: 89.613
47 Train Loss: 32.696 | Train Acc: 89.713
48 Train Loss: 32.135 | Train Acc: 89.951
49 Train Loss: 31.958 | Train Acc: 89.974
50 Train Loss: 31.992 | Train Acc: 89.951
51 Train Loss: 31.500 | Train Acc: 90.069
52 Train Loss: 31.464 | Train Acc: 90.112
53 Train Loss: 31.406 | Train Acc: 90.122
54 Train Loss: 31.252 | Train Acc: 90.226
55 Train Loss: 30.783 | Train Acc: 90.449
56 Train Loss: 30.746 | Train Acc: 90.274
57 Train Loss: 30.825 | Train Acc: 90.350
58 Train Loss: 30.859 | Train Acc: 90.150
59 Train Loss: 30.294 | Train Acc: 90.373
60 Train Loss: 29.637 | Train Acc: 90.734
61 Train Loss: 29.435 | Train Acc: 90.877
62 Train Loss: 29.401 | Train Acc: 90.900
63 Train Loss: 29.497 | Train Acc: 90.853
64 Train Loss: 29.217 | Train Acc: 91.038
65 Train Loss: 29.149 | Train Acc: 91.048
66 Train Loss: 29.010 | Train Acc: 91.014
67 Train Loss: 29.061 | Train Acc: 91.010
68 Train Loss: 29.025 | Train Acc: 91.124
69 Train Loss: 28.936 | Train Acc: 90.948
70 Train Loss: 28.884 | Train Acc: 91.171
71 Train Loss: 28.732 | Train Acc: 91.190
72 Train Loss: 28.766 | Train Acc: 91.299
73 Train Loss: 28.520 | Train Acc: 91.204
74 Train Loss: 28.687 | Train Acc: 91.143
75 Train Loss: 28.501 | Train Acc: 91.200
76 Train Loss: 28.504 | Train Acc: 91.228
77 Train Loss: 28.327 | Train Acc: 91.328
78 Train Loss: 28.255 | Train Acc: 91.380
79 Train Loss: 28.390 | Train Acc: 91.276
80 Train Loss: 27.885 | Train Acc: 91.565
81 Train Loss: 27.890 | Train Acc: 91.504
82 Train Loss: 27.828 | Train Acc: 91.551
83 Train Loss: 27.786 | Train Acc: 91.489
84 Train Loss: 27.757 | Train Acc: 91.532
85 Train Loss: 27.703 | Train Acc: 91.656
86 Train Loss: 27.758 | Train Acc: 91.570
87 Train Loss: 27.767 | Train Acc: 91.584
88 Train Loss: 27.706 | Train Acc: 91.599
89 Train Loss: 27.741 | Train Acc: 91.561
90 Train Loss: 27.577 | Train Acc: 91.698
91 Train Loss: 27.595 | Train Acc: 91.618
92 Train Loss: 27.557 | Train Acc: 91.660
93 Train Loss: 27.542 | Train Acc: 91.613
94 Train Loss: 27.486 | Train Acc: 91.665
95 Train Loss: 27.533 | Train Acc: 91.608
96 Train Loss: 27.432 | Train Acc: 91.627
97 Train Loss: 27.419 | Train Acc: 91.703
98 Train Loss: 27.362 | Train Acc: 91.694
99 Train Loss: 27.415 | Train Acc: 91.679
CNN trained successfully...
image_next_flat.shape :  torch.Size([21056, 2304])
printing expected split from k means
{4: 0, 2: 0, 6: 0, 3: 0, 5: 0, 7: 0, 1: 0, 8: 1, 9: 0, 0: 1}
Printing final_dict items...
{4: 0, 2: 0, 6: 0, 3: 0, 5: 0, 7: 0, 1: 0, 8: 1, 9: 0, 0: 1}
Image Statistics before MLP : L R :  15100 5956
expectedMlpLabels.shape :  torch.Size([21056])
0 Loss: 21.287 | Acc: 91.510
1 Loss: 13.381 | Acc: 94.300
2 Loss: 11.965 | Acc: 95.090
3 Loss: 10.144 | Acc: 95.657
4 Loss: 9.263 | Acc: 96.105
5 Loss: 8.662 | Acc: 96.343
6 Loss: 7.632 | Acc: 96.662
7 Loss: 7.389 | Acc: 97.062
8 Loss: 6.647 | Acc: 97.348
9 Loss: 6.270 | Acc: 97.443
10 Loss: 5.118 | Acc: 97.981
11 Loss: 4.175 | Acc: 98.257
12 Loss: 3.974 | Acc: 98.319
13 Loss: 4.005 | Acc: 98.414
14 Loss: 3.750 | Acc: 98.443
15 Loss: 3.417 | Acc: 98.638
16 Loss: 3.488 | Acc: 98.595
17 Loss: 3.205 | Acc: 98.781
18 Loss: 3.165 | Acc: 98.719
19 Loss: 3.258 | Acc: 98.771
20 Loss: 2.730 | Acc: 98.871
21 Loss: 2.205 | Acc: 99.133
22 Loss: 2.367 | Acc: 99.057
23 Loss: 2.098 | Acc: 99.138
24 Loss: 2.087 | Acc: 99.162
25 Loss: 1.795 | Acc: 99.314
26 Loss: 2.116 | Acc: 99.181
27 Loss: 1.918 | Acc: 99.190
28 Loss: 1.690 | Acc: 99.324
29 Loss: 1.813 | Acc: 99.271
30 Loss: 1.571 | Acc: 99.343
31 Loss: 1.578 | Acc: 99.414
32 Loss: 1.386 | Acc: 99.471
33 Loss: 1.484 | Acc: 99.471
34 Loss: 1.375 | Acc: 99.467
35 Loss: 1.560 | Acc: 99.400
36 Loss: 1.325 | Acc: 99.490
37 Loss: 1.275 | Acc: 99.571
38 Loss: 1.461 | Acc: 99.433
39 Loss: 1.259 | Acc: 99.495
40 Loss: 1.130 | Acc: 99.600
41 Loss: 1.105 | Acc: 99.605
42 Loss: 1.244 | Acc: 99.481
43 Loss: 1.083 | Acc: 99.576
44 Loss: 1.245 | Acc: 99.567
45 Loss: 1.116 | Acc: 99.595
46 Loss: 1.147 | Acc: 99.548
47 Loss: 1.219 | Acc: 99.538
48 Loss: 1.130 | Acc: 99.538
49 Loss: 1.260 | Acc: 99.481
50 Loss: 1.065 | Acc: 99.529
51 Loss: 1.004 | Acc: 99.619
52 Loss: 1.000 | Acc: 99.633
53 Loss: 1.004 | Acc: 99.652
54 Loss: 0.951 | Acc: 99.619
55 Loss: 1.070 | Acc: 99.633
56 Loss: 1.060 | Acc: 99.595
57 Loss: 0.990 | Acc: 99.605
58 Loss: 0.971 | Acc: 99.605
59 Loss: 1.069 | Acc: 99.586
MLP trained successfully...
# of Left images:  5526.0
# of Right images:  1446.0
giniRightRatio:  0.7770881278827079
giniLeftRatio:  0.8078302301141094
impurityDrop:  0.8945714314309265
giniGain:  -0.08873267603231372
lclasses:  [31, 11, 858, 921, 1134, 648, 1575, 309, 17, 22]
rclasses:  [79, 13, 282, 95, 284, 65, 531, 60, 17, 20]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([5526, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([5526])
rTrainDict[data].shape:  torch.Size([1446, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([1446])
RETURNING FROM WORK...
nodeId:  56 , imgTensorShape :  torch.Size([5526, 16, 12, 12])
nodeId: 56 ,  parentId: 28 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 5526
nodeId:  57 , imgTensorShape :  torch.Size([1446, 16, 12, 12])
nodeId: 57 ,  parentId: 28 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1446
Running nodeId:  29
trainInputDict[data].shape :  torch.Size([1873, 16, 16, 16])
copy.shape :  torch.Size([1873, 4096])
copyLabel.shape :  torch.Size([1873])
Class 0 has 569 instances after oversampling
Class 1 has 569 instances after oversampling
Class 2 has 570 instances after oversampling
Class 3 has 569 instances after oversampling
Class 4 has 570 instances after oversampling
Class 5 has 569 instances after oversampling
Class 6 has 570 instances after oversampling
Class 7 has 569 instances after oversampling
Class 8 has 569 instances after oversampling
Class 9 has 569 instances after oversampling
0 Train Loss: 203.993 | Train Acc: 28.790
1 Train Loss: 132.021 | Train Acc: 55.120
2 Train Loss: 101.815 | Train Acc: 66.046
3 Train Loss: 81.855 | Train Acc: 72.651
4 Train Loss: 68.598 | Train Acc: 77.411
5 Train Loss: 60.590 | Train Acc: 79.888
6 Train Loss: 50.980 | Train Acc: 83.488
7 Train Loss: 43.919 | Train Acc: 85.895
8 Train Loss: 38.322 | Train Acc: 87.511
9 Train Loss: 33.359 | Train Acc: 89.127
10 Train Loss: 32.110 | Train Acc: 90.005
11 Train Loss: 28.278 | Train Acc: 91.428
12 Train Loss: 25.645 | Train Acc: 91.902
13 Train Loss: 22.079 | Train Acc: 93.202
14 Train Loss: 21.260 | Train Acc: 93.553
15 Train Loss: 24.914 | Train Acc: 92.008
16 Train Loss: 16.943 | Train Acc: 95.292
17 Train Loss: 15.676 | Train Acc: 95.257
18 Train Loss: 14.622 | Train Acc: 95.696
19 Train Loss: 13.715 | Train Acc: 95.995
20 Train Loss: 10.811 | Train Acc: 97.488
21 Train Loss: 9.902 | Train Acc: 97.523
22 Train Loss: 9.344 | Train Acc: 97.629
23 Train Loss: 8.928 | Train Acc: 98.033
24 Train Loss: 8.593 | Train Acc: 98.015
25 Train Loss: 8.312 | Train Acc: 98.138
26 Train Loss: 7.953 | Train Acc: 98.349
27 Train Loss: 7.732 | Train Acc: 98.279
28 Train Loss: 7.273 | Train Acc: 98.612
29 Train Loss: 7.006 | Train Acc: 98.630
30 Train Loss: 6.692 | Train Acc: 98.718
31 Train Loss: 6.558 | Train Acc: 98.753
32 Train Loss: 6.241 | Train Acc: 98.858
33 Train Loss: 5.835 | Train Acc: 99.087
34 Train Loss: 5.729 | Train Acc: 99.016
35 Train Loss: 5.522 | Train Acc: 98.981
36 Train Loss: 5.121 | Train Acc: 99.245
37 Train Loss: 4.861 | Train Acc: 99.262
38 Train Loss: 4.486 | Train Acc: 99.526
39 Train Loss: 4.369 | Train Acc: 99.420
40 Train Loss: 3.921 | Train Acc: 99.631
41 Train Loss: 3.761 | Train Acc: 99.684
42 Train Loss: 3.658 | Train Acc: 99.684
43 Train Loss: 3.599 | Train Acc: 99.701
44 Train Loss: 3.551 | Train Acc: 99.719
45 Train Loss: 3.458 | Train Acc: 99.737
46 Train Loss: 3.375 | Train Acc: 99.772
47 Train Loss: 3.283 | Train Acc: 99.754
48 Train Loss: 3.237 | Train Acc: 99.789
49 Train Loss: 3.153 | Train Acc: 99.789
50 Train Loss: 3.067 | Train Acc: 99.737
51 Train Loss: 3.043 | Train Acc: 99.754
52 Train Loss: 2.983 | Train Acc: 99.807
53 Train Loss: 2.845 | Train Acc: 99.842
54 Train Loss: 2.816 | Train Acc: 99.754
55 Train Loss: 2.729 | Train Acc: 99.859
56 Train Loss: 2.634 | Train Acc: 99.842
57 Train Loss: 2.569 | Train Acc: 99.842
58 Train Loss: 2.474 | Train Acc: 99.877
59 Train Loss: 2.436 | Train Acc: 99.877
60 Train Loss: 2.250 | Train Acc: 99.912
61 Train Loss: 2.222 | Train Acc: 99.895
62 Train Loss: 2.204 | Train Acc: 99.895
63 Train Loss: 2.171 | Train Acc: 99.877
64 Train Loss: 2.143 | Train Acc: 99.912
65 Train Loss: 2.120 | Train Acc: 99.895
66 Train Loss: 2.095 | Train Acc: 99.895
67 Train Loss: 2.071 | Train Acc: 99.895
68 Train Loss: 2.052 | Train Acc: 99.895
69 Train Loss: 2.009 | Train Acc: 99.895
70 Train Loss: 1.988 | Train Acc: 99.912
71 Train Loss: 1.949 | Train Acc: 99.912
72 Train Loss: 1.936 | Train Acc: 99.912
73 Train Loss: 1.904 | Train Acc: 99.912
74 Train Loss: 1.882 | Train Acc: 99.912
75 Train Loss: 1.846 | Train Acc: 99.912
76 Train Loss: 1.820 | Train Acc: 99.912
77 Train Loss: 1.796 | Train Acc: 99.895
78 Train Loss: 1.777 | Train Acc: 99.912
79 Train Loss: 1.752 | Train Acc: 99.930
80 Train Loss: 1.677 | Train Acc: 99.947
81 Train Loss: 1.658 | Train Acc: 99.930
82 Train Loss: 1.659 | Train Acc: 99.912
83 Train Loss: 1.654 | Train Acc: 99.947
84 Train Loss: 1.635 | Train Acc: 99.947
85 Train Loss: 1.619 | Train Acc: 99.947
86 Train Loss: 1.616 | Train Acc: 99.947
87 Train Loss: 1.602 | Train Acc: 99.947
88 Train Loss: 1.590 | Train Acc: 99.947
89 Train Loss: 1.586 | Train Acc: 99.930
90 Train Loss: 1.576 | Train Acc: 99.947
91 Train Loss: 1.566 | Train Acc: 99.947
92 Train Loss: 1.545 | Train Acc: 99.965
93 Train Loss: 1.540 | Train Acc: 99.947
94 Train Loss: 1.529 | Train Acc: 99.965
95 Train Loss: 1.517 | Train Acc: 99.965
96 Train Loss: 1.500 | Train Acc: 99.947
97 Train Loss: 1.494 | Train Acc: 99.965
98 Train Loss: 1.487 | Train Acc: 99.965
99 Train Loss: 1.477 | Train Acc: 99.965
CNN trained successfully...
image_next_flat.shape :  torch.Size([5693, 2304])
printing expected split from k means
{4: 0, 6: 0, 2: 0, 3: 0, 5: 0, 0: 0, 7: 0, 8: 0, 9: 0, 1: 1}
Printing final_dict items...
{4: 0, 6: 0, 2: 0, 3: 0, 5: 0, 0: 0, 7: 0, 8: 0, 9: 0, 1: 1}
Image Statistics before MLP : L R :  5013 680
expectedMlpLabels.shape :  torch.Size([5693])
0 Loss: 9.250 | Acc: 94.696
1 Loss: 3.108 | Acc: 97.143
2 Loss: 2.103 | Acc: 97.929
3 Loss: 1.475 | Acc: 98.357
4 Loss: 1.941 | Acc: 98.000
5 Loss: 1.895 | Acc: 98.375
6 Loss: 1.751 | Acc: 98.482
7 Loss: 1.982 | Acc: 98.429
8 Loss: 0.910 | Acc: 99.071
9 Loss: 0.772 | Acc: 99.268
10 Loss: 0.583 | Acc: 99.357
11 Loss: 0.549 | Acc: 99.500
12 Loss: 0.409 | Acc: 99.500
13 Loss: 0.256 | Acc: 99.750
14 Loss: 0.421 | Acc: 99.643
15 Loss: 0.302 | Acc: 99.679
16 Loss: 0.542 | Acc: 99.554
17 Loss: 0.628 | Acc: 99.554
18 Loss: 0.254 | Acc: 99.732
19 Loss: 0.393 | Acc: 99.589
20 Loss: 0.478 | Acc: 99.768
21 Loss: 0.183 | Acc: 99.679
22 Loss: 0.190 | Acc: 99.768
23 Loss: 0.145 | Acc: 99.857
24 Loss: 0.183 | Acc: 99.768
25 Loss: 0.155 | Acc: 99.821
26 Loss: 0.114 | Acc: 99.875
27 Loss: 0.258 | Acc: 99.804
28 Loss: 0.164 | Acc: 99.839
29 Loss: 0.182 | Acc: 99.821
30 Loss: 0.128 | Acc: 99.839
31 Loss: 0.093 | Acc: 99.875
32 Loss: 0.099 | Acc: 99.875
33 Loss: 0.109 | Acc: 99.875
34 Loss: 0.121 | Acc: 99.821
35 Loss: 0.070 | Acc: 99.911
36 Loss: 0.104 | Acc: 99.875
37 Loss: 0.075 | Acc: 99.911
38 Loss: 0.101 | Acc: 99.893
39 Loss: 0.154 | Acc: 99.875
40 Loss: 0.122 | Acc: 99.821
41 Loss: 0.091 | Acc: 99.875
42 Loss: 0.077 | Acc: 99.929
43 Loss: 0.116 | Acc: 99.857
44 Loss: 0.066 | Acc: 99.911
45 Loss: 0.071 | Acc: 99.911
46 Loss: 0.095 | Acc: 99.875
47 Loss: 0.058 | Acc: 99.911
48 Loss: 0.064 | Acc: 99.893
49 Loss: 0.054 | Acc: 99.946
50 Loss: 0.149 | Acc: 99.893
51 Loss: 0.085 | Acc: 99.875
52 Loss: 0.069 | Acc: 99.946
53 Loss: 0.051 | Acc: 99.911
54 Loss: 0.068 | Acc: 99.911
55 Loss: 0.053 | Acc: 99.929
56 Loss: 0.037 | Acc: 99.946
57 Loss: 0.068 | Acc: 99.875
58 Loss: 0.077 | Acc: 99.911
59 Loss: 0.055 | Acc: 99.911
MLP trained successfully...
# of Left images:  1782.0
# of Right images:  91.0
giniRightRatio:  0.63229078613694
giniLeftRatio:  0.779257848468473
impurityDrop:  3.5102611715742125
giniGain:  -2.7297915822290086
lclasses:  [90, 0, 516, 147, 558, 104, 283, 37, 35, 12]
rclasses:  [0, 4, 24, 2, 12, 1, 48, 0, 0, 0]
noOfLeftClasses:  9
noOfRightClasses:  6
lTrainDict[data].shape:  torch.Size([1782, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([1782])
rTrainDict[data].shape:  torch.Size([91, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([91])
RETURNING FROM WORK...
DATANUM THRESHOLD REACHED IN RIGHT 91 100
nodeId:  58 , imgTensorShape :  torch.Size([1782, 16, 12, 12])
nodeId: 58 ,  parentId: 29 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 9 ,  numData: 1782
nodeId:  59 , imgTensorShape :  torch.Size([91, 16, 12, 12])
nodeId: 59 ,  parentId: 29 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 6 ,  numData: 91
Running nodeId:  30
trainInputDict[data].shape :  torch.Size([1829, 16, 16, 16])
copy.shape :  torch.Size([1829, 4096])
copyLabel.shape :  torch.Size([1829])
Class 0 has 418 instances after oversampling
Class 1 has 418 instances after oversampling
Class 2 has 418 instances after oversampling
Class 3 has 418 instances after oversampling
Class 4 has 418 instances after oversampling
Class 5 has 418 instances after oversampling
Class 6 has 418 instances after oversampling
Class 7 has 418 instances after oversampling
Class 8 has 418 instances after oversampling
Class 9 has 418 instances after oversampling
0 Train Loss: 226.725 | Train Acc: 11.388
1 Train Loss: 201.640 | Train Acc: 27.033
2 Train Loss: 165.954 | Train Acc: 47.727
3 Train Loss: 129.103 | Train Acc: 58.301
4 Train Loss: 92.325 | Train Acc: 70.239
5 Train Loss: 74.465 | Train Acc: 75.646
6 Train Loss: 60.592 | Train Acc: 80.598
7 Train Loss: 50.481 | Train Acc: 84.689
8 Train Loss: 42.474 | Train Acc: 87.368
9 Train Loss: 33.842 | Train Acc: 90.478
10 Train Loss: 27.831 | Train Acc: 92.057
11 Train Loss: 22.440 | Train Acc: 93.804
12 Train Loss: 18.623 | Train Acc: 95.455
13 Train Loss: 16.059 | Train Acc: 95.933
14 Train Loss: 13.288 | Train Acc: 97.057
15 Train Loss: 10.975 | Train Acc: 97.560
16 Train Loss: 9.020 | Train Acc: 98.254
17 Train Loss: 7.110 | Train Acc: 99.091
18 Train Loss: 5.909 | Train Acc: 99.258
19 Train Loss: 4.999 | Train Acc: 99.426
20 Train Loss: 3.402 | Train Acc: 99.928
21 Train Loss: 2.949 | Train Acc: 99.976
22 Train Loss: 2.735 | Train Acc: 99.976
23 Train Loss: 2.529 | Train Acc: 100.000
24 Train Loss: 2.346 | Train Acc: 99.976
25 Train Loss: 2.207 | Train Acc: 100.000
26 Train Loss: 2.085 | Train Acc: 100.000
27 Train Loss: 1.948 | Train Acc: 100.000
28 Train Loss: 1.796 | Train Acc: 100.000
29 Train Loss: 1.695 | Train Acc: 100.000
30 Train Loss: 1.555 | Train Acc: 100.000
31 Train Loss: 1.476 | Train Acc: 100.000
32 Train Loss: 1.317 | Train Acc: 100.000
33 Train Loss: 1.218 | Train Acc: 100.000
34 Train Loss: 1.140 | Train Acc: 100.000
35 Train Loss: 1.061 | Train Acc: 100.000
36 Train Loss: 0.961 | Train Acc: 100.000
37 Train Loss: 0.898 | Train Acc: 100.000
38 Train Loss: 0.834 | Train Acc: 100.000
39 Train Loss: 0.788 | Train Acc: 100.000
40 Train Loss: 0.686 | Train Acc: 100.000
41 Train Loss: 0.673 | Train Acc: 100.000
42 Train Loss: 0.652 | Train Acc: 100.000
43 Train Loss: 0.635 | Train Acc: 100.000
44 Train Loss: 0.610 | Train Acc: 100.000
45 Train Loss: 0.597 | Train Acc: 100.000
46 Train Loss: 0.577 | Train Acc: 100.000
47 Train Loss: 0.565 | Train Acc: 100.000
48 Train Loss: 0.544 | Train Acc: 100.000
49 Train Loss: 0.526 | Train Acc: 100.000
50 Train Loss: 0.512 | Train Acc: 100.000
51 Train Loss: 0.497 | Train Acc: 100.000
52 Train Loss: 0.481 | Train Acc: 100.000
53 Train Loss: 0.461 | Train Acc: 100.000
54 Train Loss: 0.450 | Train Acc: 100.000
55 Train Loss: 0.432 | Train Acc: 100.000
56 Train Loss: 0.417 | Train Acc: 100.000
57 Train Loss: 0.406 | Train Acc: 100.000
58 Train Loss: 0.391 | Train Acc: 100.000
59 Train Loss: 0.375 | Train Acc: 100.000
60 Train Loss: 0.356 | Train Acc: 100.000
61 Train Loss: 0.348 | Train Acc: 100.000
62 Train Loss: 0.342 | Train Acc: 100.000
63 Train Loss: 0.337 | Train Acc: 100.000
64 Train Loss: 0.332 | Train Acc: 100.000
65 Train Loss: 0.326 | Train Acc: 100.000
66 Train Loss: 0.321 | Train Acc: 100.000
67 Train Loss: 0.314 | Train Acc: 100.000
68 Train Loss: 0.311 | Train Acc: 100.000
69 Train Loss: 0.305 | Train Acc: 100.000
70 Train Loss: 0.298 | Train Acc: 100.000
71 Train Loss: 0.293 | Train Acc: 100.000
72 Train Loss: 0.287 | Train Acc: 100.000
73 Train Loss: 0.281 | Train Acc: 100.000
74 Train Loss: 0.276 | Train Acc: 100.000
75 Train Loss: 0.271 | Train Acc: 100.000
76 Train Loss: 0.264 | Train Acc: 100.000
77 Train Loss: 0.261 | Train Acc: 100.000
78 Train Loss: 0.253 | Train Acc: 100.000
79 Train Loss: 0.247 | Train Acc: 100.000
80 Train Loss: 0.237 | Train Acc: 100.000
81 Train Loss: 0.235 | Train Acc: 100.000
82 Train Loss: 0.233 | Train Acc: 100.000
83 Train Loss: 0.231 | Train Acc: 100.000
84 Train Loss: 0.229 | Train Acc: 100.000
85 Train Loss: 0.226 | Train Acc: 100.000
86 Train Loss: 0.224 | Train Acc: 100.000
87 Train Loss: 0.222 | Train Acc: 100.000
88 Train Loss: 0.219 | Train Acc: 100.000
89 Train Loss: 0.217 | Train Acc: 100.000
90 Train Loss: 0.215 | Train Acc: 100.000
91 Train Loss: 0.212 | Train Acc: 100.000
92 Train Loss: 0.209 | Train Acc: 100.000
93 Train Loss: 0.206 | Train Acc: 100.000
94 Train Loss: 0.204 | Train Acc: 100.000
95 Train Loss: 0.201 | Train Acc: 100.000
96 Train Loss: 0.199 | Train Acc: 100.000
97 Train Loss: 0.196 | Train Acc: 100.000
98 Train Loss: 0.193 | Train Acc: 100.000
99 Train Loss: 0.191 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([4180, 2304])
printing expected split from k means
{7: 1, 5: 0, 3: 1, 6: 1, 2: 1, 4: 1, 1: 1, 8: 1, 9: 1, 0: 1}
Printing final_dict items...
{7: 1, 5: 0, 3: 1, 6: 1, 2: 1, 4: 1, 1: 1, 8: 1, 9: 1, 0: 1}
Image Statistics before MLP : L R :  1082 3098
expectedMlpLabels.shape :  torch.Size([4180])
0 Loss: 27.726 | Acc: 88.780
1 Loss: 14.822 | Acc: 93.230
2 Loss: 10.840 | Acc: 94.880
3 Loss: 8.816 | Acc: 95.933
4 Loss: 7.816 | Acc: 96.459
5 Loss: 7.387 | Acc: 96.196
6 Loss: 6.941 | Acc: 96.675
7 Loss: 6.959 | Acc: 96.818
8 Loss: 5.544 | Acc: 97.201
9 Loss: 5.132 | Acc: 97.560
10 Loss: 3.482 | Acc: 98.565
11 Loss: 2.366 | Acc: 98.852
12 Loss: 2.106 | Acc: 98.995
13 Loss: 2.563 | Acc: 98.828
14 Loss: 1.708 | Acc: 99.258
15 Loss: 1.703 | Acc: 99.378
16 Loss: 2.080 | Acc: 99.139
17 Loss: 1.881 | Acc: 99.282
18 Loss: 1.300 | Acc: 99.426
19 Loss: 1.580 | Acc: 99.354
20 Loss: 1.181 | Acc: 99.330
21 Loss: 0.927 | Acc: 99.713
22 Loss: 1.150 | Acc: 99.569
23 Loss: 1.009 | Acc: 99.522
24 Loss: 0.909 | Acc: 99.617
25 Loss: 0.989 | Acc: 99.593
26 Loss: 0.648 | Acc: 99.737
27 Loss: 0.868 | Acc: 99.641
28 Loss: 0.673 | Acc: 99.665
29 Loss: 0.770 | Acc: 99.665
30 Loss: 0.547 | Acc: 99.737
31 Loss: 0.451 | Acc: 99.785
32 Loss: 0.668 | Acc: 99.713
33 Loss: 0.451 | Acc: 99.833
34 Loss: 0.601 | Acc: 99.809
35 Loss: 0.456 | Acc: 99.785
36 Loss: 0.633 | Acc: 99.809
37 Loss: 0.344 | Acc: 99.904
38 Loss: 0.508 | Acc: 99.856
39 Loss: 0.519 | Acc: 99.856
40 Loss: 0.464 | Acc: 99.713
41 Loss: 0.306 | Acc: 99.856
42 Loss: 0.377 | Acc: 99.856
43 Loss: 0.310 | Acc: 99.904
44 Loss: 0.538 | Acc: 99.785
45 Loss: 0.298 | Acc: 99.880
46 Loss: 0.285 | Acc: 99.880
47 Loss: 0.314 | Acc: 99.880
48 Loss: 0.210 | Acc: 99.952
49 Loss: 0.472 | Acc: 99.856
50 Loss: 0.214 | Acc: 99.976
51 Loss: 0.183 | Acc: 99.952
52 Loss: 0.256 | Acc: 99.904
53 Loss: 0.343 | Acc: 99.856
54 Loss: 0.239 | Acc: 99.904
55 Loss: 0.289 | Acc: 99.880
56 Loss: 0.158 | Acc: 99.928
57 Loss: 0.322 | Acc: 99.880
58 Loss: 0.196 | Acc: 99.928
59 Loss: 0.241 | Acc: 99.952
MLP trained successfully...
# of Left images:  719.0
# of Right images:  1110.0
giniRightRatio:  0.8435825014203392
giniLeftRatio:  0.8211102965214009
impurityDrop:  0.8290261813101261
giniGain:  0.013839250507790779
lclasses:  [26, 7, 175, 103, 53, 146, 45, 156, 3, 5]
rclasses:  [71, 31, 243, 86, 193, 86, 118, 247, 11, 24]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([719, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([719])
rTrainDict[data].shape:  torch.Size([1110, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([1110])
RETURNING FROM WORK...
nodeId:  60 , imgTensorShape :  torch.Size([719, 16, 12, 12])
nodeId: 60 ,  parentId: 30 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 719
nodeId:  61 , imgTensorShape :  torch.Size([1110, 16, 12, 12])
nodeId: 61 ,  parentId: 30 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1110
Running nodeId:  31
trainInputDict[data].shape :  torch.Size([9031, 16, 16, 16])
copy.shape :  torch.Size([9031, 4096])
copyLabel.shape :  torch.Size([9031])
Class 0 has 2089 instances after oversampling
Class 1 has 2089 instances after oversampling
Class 2 has 2089 instances after oversampling
Class 3 has 2090 instances after oversampling
Class 4 has 2090 instances after oversampling
Class 5 has 2090 instances after oversampling
Class 6 has 2090 instances after oversampling
Class 7 has 2090 instances after oversampling
Class 8 has 2089 instances after oversampling
Class 9 has 2089 instances after oversampling
0 Train Loss: 226.487 | Train Acc: 19.407
1 Train Loss: 180.377 | Train Acc: 40.574
2 Train Loss: 136.724 | Train Acc: 54.850
3 Train Loss: 114.389 | Train Acc: 61.144
4 Train Loss: 100.597 | Train Acc: 64.752
5 Train Loss: 91.825 | Train Acc: 68.442
6 Train Loss: 88.086 | Train Acc: 69.476
7 Train Loss: 88.865 | Train Acc: 69.744
8 Train Loss: 78.549 | Train Acc: 72.237
9 Train Loss: 75.836 | Train Acc: 73.137
10 Train Loss: 73.269 | Train Acc: 74.152
11 Train Loss: 67.245 | Train Acc: 76.540
12 Train Loss: 67.365 | Train Acc: 76.157
13 Train Loss: 63.387 | Train Acc: 77.554
14 Train Loss: 62.864 | Train Acc: 77.669
15 Train Loss: 59.788 | Train Acc: 78.894
16 Train Loss: 57.332 | Train Acc: 79.986
17 Train Loss: 58.140 | Train Acc: 79.517
18 Train Loss: 55.513 | Train Acc: 80.550
19 Train Loss: 54.538 | Train Acc: 80.814
20 Train Loss: 48.427 | Train Acc: 83.580
21 Train Loss: 48.583 | Train Acc: 83.087
22 Train Loss: 48.685 | Train Acc: 83.250
23 Train Loss: 47.004 | Train Acc: 83.920
24 Train Loss: 45.794 | Train Acc: 84.369
25 Train Loss: 45.845 | Train Acc: 84.231
26 Train Loss: 44.516 | Train Acc: 84.762
27 Train Loss: 44.440 | Train Acc: 84.795
28 Train Loss: 44.989 | Train Acc: 84.346
29 Train Loss: 42.928 | Train Acc: 85.374
30 Train Loss: 42.611 | Train Acc: 85.312
31 Train Loss: 44.256 | Train Acc: 84.738
32 Train Loss: 42.054 | Train Acc: 85.623
33 Train Loss: 42.345 | Train Acc: 85.441
34 Train Loss: 40.792 | Train Acc: 86.059
35 Train Loss: 40.389 | Train Acc: 86.322
36 Train Loss: 40.478 | Train Acc: 86.303
37 Train Loss: 40.355 | Train Acc: 86.389
38 Train Loss: 38.942 | Train Acc: 86.724
39 Train Loss: 38.965 | Train Acc: 86.901
40 Train Loss: 37.034 | Train Acc: 87.782
41 Train Loss: 36.670 | Train Acc: 87.820
42 Train Loss: 36.024 | Train Acc: 88.413
43 Train Loss: 36.006 | Train Acc: 88.337
44 Train Loss: 35.899 | Train Acc: 88.423
45 Train Loss: 35.873 | Train Acc: 88.193
46 Train Loss: 35.710 | Train Acc: 88.289
47 Train Loss: 35.305 | Train Acc: 88.595
48 Train Loss: 35.345 | Train Acc: 88.581
49 Train Loss: 34.898 | Train Acc: 88.509
50 Train Loss: 34.627 | Train Acc: 88.772
51 Train Loss: 35.022 | Train Acc: 88.772
52 Train Loss: 34.466 | Train Acc: 88.739
53 Train Loss: 34.310 | Train Acc: 88.964
54 Train Loss: 34.672 | Train Acc: 88.749
55 Train Loss: 34.032 | Train Acc: 89.045
56 Train Loss: 33.785 | Train Acc: 89.088
57 Train Loss: 33.483 | Train Acc: 89.107
58 Train Loss: 33.688 | Train Acc: 89.356
59 Train Loss: 33.127 | Train Acc: 89.462
60 Train Loss: 32.758 | Train Acc: 89.409
61 Train Loss: 32.301 | Train Acc: 89.806
62 Train Loss: 32.233 | Train Acc: 89.911
63 Train Loss: 32.205 | Train Acc: 89.907
64 Train Loss: 32.089 | Train Acc: 89.849
65 Train Loss: 32.070 | Train Acc: 89.931
66 Train Loss: 31.980 | Train Acc: 89.902
67 Train Loss: 31.973 | Train Acc: 90.103
68 Train Loss: 31.939 | Train Acc: 89.940
69 Train Loss: 31.750 | Train Acc: 90.103
70 Train Loss: 31.617 | Train Acc: 90.031
71 Train Loss: 31.734 | Train Acc: 90.108
72 Train Loss: 31.561 | Train Acc: 90.093
73 Train Loss: 31.478 | Train Acc: 90.179
74 Train Loss: 31.591 | Train Acc: 90.112
75 Train Loss: 31.361 | Train Acc: 90.199
76 Train Loss: 31.311 | Train Acc: 90.347
77 Train Loss: 31.181 | Train Acc: 90.400
78 Train Loss: 31.114 | Train Acc: 90.318
79 Train Loss: 31.079 | Train Acc: 90.347
80 Train Loss: 30.806 | Train Acc: 90.581
81 Train Loss: 30.652 | Train Acc: 90.581
82 Train Loss: 30.637 | Train Acc: 90.543
83 Train Loss: 30.603 | Train Acc: 90.596
84 Train Loss: 30.650 | Train Acc: 90.553
85 Train Loss: 30.538 | Train Acc: 90.668
86 Train Loss: 30.552 | Train Acc: 90.591
87 Train Loss: 30.551 | Train Acc: 90.601
88 Train Loss: 30.439 | Train Acc: 90.620
89 Train Loss: 30.466 | Train Acc: 90.653
90 Train Loss: 30.480 | Train Acc: 90.644
91 Train Loss: 30.397 | Train Acc: 90.735
92 Train Loss: 30.329 | Train Acc: 90.763
93 Train Loss: 30.364 | Train Acc: 90.754
94 Train Loss: 30.359 | Train Acc: 90.715
95 Train Loss: 30.323 | Train Acc: 90.701
96 Train Loss: 30.254 | Train Acc: 90.682
97 Train Loss: 30.249 | Train Acc: 90.754
98 Train Loss: 30.197 | Train Acc: 90.778
99 Train Loss: 30.271 | Train Acc: 90.730
CNN trained successfully...
image_next_flat.shape :  torch.Size([20895, 2304])
printing expected split from k means
{7: 0, 3: 1, 2: 1, 5: 1, 4: 1, 6: 1, 1: 1, 9: 1, 8: 0, 0: 1}
Printing final_dict items...
{7: 0, 3: 1, 2: 1, 5: 1, 4: 1, 6: 1, 1: 1, 9: 1, 8: 0, 0: 1}
Image Statistics before MLP : L R :  5984 14911
expectedMlpLabels.shape :  torch.Size([20895])
0 Loss: 22.065 | Acc: 91.251
1 Loss: 14.801 | Acc: 93.908
2 Loss: 12.687 | Acc: 94.745
3 Loss: 10.832 | Acc: 95.319
4 Loss: 9.780 | Acc: 95.860
5 Loss: 9.419 | Acc: 95.918
6 Loss: 8.529 | Acc: 96.525
7 Loss: 8.235 | Acc: 96.482
8 Loss: 7.715 | Acc: 96.789
9 Loss: 7.248 | Acc: 97.057
10 Loss: 5.224 | Acc: 97.918
11 Loss: 4.682 | Acc: 98.090
12 Loss: 4.383 | Acc: 98.263
13 Loss: 3.999 | Acc: 98.387
14 Loss: 3.632 | Acc: 98.526
15 Loss: 3.502 | Acc: 98.593
16 Loss: 3.562 | Acc: 98.564
17 Loss: 3.302 | Acc: 98.737
18 Loss: 3.027 | Acc: 98.775
19 Loss: 3.004 | Acc: 98.842
20 Loss: 2.480 | Acc: 99.052
21 Loss: 2.294 | Acc: 99.052
22 Loss: 1.918 | Acc: 99.306
23 Loss: 2.135 | Acc: 99.167
24 Loss: 2.039 | Acc: 99.320
25 Loss: 1.853 | Acc: 99.296
26 Loss: 2.020 | Acc: 99.239
27 Loss: 1.980 | Acc: 99.301
28 Loss: 1.936 | Acc: 99.234
29 Loss: 1.764 | Acc: 99.325
30 Loss: 1.596 | Acc: 99.435
31 Loss: 1.397 | Acc: 99.464
32 Loss: 1.361 | Acc: 99.483
33 Loss: 1.413 | Acc: 99.531
34 Loss: 1.359 | Acc: 99.574
35 Loss: 1.279 | Acc: 99.497
36 Loss: 1.282 | Acc: 99.526
37 Loss: 1.153 | Acc: 99.512
38 Loss: 1.149 | Acc: 99.569
39 Loss: 1.247 | Acc: 99.574
40 Loss: 1.152 | Acc: 99.564
41 Loss: 1.148 | Acc: 99.541
42 Loss: 1.222 | Acc: 99.517
43 Loss: 1.033 | Acc: 99.646
44 Loss: 1.123 | Acc: 99.617
45 Loss: 1.061 | Acc: 99.579
46 Loss: 0.984 | Acc: 99.655
47 Loss: 1.111 | Acc: 99.593
48 Loss: 1.058 | Acc: 99.588
49 Loss: 0.996 | Acc: 99.651
50 Loss: 1.061 | Acc: 99.627
51 Loss: 0.983 | Acc: 99.622
52 Loss: 1.087 | Acc: 99.588
53 Loss: 0.926 | Acc: 99.675
54 Loss: 1.132 | Acc: 99.622
55 Loss: 0.986 | Acc: 99.603
56 Loss: 0.989 | Acc: 99.617
57 Loss: 0.926 | Acc: 99.641
58 Loss: 0.967 | Acc: 99.651
59 Loss: 1.004 | Acc: 99.636
MLP trained successfully...
# of Left images:  3337.0
# of Right images:  5694.0
giniRightRatio:  0.8149829330019004
giniLeftRatio:  0.7852949409230907
impurityDrop:  0.797584122048794
giniGain:  0.02703540688316486
lclasses:  [11, 4, 314, 337, 596, 403, 402, 1224, 16, 30]
rclasses:  [46, 30, 439, 1158, 641, 1615, 830, 866, 7, 62]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([3337, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([3337])
rTrainDict[data].shape:  torch.Size([5694, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([5694])
RETURNING FROM WORK...
nodeId:  62 , imgTensorShape :  torch.Size([3337, 16, 12, 12])
nodeId: 62 ,  parentId: 31 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3337
nodeId:  63 , imgTensorShape :  torch.Size([5694, 16, 12, 12])
nodeId: 63 ,  parentId: 31 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 5694
Running nodeId:  32
trainInputDict[data].shape :  torch.Size([1458, 16, 12, 12])
copy.shape :  torch.Size([1458, 2304])
copyLabel.shape :  torch.Size([1458])
Class 0 has 566 instances after oversampling
Class 1 has 566 instances after oversampling
Class 2 has 566 instances after oversampling
Class 3 has 566 instances after oversampling
Class 4 has 566 instances after oversampling
Class 5 has 566 instances after oversampling
Class 6 has 566 instances after oversampling
Class 7 has 566 instances after oversampling
Class 8 has 566 instances after oversampling
Class 9 has 566 instances after oversampling
0 Train Loss: 217.613 | Train Acc: 18.428
1 Train Loss: 151.595 | Train Acc: 53.551
2 Train Loss: 98.959 | Train Acc: 69.611
3 Train Loss: 69.059 | Train Acc: 79.046
4 Train Loss: 50.099 | Train Acc: 84.700
5 Train Loss: 45.366 | Train Acc: 85.406
6 Train Loss: 36.839 | Train Acc: 88.339
7 Train Loss: 31.930 | Train Acc: 89.399
8 Train Loss: 24.806 | Train Acc: 92.067
9 Train Loss: 22.512 | Train Acc: 92.562
10 Train Loss: 21.014 | Train Acc: 93.534
11 Train Loss: 20.880 | Train Acc: 93.339
12 Train Loss: 16.294 | Train Acc: 94.664
13 Train Loss: 12.894 | Train Acc: 95.742
14 Train Loss: 11.901 | Train Acc: 96.095
15 Train Loss: 10.867 | Train Acc: 96.608
16 Train Loss: 10.031 | Train Acc: 96.696
17 Train Loss: 8.978 | Train Acc: 97.314
18 Train Loss: 8.962 | Train Acc: 96.996
19 Train Loss: 8.354 | Train Acc: 97.385
20 Train Loss: 6.202 | Train Acc: 98.216
21 Train Loss: 5.095 | Train Acc: 98.869
22 Train Loss: 4.876 | Train Acc: 98.746
23 Train Loss: 4.533 | Train Acc: 98.975
24 Train Loss: 4.495 | Train Acc: 99.011
25 Train Loss: 4.280 | Train Acc: 99.064
26 Train Loss: 4.011 | Train Acc: 99.152
27 Train Loss: 3.711 | Train Acc: 99.399
28 Train Loss: 3.633 | Train Acc: 99.399
29 Train Loss: 3.426 | Train Acc: 99.364
30 Train Loss: 3.289 | Train Acc: 99.435
31 Train Loss: 3.236 | Train Acc: 99.523
32 Train Loss: 2.998 | Train Acc: 99.576
33 Train Loss: 2.927 | Train Acc: 99.541
34 Train Loss: 2.748 | Train Acc: 99.541
35 Train Loss: 2.733 | Train Acc: 99.594
36 Train Loss: 2.390 | Train Acc: 99.788
37 Train Loss: 2.431 | Train Acc: 99.647
38 Train Loss: 2.262 | Train Acc: 99.753
39 Train Loss: 2.173 | Train Acc: 99.788
40 Train Loss: 1.893 | Train Acc: 99.876
41 Train Loss: 1.790 | Train Acc: 99.894
42 Train Loss: 1.672 | Train Acc: 99.894
43 Train Loss: 1.663 | Train Acc: 99.876
44 Train Loss: 1.607 | Train Acc: 99.894
45 Train Loss: 1.557 | Train Acc: 99.912
46 Train Loss: 1.530 | Train Acc: 99.894
47 Train Loss: 1.501 | Train Acc: 99.947
48 Train Loss: 1.461 | Train Acc: 99.894
49 Train Loss: 1.447 | Train Acc: 99.894
50 Train Loss: 1.392 | Train Acc: 99.912
51 Train Loss: 1.338 | Train Acc: 99.912
52 Train Loss: 1.315 | Train Acc: 99.912
53 Train Loss: 1.285 | Train Acc: 99.929
54 Train Loss: 1.276 | Train Acc: 99.929
55 Train Loss: 1.250 | Train Acc: 99.929
56 Train Loss: 1.211 | Train Acc: 99.947
57 Train Loss: 1.157 | Train Acc: 99.929
58 Train Loss: 1.111 | Train Acc: 99.965
59 Train Loss: 1.105 | Train Acc: 99.965
60 Train Loss: 1.003 | Train Acc: 99.947
61 Train Loss: 0.979 | Train Acc: 99.929
62 Train Loss: 0.958 | Train Acc: 99.929
63 Train Loss: 0.937 | Train Acc: 99.965
64 Train Loss: 0.941 | Train Acc: 99.947
65 Train Loss: 0.918 | Train Acc: 99.982
66 Train Loss: 0.923 | Train Acc: 99.929
67 Train Loss: 0.901 | Train Acc: 99.947
68 Train Loss: 0.885 | Train Acc: 99.965
69 Train Loss: 0.884 | Train Acc: 99.947
70 Train Loss: 0.858 | Train Acc: 99.947
71 Train Loss: 0.844 | Train Acc: 99.982
72 Train Loss: 0.843 | Train Acc: 99.947
73 Train Loss: 0.828 | Train Acc: 99.947
74 Train Loss: 0.803 | Train Acc: 99.965
75 Train Loss: 0.805 | Train Acc: 99.982
76 Train Loss: 0.777 | Train Acc: 99.965
77 Train Loss: 0.766 | Train Acc: 99.947
78 Train Loss: 0.751 | Train Acc: 99.965
79 Train Loss: 0.748 | Train Acc: 99.947
80 Train Loss: 0.709 | Train Acc: 99.947
81 Train Loss: 0.697 | Train Acc: 99.982
82 Train Loss: 0.698 | Train Acc: 99.947
83 Train Loss: 0.687 | Train Acc: 99.982
84 Train Loss: 0.687 | Train Acc: 99.982
85 Train Loss: 0.678 | Train Acc: 99.982
86 Train Loss: 0.675 | Train Acc: 99.982
87 Train Loss: 0.668 | Train Acc: 99.965
88 Train Loss: 0.664 | Train Acc: 99.982
89 Train Loss: 0.657 | Train Acc: 99.982
90 Train Loss: 0.654 | Train Acc: 99.982
91 Train Loss: 0.647 | Train Acc: 99.982
92 Train Loss: 0.639 | Train Acc: 99.982
93 Train Loss: 0.636 | Train Acc: 99.982
94 Train Loss: 0.632 | Train Acc: 99.982
95 Train Loss: 0.626 | Train Acc: 99.982
96 Train Loss: 0.619 | Train Acc: 99.982
97 Train Loss: 0.617 | Train Acc: 99.982
98 Train Loss: 0.608 | Train Acc: 99.982
99 Train Loss: 0.600 | Train Acc: 99.982
CNN trained successfully...
image_next_flat.shape :  torch.Size([5660, 1024])
printing expected split from k means
{9: 0, 0: 0, 2: 0, 8: 1, 4: 0, 5: 0, 7: 0, 6: 0, 3: 0, 1: 0}
Printing final_dict items...
{9: 0, 0: 0, 2: 0, 8: 1, 4: 0, 5: 0, 7: 0, 6: 0, 3: 0, 1: 0}
Image Statistics before MLP : L R :  4153 1507
expectedMlpLabels.shape :  torch.Size([5660])
0 Loss: 41.111 | Acc: 80.571
1 Loss: 28.692 | Acc: 87.750
2 Loss: 25.776 | Acc: 89.018
3 Loss: 21.826 | Acc: 89.750
4 Loss: 20.481 | Acc: 90.625
5 Loss: 18.495 | Acc: 91.804
6 Loss: 17.631 | Acc: 91.643
7 Loss: 16.899 | Acc: 92.268
8 Loss: 16.315 | Acc: 92.643
9 Loss: 14.367 | Acc: 93.482
10 Loss: 11.431 | Acc: 94.321
11 Loss: 9.914 | Acc: 95.125
12 Loss: 9.323 | Acc: 95.571
13 Loss: 10.031 | Acc: 95.518
14 Loss: 8.403 | Acc: 96.143
15 Loss: 8.715 | Acc: 95.911
16 Loss: 8.644 | Acc: 95.946
17 Loss: 8.284 | Acc: 96.536
18 Loss: 8.766 | Acc: 95.857
19 Loss: 8.258 | Acc: 96.250
20 Loss: 6.710 | Acc: 96.946
21 Loss: 6.115 | Acc: 97.143
22 Loss: 6.113 | Acc: 97.268
23 Loss: 5.847 | Acc: 97.339
24 Loss: 5.776 | Acc: 97.518
25 Loss: 5.746 | Acc: 97.321
26 Loss: 5.147 | Acc: 97.607
27 Loss: 5.115 | Acc: 97.661
28 Loss: 4.868 | Acc: 97.821
29 Loss: 5.295 | Acc: 97.661
30 Loss: 4.846 | Acc: 97.768
31 Loss: 4.035 | Acc: 98.214
32 Loss: 4.316 | Acc: 98.161
33 Loss: 3.865 | Acc: 98.339
34 Loss: 4.170 | Acc: 98.482
35 Loss: 4.052 | Acc: 98.268
36 Loss: 4.012 | Acc: 98.250
37 Loss: 3.694 | Acc: 98.429
38 Loss: 3.994 | Acc: 98.214
39 Loss: 3.911 | Acc: 98.286
40 Loss: 3.652 | Acc: 98.411
41 Loss: 3.691 | Acc: 98.482
42 Loss: 3.901 | Acc: 98.125
43 Loss: 3.316 | Acc: 98.661
44 Loss: 3.325 | Acc: 98.750
45 Loss: 3.430 | Acc: 98.554
46 Loss: 3.370 | Acc: 98.518
47 Loss: 3.489 | Acc: 98.536
48 Loss: 3.269 | Acc: 98.589
49 Loss: 3.412 | Acc: 98.393
50 Loss: 3.168 | Acc: 98.554
51 Loss: 3.280 | Acc: 98.679
52 Loss: 2.949 | Acc: 98.696
53 Loss: 3.355 | Acc: 98.518
54 Loss: 3.480 | Acc: 98.357
55 Loss: 3.115 | Acc: 98.643
56 Loss: 3.227 | Acc: 98.750
57 Loss: 3.044 | Acc: 98.750
58 Loss: 3.549 | Acc: 98.482
59 Loss: 3.885 | Acc: 98.375
MLP trained successfully...
# of Left images:  637.0
# of Right images:  821.0
giniRightRatio:  0.6742705562421276
giniLeftRatio:  0.7813608235227432
impurityDrop:  0.757360081525626
giniGain:  -0.024918474649227584
lclasses:  [218, 30, 67, 22, 50, 13, 15, 9, 176, 37]
rclasses:  [239, 9, 88, 15, 43, 3, 11, 7, 390, 16]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([637, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([637])
rTrainDict[data].shape:  torch.Size([821, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([821])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  64 , imgTensorShape :  torch.Size([637, 16, 8, 8])
nodeId: 64 ,  parentId: 32 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 637
nodeId:  65 , imgTensorShape :  torch.Size([821, 16, 8, 8])
nodeId: 65 ,  parentId: 32 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 821
Running nodeId:  33
trainInputDict[data].shape :  torch.Size([521, 16, 12, 12])
copy.shape :  torch.Size([521, 2304])
copyLabel.shape :  torch.Size([521])
Class 0 has 146 instances after oversampling
Class 1 has 146 instances after oversampling
Class 2 has 146 instances after oversampling
Class 3 has 146 instances after oversampling
Class 4 has 146 instances after oversampling
Class 5 has 146 instances after oversampling
Class 6 has 146 instances after oversampling
Class 7 has 146 instances after oversampling
Class 8 has 146 instances after oversampling
Class 9 has 146 instances after oversampling
0 Train Loss: 210.667 | Train Acc: 23.143
1 Train Loss: 113.382 | Train Acc: 65.357
2 Train Loss: 66.314 | Train Acc: 78.857
3 Train Loss: 44.144 | Train Acc: 86.143
4 Train Loss: 30.522 | Train Acc: 90.286
5 Train Loss: 22.507 | Train Acc: 92.786
6 Train Loss: 17.224 | Train Acc: 95.143
7 Train Loss: 13.439 | Train Acc: 96.000
8 Train Loss: 8.642 | Train Acc: 98.714
9 Train Loss: 7.269 | Train Acc: 98.429
10 Train Loss: 5.113 | Train Acc: 99.143
11 Train Loss: 3.293 | Train Acc: 99.643
12 Train Loss: 2.344 | Train Acc: 99.857
13 Train Loss: 1.720 | Train Acc: 100.000
14 Train Loss: 1.454 | Train Acc: 99.929
15 Train Loss: 1.107 | Train Acc: 100.000
16 Train Loss: 0.961 | Train Acc: 100.000
17 Train Loss: 0.781 | Train Acc: 100.000
18 Train Loss: 0.679 | Train Acc: 100.000
19 Train Loss: 0.570 | Train Acc: 100.000
20 Train Loss: 0.464 | Train Acc: 100.000
21 Train Loss: 0.440 | Train Acc: 100.000
22 Train Loss: 0.421 | Train Acc: 100.000
23 Train Loss: 0.399 | Train Acc: 100.000
24 Train Loss: 0.374 | Train Acc: 100.000
25 Train Loss: 0.355 | Train Acc: 100.000
26 Train Loss: 0.337 | Train Acc: 100.000
27 Train Loss: 0.320 | Train Acc: 100.000
28 Train Loss: 0.309 | Train Acc: 100.000
29 Train Loss: 0.289 | Train Acc: 100.000
30 Train Loss: 0.279 | Train Acc: 100.000
31 Train Loss: 0.261 | Train Acc: 100.000
32 Train Loss: 0.245 | Train Acc: 100.000
33 Train Loss: 0.234 | Train Acc: 100.000
34 Train Loss: 0.222 | Train Acc: 100.000
35 Train Loss: 0.209 | Train Acc: 100.000
36 Train Loss: 0.201 | Train Acc: 100.000
37 Train Loss: 0.185 | Train Acc: 100.000
38 Train Loss: 0.178 | Train Acc: 100.000
39 Train Loss: 0.167 | Train Acc: 100.000
40 Train Loss: 0.153 | Train Acc: 100.000
41 Train Loss: 0.150 | Train Acc: 100.000
42 Train Loss: 0.146 | Train Acc: 100.000
43 Train Loss: 0.143 | Train Acc: 100.000
44 Train Loss: 0.140 | Train Acc: 100.000
45 Train Loss: 0.137 | Train Acc: 100.000
46 Train Loss: 0.133 | Train Acc: 100.000
47 Train Loss: 0.129 | Train Acc: 100.000
48 Train Loss: 0.126 | Train Acc: 100.000
49 Train Loss: 0.123 | Train Acc: 100.000
50 Train Loss: 0.119 | Train Acc: 100.000
51 Train Loss: 0.117 | Train Acc: 100.000
52 Train Loss: 0.113 | Train Acc: 100.000
53 Train Loss: 0.109 | Train Acc: 100.000
54 Train Loss: 0.106 | Train Acc: 100.000
55 Train Loss: 0.102 | Train Acc: 100.000
56 Train Loss: 0.099 | Train Acc: 100.000
57 Train Loss: 0.096 | Train Acc: 100.000
58 Train Loss: 0.092 | Train Acc: 100.000
59 Train Loss: 0.089 | Train Acc: 100.000
60 Train Loss: 0.084 | Train Acc: 100.000
61 Train Loss: 0.083 | Train Acc: 100.000
62 Train Loss: 0.082 | Train Acc: 100.000
63 Train Loss: 0.081 | Train Acc: 100.000
64 Train Loss: 0.080 | Train Acc: 100.000
65 Train Loss: 0.078 | Train Acc: 100.000
66 Train Loss: 0.077 | Train Acc: 100.000
67 Train Loss: 0.076 | Train Acc: 100.000
68 Train Loss: 0.074 | Train Acc: 100.000
69 Train Loss: 0.073 | Train Acc: 100.000
70 Train Loss: 0.072 | Train Acc: 100.000
71 Train Loss: 0.070 | Train Acc: 100.000
72 Train Loss: 0.069 | Train Acc: 100.000
73 Train Loss: 0.067 | Train Acc: 100.000
74 Train Loss: 0.066 | Train Acc: 100.000
75 Train Loss: 0.065 | Train Acc: 100.000
76 Train Loss: 0.063 | Train Acc: 100.000
77 Train Loss: 0.061 | Train Acc: 100.000
78 Train Loss: 0.060 | Train Acc: 100.000
79 Train Loss: 0.059 | Train Acc: 100.000
80 Train Loss: 0.057 | Train Acc: 100.000
81 Train Loss: 0.056 | Train Acc: 100.000
82 Train Loss: 0.056 | Train Acc: 100.000
83 Train Loss: 0.055 | Train Acc: 100.000
84 Train Loss: 0.054 | Train Acc: 100.000
85 Train Loss: 0.053 | Train Acc: 100.000
86 Train Loss: 0.053 | Train Acc: 100.000
87 Train Loss: 0.052 | Train Acc: 100.000
88 Train Loss: 0.051 | Train Acc: 100.000
89 Train Loss: 0.051 | Train Acc: 100.000
90 Train Loss: 0.050 | Train Acc: 100.000
91 Train Loss: 0.049 | Train Acc: 100.000
92 Train Loss: 0.049 | Train Acc: 100.000
93 Train Loss: 0.048 | Train Acc: 100.000
94 Train Loss: 0.047 | Train Acc: 100.000
95 Train Loss: 0.046 | Train Acc: 100.000
96 Train Loss: 0.046 | Train Acc: 100.000
97 Train Loss: 0.045 | Train Acc: 100.000
98 Train Loss: 0.044 | Train Acc: 100.000
99 Train Loss: 0.043 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([1460, 1024])
printing expected split from k means
{9: 0, 3: 0, 6: 0, 4: 0, 2: 1, 0: 1, 5: 0, 8: 1, 7: 0, 1: 0}
Printing final_dict items...
{9: 0, 3: 0, 6: 0, 4: 0, 2: 1, 0: 1, 5: 0, 8: 1, 7: 0, 1: 0}
Image Statistics before MLP : L R :  1014 446
expectedMlpLabels.shape :  torch.Size([1460])
0 Loss: 50.851 | Acc: 79.000
1 Loss: 38.649 | Acc: 86.214
2 Loss: 32.192 | Acc: 88.286
3 Loss: 35.652 | Acc: 86.786
4 Loss: 25.156 | Acc: 89.857
5 Loss: 21.830 | Acc: 91.857
6 Loss: 21.930 | Acc: 91.286
7 Loss: 23.326 | Acc: 91.571
8 Loss: 19.005 | Acc: 92.571
9 Loss: 18.867 | Acc: 92.571
10 Loss: 16.953 | Acc: 92.929
11 Loss: 13.625 | Acc: 94.643
12 Loss: 11.193 | Acc: 95.000
13 Loss: 13.678 | Acc: 93.571
14 Loss: 10.554 | Acc: 95.500
15 Loss: 11.404 | Acc: 95.071
16 Loss: 9.043 | Acc: 96.786
17 Loss: 12.039 | Acc: 94.643
18 Loss: 9.984 | Acc: 96.357
19 Loss: 7.522 | Acc: 97.071
20 Loss: 6.706 | Acc: 97.429
21 Loss: 6.320 | Acc: 97.429
22 Loss: 7.226 | Acc: 97.000
23 Loss: 6.413 | Acc: 97.643
24 Loss: 5.790 | Acc: 97.500
25 Loss: 6.507 | Acc: 97.286
26 Loss: 5.408 | Acc: 98.071
27 Loss: 4.619 | Acc: 98.571
28 Loss: 4.331 | Acc: 98.214
29 Loss: 5.214 | Acc: 98.143
30 Loss: 3.907 | Acc: 98.286
31 Loss: 3.282 | Acc: 98.786
32 Loss: 4.517 | Acc: 98.500
33 Loss: 3.470 | Acc: 98.429
34 Loss: 2.965 | Acc: 98.857
35 Loss: 3.107 | Acc: 98.857
36 Loss: 3.498 | Acc: 98.643
37 Loss: 2.330 | Acc: 99.000
38 Loss: 2.795 | Acc: 98.786
39 Loss: 3.699 | Acc: 98.857
40 Loss: 3.696 | Acc: 98.500
41 Loss: 2.564 | Acc: 99.071
42 Loss: 3.009 | Acc: 98.929
43 Loss: 3.056 | Acc: 98.929
44 Loss: 3.023 | Acc: 99.000
45 Loss: 2.020 | Acc: 99.286
46 Loss: 2.438 | Acc: 99.000
47 Loss: 2.041 | Acc: 99.143
48 Loss: 2.529 | Acc: 98.857
49 Loss: 3.101 | Acc: 99.071
50 Loss: 2.118 | Acc: 99.214
51 Loss: 2.103 | Acc: 99.143
52 Loss: 1.798 | Acc: 99.357
53 Loss: 2.394 | Acc: 99.214
54 Loss: 2.701 | Acc: 99.071
55 Loss: 2.256 | Acc: 99.286
56 Loss: 2.045 | Acc: 99.214
57 Loss: 2.405 | Acc: 99.071
58 Loss: 2.874 | Acc: 99.000
59 Loss: 2.025 | Acc: 99.143
MLP trained successfully...
# of Left images:  274.0
# of Right images:  247.0
giniRightRatio:  0.7695585897162714
giniLeftRatio:  0.8103255367893868
impurityDrop:  0.8147818427447475
giniGain:  0.007599448217192495
lclasses:  [14, 4, 60, 11, 85, 12, 46, 5, 26, 11]
rclasses:  [51, 2, 86, 7, 26, 4, 4, 6, 57, 4]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([274, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([274])
rTrainDict[data].shape:  torch.Size([247, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([247])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  66 , imgTensorShape :  torch.Size([274, 16, 8, 8])
nodeId: 66 ,  parentId: 33 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 274
nodeId:  67 , imgTensorShape :  torch.Size([247, 16, 8, 8])
nodeId: 67 ,  parentId: 33 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 247
Running nodeId:  34
trainInputDict[data].shape :  torch.Size([956, 16, 12, 12])
copy.shape :  torch.Size([956, 2304])
copyLabel.shape :  torch.Size([956])
Class 0 has 548 instances after oversampling
Class 1 has 548 instances after oversampling
Class 2 has 548 instances after oversampling
Class 3 has 548 instances after oversampling
Class 4 has 548 instances after oversampling
Class 5 has 1 instances after oversampling
Class 6 has 548 instances after oversampling
Class 7 has 548 instances after oversampling
Class 8 has 548 instances after oversampling
0 Train Loss: 142.772 | Train Acc: 49.669
1 Train Loss: 61.060 | Train Acc: 79.590
2 Train Loss: 37.502 | Train Acc: 87.001
3 Train Loss: 32.175 | Train Acc: 88.483
4 Train Loss: 19.353 | Train Acc: 93.729
5 Train Loss: 17.484 | Train Acc: 94.048
6 Train Loss: 14.959 | Train Acc: 95.348
7 Train Loss: 13.227 | Train Acc: 95.941
8 Train Loss: 10.352 | Train Acc: 96.602
9 Train Loss: 11.417 | Train Acc: 96.214
10 Train Loss: 7.181 | Train Acc: 97.834
11 Train Loss: 7.435 | Train Acc: 97.697
12 Train Loss: 5.287 | Train Acc: 98.609
13 Train Loss: 5.206 | Train Acc: 98.632
14 Train Loss: 4.860 | Train Acc: 98.404
15 Train Loss: 3.859 | Train Acc: 98.951
16 Train Loss: 3.417 | Train Acc: 99.065
17 Train Loss: 2.713 | Train Acc: 99.316
18 Train Loss: 2.394 | Train Acc: 99.498
19 Train Loss: 2.303 | Train Acc: 99.407
20 Train Loss: 1.443 | Train Acc: 99.840
21 Train Loss: 1.307 | Train Acc: 99.909
22 Train Loss: 1.259 | Train Acc: 99.932
23 Train Loss: 1.209 | Train Acc: 99.886
24 Train Loss: 1.083 | Train Acc: 99.954
25 Train Loss: 1.062 | Train Acc: 99.954
26 Train Loss: 1.021 | Train Acc: 99.909
27 Train Loss: 0.928 | Train Acc: 99.954
28 Train Loss: 1.009 | Train Acc: 99.932
29 Train Loss: 1.044 | Train Acc: 99.932
30 Train Loss: 0.962 | Train Acc: 99.840
31 Train Loss: 0.808 | Train Acc: 99.977
32 Train Loss: 0.681 | Train Acc: 100.000
33 Train Loss: 0.701 | Train Acc: 100.000
34 Train Loss: 0.650 | Train Acc: 99.977
35 Train Loss: 0.572 | Train Acc: 100.000
36 Train Loss: 0.550 | Train Acc: 100.000
37 Train Loss: 0.517 | Train Acc: 100.000
38 Train Loss: 0.477 | Train Acc: 100.000
39 Train Loss: 0.440 | Train Acc: 100.000
40 Train Loss: 0.397 | Train Acc: 100.000
41 Train Loss: 0.378 | Train Acc: 100.000
42 Train Loss: 0.379 | Train Acc: 100.000
43 Train Loss: 0.358 | Train Acc: 100.000
44 Train Loss: 0.349 | Train Acc: 100.000
45 Train Loss: 0.342 | Train Acc: 100.000
46 Train Loss: 0.334 | Train Acc: 100.000
47 Train Loss: 0.321 | Train Acc: 100.000
48 Train Loss: 0.315 | Train Acc: 100.000
49 Train Loss: 0.304 | Train Acc: 100.000
50 Train Loss: 0.296 | Train Acc: 100.000
51 Train Loss: 0.289 | Train Acc: 100.000
52 Train Loss: 0.277 | Train Acc: 100.000
53 Train Loss: 0.272 | Train Acc: 100.000
54 Train Loss: 0.257 | Train Acc: 100.000
55 Train Loss: 0.252 | Train Acc: 100.000
56 Train Loss: 0.245 | Train Acc: 100.000
57 Train Loss: 0.236 | Train Acc: 100.000
58 Train Loss: 0.225 | Train Acc: 100.000
59 Train Loss: 0.219 | Train Acc: 100.000
60 Train Loss: 0.205 | Train Acc: 100.000
61 Train Loss: 0.201 | Train Acc: 100.000
62 Train Loss: 0.199 | Train Acc: 100.000
63 Train Loss: 0.195 | Train Acc: 100.000
64 Train Loss: 0.191 | Train Acc: 100.000
65 Train Loss: 0.189 | Train Acc: 100.000
66 Train Loss: 0.187 | Train Acc: 100.000
67 Train Loss: 0.182 | Train Acc: 100.000
68 Train Loss: 0.177 | Train Acc: 100.000
69 Train Loss: 0.178 | Train Acc: 100.000
70 Train Loss: 0.174 | Train Acc: 100.000
71 Train Loss: 0.172 | Train Acc: 100.000
72 Train Loss: 0.168 | Train Acc: 100.000
73 Train Loss: 0.165 | Train Acc: 100.000
74 Train Loss: 0.159 | Train Acc: 100.000
75 Train Loss: 0.156 | Train Acc: 100.000
76 Train Loss: 0.153 | Train Acc: 100.000
77 Train Loss: 0.150 | Train Acc: 100.000
78 Train Loss: 0.148 | Train Acc: 100.000
79 Train Loss: 0.146 | Train Acc: 100.000
80 Train Loss: 0.137 | Train Acc: 100.000
81 Train Loss: 0.135 | Train Acc: 100.000
82 Train Loss: 0.134 | Train Acc: 100.000
83 Train Loss: 0.132 | Train Acc: 100.000
84 Train Loss: 0.131 | Train Acc: 100.000
85 Train Loss: 0.130 | Train Acc: 100.000
86 Train Loss: 0.128 | Train Acc: 100.000
87 Train Loss: 0.126 | Train Acc: 100.000
88 Train Loss: 0.125 | Train Acc: 100.000
89 Train Loss: 0.124 | Train Acc: 100.000
90 Train Loss: 0.123 | Train Acc: 100.000
91 Train Loss: 0.121 | Train Acc: 100.000
92 Train Loss: 0.119 | Train Acc: 100.000
93 Train Loss: 0.118 | Train Acc: 100.000
94 Train Loss: 0.118 | Train Acc: 100.000
95 Train Loss: 0.115 | Train Acc: 100.000
96 Train Loss: 0.113 | Train Acc: 100.000
97 Train Loss: 0.111 | Train Acc: 100.000
98 Train Loss: 0.110 | Train Acc: 100.000
99 Train Loss: 0.110 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([4385, 1024])
printing expected split from k means
{2: 0, 7: 1, 0: 0, 1: 0, 4: 0, 6: 0, 8: 1, 5: 0, 3: 1}
Printing final_dict items...
{2: 0, 7: 1, 0: 0, 1: 0, 4: 0, 6: 0, 8: 1, 5: 0, 3: 1}
Image Statistics before MLP : L R :  2911 1474
expectedMlpLabels.shape :  torch.Size([4385])
0 Loss: 15.793 | Acc: 94.732
1 Loss: 9.773 | Acc: 97.218
2 Loss: 8.701 | Acc: 97.514
3 Loss: 7.441 | Acc: 97.605
4 Loss: 6.047 | Acc: 98.039
5 Loss: 5.800 | Acc: 98.130
6 Loss: 4.521 | Acc: 98.632
7 Loss: 4.927 | Acc: 98.655
8 Loss: 4.635 | Acc: 98.449
9 Loss: 3.773 | Acc: 98.905
10 Loss: 3.496 | Acc: 98.928
11 Loss: 1.843 | Acc: 99.544
12 Loss: 2.366 | Acc: 99.202
13 Loss: 2.687 | Acc: 99.339
14 Loss: 1.877 | Acc: 99.179
15 Loss: 2.011 | Acc: 99.339
16 Loss: 2.453 | Acc: 99.247
17 Loss: 1.562 | Acc: 99.430
18 Loss: 1.669 | Acc: 99.498
19 Loss: 1.243 | Acc: 99.521
20 Loss: 1.046 | Acc: 99.681
21 Loss: 1.313 | Acc: 99.544
22 Loss: 1.039 | Acc: 99.658
23 Loss: 1.023 | Acc: 99.772
24 Loss: 0.989 | Acc: 99.704
25 Loss: 1.182 | Acc: 99.590
26 Loss: 1.245 | Acc: 99.658
27 Loss: 0.950 | Acc: 99.772
28 Loss: 1.310 | Acc: 99.681
29 Loss: 0.812 | Acc: 99.818
30 Loss: 0.814 | Acc: 99.726
31 Loss: 0.737 | Acc: 99.704
32 Loss: 1.044 | Acc: 99.681
33 Loss: 0.612 | Acc: 99.772
34 Loss: 0.391 | Acc: 99.886
35 Loss: 0.591 | Acc: 99.863
36 Loss: 0.736 | Acc: 99.772
37 Loss: 0.644 | Acc: 99.795
38 Loss: 0.810 | Acc: 99.726
39 Loss: 0.621 | Acc: 99.909
40 Loss: 0.648 | Acc: 99.818
41 Loss: 0.524 | Acc: 99.886
42 Loss: 0.581 | Acc: 99.749
43 Loss: 0.512 | Acc: 99.840
44 Loss: 0.615 | Acc: 99.840
45 Loss: 0.560 | Acc: 99.840
46 Loss: 0.383 | Acc: 99.886
47 Loss: 0.474 | Acc: 99.886
48 Loss: 0.576 | Acc: 99.795
49 Loss: 0.444 | Acc: 99.886
50 Loss: 0.463 | Acc: 99.863
51 Loss: 0.455 | Acc: 99.772
52 Loss: 0.344 | Acc: 99.840
53 Loss: 0.367 | Acc: 99.909
54 Loss: 0.513 | Acc: 99.818
55 Loss: 0.331 | Acc: 99.886
56 Loss: 0.469 | Acc: 99.863
57 Loss: 0.310 | Acc: 99.932
58 Loss: 0.371 | Acc: 99.886
59 Loss: 0.356 | Acc: 99.863
MLP trained successfully...
# of Left images:  542.0
# of Right images:  414.0
giniRightRatio:  0.546430488459474
giniLeftRatio:  0.5129287455236177
impurityDrop:  0.5025707187221935
giniGain:  0.07263804863131929
lclasses:  [365, 6, 54, 2, 28, 1, 5, 78, 3, 0]
rclasses:  [183, 2, 9, 1, 0, 0, 1, 210, 8, 0]
noOfLeftClasses:  9
noOfRightClasses:  7
lTrainDict[data].shape:  torch.Size([542, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([542])
rTrainDict[data].shape:  torch.Size([414, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([414])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  68 , imgTensorShape :  torch.Size([542, 16, 8, 8])
nodeId: 68 ,  parentId: 34 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 542
nodeId:  69 , imgTensorShape :  torch.Size([414, 16, 8, 8])
nodeId: 69 ,  parentId: 34 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 7 ,  numData: 414
Running nodeId:  35
trainInputDict[data].shape :  torch.Size([1117, 16, 12, 12])
copy.shape :  torch.Size([1117, 2304])
copyLabel.shape :  torch.Size([1117])
Class 0 has 514 instances after oversampling
Class 1 has 514 instances after oversampling
Class 2 has 514 instances after oversampling
Class 3 has 513 instances after oversampling
Class 4 has 514 instances after oversampling
Class 5 has 513 instances after oversampling
Class 6 has 513 instances after oversampling
Class 7 has 513 instances after oversampling
Class 8 has 514 instances after oversampling
Class 9 has 514 instances after oversampling
0 Train Loss: 206.515 | Train Acc: 29.647
1 Train Loss: 120.768 | Train Acc: 60.471
2 Train Loss: 77.163 | Train Acc: 76.255
3 Train Loss: 58.915 | Train Acc: 81.784
4 Train Loss: 43.863 | Train Acc: 86.216
5 Train Loss: 33.865 | Train Acc: 89.647
6 Train Loss: 31.379 | Train Acc: 90.196
7 Train Loss: 22.960 | Train Acc: 93.333
8 Train Loss: 21.921 | Train Acc: 93.294
9 Train Loss: 18.070 | Train Acc: 94.431
10 Train Loss: 16.576 | Train Acc: 94.980
11 Train Loss: 12.552 | Train Acc: 96.333
12 Train Loss: 13.916 | Train Acc: 95.941
13 Train Loss: 11.761 | Train Acc: 96.039
14 Train Loss: 7.570 | Train Acc: 98.000
15 Train Loss: 6.676 | Train Acc: 98.157
16 Train Loss: 8.137 | Train Acc: 97.275
17 Train Loss: 5.678 | Train Acc: 98.412
18 Train Loss: 5.125 | Train Acc: 98.725
19 Train Loss: 3.914 | Train Acc: 99.235
20 Train Loss: 3.012 | Train Acc: 99.608
21 Train Loss: 3.023 | Train Acc: 99.471
22 Train Loss: 2.695 | Train Acc: 99.667
23 Train Loss: 2.574 | Train Acc: 99.725
24 Train Loss: 2.313 | Train Acc: 99.784
25 Train Loss: 2.315 | Train Acc: 99.706
26 Train Loss: 2.131 | Train Acc: 99.784
27 Train Loss: 2.130 | Train Acc: 99.843
28 Train Loss: 1.919 | Train Acc: 99.882
29 Train Loss: 1.903 | Train Acc: 99.824
30 Train Loss: 1.764 | Train Acc: 99.804
31 Train Loss: 2.017 | Train Acc: 99.647
32 Train Loss: 1.499 | Train Acc: 99.902
33 Train Loss: 1.422 | Train Acc: 99.941
34 Train Loss: 1.400 | Train Acc: 99.961
35 Train Loss: 1.309 | Train Acc: 99.961
36 Train Loss: 1.199 | Train Acc: 99.922
37 Train Loss: 1.199 | Train Acc: 99.941
38 Train Loss: 1.073 | Train Acc: 99.980
39 Train Loss: 1.860 | Train Acc: 99.627
40 Train Loss: 0.966 | Train Acc: 99.980
41 Train Loss: 0.910 | Train Acc: 99.980
42 Train Loss: 0.875 | Train Acc: 99.980
43 Train Loss: 0.847 | Train Acc: 99.980
44 Train Loss: 0.807 | Train Acc: 99.980
45 Train Loss: 0.807 | Train Acc: 99.980
46 Train Loss: 0.762 | Train Acc: 99.980
47 Train Loss: 0.744 | Train Acc: 99.980
48 Train Loss: 0.717 | Train Acc: 100.000
49 Train Loss: 0.709 | Train Acc: 100.000
50 Train Loss: 0.681 | Train Acc: 99.980
51 Train Loss: 0.661 | Train Acc: 100.000
52 Train Loss: 0.650 | Train Acc: 100.000
53 Train Loss: 0.632 | Train Acc: 100.000
54 Train Loss: 0.615 | Train Acc: 100.000
55 Train Loss: 0.586 | Train Acc: 100.000
56 Train Loss: 0.578 | Train Acc: 100.000
57 Train Loss: 0.556 | Train Acc: 100.000
58 Train Loss: 0.537 | Train Acc: 100.000
59 Train Loss: 0.520 | Train Acc: 100.000
60 Train Loss: 0.482 | Train Acc: 100.000
61 Train Loss: 0.472 | Train Acc: 100.000
62 Train Loss: 0.460 | Train Acc: 100.000
63 Train Loss: 0.456 | Train Acc: 100.000
64 Train Loss: 0.449 | Train Acc: 100.000
65 Train Loss: 0.441 | Train Acc: 100.000
66 Train Loss: 0.435 | Train Acc: 100.000
67 Train Loss: 0.431 | Train Acc: 100.000
68 Train Loss: 0.424 | Train Acc: 100.000
69 Train Loss: 0.418 | Train Acc: 100.000
70 Train Loss: 0.408 | Train Acc: 100.000
71 Train Loss: 0.404 | Train Acc: 100.000
72 Train Loss: 0.396 | Train Acc: 100.000
73 Train Loss: 0.389 | Train Acc: 100.000
74 Train Loss: 0.387 | Train Acc: 100.000
75 Train Loss: 0.376 | Train Acc: 100.000
76 Train Loss: 0.366 | Train Acc: 100.000
77 Train Loss: 0.359 | Train Acc: 100.000
78 Train Loss: 0.351 | Train Acc: 100.000
79 Train Loss: 0.346 | Train Acc: 100.000
80 Train Loss: 0.331 | Train Acc: 100.000
81 Train Loss: 0.326 | Train Acc: 100.000
82 Train Loss: 0.322 | Train Acc: 100.000
83 Train Loss: 0.319 | Train Acc: 100.000
84 Train Loss: 0.317 | Train Acc: 100.000
85 Train Loss: 0.315 | Train Acc: 100.000
86 Train Loss: 0.312 | Train Acc: 100.000
87 Train Loss: 0.308 | Train Acc: 100.000
88 Train Loss: 0.306 | Train Acc: 100.000
89 Train Loss: 0.303 | Train Acc: 100.000
90 Train Loss: 0.300 | Train Acc: 100.000
91 Train Loss: 0.297 | Train Acc: 100.000
92 Train Loss: 0.294 | Train Acc: 100.000
93 Train Loss: 0.290 | Train Acc: 100.000
94 Train Loss: 0.288 | Train Acc: 100.000
95 Train Loss: 0.285 | Train Acc: 100.000
96 Train Loss: 0.281 | Train Acc: 100.000
97 Train Loss: 0.278 | Train Acc: 100.000
98 Train Loss: 0.273 | Train Acc: 100.000
99 Train Loss: 0.271 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([5136, 1024])
printing expected split from k means
{8: 0, 0: 1, 4: 1, 2: 1, 1: 1, 9: 1, 5: 1, 6: 1, 7: 1, 3: 1}
Printing final_dict items...
{8: 0, 0: 1, 4: 1, 2: 1, 1: 1, 9: 1, 5: 1, 6: 1, 7: 1, 3: 1}
Image Statistics before MLP : L R :  670 4466
expectedMlpLabels.shape :  torch.Size([5136])
0 Loss: 11.373 | Acc: 90.960
1 Loss: 5.989 | Acc: 94.400
2 Loss: 6.360 | Acc: 95.240
3 Loss: 5.564 | Acc: 95.140
4 Loss: 5.487 | Acc: 95.040
5 Loss: 4.503 | Acc: 96.100
6 Loss: 4.322 | Acc: 96.040
7 Loss: 3.200 | Acc: 97.080
8 Loss: 3.571 | Acc: 96.420
9 Loss: 2.445 | Acc: 97.600
10 Loss: 1.831 | Acc: 98.140
11 Loss: 1.440 | Acc: 98.660
12 Loss: 1.556 | Acc: 98.460
13 Loss: 1.679 | Acc: 98.340
14 Loss: 1.722 | Acc: 98.180
15 Loss: 1.421 | Acc: 98.800
16 Loss: 1.944 | Acc: 98.240
17 Loss: 1.340 | Acc: 98.700
18 Loss: 1.236 | Acc: 98.620
19 Loss: 1.387 | Acc: 98.740
20 Loss: 0.963 | Acc: 99.000
21 Loss: 0.979 | Acc: 98.880
22 Loss: 0.957 | Acc: 98.920
23 Loss: 0.732 | Acc: 99.280
24 Loss: 0.696 | Acc: 99.340
25 Loss: 0.752 | Acc: 99.280
26 Loss: 0.682 | Acc: 99.260
27 Loss: 0.735 | Acc: 99.300
28 Loss: 0.697 | Acc: 99.400
29 Loss: 0.704 | Acc: 99.280
30 Loss: 0.579 | Acc: 99.400
31 Loss: 0.754 | Acc: 99.260
32 Loss: 0.522 | Acc: 99.380
33 Loss: 0.464 | Acc: 99.580
34 Loss: 0.689 | Acc: 99.420
35 Loss: 0.476 | Acc: 99.580
36 Loss: 0.482 | Acc: 99.500
37 Loss: 0.565 | Acc: 99.460
38 Loss: 0.423 | Acc: 99.500
39 Loss: 0.526 | Acc: 99.440
40 Loss: 0.419 | Acc: 99.520
41 Loss: 0.409 | Acc: 99.500
42 Loss: 0.573 | Acc: 99.560
43 Loss: 0.472 | Acc: 99.520
44 Loss: 0.446 | Acc: 99.520
45 Loss: 0.374 | Acc: 99.540
46 Loss: 0.373 | Acc: 99.620
47 Loss: 0.517 | Acc: 99.560
48 Loss: 0.366 | Acc: 99.640
49 Loss: 0.393 | Acc: 99.620
50 Loss: 0.435 | Acc: 99.560
51 Loss: 0.328 | Acc: 99.620
52 Loss: 0.424 | Acc: 99.600
53 Loss: 0.671 | Acc: 99.460
54 Loss: 0.405 | Acc: 99.600
55 Loss: 0.334 | Acc: 99.580
56 Loss: 0.323 | Acc: 99.600
57 Loss: 0.451 | Acc: 99.620
58 Loss: 0.336 | Acc: 99.560
59 Loss: 0.373 | Acc: 99.620
MLP trained successfully...
# of Left images:  275.0
# of Right images:  842.0
giniRightRatio:  0.6741809175078003
giniLeftRatio:  0.6194247933884297
impurityDrop:  0.6562973852835403
giniGain:  0.016588245670968393
lclasses:  [101, 7, 11, 0, 12, 2, 1, 0, 135, 6]
rclasses:  [413, 41, 62, 9, 44, 9, 5, 3, 228, 28]
noOfLeftClasses:  8
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([275, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([275])
rTrainDict[data].shape:  torch.Size([842, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([842])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  70 , imgTensorShape :  torch.Size([275, 16, 8, 8])
nodeId: 70 ,  parentId: 35 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 275
nodeId:  71 , imgTensorShape :  torch.Size([842, 16, 8, 8])
nodeId: 71 ,  parentId: 35 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 842
Running nodeId:  36
trainInputDict[data].shape :  torch.Size([2560, 16, 12, 12])
copy.shape :  torch.Size([2560, 2304])
copyLabel.shape :  torch.Size([2560])
Class 0 has 1077 instances after oversampling
Class 1 has 1077 instances after oversampling
Class 2 has 1077 instances after oversampling
Class 3 has 1077 instances after oversampling
Class 4 has 1077 instances after oversampling
Class 5 has 1077 instances after oversampling
Class 6 has 1077 instances after oversampling
Class 7 has 1077 instances after oversampling
Class 8 has 1077 instances after oversampling
Class 9 has 1077 instances after oversampling
0 Train Loss: 228.121 | Train Acc: 18.143
1 Train Loss: 197.397 | Train Acc: 31.931
2 Train Loss: 151.005 | Train Acc: 51.922
3 Train Loss: 112.917 | Train Acc: 64.559
4 Train Loss: 89.248 | Train Acc: 72.433
5 Train Loss: 72.528 | Train Acc: 77.911
6 Train Loss: 58.308 | Train Acc: 82.293
7 Train Loss: 51.807 | Train Acc: 84.030
8 Train Loss: 46.088 | Train Acc: 86.314
9 Train Loss: 38.760 | Train Acc: 88.069
10 Train Loss: 33.913 | Train Acc: 89.805
11 Train Loss: 31.726 | Train Acc: 90.037
12 Train Loss: 27.751 | Train Acc: 91.634
13 Train Loss: 24.030 | Train Acc: 92.609
14 Train Loss: 23.842 | Train Acc: 92.832
15 Train Loss: 19.822 | Train Acc: 94.113
16 Train Loss: 19.144 | Train Acc: 93.937
17 Train Loss: 17.381 | Train Acc: 94.726
18 Train Loss: 14.804 | Train Acc: 95.840
19 Train Loss: 15.480 | Train Acc: 95.200
20 Train Loss: 11.219 | Train Acc: 97.066
21 Train Loss: 10.352 | Train Acc: 97.363
22 Train Loss: 10.229 | Train Acc: 97.317
23 Train Loss: 10.144 | Train Acc: 97.205
24 Train Loss: 10.030 | Train Acc: 97.233
25 Train Loss: 8.837 | Train Acc: 97.864
26 Train Loss: 8.585 | Train Acc: 97.679
27 Train Loss: 8.254 | Train Acc: 97.967
28 Train Loss: 8.169 | Train Acc: 97.902
29 Train Loss: 7.815 | Train Acc: 98.013
30 Train Loss: 7.509 | Train Acc: 98.189
31 Train Loss: 7.217 | Train Acc: 98.412
32 Train Loss: 7.883 | Train Acc: 97.976
33 Train Loss: 7.039 | Train Acc: 98.273
34 Train Loss: 6.408 | Train Acc: 98.579
35 Train Loss: 6.198 | Train Acc: 98.459
36 Train Loss: 6.306 | Train Acc: 98.468
37 Train Loss: 5.748 | Train Acc: 98.756
38 Train Loss: 5.476 | Train Acc: 98.830
39 Train Loss: 5.154 | Train Acc: 98.895
40 Train Loss: 4.575 | Train Acc: 99.201
41 Train Loss: 4.445 | Train Acc: 99.248
42 Train Loss: 4.451 | Train Acc: 99.220
43 Train Loss: 4.384 | Train Acc: 99.266
44 Train Loss: 4.250 | Train Acc: 99.248
45 Train Loss: 4.123 | Train Acc: 99.443
46 Train Loss: 4.101 | Train Acc: 99.359
47 Train Loss: 4.030 | Train Acc: 99.341
48 Train Loss: 4.019 | Train Acc: 99.378
49 Train Loss: 3.810 | Train Acc: 99.461
50 Train Loss: 3.762 | Train Acc: 99.480
51 Train Loss: 3.787 | Train Acc: 99.499
52 Train Loss: 3.645 | Train Acc: 99.471
53 Train Loss: 3.488 | Train Acc: 99.582
54 Train Loss: 3.416 | Train Acc: 99.517
55 Train Loss: 3.361 | Train Acc: 99.666
56 Train Loss: 3.310 | Train Acc: 99.694
57 Train Loss: 3.312 | Train Acc: 99.619
58 Train Loss: 3.183 | Train Acc: 99.684
59 Train Loss: 3.139 | Train Acc: 99.619
60 Train Loss: 2.886 | Train Acc: 99.740
61 Train Loss: 2.811 | Train Acc: 99.796
62 Train Loss: 2.773 | Train Acc: 99.786
63 Train Loss: 2.775 | Train Acc: 99.786
64 Train Loss: 2.789 | Train Acc: 99.786
65 Train Loss: 2.695 | Train Acc: 99.786
66 Train Loss: 2.655 | Train Acc: 99.786
67 Train Loss: 2.628 | Train Acc: 99.842
68 Train Loss: 2.619 | Train Acc: 99.833
69 Train Loss: 2.611 | Train Acc: 99.805
70 Train Loss: 2.551 | Train Acc: 99.814
71 Train Loss: 2.520 | Train Acc: 99.851
72 Train Loss: 2.509 | Train Acc: 99.861
73 Train Loss: 2.469 | Train Acc: 99.861
74 Train Loss: 2.443 | Train Acc: 99.842
75 Train Loss: 2.414 | Train Acc: 99.861
76 Train Loss: 2.409 | Train Acc: 99.879
77 Train Loss: 2.332 | Train Acc: 99.879
78 Train Loss: 2.319 | Train Acc: 99.879
79 Train Loss: 2.274 | Train Acc: 99.851
80 Train Loss: 2.188 | Train Acc: 99.898
81 Train Loss: 2.183 | Train Acc: 99.907
82 Train Loss: 2.163 | Train Acc: 99.898
83 Train Loss: 2.164 | Train Acc: 99.879
84 Train Loss: 2.143 | Train Acc: 99.898
85 Train Loss: 2.144 | Train Acc: 99.898
86 Train Loss: 2.129 | Train Acc: 99.898
87 Train Loss: 2.112 | Train Acc: 99.907
88 Train Loss: 2.097 | Train Acc: 99.907
89 Train Loss: 2.087 | Train Acc: 99.889
90 Train Loss: 2.087 | Train Acc: 99.898
91 Train Loss: 2.067 | Train Acc: 99.907
92 Train Loss: 2.044 | Train Acc: 99.916
93 Train Loss: 2.046 | Train Acc: 99.898
94 Train Loss: 2.043 | Train Acc: 99.907
95 Train Loss: 2.016 | Train Acc: 99.907
96 Train Loss: 2.010 | Train Acc: 99.898
97 Train Loss: 1.995 | Train Acc: 99.898
98 Train Loss: 1.976 | Train Acc: 99.916
99 Train Loss: 1.969 | Train Acc: 99.916
CNN trained successfully...
image_next_flat.shape :  torch.Size([10770, 1024])
printing expected split from k means
{7: 1, 9: 0, 8: 1, 0: 1, 1: 1, 2: 1, 4: 1, 6: 1, 5: 1, 3: 1}
Printing final_dict items...
{7: 1, 9: 0, 8: 1, 0: 1, 1: 1, 2: 1, 4: 1, 6: 1, 5: 1, 3: 1}
Image Statistics before MLP : L R :  3122 7648
expectedMlpLabels.shape :  torch.Size([10770])
0 Loss: 18.128 | Acc: 92.804
1 Loss: 10.779 | Acc: 95.664
2 Loss: 9.265 | Acc: 96.342
3 Loss: 8.892 | Acc: 96.370
4 Loss: 7.731 | Acc: 96.880
5 Loss: 7.608 | Acc: 96.797
6 Loss: 6.436 | Acc: 97.344
7 Loss: 6.184 | Acc: 97.326
8 Loss: 6.373 | Acc: 97.279
9 Loss: 5.545 | Acc: 97.883
10 Loss: 3.950 | Acc: 98.375
11 Loss: 3.618 | Acc: 98.477
12 Loss: 3.693 | Acc: 98.672
13 Loss: 3.163 | Acc: 98.607
14 Loss: 3.055 | Acc: 98.793
15 Loss: 3.729 | Acc: 98.607
16 Loss: 3.180 | Acc: 98.682
17 Loss: 3.049 | Acc: 98.812
18 Loss: 2.719 | Acc: 98.914
19 Loss: 2.865 | Acc: 98.867
20 Loss: 2.044 | Acc: 99.257
21 Loss: 1.995 | Acc: 99.164
22 Loss: 1.849 | Acc: 99.313
23 Loss: 1.599 | Acc: 99.387
24 Loss: 1.575 | Acc: 99.369
25 Loss: 2.039 | Acc: 99.211
26 Loss: 1.586 | Acc: 99.415
27 Loss: 1.493 | Acc: 99.415
28 Loss: 1.556 | Acc: 99.452
29 Loss: 1.742 | Acc: 99.322
30 Loss: 1.406 | Acc: 99.517
31 Loss: 1.106 | Acc: 99.545
32 Loss: 1.299 | Acc: 99.564
33 Loss: 1.091 | Acc: 99.619
34 Loss: 1.042 | Acc: 99.619
35 Loss: 1.093 | Acc: 99.582
36 Loss: 1.145 | Acc: 99.591
37 Loss: 1.181 | Acc: 99.536
38 Loss: 1.098 | Acc: 99.647
39 Loss: 0.955 | Acc: 99.656
40 Loss: 0.958 | Acc: 99.694
41 Loss: 0.937 | Acc: 99.619
42 Loss: 0.740 | Acc: 99.731
43 Loss: 0.788 | Acc: 99.740
44 Loss: 0.780 | Acc: 99.721
45 Loss: 0.876 | Acc: 99.675
46 Loss: 0.908 | Acc: 99.638
47 Loss: 0.908 | Acc: 99.694
48 Loss: 0.875 | Acc: 99.684
49 Loss: 0.710 | Acc: 99.749
50 Loss: 0.884 | Acc: 99.684
51 Loss: 0.773 | Acc: 99.694
52 Loss: 0.776 | Acc: 99.721
53 Loss: 0.843 | Acc: 99.721
54 Loss: 0.823 | Acc: 99.712
55 Loss: 0.756 | Acc: 99.731
56 Loss: 0.806 | Acc: 99.647
57 Loss: 0.733 | Acc: 99.703
58 Loss: 0.770 | Acc: 99.703
59 Loss: 0.666 | Acc: 99.731
MLP trained successfully...
# of Left images:  1245.0
# of Right images:  1315.0
giniRightRatio:  0.781439083982709
giniLeftRatio:  0.668391800132256
impurityDrop:  0.674409526268782
giniGain:  0.06422481211012421
lclasses:  [83, 157, 23, 7, 29, 4, 3, 39, 257, 643]
rclasses:  [127, 311, 36, 31, 34, 15, 28, 32, 267, 434]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1245, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([1245])
rTrainDict[data].shape:  torch.Size([1315, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([1315])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  72 , imgTensorShape :  torch.Size([1245, 16, 8, 8])
nodeId: 72 ,  parentId: 36 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1245
nodeId:  73 , imgTensorShape :  torch.Size([1315, 16, 8, 8])
nodeId: 73 ,  parentId: 36 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1315
Running nodeId:  37
trainInputDict[data].shape :  torch.Size([2076, 16, 12, 12])
copy.shape :  torch.Size([2076, 2304])
copyLabel.shape :  torch.Size([2076])
Class 0 has 932 instances after oversampling
Class 1 has 932 instances after oversampling
Class 2 has 932 instances after oversampling
Class 3 has 931 instances after oversampling
Class 4 has 931 instances after oversampling
Class 5 has 931 instances after oversampling
Class 6 has 931 instances after oversampling
Class 7 has 932 instances after oversampling
Class 8 has 932 instances after oversampling
Class 9 has 932 instances after oversampling
0 Train Loss: 224.520 | Train Acc: 18.302
1 Train Loss: 153.812 | Train Acc: 50.397
2 Train Loss: 87.590 | Train Acc: 73.229
3 Train Loss: 82.146 | Train Acc: 74.807
4 Train Loss: 55.511 | Train Acc: 82.342
5 Train Loss: 46.602 | Train Acc: 85.101
6 Train Loss: 38.292 | Train Acc: 87.291
7 Train Loss: 35.335 | Train Acc: 88.343
8 Train Loss: 29.190 | Train Acc: 90.296
9 Train Loss: 26.723 | Train Acc: 91.262
10 Train Loss: 21.524 | Train Acc: 93.173
11 Train Loss: 21.167 | Train Acc: 93.420
12 Train Loss: 19.380 | Train Acc: 93.785
13 Train Loss: 16.879 | Train Acc: 94.558
14 Train Loss: 16.173 | Train Acc: 94.687
15 Train Loss: 15.808 | Train Acc: 94.719
16 Train Loss: 11.368 | Train Acc: 96.662
17 Train Loss: 9.288 | Train Acc: 97.274
18 Train Loss: 10.428 | Train Acc: 96.705
19 Train Loss: 8.427 | Train Acc: 97.445
20 Train Loss: 6.425 | Train Acc: 98.551
21 Train Loss: 5.752 | Train Acc: 98.723
22 Train Loss: 5.651 | Train Acc: 98.744
23 Train Loss: 5.120 | Train Acc: 98.980
24 Train Loss: 5.120 | Train Acc: 98.927
25 Train Loss: 4.804 | Train Acc: 99.120
26 Train Loss: 4.578 | Train Acc: 99.152
27 Train Loss: 4.439 | Train Acc: 99.302
28 Train Loss: 4.279 | Train Acc: 99.227
29 Train Loss: 4.081 | Train Acc: 99.216
30 Train Loss: 4.361 | Train Acc: 99.066
31 Train Loss: 3.743 | Train Acc: 99.442
32 Train Loss: 3.509 | Train Acc: 99.431
33 Train Loss: 3.331 | Train Acc: 99.474
34 Train Loss: 2.998 | Train Acc: 99.592
35 Train Loss: 2.978 | Train Acc: 99.474
36 Train Loss: 2.678 | Train Acc: 99.721
37 Train Loss: 2.633 | Train Acc: 99.646
38 Train Loss: 2.568 | Train Acc: 99.678
39 Train Loss: 2.327 | Train Acc: 99.764
40 Train Loss: 1.975 | Train Acc: 99.871
41 Train Loss: 1.884 | Train Acc: 99.882
42 Train Loss: 1.818 | Train Acc: 99.925
43 Train Loss: 1.768 | Train Acc: 99.925
44 Train Loss: 1.733 | Train Acc: 99.893
45 Train Loss: 1.679 | Train Acc: 99.936
46 Train Loss: 1.672 | Train Acc: 99.936
47 Train Loss: 1.644 | Train Acc: 99.936
48 Train Loss: 1.572 | Train Acc: 99.936
49 Train Loss: 1.512 | Train Acc: 99.936
50 Train Loss: 1.508 | Train Acc: 99.946
51 Train Loss: 1.413 | Train Acc: 99.946
52 Train Loss: 1.395 | Train Acc: 99.946
53 Train Loss: 1.338 | Train Acc: 99.957
54 Train Loss: 1.312 | Train Acc: 99.946
55 Train Loss: 1.243 | Train Acc: 99.957
56 Train Loss: 1.231 | Train Acc: 99.968
57 Train Loss: 1.202 | Train Acc: 99.957
58 Train Loss: 1.124 | Train Acc: 99.968
59 Train Loss: 1.141 | Train Acc: 99.968
60 Train Loss: 1.003 | Train Acc: 99.979
61 Train Loss: 0.976 | Train Acc: 99.979
62 Train Loss: 0.964 | Train Acc: 99.979
63 Train Loss: 0.946 | Train Acc: 99.979
64 Train Loss: 0.934 | Train Acc: 99.979
65 Train Loss: 0.918 | Train Acc: 99.989
66 Train Loss: 0.905 | Train Acc: 99.989
67 Train Loss: 0.894 | Train Acc: 99.989
68 Train Loss: 0.877 | Train Acc: 99.989
69 Train Loss: 0.864 | Train Acc: 99.989
70 Train Loss: 0.855 | Train Acc: 99.989
71 Train Loss: 0.850 | Train Acc: 99.989
72 Train Loss: 0.812 | Train Acc: 99.989
73 Train Loss: 0.813 | Train Acc: 99.989
74 Train Loss: 0.796 | Train Acc: 99.989
75 Train Loss: 0.767 | Train Acc: 99.989
76 Train Loss: 0.764 | Train Acc: 99.989
77 Train Loss: 0.747 | Train Acc: 99.989
78 Train Loss: 0.738 | Train Acc: 99.989
79 Train Loss: 0.719 | Train Acc: 99.989
80 Train Loss: 0.682 | Train Acc: 100.000
81 Train Loss: 0.673 | Train Acc: 100.000
82 Train Loss: 0.666 | Train Acc: 100.000
83 Train Loss: 0.664 | Train Acc: 100.000
84 Train Loss: 0.661 | Train Acc: 100.000
85 Train Loss: 0.654 | Train Acc: 100.000
86 Train Loss: 0.647 | Train Acc: 100.000
87 Train Loss: 0.643 | Train Acc: 100.000
88 Train Loss: 0.633 | Train Acc: 100.000
89 Train Loss: 0.632 | Train Acc: 100.000
90 Train Loss: 0.626 | Train Acc: 100.000
91 Train Loss: 0.619 | Train Acc: 100.000
92 Train Loss: 0.612 | Train Acc: 100.000
93 Train Loss: 0.606 | Train Acc: 100.000
94 Train Loss: 0.600 | Train Acc: 100.000
95 Train Loss: 0.595 | Train Acc: 100.000
96 Train Loss: 0.586 | Train Acc: 100.000
97 Train Loss: 0.586 | Train Acc: 100.000
98 Train Loss: 0.578 | Train Acc: 100.000
99 Train Loss: 0.571 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9316, 1024])
printing expected split from k means
{9: 1, 1: 1, 0: 1, 3: 1, 7: 0, 8: 1, 2: 1, 4: 1, 6: 1, 5: 1}
Printing final_dict items...
{9: 1, 1: 1, 0: 1, 3: 1, 7: 0, 8: 1, 2: 1, 4: 1, 6: 1, 5: 1}
Image Statistics before MLP : L R :  2065 7251
expectedMlpLabels.shape :  torch.Size([9316])
0 Loss: 14.902 | Acc: 92.793
1 Loss: 7.860 | Acc: 95.446
2 Loss: 7.539 | Acc: 95.870
3 Loss: 5.803 | Acc: 96.674
4 Loss: 5.419 | Acc: 97.109
5 Loss: 5.238 | Acc: 97.011
6 Loss: 4.531 | Acc: 97.283
7 Loss: 4.468 | Acc: 97.576
8 Loss: 4.075 | Acc: 97.652
9 Loss: 3.679 | Acc: 98.033
10 Loss: 3.319 | Acc: 98.076
11 Loss: 2.430 | Acc: 98.630
12 Loss: 2.423 | Acc: 98.630
13 Loss: 2.383 | Acc: 98.750
14 Loss: 1.837 | Acc: 99.043
15 Loss: 2.223 | Acc: 98.870
16 Loss: 1.994 | Acc: 98.804
17 Loss: 1.844 | Acc: 99.065
18 Loss: 1.991 | Acc: 98.967
19 Loss: 2.095 | Acc: 99.033
20 Loss: 1.618 | Acc: 99.033
21 Loss: 1.415 | Acc: 99.293
22 Loss: 1.225 | Acc: 99.261
23 Loss: 1.188 | Acc: 99.402
24 Loss: 0.983 | Acc: 99.446
25 Loss: 0.905 | Acc: 99.543
26 Loss: 1.261 | Acc: 99.283
27 Loss: 1.208 | Acc: 99.402
28 Loss: 0.946 | Acc: 99.500
29 Loss: 0.987 | Acc: 99.522
30 Loss: 0.778 | Acc: 99.576
31 Loss: 0.681 | Acc: 99.641
32 Loss: 0.916 | Acc: 99.543
33 Loss: 0.779 | Acc: 99.641
34 Loss: 0.637 | Acc: 99.663
35 Loss: 0.671 | Acc: 99.696
36 Loss: 0.702 | Acc: 99.652
37 Loss: 0.587 | Acc: 99.674
38 Loss: 0.715 | Acc: 99.663
39 Loss: 0.724 | Acc: 99.663
40 Loss: 0.720 | Acc: 99.685
41 Loss: 0.530 | Acc: 99.728
42 Loss: 0.454 | Acc: 99.804
43 Loss: 0.499 | Acc: 99.717
44 Loss: 0.625 | Acc: 99.761
45 Loss: 0.433 | Acc: 99.804
46 Loss: 0.609 | Acc: 99.663
47 Loss: 0.530 | Acc: 99.717
48 Loss: 0.448 | Acc: 99.837
49 Loss: 0.492 | Acc: 99.707
50 Loss: 0.515 | Acc: 99.696
51 Loss: 0.480 | Acc: 99.815
52 Loss: 0.481 | Acc: 99.750
53 Loss: 0.361 | Acc: 99.848
54 Loss: 0.492 | Acc: 99.793
55 Loss: 0.479 | Acc: 99.783
56 Loss: 0.491 | Acc: 99.750
57 Loss: 0.523 | Acc: 99.815
58 Loss: 0.385 | Acc: 99.783
59 Loss: 0.564 | Acc: 99.750
MLP trained successfully...
# of Left images:  661.0
# of Right images:  1415.0
giniRightRatio:  0.7347026433093184
giniLeftRatio:  0.5637403558080294
impurityDrop:  0.6548396948723205
giniGain:  0.056702621944145104
lclasses:  [34, 400, 4, 4, 7, 1, 2, 18, 22, 169]
rclasses:  [162, 532, 35, 15, 16, 11, 5, 20, 428, 191]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([661, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([661])
rTrainDict[data].shape:  torch.Size([1415, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([1415])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  74 , imgTensorShape :  torch.Size([661, 16, 8, 8])
nodeId: 74 ,  parentId: 37 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 661
nodeId:  75 , imgTensorShape :  torch.Size([1415, 16, 8, 8])
nodeId: 75 ,  parentId: 37 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1415
Running nodeId:  38
trainInputDict[data].shape :  torch.Size([2667, 16, 12, 12])
copy.shape :  torch.Size([2667, 2304])
copyLabel.shape :  torch.Size([2667])
Class 0 has 1136 instances after oversampling
Class 1 has 1136 instances after oversampling
Class 2 has 1136 instances after oversampling
Class 3 has 1136 instances after oversampling
Class 4 has 1136 instances after oversampling
Class 5 has 1136 instances after oversampling
Class 6 has 1 instances after oversampling
Class 7 has 1136 instances after oversampling
Class 8 has 1136 instances after oversampling
Class 9 has 1136 instances after oversampling
0 Train Loss: 184.136 | Train Acc: 38.670
1 Train Loss: 94.877 | Train Acc: 67.785
2 Train Loss: 69.867 | Train Acc: 74.592
3 Train Loss: 54.881 | Train Acc: 79.941
4 Train Loss: 44.410 | Train Acc: 83.697
5 Train Loss: 40.013 | Train Acc: 85.623
6 Train Loss: 37.520 | Train Acc: 86.005
7 Train Loss: 32.556 | Train Acc: 88.215
8 Train Loss: 31.557 | Train Acc: 88.518
9 Train Loss: 33.045 | Train Acc: 87.961
10 Train Loss: 27.113 | Train Acc: 90.533
11 Train Loss: 26.682 | Train Acc: 90.631
12 Train Loss: 22.137 | Train Acc: 92.381
13 Train Loss: 20.723 | Train Acc: 92.998
14 Train Loss: 20.712 | Train Acc: 93.017
15 Train Loss: 19.646 | Train Acc: 93.066
16 Train Loss: 15.277 | Train Acc: 94.866
17 Train Loss: 14.795 | Train Acc: 94.778
18 Train Loss: 16.257 | Train Acc: 94.083
19 Train Loss: 13.928 | Train Acc: 95.570
20 Train Loss: 10.875 | Train Acc: 96.714
21 Train Loss: 10.953 | Train Acc: 96.548
22 Train Loss: 10.087 | Train Acc: 97.086
23 Train Loss: 9.507 | Train Acc: 97.125
24 Train Loss: 9.025 | Train Acc: 97.369
25 Train Loss: 9.123 | Train Acc: 97.399
26 Train Loss: 8.804 | Train Acc: 97.447
27 Train Loss: 8.295 | Train Acc: 97.770
28 Train Loss: 7.939 | Train Acc: 97.995
29 Train Loss: 7.877 | Train Acc: 97.809
30 Train Loss: 7.655 | Train Acc: 97.976
31 Train Loss: 7.233 | Train Acc: 98.181
32 Train Loss: 6.832 | Train Acc: 98.240
33 Train Loss: 6.641 | Train Acc: 98.337
34 Train Loss: 6.479 | Train Acc: 98.210
35 Train Loss: 6.262 | Train Acc: 98.484
36 Train Loss: 5.841 | Train Acc: 98.582
37 Train Loss: 6.036 | Train Acc: 98.484
38 Train Loss: 5.456 | Train Acc: 98.572
39 Train Loss: 5.083 | Train Acc: 98.895
40 Train Loss: 4.610 | Train Acc: 99.139
41 Train Loss: 4.538 | Train Acc: 99.149
42 Train Loss: 4.476 | Train Acc: 99.159
43 Train Loss: 4.341 | Train Acc: 99.267
44 Train Loss: 4.264 | Train Acc: 99.267
45 Train Loss: 4.175 | Train Acc: 99.257
46 Train Loss: 4.098 | Train Acc: 99.286
47 Train Loss: 3.994 | Train Acc: 99.374
48 Train Loss: 3.937 | Train Acc: 99.315
49 Train Loss: 3.974 | Train Acc: 99.296
50 Train Loss: 3.830 | Train Acc: 99.374
51 Train Loss: 3.778 | Train Acc: 99.462
52 Train Loss: 3.686 | Train Acc: 99.443
53 Train Loss: 3.569 | Train Acc: 99.511
54 Train Loss: 3.439 | Train Acc: 99.511
55 Train Loss: 3.406 | Train Acc: 99.540
56 Train Loss: 3.376 | Train Acc: 99.521
57 Train Loss: 3.254 | Train Acc: 99.560
58 Train Loss: 3.302 | Train Acc: 99.501
59 Train Loss: 3.195 | Train Acc: 99.599
60 Train Loss: 2.891 | Train Acc: 99.667
61 Train Loss: 2.867 | Train Acc: 99.658
62 Train Loss: 2.831 | Train Acc: 99.677
63 Train Loss: 2.792 | Train Acc: 99.687
64 Train Loss: 2.792 | Train Acc: 99.677
65 Train Loss: 2.744 | Train Acc: 99.697
66 Train Loss: 2.731 | Train Acc: 99.687
67 Train Loss: 2.695 | Train Acc: 99.726
68 Train Loss: 2.672 | Train Acc: 99.697
69 Train Loss: 2.649 | Train Acc: 99.707
70 Train Loss: 2.617 | Train Acc: 99.716
71 Train Loss: 2.576 | Train Acc: 99.716
72 Train Loss: 2.546 | Train Acc: 99.726
73 Train Loss: 2.509 | Train Acc: 99.726
74 Train Loss: 2.487 | Train Acc: 99.775
75 Train Loss: 2.469 | Train Acc: 99.746
76 Train Loss: 2.434 | Train Acc: 99.785
77 Train Loss: 2.405 | Train Acc: 99.785
78 Train Loss: 2.380 | Train Acc: 99.795
79 Train Loss: 2.333 | Train Acc: 99.785
80 Train Loss: 2.271 | Train Acc: 99.814
81 Train Loss: 2.259 | Train Acc: 99.785
82 Train Loss: 2.237 | Train Acc: 99.814
83 Train Loss: 2.223 | Train Acc: 99.834
84 Train Loss: 2.228 | Train Acc: 99.824
85 Train Loss: 2.205 | Train Acc: 99.814
86 Train Loss: 2.194 | Train Acc: 99.824
87 Train Loss: 2.178 | Train Acc: 99.863
88 Train Loss: 2.168 | Train Acc: 99.853
89 Train Loss: 2.157 | Train Acc: 99.834
90 Train Loss: 2.144 | Train Acc: 99.834
91 Train Loss: 2.137 | Train Acc: 99.834
92 Train Loss: 2.119 | Train Acc: 99.834
93 Train Loss: 2.108 | Train Acc: 99.863
94 Train Loss: 2.104 | Train Acc: 99.834
95 Train Loss: 2.092 | Train Acc: 99.853
96 Train Loss: 2.077 | Train Acc: 99.834
97 Train Loss: 2.062 | Train Acc: 99.853
98 Train Loss: 2.044 | Train Acc: 99.863
99 Train Loss: 2.036 | Train Acc: 99.873
CNN trained successfully...
image_next_flat.shape :  torch.Size([10225, 1024])
printing expected split from k means
{8: 1, 1: 1, 2: 1, 0: 1, 4: 0, 9: 1, 5: 1, 3: 0, 7: 1, 6: 1}
Printing final_dict items...
{8: 1, 1: 1, 2: 1, 0: 1, 4: 0, 9: 1, 5: 1, 3: 0, 7: 1, 6: 1}
Image Statistics before MLP : L R :  2501 7724
expectedMlpLabels.shape :  torch.Size([10225])
0 Loss: 21.732 | Acc: 88.490
1 Loss: 14.257 | Acc: 93.569
2 Loss: 11.551 | Acc: 94.775
3 Loss: 10.787 | Acc: 95.608
4 Loss: 9.740 | Acc: 95.402
5 Loss: 8.715 | Acc: 96.020
6 Loss: 8.091 | Acc: 96.137
7 Loss: 7.342 | Acc: 96.745
8 Loss: 7.966 | Acc: 96.373
9 Loss: 7.162 | Acc: 96.706
10 Loss: 5.636 | Acc: 97.480
11 Loss: 5.181 | Acc: 97.676
12 Loss: 4.767 | Acc: 97.873
13 Loss: 4.604 | Acc: 98.069
14 Loss: 4.671 | Acc: 97.961
15 Loss: 4.415 | Acc: 98.078
16 Loss: 4.139 | Acc: 98.206
17 Loss: 4.465 | Acc: 97.980
18 Loss: 4.059 | Acc: 98.343
19 Loss: 4.591 | Acc: 98.069
20 Loss: 3.312 | Acc: 98.529
21 Loss: 3.158 | Acc: 98.735
22 Loss: 2.859 | Acc: 98.843
23 Loss: 2.925 | Acc: 98.902
24 Loss: 2.975 | Acc: 98.794
25 Loss: 2.777 | Acc: 98.853
26 Loss: 2.793 | Acc: 98.863
27 Loss: 2.795 | Acc: 99.010
28 Loss: 2.677 | Acc: 99.029
29 Loss: 2.737 | Acc: 98.971
30 Loss: 2.605 | Acc: 99.088
31 Loss: 2.371 | Acc: 99.069
32 Loss: 2.392 | Acc: 99.118
33 Loss: 2.307 | Acc: 99.186
34 Loss: 2.395 | Acc: 99.206
35 Loss: 2.317 | Acc: 99.186
36 Loss: 2.116 | Acc: 99.314
37 Loss: 2.345 | Acc: 99.137
38 Loss: 2.161 | Acc: 99.137
39 Loss: 2.064 | Acc: 99.324
40 Loss: 2.121 | Acc: 99.235
41 Loss: 1.843 | Acc: 99.451
42 Loss: 1.836 | Acc: 99.471
43 Loss: 2.074 | Acc: 99.363
44 Loss: 2.035 | Acc: 99.294
45 Loss: 1.987 | Acc: 99.275
46 Loss: 1.925 | Acc: 99.333
47 Loss: 1.902 | Acc: 99.314
48 Loss: 2.013 | Acc: 99.284
49 Loss: 1.915 | Acc: 99.392
50 Loss: 1.902 | Acc: 99.314
51 Loss: 1.937 | Acc: 99.392
52 Loss: 1.821 | Acc: 99.392
53 Loss: 1.911 | Acc: 99.304
54 Loss: 1.716 | Acc: 99.471
55 Loss: 1.864 | Acc: 99.373
56 Loss: 2.020 | Acc: 99.294
57 Loss: 1.929 | Acc: 99.392
58 Loss: 2.037 | Acc: 99.363
59 Loss: 1.774 | Acc: 99.471
MLP trained successfully...
# of Left images:  285.0
# of Right images:  2382.0
giniRightRatio:  0.6825375172455606
giniLeftRatio:  0.7621791320406279
impurityDrop:  0.6920664258167588
giniGain:  0.0027505465836258347
lclasses:  [92, 63, 14, 2, 14, 2, 0, 0, 78, 20]
rclasses:  [586, 563, 12, 3, 5, 5, 1, 3, 1058, 146]
noOfLeftClasses:  8
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([285, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([285])
rTrainDict[data].shape:  torch.Size([2382, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([2382])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  76 , imgTensorShape :  torch.Size([285, 16, 8, 8])
nodeId: 76 ,  parentId: 38 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 285
nodeId:  77 , imgTensorShape :  torch.Size([2382, 16, 8, 8])
nodeId: 77 ,  parentId: 38 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2382
Running nodeId:  39
trainInputDict[data].shape :  torch.Size([2482, 16, 12, 12])
copy.shape :  torch.Size([2482, 2304])
copyLabel.shape :  torch.Size([2482])
Class 0 has 757 instances after oversampling
Class 1 has 757 instances after oversampling
Class 2 has 757 instances after oversampling
Class 3 has 756 instances after oversampling
Class 4 has 756 instances after oversampling
Class 5 has 1 instances after oversampling
Class 6 has 756 instances after oversampling
Class 7 has 757 instances after oversampling
Class 8 has 757 instances after oversampling
Class 9 has 757 instances after oversampling
0 Train Loss: 202.968 | Train Acc: 29.000
1 Train Loss: 118.613 | Train Acc: 60.559
2 Train Loss: 79.614 | Train Acc: 74.250
3 Train Loss: 66.920 | Train Acc: 78.015
4 Train Loss: 53.334 | Train Acc: 82.147
5 Train Loss: 43.782 | Train Acc: 84.574
6 Train Loss: 42.087 | Train Acc: 85.309
7 Train Loss: 37.209 | Train Acc: 86.912
8 Train Loss: 34.625 | Train Acc: 88.103
9 Train Loss: 31.594 | Train Acc: 88.603
10 Train Loss: 30.096 | Train Acc: 89.235
11 Train Loss: 28.432 | Train Acc: 89.632
12 Train Loss: 31.728 | Train Acc: 88.882
13 Train Loss: 25.043 | Train Acc: 91.456
14 Train Loss: 25.302 | Train Acc: 91.574
15 Train Loss: 22.452 | Train Acc: 92.353
16 Train Loss: 19.930 | Train Acc: 93.382
17 Train Loss: 18.605 | Train Acc: 93.735
18 Train Loss: 18.005 | Train Acc: 94.353
19 Train Loss: 15.661 | Train Acc: 95.118
20 Train Loss: 13.370 | Train Acc: 96.132
21 Train Loss: 12.672 | Train Acc: 96.485
22 Train Loss: 12.079 | Train Acc: 96.412
23 Train Loss: 11.786 | Train Acc: 96.853
24 Train Loss: 11.539 | Train Acc: 96.809
25 Train Loss: 10.917 | Train Acc: 97.118
26 Train Loss: 10.674 | Train Acc: 97.103
27 Train Loss: 10.340 | Train Acc: 97.368
28 Train Loss: 9.913 | Train Acc: 97.500
29 Train Loss: 9.961 | Train Acc: 97.353
30 Train Loss: 9.116 | Train Acc: 97.794
31 Train Loss: 8.974 | Train Acc: 97.735
32 Train Loss: 8.719 | Train Acc: 97.824
33 Train Loss: 8.329 | Train Acc: 98.029
34 Train Loss: 7.780 | Train Acc: 98.544
35 Train Loss: 7.791 | Train Acc: 98.309
36 Train Loss: 7.378 | Train Acc: 98.426
37 Train Loss: 7.011 | Train Acc: 98.721
38 Train Loss: 6.997 | Train Acc: 98.809
39 Train Loss: 6.463 | Train Acc: 98.706
40 Train Loss: 5.660 | Train Acc: 99.176
41 Train Loss: 5.429 | Train Acc: 99.324
42 Train Loss: 5.364 | Train Acc: 99.324
43 Train Loss: 5.251 | Train Acc: 99.338
44 Train Loss: 5.176 | Train Acc: 99.338
45 Train Loss: 5.135 | Train Acc: 99.412
46 Train Loss: 5.007 | Train Acc: 99.353
47 Train Loss: 4.871 | Train Acc: 99.500
48 Train Loss: 4.824 | Train Acc: 99.441
49 Train Loss: 4.857 | Train Acc: 99.544
50 Train Loss: 4.577 | Train Acc: 99.485
51 Train Loss: 4.496 | Train Acc: 99.618
52 Train Loss: 4.402 | Train Acc: 99.588
53 Train Loss: 4.247 | Train Acc: 99.603
54 Train Loss: 4.125 | Train Acc: 99.662
55 Train Loss: 4.086 | Train Acc: 99.676
56 Train Loss: 3.979 | Train Acc: 99.735
57 Train Loss: 3.957 | Train Acc: 99.662
58 Train Loss: 3.765 | Train Acc: 99.750
59 Train Loss: 3.679 | Train Acc: 99.765
60 Train Loss: 3.449 | Train Acc: 99.824
61 Train Loss: 3.399 | Train Acc: 99.809
62 Train Loss: 3.373 | Train Acc: 99.838
63 Train Loss: 3.318 | Train Acc: 99.838
64 Train Loss: 3.306 | Train Acc: 99.838
65 Train Loss: 3.258 | Train Acc: 99.868
66 Train Loss: 3.229 | Train Acc: 99.868
67 Train Loss: 3.189 | Train Acc: 99.897
68 Train Loss: 3.143 | Train Acc: 99.853
69 Train Loss: 3.111 | Train Acc: 99.897
70 Train Loss: 3.088 | Train Acc: 99.882
71 Train Loss: 3.047 | Train Acc: 99.897
72 Train Loss: 2.997 | Train Acc: 99.912
73 Train Loss: 2.971 | Train Acc: 99.912
74 Train Loss: 2.942 | Train Acc: 99.897
75 Train Loss: 2.922 | Train Acc: 99.897
76 Train Loss: 2.864 | Train Acc: 99.926
77 Train Loss: 2.832 | Train Acc: 99.912
78 Train Loss: 2.794 | Train Acc: 99.912
79 Train Loss: 2.752 | Train Acc: 99.912
80 Train Loss: 2.666 | Train Acc: 99.912
81 Train Loss: 2.650 | Train Acc: 99.941
82 Train Loss: 2.639 | Train Acc: 99.926
83 Train Loss: 2.633 | Train Acc: 99.912
84 Train Loss: 2.605 | Train Acc: 99.941
85 Train Loss: 2.592 | Train Acc: 99.926
86 Train Loss: 2.579 | Train Acc: 99.926
87 Train Loss: 2.555 | Train Acc: 99.941
88 Train Loss: 2.562 | Train Acc: 99.941
89 Train Loss: 2.530 | Train Acc: 99.956
90 Train Loss: 2.523 | Train Acc: 99.956
91 Train Loss: 2.508 | Train Acc: 99.926
92 Train Loss: 2.498 | Train Acc: 99.956
93 Train Loss: 2.479 | Train Acc: 99.941
94 Train Loss: 2.463 | Train Acc: 99.956
95 Train Loss: 2.453 | Train Acc: 99.956
96 Train Loss: 2.435 | Train Acc: 99.971
97 Train Loss: 2.418 | Train Acc: 99.956
98 Train Loss: 2.415 | Train Acc: 99.971
99 Train Loss: 2.396 | Train Acc: 99.956
CNN trained successfully...
image_next_flat.shape :  torch.Size([6811, 1024])
printing expected split from k means
{1: 1, 8: 1, 0: 1, 7: 0, 3: 0, 4: 1, 9: 1, 2: 1, 6: 1, 5: 1}
Printing final_dict items...
{1: 1, 8: 1, 0: 1, 7: 0, 3: 0, 4: 1, 9: 1, 2: 1, 6: 1, 5: 1}
Image Statistics before MLP : L R :  2000 4811
expectedMlpLabels.shape :  torch.Size([6811])
0 Loss: 42.820 | Acc: 79.941
1 Loss: 28.656 | Acc: 88.647
2 Loss: 24.968 | Acc: 90.544
3 Loss: 21.784 | Acc: 90.912
4 Loss: 19.121 | Acc: 92.132
5 Loss: 18.684 | Acc: 92.162
6 Loss: 17.213 | Acc: 93.353
7 Loss: 16.851 | Acc: 93.309
8 Loss: 15.691 | Acc: 93.897
9 Loss: 14.483 | Acc: 93.750
10 Loss: 12.049 | Acc: 95.324
11 Loss: 10.560 | Acc: 95.750
12 Loss: 10.297 | Acc: 96.000
13 Loss: 9.772 | Acc: 96.015
14 Loss: 9.552 | Acc: 96.059
15 Loss: 8.251 | Acc: 96.500
16 Loss: 8.672 | Acc: 96.706
17 Loss: 8.602 | Acc: 96.456
18 Loss: 8.731 | Acc: 96.471
19 Loss: 7.781 | Acc: 97.103
20 Loss: 6.694 | Acc: 97.309
21 Loss: 6.228 | Acc: 97.353
22 Loss: 6.246 | Acc: 97.632
23 Loss: 5.727 | Acc: 97.574
24 Loss: 5.456 | Acc: 97.779
25 Loss: 5.196 | Acc: 97.897
26 Loss: 5.257 | Acc: 97.750
27 Loss: 5.018 | Acc: 98.147
28 Loss: 4.673 | Acc: 98.353
29 Loss: 5.100 | Acc: 98.191
30 Loss: 4.300 | Acc: 98.324
31 Loss: 4.274 | Acc: 98.294
32 Loss: 4.511 | Acc: 98.221
33 Loss: 3.684 | Acc: 98.676
34 Loss: 4.354 | Acc: 98.412
35 Loss: 4.015 | Acc: 98.441
36 Loss: 3.987 | Acc: 98.441
37 Loss: 3.907 | Acc: 98.397
38 Loss: 3.556 | Acc: 98.647
39 Loss: 3.862 | Acc: 98.603
40 Loss: 3.277 | Acc: 98.838
41 Loss: 3.344 | Acc: 98.779
42 Loss: 3.543 | Acc: 98.632
43 Loss: 3.736 | Acc: 98.647
44 Loss: 3.245 | Acc: 98.868
45 Loss: 3.262 | Acc: 98.809
46 Loss: 3.379 | Acc: 98.676
47 Loss: 3.350 | Acc: 98.750
48 Loss: 3.532 | Acc: 98.765
49 Loss: 2.977 | Acc: 98.912
50 Loss: 3.002 | Acc: 98.941
51 Loss: 3.595 | Acc: 98.662
52 Loss: 3.350 | Acc: 98.853
53 Loss: 3.076 | Acc: 99.000
54 Loss: 3.427 | Acc: 98.765
55 Loss: 3.096 | Acc: 98.794
56 Loss: 3.162 | Acc: 98.794
57 Loss: 2.890 | Acc: 98.897
58 Loss: 3.028 | Acc: 98.941
59 Loss: 2.979 | Acc: 98.956
MLP trained successfully...
# of Left images:  493.0
# of Right images:  1989.0
giniRightRatio:  0.7558782959368533
giniLeftRatio:  0.7917415829729808
impurityDrop:  0.7647674867406797
giniGain:  0.0018564765443682685
lclasses:  [149, 124, 13, 6, 21, 0, 2, 25, 82, 71]
rclasses:  [438, 633, 17, 2, 9, 1, 13, 13, 440, 423]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([493, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([493])
rTrainDict[data].shape:  torch.Size([1989, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([1989])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  78 , imgTensorShape :  torch.Size([493, 16, 8, 8])
nodeId: 78 ,  parentId: 39 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 493
nodeId:  79 , imgTensorShape :  torch.Size([1989, 16, 8, 8])
nodeId: 79 ,  parentId: 39 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1989
Running nodeId:  40
trainInputDict[data].shape :  torch.Size([1583, 16, 12, 12])
copy.shape :  torch.Size([1583, 2304])
copyLabel.shape :  torch.Size([1583])
Class 0 has 596 instances after oversampling
Class 1 has 596 instances after oversampling
Class 2 has 596 instances after oversampling
Class 3 has 596 instances after oversampling
Class 4 has 596 instances after oversampling
Class 5 has 596 instances after oversampling
Class 6 has 596 instances after oversampling
Class 7 has 596 instances after oversampling
Class 8 has 596 instances after oversampling
Class 9 has 596 instances after oversampling
0 Train Loss: 232.127 | Train Acc: 11.728
1 Train Loss: 207.496 | Train Acc: 26.074
2 Train Loss: 181.900 | Train Acc: 37.500
3 Train Loss: 144.182 | Train Acc: 54.547
4 Train Loss: 104.675 | Train Acc: 67.466
5 Train Loss: 81.417 | Train Acc: 75.990
6 Train Loss: 63.180 | Train Acc: 81.292
7 Train Loss: 46.521 | Train Acc: 87.114
8 Train Loss: 35.416 | Train Acc: 91.074
9 Train Loss: 28.154 | Train Acc: 92.601
10 Train Loss: 22.877 | Train Acc: 94.111
11 Train Loss: 17.050 | Train Acc: 95.906
12 Train Loss: 13.667 | Train Acc: 96.913
13 Train Loss: 10.859 | Train Acc: 97.752
14 Train Loss: 9.017 | Train Acc: 98.171
15 Train Loss: 7.946 | Train Acc: 98.490
16 Train Loss: 5.526 | Train Acc: 99.228
17 Train Loss: 5.345 | Train Acc: 99.010
18 Train Loss: 4.140 | Train Acc: 99.513
19 Train Loss: 2.716 | Train Acc: 99.916
20 Train Loss: 2.012 | Train Acc: 99.966
21 Train Loss: 1.815 | Train Acc: 99.983
22 Train Loss: 1.658 | Train Acc: 99.983
23 Train Loss: 1.637 | Train Acc: 99.983
24 Train Loss: 1.457 | Train Acc: 99.983
25 Train Loss: 1.401 | Train Acc: 99.983
26 Train Loss: 1.310 | Train Acc: 99.983
27 Train Loss: 1.221 | Train Acc: 99.983
28 Train Loss: 1.186 | Train Acc: 99.983
29 Train Loss: 1.075 | Train Acc: 100.000
30 Train Loss: 1.017 | Train Acc: 99.983
31 Train Loss: 0.940 | Train Acc: 100.000
32 Train Loss: 0.889 | Train Acc: 100.000
33 Train Loss: 0.831 | Train Acc: 100.000
34 Train Loss: 0.780 | Train Acc: 100.000
35 Train Loss: 0.741 | Train Acc: 100.000
36 Train Loss: 0.729 | Train Acc: 100.000
37 Train Loss: 0.649 | Train Acc: 100.000
38 Train Loss: 0.612 | Train Acc: 100.000
39 Train Loss: 0.559 | Train Acc: 100.000
40 Train Loss: 0.516 | Train Acc: 100.000
41 Train Loss: 0.500 | Train Acc: 100.000
42 Train Loss: 0.487 | Train Acc: 100.000
43 Train Loss: 0.477 | Train Acc: 100.000
44 Train Loss: 0.464 | Train Acc: 100.000
45 Train Loss: 0.450 | Train Acc: 100.000
46 Train Loss: 0.444 | Train Acc: 100.000
47 Train Loss: 0.423 | Train Acc: 100.000
48 Train Loss: 0.420 | Train Acc: 100.000
49 Train Loss: 0.404 | Train Acc: 100.000
50 Train Loss: 0.393 | Train Acc: 100.000
51 Train Loss: 0.387 | Train Acc: 100.000
52 Train Loss: 0.374 | Train Acc: 100.000
53 Train Loss: 0.360 | Train Acc: 100.000
54 Train Loss: 0.347 | Train Acc: 100.000
55 Train Loss: 0.339 | Train Acc: 100.000
56 Train Loss: 0.325 | Train Acc: 100.000
57 Train Loss: 0.314 | Train Acc: 100.000
58 Train Loss: 0.303 | Train Acc: 100.000
59 Train Loss: 0.298 | Train Acc: 100.000
60 Train Loss: 0.274 | Train Acc: 100.000
61 Train Loss: 0.269 | Train Acc: 100.000
62 Train Loss: 0.267 | Train Acc: 100.000
63 Train Loss: 0.262 | Train Acc: 100.000
64 Train Loss: 0.258 | Train Acc: 100.000
65 Train Loss: 0.254 | Train Acc: 100.000
66 Train Loss: 0.250 | Train Acc: 100.000
67 Train Loss: 0.246 | Train Acc: 100.000
68 Train Loss: 0.240 | Train Acc: 100.000
69 Train Loss: 0.236 | Train Acc: 100.000
70 Train Loss: 0.232 | Train Acc: 100.000
71 Train Loss: 0.226 | Train Acc: 100.000
72 Train Loss: 0.223 | Train Acc: 100.000
73 Train Loss: 0.218 | Train Acc: 100.000
74 Train Loss: 0.216 | Train Acc: 100.000
75 Train Loss: 0.210 | Train Acc: 100.000
76 Train Loss: 0.203 | Train Acc: 100.000
77 Train Loss: 0.200 | Train Acc: 100.000
78 Train Loss: 0.195 | Train Acc: 100.000
79 Train Loss: 0.191 | Train Acc: 100.000
80 Train Loss: 0.184 | Train Acc: 100.000
81 Train Loss: 0.181 | Train Acc: 100.000
82 Train Loss: 0.180 | Train Acc: 100.000
83 Train Loss: 0.178 | Train Acc: 100.000
84 Train Loss: 0.176 | Train Acc: 100.000
85 Train Loss: 0.174 | Train Acc: 100.000
86 Train Loss: 0.173 | Train Acc: 100.000
87 Train Loss: 0.171 | Train Acc: 100.000
88 Train Loss: 0.168 | Train Acc: 100.000
89 Train Loss: 0.167 | Train Acc: 100.000
90 Train Loss: 0.164 | Train Acc: 100.000
91 Train Loss: 0.163 | Train Acc: 100.000
92 Train Loss: 0.161 | Train Acc: 100.000
93 Train Loss: 0.159 | Train Acc: 100.000
94 Train Loss: 0.156 | Train Acc: 100.000
95 Train Loss: 0.154 | Train Acc: 100.000
96 Train Loss: 0.152 | Train Acc: 100.000
97 Train Loss: 0.150 | Train Acc: 100.000
98 Train Loss: 0.147 | Train Acc: 100.000
99 Train Loss: 0.146 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([5960, 1024])
printing expected split from k means
{0: 1, 8: 1, 7: 1, 2: 0, 1: 1, 4: 1, 9: 1, 3: 1, 5: 1, 6: 1}
Printing final_dict items...
{0: 1, 8: 1, 7: 1, 2: 0, 1: 1, 4: 1, 9: 1, 3: 1, 5: 1, 6: 1}
Image Statistics before MLP : L R :  1529 4431
expectedMlpLabels.shape :  torch.Size([5960])
0 Loss: 23.156 | Acc: 89.672
1 Loss: 15.547 | Acc: 92.621
2 Loss: 14.633 | Acc: 93.310
3 Loss: 12.562 | Acc: 94.483
4 Loss: 12.842 | Acc: 94.276
5 Loss: 9.848 | Acc: 94.966
6 Loss: 8.362 | Acc: 96.224
7 Loss: 9.216 | Acc: 95.845
8 Loss: 8.078 | Acc: 96.207
9 Loss: 6.683 | Acc: 96.879
10 Loss: 5.769 | Acc: 97.241
11 Loss: 5.254 | Acc: 97.672
12 Loss: 4.160 | Acc: 98.224
13 Loss: 3.938 | Acc: 98.069
14 Loss: 4.062 | Acc: 98.034
15 Loss: 3.732 | Acc: 98.328
16 Loss: 3.539 | Acc: 98.328
17 Loss: 3.989 | Acc: 98.259
18 Loss: 3.244 | Acc: 98.690
19 Loss: 3.186 | Acc: 98.569
20 Loss: 2.454 | Acc: 98.931
21 Loss: 1.967 | Acc: 99.103
22 Loss: 2.261 | Acc: 98.931
23 Loss: 2.279 | Acc: 98.983
24 Loss: 2.126 | Acc: 99.069
25 Loss: 2.317 | Acc: 99.138
26 Loss: 1.759 | Acc: 99.241
27 Loss: 1.876 | Acc: 99.345
28 Loss: 1.605 | Acc: 99.362
29 Loss: 1.826 | Acc: 99.293
30 Loss: 1.580 | Acc: 99.310
31 Loss: 1.407 | Acc: 99.362
32 Loss: 1.525 | Acc: 99.328
33 Loss: 1.359 | Acc: 99.414
34 Loss: 1.573 | Acc: 99.379
35 Loss: 1.097 | Acc: 99.552
36 Loss: 1.267 | Acc: 99.500
37 Loss: 1.236 | Acc: 99.500
38 Loss: 1.211 | Acc: 99.448
39 Loss: 1.157 | Acc: 99.569
40 Loss: 1.001 | Acc: 99.534
41 Loss: 1.064 | Acc: 99.603
42 Loss: 1.235 | Acc: 99.414
43 Loss: 1.097 | Acc: 99.448
44 Loss: 1.219 | Acc: 99.690
45 Loss: 1.301 | Acc: 99.397
46 Loss: 1.126 | Acc: 99.552
47 Loss: 1.211 | Acc: 99.500
48 Loss: 1.064 | Acc: 99.586
49 Loss: 0.984 | Acc: 99.672
50 Loss: 1.122 | Acc: 99.552
51 Loss: 1.027 | Acc: 99.534
52 Loss: 1.111 | Acc: 99.638
53 Loss: 1.038 | Acc: 99.603
54 Loss: 1.017 | Acc: 99.500
55 Loss: 0.958 | Acc: 99.638
56 Loss: 0.978 | Acc: 99.621
57 Loss: 1.111 | Acc: 99.517
58 Loss: 0.914 | Acc: 99.621
59 Loss: 0.838 | Acc: 99.638
MLP trained successfully...
# of Left images:  435.0
# of Right images:  1148.0
giniRightRatio:  0.7499757190205054
giniLeftRatio:  0.8624019024970275
impurityDrop:  0.7925762327942747
giniGain:  0.009494409600500076
lclasses:  [68, 64, 43, 17, 13, 19, 7, 46, 80, 78]
rclasses:  [73, 142, 22, 54, 47, 45, 30, 151, 66, 518]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([435, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([435])
rTrainDict[data].shape:  torch.Size([1148, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([1148])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  80 , imgTensorShape :  torch.Size([435, 16, 8, 8])
nodeId: 80 ,  parentId: 40 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 435
nodeId:  81 , imgTensorShape :  torch.Size([1148, 16, 8, 8])
nodeId: 81 ,  parentId: 40 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1148
Running nodeId:  41
trainInputDict[data].shape :  torch.Size([1430, 16, 12, 12])
copy.shape :  torch.Size([1430, 2304])
copyLabel.shape :  torch.Size([1430])
Class 0 has 332 instances after oversampling
Class 1 has 332 instances after oversampling
Class 2 has 332 instances after oversampling
Class 3 has 332 instances after oversampling
Class 4 has 332 instances after oversampling
Class 5 has 332 instances after oversampling
Class 6 has 332 instances after oversampling
Class 7 has 332 instances after oversampling
Class 8 has 332 instances after oversampling
Class 9 has 332 instances after oversampling
0 Train Loss: 223.525 | Train Acc: 16.879
1 Train Loss: 178.618 | Train Acc: 40.636
2 Train Loss: 134.258 | Train Acc: 57.455
3 Train Loss: 100.008 | Train Acc: 69.424
4 Train Loss: 79.334 | Train Acc: 75.848
5 Train Loss: 70.133 | Train Acc: 78.455
6 Train Loss: 53.495 | Train Acc: 85.121
7 Train Loss: 42.733 | Train Acc: 88.485
8 Train Loss: 36.510 | Train Acc: 90.061
9 Train Loss: 26.123 | Train Acc: 93.182
10 Train Loss: 23.258 | Train Acc: 94.091
11 Train Loss: 18.297 | Train Acc: 95.606
12 Train Loss: 14.281 | Train Acc: 97.182
13 Train Loss: 11.850 | Train Acc: 97.788
14 Train Loss: 9.204 | Train Acc: 98.606
15 Train Loss: 6.582 | Train Acc: 99.394
16 Train Loss: 5.341 | Train Acc: 99.606
17 Train Loss: 4.806 | Train Acc: 99.545
18 Train Loss: 3.735 | Train Acc: 99.727
19 Train Loss: 3.302 | Train Acc: 99.818
20 Train Loss: 2.048 | Train Acc: 99.939
21 Train Loss: 1.811 | Train Acc: 100.000
22 Train Loss: 1.667 | Train Acc: 100.000
23 Train Loss: 1.536 | Train Acc: 100.000
24 Train Loss: 1.416 | Train Acc: 100.000
25 Train Loss: 1.352 | Train Acc: 100.000
26 Train Loss: 1.268 | Train Acc: 100.000
27 Train Loss: 1.199 | Train Acc: 100.000
28 Train Loss: 1.096 | Train Acc: 100.000
29 Train Loss: 1.041 | Train Acc: 100.000
30 Train Loss: 0.979 | Train Acc: 100.000
31 Train Loss: 0.919 | Train Acc: 100.000
32 Train Loss: 0.872 | Train Acc: 100.000
33 Train Loss: 0.803 | Train Acc: 100.000
34 Train Loss: 0.770 | Train Acc: 100.000
35 Train Loss: 0.719 | Train Acc: 100.000
36 Train Loss: 0.672 | Train Acc: 100.000
37 Train Loss: 0.623 | Train Acc: 100.000
38 Train Loss: 0.599 | Train Acc: 100.000
39 Train Loss: 0.569 | Train Acc: 100.000
40 Train Loss: 0.502 | Train Acc: 100.000
41 Train Loss: 0.492 | Train Acc: 100.000
42 Train Loss: 0.480 | Train Acc: 100.000
43 Train Loss: 0.466 | Train Acc: 100.000
44 Train Loss: 0.457 | Train Acc: 100.000
45 Train Loss: 0.443 | Train Acc: 100.000
46 Train Loss: 0.434 | Train Acc: 100.000
47 Train Loss: 0.424 | Train Acc: 100.000
48 Train Loss: 0.409 | Train Acc: 100.000
49 Train Loss: 0.399 | Train Acc: 100.000
50 Train Loss: 0.388 | Train Acc: 100.000
51 Train Loss: 0.376 | Train Acc: 100.000
52 Train Loss: 0.364 | Train Acc: 100.000
53 Train Loss: 0.355 | Train Acc: 100.000
54 Train Loss: 0.342 | Train Acc: 100.000
55 Train Loss: 0.335 | Train Acc: 100.000
56 Train Loss: 0.320 | Train Acc: 100.000
57 Train Loss: 0.310 | Train Acc: 100.000
58 Train Loss: 0.299 | Train Acc: 100.000
59 Train Loss: 0.289 | Train Acc: 100.000
60 Train Loss: 0.274 | Train Acc: 100.000
61 Train Loss: 0.268 | Train Acc: 100.000
62 Train Loss: 0.263 | Train Acc: 100.000
63 Train Loss: 0.261 | Train Acc: 100.000
64 Train Loss: 0.256 | Train Acc: 100.000
65 Train Loss: 0.254 | Train Acc: 100.000
66 Train Loss: 0.249 | Train Acc: 100.000
67 Train Loss: 0.245 | Train Acc: 100.000
68 Train Loss: 0.240 | Train Acc: 100.000
69 Train Loss: 0.237 | Train Acc: 100.000
70 Train Loss: 0.232 | Train Acc: 100.000
71 Train Loss: 0.227 | Train Acc: 100.000
72 Train Loss: 0.223 | Train Acc: 100.000
73 Train Loss: 0.218 | Train Acc: 100.000
74 Train Loss: 0.216 | Train Acc: 100.000
75 Train Loss: 0.210 | Train Acc: 100.000
76 Train Loss: 0.206 | Train Acc: 100.000
77 Train Loss: 0.200 | Train Acc: 100.000
78 Train Loss: 0.196 | Train Acc: 100.000
79 Train Loss: 0.192 | Train Acc: 100.000
80 Train Loss: 0.184 | Train Acc: 100.000
81 Train Loss: 0.182 | Train Acc: 100.000
82 Train Loss: 0.180 | Train Acc: 100.000
83 Train Loss: 0.178 | Train Acc: 100.000
84 Train Loss: 0.176 | Train Acc: 100.000
85 Train Loss: 0.174 | Train Acc: 100.000
86 Train Loss: 0.173 | Train Acc: 100.000
87 Train Loss: 0.170 | Train Acc: 100.000
88 Train Loss: 0.169 | Train Acc: 100.000
89 Train Loss: 0.167 | Train Acc: 100.000
90 Train Loss: 0.164 | Train Acc: 100.000
91 Train Loss: 0.162 | Train Acc: 100.000
92 Train Loss: 0.161 | Train Acc: 100.000
93 Train Loss: 0.158 | Train Acc: 100.000
94 Train Loss: 0.156 | Train Acc: 100.000
95 Train Loss: 0.154 | Train Acc: 100.000
96 Train Loss: 0.152 | Train Acc: 100.000
97 Train Loss: 0.150 | Train Acc: 100.000
98 Train Loss: 0.148 | Train Acc: 100.000
99 Train Loss: 0.145 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([3320, 1024])
printing expected split from k means
{2: 1, 3: 1, 9: 1, 5: 0, 7: 0, 0: 1, 4: 1, 6: 1, 8: 1, 1: 1}
Printing final_dict items...
{2: 1, 3: 1, 9: 1, 5: 0, 7: 0, 0: 1, 4: 1, 6: 1, 8: 1, 1: 1}
Image Statistics before MLP : L R :  964 2356
expectedMlpLabels.shape :  torch.Size([3320])
0 Loss: 43.521 | Acc: 79.438
1 Loss: 31.377 | Acc: 86.750
2 Loss: 26.899 | Acc: 88.594
3 Loss: 25.370 | Acc: 89.281
4 Loss: 22.215 | Acc: 90.656
5 Loss: 18.888 | Acc: 92.125
6 Loss: 19.176 | Acc: 91.406
7 Loss: 16.033 | Acc: 93.250
8 Loss: 16.558 | Acc: 92.844
9 Loss: 14.380 | Acc: 94.156
10 Loss: 11.875 | Acc: 94.969
11 Loss: 10.495 | Acc: 95.250
12 Loss: 9.833 | Acc: 95.812
13 Loss: 8.684 | Acc: 96.344
14 Loss: 8.418 | Acc: 96.781
15 Loss: 7.735 | Acc: 96.719
16 Loss: 7.774 | Acc: 96.844
17 Loss: 6.948 | Acc: 96.969
18 Loss: 7.685 | Acc: 96.969
19 Loss: 7.338 | Acc: 96.969
20 Loss: 4.394 | Acc: 98.375
21 Loss: 5.036 | Acc: 97.844
22 Loss: 4.191 | Acc: 98.250
23 Loss: 4.284 | Acc: 98.188
24 Loss: 3.847 | Acc: 98.562
25 Loss: 3.804 | Acc: 98.531
26 Loss: 3.419 | Acc: 98.594
27 Loss: 3.972 | Acc: 98.688
28 Loss: 3.633 | Acc: 98.562
29 Loss: 2.940 | Acc: 98.719
30 Loss: 2.529 | Acc: 99.094
31 Loss: 2.576 | Acc: 98.938
32 Loss: 2.558 | Acc: 98.875
33 Loss: 2.968 | Acc: 98.625
34 Loss: 2.611 | Acc: 99.031
35 Loss: 2.645 | Acc: 99.031
36 Loss: 2.284 | Acc: 99.156
37 Loss: 2.747 | Acc: 98.938
38 Loss: 2.539 | Acc: 98.969
39 Loss: 2.188 | Acc: 99.125
40 Loss: 1.731 | Acc: 99.406
41 Loss: 1.999 | Acc: 99.250
42 Loss: 2.149 | Acc: 99.156
43 Loss: 2.053 | Acc: 99.062
44 Loss: 2.035 | Acc: 99.219
45 Loss: 1.660 | Acc: 99.406
46 Loss: 1.810 | Acc: 99.281
47 Loss: 2.563 | Acc: 98.969
48 Loss: 2.128 | Acc: 99.125
49 Loss: 1.941 | Acc: 99.406
50 Loss: 1.936 | Acc: 99.188
51 Loss: 1.666 | Acc: 99.438
52 Loss: 1.877 | Acc: 99.125
53 Loss: 2.028 | Acc: 99.344
54 Loss: 1.920 | Acc: 99.281
55 Loss: 1.702 | Acc: 99.312
56 Loss: 1.752 | Acc: 99.406
57 Loss: 1.696 | Acc: 99.406
58 Loss: 1.625 | Acc: 99.312
59 Loss: 1.704 | Acc: 99.312
MLP trained successfully...
# of Left images:  675.0
# of Right images:  755.0
giniRightRatio:  0.8816665935704574
giniLeftRatio:  0.8029805212620028
impurityDrop:  0.8113181183277993
giniGain:  0.053528084420501276
lclasses:  [74, 2, 51, 104, 36, 106, 13, 237, 8, 44]
rclasses:  [84, 17, 83, 127, 64, 50, 108, 95, 34, 93]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([675, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([675])
rTrainDict[data].shape:  torch.Size([755, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([755])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  82 , imgTensorShape :  torch.Size([675, 16, 8, 8])
nodeId: 82 ,  parentId: 41 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 675
nodeId:  83 , imgTensorShape :  torch.Size([755, 16, 8, 8])
nodeId: 83 ,  parentId: 41 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 755
Running nodeId:  42
trainInputDict[data].shape :  torch.Size([497, 16, 12, 12])
copy.shape :  torch.Size([497, 2304])
copyLabel.shape :  torch.Size([497])
Class 0 has 127 instances after oversampling
Class 1 has 126 instances after oversampling
Class 2 has 127 instances after oversampling
Class 3 has 127 instances after oversampling
Class 4 has 127 instances after oversampling
Class 5 has 127 instances after oversampling
Class 6 has 126 instances after oversampling
Class 7 has 127 instances after oversampling
Class 8 has 126 instances after oversampling
Class 9 has 126 instances after oversampling
0 Train Loss: 164.067 | Train Acc: 45.083
1 Train Loss: 76.961 | Train Acc: 75.583
2 Train Loss: 48.415 | Train Acc: 85.250
3 Train Loss: 28.797 | Train Acc: 91.667
4 Train Loss: 27.348 | Train Acc: 91.917
5 Train Loss: 20.868 | Train Acc: 93.750
6 Train Loss: 11.866 | Train Acc: 96.250
7 Train Loss: 7.666 | Train Acc: 98.417
8 Train Loss: 5.309 | Train Acc: 98.833
9 Train Loss: 3.142 | Train Acc: 99.833
10 Train Loss: 2.091 | Train Acc: 99.917
11 Train Loss: 1.387 | Train Acc: 99.917
12 Train Loss: 0.820 | Train Acc: 100.000
13 Train Loss: 0.689 | Train Acc: 100.000
14 Train Loss: 0.534 | Train Acc: 100.000
15 Train Loss: 0.465 | Train Acc: 100.000
16 Train Loss: 0.378 | Train Acc: 100.000
17 Train Loss: 0.335 | Train Acc: 100.000
18 Train Loss: 0.296 | Train Acc: 100.000
19 Train Loss: 0.262 | Train Acc: 100.000
20 Train Loss: 0.227 | Train Acc: 100.000
21 Train Loss: 0.215 | Train Acc: 100.000
22 Train Loss: 0.208 | Train Acc: 100.000
23 Train Loss: 0.198 | Train Acc: 100.000
24 Train Loss: 0.193 | Train Acc: 100.000
25 Train Loss: 0.184 | Train Acc: 100.000
26 Train Loss: 0.175 | Train Acc: 100.000
27 Train Loss: 0.168 | Train Acc: 100.000
28 Train Loss: 0.162 | Train Acc: 100.000
29 Train Loss: 0.151 | Train Acc: 100.000
30 Train Loss: 0.147 | Train Acc: 100.000
31 Train Loss: 0.140 | Train Acc: 100.000
32 Train Loss: 0.132 | Train Acc: 100.000
33 Train Loss: 0.127 | Train Acc: 100.000
34 Train Loss: 0.121 | Train Acc: 100.000
35 Train Loss: 0.115 | Train Acc: 100.000
36 Train Loss: 0.110 | Train Acc: 100.000
37 Train Loss: 0.105 | Train Acc: 100.000
38 Train Loss: 0.100 | Train Acc: 100.000
39 Train Loss: 0.093 | Train Acc: 100.000
40 Train Loss: 0.089 | Train Acc: 100.000
41 Train Loss: 0.086 | Train Acc: 100.000
42 Train Loss: 0.084 | Train Acc: 100.000
43 Train Loss: 0.082 | Train Acc: 100.000
44 Train Loss: 0.081 | Train Acc: 100.000
45 Train Loss: 0.079 | Train Acc: 100.000
46 Train Loss: 0.077 | Train Acc: 100.000
47 Train Loss: 0.075 | Train Acc: 100.000
48 Train Loss: 0.073 | Train Acc: 100.000
49 Train Loss: 0.072 | Train Acc: 100.000
50 Train Loss: 0.069 | Train Acc: 100.000
51 Train Loss: 0.068 | Train Acc: 100.000
52 Train Loss: 0.066 | Train Acc: 100.000
53 Train Loss: 0.064 | Train Acc: 100.000
54 Train Loss: 0.063 | Train Acc: 100.000
55 Train Loss: 0.061 | Train Acc: 100.000
56 Train Loss: 0.059 | Train Acc: 100.000
57 Train Loss: 0.057 | Train Acc: 100.000
58 Train Loss: 0.055 | Train Acc: 100.000
59 Train Loss: 0.054 | Train Acc: 100.000
60 Train Loss: 0.051 | Train Acc: 100.000
61 Train Loss: 0.050 | Train Acc: 100.000
62 Train Loss: 0.050 | Train Acc: 100.000
63 Train Loss: 0.049 | Train Acc: 100.000
64 Train Loss: 0.048 | Train Acc: 100.000
65 Train Loss: 0.047 | Train Acc: 100.000
66 Train Loss: 0.047 | Train Acc: 100.000
67 Train Loss: 0.046 | Train Acc: 100.000
68 Train Loss: 0.045 | Train Acc: 100.000
69 Train Loss: 0.044 | Train Acc: 100.000
70 Train Loss: 0.044 | Train Acc: 100.000
71 Train Loss: 0.043 | Train Acc: 100.000
72 Train Loss: 0.042 | Train Acc: 100.000
73 Train Loss: 0.041 | Train Acc: 100.000
74 Train Loss: 0.040 | Train Acc: 100.000
75 Train Loss: 0.039 | Train Acc: 100.000
76 Train Loss: 0.039 | Train Acc: 100.000
77 Train Loss: 0.038 | Train Acc: 100.000
78 Train Loss: 0.037 | Train Acc: 100.000
79 Train Loss: 0.036 | Train Acc: 100.000
80 Train Loss: 0.034 | Train Acc: 100.000
81 Train Loss: 0.034 | Train Acc: 100.000
82 Train Loss: 0.034 | Train Acc: 100.000
83 Train Loss: 0.033 | Train Acc: 100.000
84 Train Loss: 0.033 | Train Acc: 100.000
85 Train Loss: 0.033 | Train Acc: 100.000
86 Train Loss: 0.032 | Train Acc: 100.000
87 Train Loss: 0.032 | Train Acc: 100.000
88 Train Loss: 0.031 | Train Acc: 100.000
89 Train Loss: 0.031 | Train Acc: 100.000
90 Train Loss: 0.031 | Train Acc: 100.000
91 Train Loss: 0.030 | Train Acc: 100.000
92 Train Loss: 0.030 | Train Acc: 100.000
93 Train Loss: 0.029 | Train Acc: 100.000
94 Train Loss: 0.029 | Train Acc: 100.000
95 Train Loss: 0.028 | Train Acc: 100.000
96 Train Loss: 0.028 | Train Acc: 100.000
97 Train Loss: 0.027 | Train Acc: 100.000
98 Train Loss: 0.027 | Train Acc: 100.000
99 Train Loss: 0.026 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([1266, 1024])
printing expected split from k means
{0: 1, 4: 1, 8: 1, 2: 1, 7: 1, 1: 0, 5: 1, 3: 1, 9: 1, 6: 1}
Printing final_dict items...
{0: 1, 4: 1, 8: 1, 2: 1, 7: 1, 1: 0, 5: 1, 3: 1, 9: 1, 6: 1}
Image Statistics before MLP : L R :  249 1017
expectedMlpLabels.shape :  torch.Size([1266])
0 Loss: 22.010 | Acc: 89.167
1 Loss: 16.921 | Acc: 95.000
2 Loss: 9.819 | Acc: 96.083
3 Loss: 10.620 | Acc: 95.750
4 Loss: 8.804 | Acc: 94.917
5 Loss: 4.957 | Acc: 97.750
6 Loss: 3.936 | Acc: 97.667
7 Loss: 2.969 | Acc: 98.667
8 Loss: 2.433 | Acc: 98.583
9 Loss: 5.142 | Acc: 97.833
10 Loss: 3.182 | Acc: 97.500
11 Loss: 1.719 | Acc: 98.833
12 Loss: 1.841 | Acc: 98.583
13 Loss: 2.141 | Acc: 98.750
14 Loss: 1.680 | Acc: 98.583
15 Loss: 1.538 | Acc: 98.917
16 Loss: 1.140 | Acc: 99.333
17 Loss: 1.301 | Acc: 98.833
18 Loss: 1.046 | Acc: 99.000
19 Loss: 0.768 | Acc: 99.417
20 Loss: 0.901 | Acc: 99.417
21 Loss: 0.407 | Acc: 99.917
22 Loss: 0.565 | Acc: 99.667
23 Loss: 0.440 | Acc: 99.667
24 Loss: 0.426 | Acc: 99.750
25 Loss: 0.323 | Acc: 99.833
26 Loss: 0.775 | Acc: 99.583
27 Loss: 0.281 | Acc: 99.750
28 Loss: 0.227 | Acc: 99.833
29 Loss: 0.181 | Acc: 99.833
30 Loss: 0.781 | Acc: 99.667
31 Loss: 0.333 | Acc: 99.833
32 Loss: 0.263 | Acc: 99.833
33 Loss: 0.241 | Acc: 99.833
34 Loss: 0.130 | Acc: 99.917
35 Loss: 0.101 | Acc: 99.917
36 Loss: 0.113 | Acc: 99.917
37 Loss: 0.114 | Acc: 100.000
38 Loss: 0.171 | Acc: 99.917
39 Loss: 0.218 | Acc: 99.917
40 Loss: 0.183 | Acc: 99.917
41 Loss: 0.090 | Acc: 99.917
42 Loss: 0.081 | Acc: 100.000
43 Loss: 0.229 | Acc: 99.833
44 Loss: 0.069 | Acc: 100.000
45 Loss: 0.147 | Acc: 99.917
46 Loss: 0.084 | Acc: 99.917
47 Loss: 0.122 | Acc: 99.917
48 Loss: 0.086 | Acc: 100.000
49 Loss: 0.192 | Acc: 99.917
50 Loss: 0.038 | Acc: 100.000
51 Loss: 0.163 | Acc: 99.917
52 Loss: 0.117 | Acc: 99.917
53 Loss: 0.087 | Acc: 99.917
54 Loss: 1.184 | Acc: 99.833
55 Loss: 0.551 | Acc: 99.833
56 Loss: 0.197 | Acc: 99.833
57 Loss: 0.031 | Acc: 100.000
58 Loss: 0.076 | Acc: 99.917
59 Loss: 0.134 | Acc: 99.917
MLP trained successfully...
# of Left images:  66.0
# of Right images:  431.0
giniRightRatio:  0.8264813389247473
giniLeftRatio:  0.5977961432506887
impurityDrop:  0.7914622602368404
giniGain:  0.029673811728148758
lclasses:  [39, 2, 14, 1, 4, 2, 0, 1, 3, 0]
rclasses:  [88, 0, 85, 42, 63, 31, 11, 102, 6, 3]
noOfLeftClasses:  8
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([66, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([66])
rTrainDict[data].shape:  torch.Size([431, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([431])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
DATANUM THRESHOLD REACHED IN LEFT 66 100
nodeId:  84 , imgTensorShape :  torch.Size([66, 16, 8, 8])
nodeId: 84 ,  parentId: 42 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 66
nodeId:  85 , imgTensorShape :  torch.Size([431, 16, 8, 8])
nodeId: 85 ,  parentId: 42 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 431
Running nodeId:  43
trainInputDict[data].shape :  torch.Size([473, 16, 12, 12])
copy.shape :  torch.Size([473, 2304])
copyLabel.shape :  torch.Size([473])
Class 0 has 197 instances after oversampling
Class 1 has 197 instances after oversampling
Class 2 has 197 instances after oversampling
Class 3 has 197 instances after oversampling
Class 4 has 197 instances after oversampling
Class 5 has 197 instances after oversampling
Class 6 has 197 instances after oversampling
Class 7 has 197 instances after oversampling
Class 8 has 197 instances after oversampling
Class 9 has 197 instances after oversampling
0 Train Loss: 204.113 | Train Acc: 29.526
1 Train Loss: 123.680 | Train Acc: 62.737
2 Train Loss: 71.159 | Train Acc: 79.053
3 Train Loss: 43.013 | Train Acc: 87.263
4 Train Loss: 26.978 | Train Acc: 92.632
5 Train Loss: 17.353 | Train Acc: 95.421
6 Train Loss: 12.497 | Train Acc: 96.684
7 Train Loss: 8.815 | Train Acc: 98.000
8 Train Loss: 5.697 | Train Acc: 99.053
9 Train Loss: 4.563 | Train Acc: 99.316
10 Train Loss: 2.941 | Train Acc: 99.789
11 Train Loss: 2.617 | Train Acc: 99.526
12 Train Loss: 1.226 | Train Acc: 100.000
13 Train Loss: 0.878 | Train Acc: 100.000
14 Train Loss: 0.708 | Train Acc: 100.000
15 Train Loss: 0.607 | Train Acc: 100.000
16 Train Loss: 0.496 | Train Acc: 100.000
17 Train Loss: 0.414 | Train Acc: 100.000
18 Train Loss: 0.373 | Train Acc: 100.000
19 Train Loss: 0.333 | Train Acc: 100.000
20 Train Loss: 0.270 | Train Acc: 100.000
21 Train Loss: 0.254 | Train Acc: 100.000
22 Train Loss: 0.244 | Train Acc: 100.000
23 Train Loss: 0.231 | Train Acc: 100.000
24 Train Loss: 0.222 | Train Acc: 100.000
25 Train Loss: 0.214 | Train Acc: 100.000
26 Train Loss: 0.200 | Train Acc: 100.000
27 Train Loss: 0.193 | Train Acc: 100.000
28 Train Loss: 0.184 | Train Acc: 100.000
29 Train Loss: 0.175 | Train Acc: 100.000
30 Train Loss: 0.164 | Train Acc: 100.000
31 Train Loss: 0.159 | Train Acc: 100.000
32 Train Loss: 0.150 | Train Acc: 100.000
33 Train Loss: 0.141 | Train Acc: 100.000
34 Train Loss: 0.136 | Train Acc: 100.000
35 Train Loss: 0.126 | Train Acc: 100.000
36 Train Loss: 0.122 | Train Acc: 100.000
37 Train Loss: 0.117 | Train Acc: 100.000
38 Train Loss: 0.109 | Train Acc: 100.000
39 Train Loss: 0.102 | Train Acc: 100.000
40 Train Loss: 0.096 | Train Acc: 100.000
41 Train Loss: 0.094 | Train Acc: 100.000
42 Train Loss: 0.092 | Train Acc: 100.000
43 Train Loss: 0.090 | Train Acc: 100.000
44 Train Loss: 0.087 | Train Acc: 100.000
45 Train Loss: 0.086 | Train Acc: 100.000
46 Train Loss: 0.084 | Train Acc: 100.000
47 Train Loss: 0.081 | Train Acc: 100.000
48 Train Loss: 0.080 | Train Acc: 100.000
49 Train Loss: 0.077 | Train Acc: 100.000
50 Train Loss: 0.075 | Train Acc: 100.000
51 Train Loss: 0.074 | Train Acc: 100.000
52 Train Loss: 0.071 | Train Acc: 100.000
53 Train Loss: 0.070 | Train Acc: 100.000
54 Train Loss: 0.067 | Train Acc: 100.000
55 Train Loss: 0.065 | Train Acc: 100.000
56 Train Loss: 0.062 | Train Acc: 100.000
57 Train Loss: 0.061 | Train Acc: 100.000
58 Train Loss: 0.059 | Train Acc: 100.000
59 Train Loss: 0.057 | Train Acc: 100.000
60 Train Loss: 0.054 | Train Acc: 100.000
61 Train Loss: 0.053 | Train Acc: 100.000
62 Train Loss: 0.052 | Train Acc: 100.000
63 Train Loss: 0.052 | Train Acc: 100.000
64 Train Loss: 0.051 | Train Acc: 100.000
65 Train Loss: 0.050 | Train Acc: 100.000
66 Train Loss: 0.049 | Train Acc: 100.000
67 Train Loss: 0.048 | Train Acc: 100.000
68 Train Loss: 0.048 | Train Acc: 100.000
69 Train Loss: 0.047 | Train Acc: 100.000
70 Train Loss: 0.046 | Train Acc: 100.000
71 Train Loss: 0.045 | Train Acc: 100.000
72 Train Loss: 0.044 | Train Acc: 100.000
73 Train Loss: 0.043 | Train Acc: 100.000
74 Train Loss: 0.042 | Train Acc: 100.000
75 Train Loss: 0.042 | Train Acc: 100.000
76 Train Loss: 0.040 | Train Acc: 100.000
77 Train Loss: 0.040 | Train Acc: 100.000
78 Train Loss: 0.039 | Train Acc: 100.000
79 Train Loss: 0.038 | Train Acc: 100.000
80 Train Loss: 0.036 | Train Acc: 100.000
81 Train Loss: 0.036 | Train Acc: 100.000
82 Train Loss: 0.035 | Train Acc: 100.000
83 Train Loss: 0.035 | Train Acc: 100.000
84 Train Loss: 0.035 | Train Acc: 100.000
85 Train Loss: 0.034 | Train Acc: 100.000
86 Train Loss: 0.034 | Train Acc: 100.000
87 Train Loss: 0.033 | Train Acc: 100.000
88 Train Loss: 0.033 | Train Acc: 100.000
89 Train Loss: 0.033 | Train Acc: 100.000
90 Train Loss: 0.032 | Train Acc: 100.000
91 Train Loss: 0.032 | Train Acc: 100.000
92 Train Loss: 0.031 | Train Acc: 100.000
93 Train Loss: 0.031 | Train Acc: 100.000
94 Train Loss: 0.030 | Train Acc: 100.000
95 Train Loss: 0.030 | Train Acc: 100.000
96 Train Loss: 0.029 | Train Acc: 100.000
97 Train Loss: 0.029 | Train Acc: 100.000
98 Train Loss: 0.028 | Train Acc: 100.000
99 Train Loss: 0.028 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([1970, 1024])
printing expected split from k means
{5: 0, 2: 0, 3: 0, 6: 0, 0: 1, 9: 0, 4: 0, 8: 1, 7: 0, 1: 1}
Printing final_dict items...
{5: 0, 2: 0, 3: 0, 6: 0, 0: 1, 9: 0, 4: 0, 8: 1, 7: 0, 1: 1}
Image Statistics before MLP : L R :  1036 934
expectedMlpLabels.shape :  torch.Size([1970])
0 Loss: 33.569 | Acc: 92.111
1 Loss: 18.486 | Acc: 96.222
2 Loss: 18.192 | Acc: 96.556
3 Loss: 11.588 | Acc: 97.889
4 Loss: 10.344 | Acc: 97.833
5 Loss: 9.386 | Acc: 98.111
6 Loss: 10.569 | Acc: 97.944
7 Loss: 6.526 | Acc: 98.833
8 Loss: 6.807 | Acc: 98.500
9 Loss: 4.636 | Acc: 99.000
10 Loss: 3.836 | Acc: 99.222
11 Loss: 3.144 | Acc: 99.167
12 Loss: 2.749 | Acc: 99.556
13 Loss: 2.689 | Acc: 99.556
14 Loss: 3.237 | Acc: 99.500
15 Loss: 2.498 | Acc: 99.556
16 Loss: 0.795 | Acc: 99.944
17 Loss: 2.897 | Acc: 99.389
18 Loss: 2.501 | Acc: 99.556
19 Loss: 2.250 | Acc: 99.500
20 Loss: 2.700 | Acc: 99.500
21 Loss: 1.218 | Acc: 99.778
22 Loss: 1.708 | Acc: 99.611
23 Loss: 0.552 | Acc: 99.944
24 Loss: 0.368 | Acc: 100.000
25 Loss: 0.656 | Acc: 99.889
26 Loss: 0.903 | Acc: 99.889
27 Loss: 0.772 | Acc: 99.722
28 Loss: 0.581 | Acc: 99.833
29 Loss: 1.474 | Acc: 99.722
30 Loss: 0.767 | Acc: 99.778
31 Loss: 0.181 | Acc: 100.000
32 Loss: 0.193 | Acc: 100.000
33 Loss: 0.856 | Acc: 99.889
34 Loss: 0.378 | Acc: 99.944
35 Loss: 0.631 | Acc: 99.833
36 Loss: 0.218 | Acc: 100.000
37 Loss: 0.536 | Acc: 99.944
38 Loss: 0.278 | Acc: 99.889
39 Loss: 0.935 | Acc: 99.833
40 Loss: 0.156 | Acc: 100.000
41 Loss: 0.303 | Acc: 99.944
42 Loss: 0.260 | Acc: 99.944
43 Loss: 0.237 | Acc: 99.944
44 Loss: 0.427 | Acc: 99.944
45 Loss: 0.375 | Acc: 99.889
46 Loss: 0.276 | Acc: 99.944
47 Loss: 0.528 | Acc: 99.889
48 Loss: 0.171 | Acc: 100.000
49 Loss: 0.073 | Acc: 100.000
50 Loss: 0.261 | Acc: 99.944
51 Loss: 0.060 | Acc: 100.000
52 Loss: 0.119 | Acc: 100.000
53 Loss: 0.125 | Acc: 100.000
54 Loss: 0.285 | Acc: 99.944
55 Loss: 0.125 | Acc: 100.000
56 Loss: 0.275 | Acc: 99.944
57 Loss: 0.142 | Acc: 100.000
58 Loss: 0.048 | Acc: 100.000
59 Loss: 0.326 | Acc: 99.944
MLP trained successfully...
# of Left images:  225.0
# of Right images:  248.0
giniRightRatio:  0.742911030176899
giniLeftRatio:  0.7959703703703703
impurityDrop:  0.7910495444653306
giniGain:  -0.013501707573376542
lclasses:  [84, 7, 39, 26, 11, 9, 6, 25, 8, 10]
rclasses:  [113, 33, 26, 5, 10, 5, 4, 20, 26, 6]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([225, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([225])
rTrainDict[data].shape:  torch.Size([248, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([248])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  86 , imgTensorShape :  torch.Size([225, 16, 8, 8])
nodeId: 86 ,  parentId: 43 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 225
nodeId:  87 , imgTensorShape :  torch.Size([248, 16, 8, 8])
nodeId: 87 ,  parentId: 43 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 248
Running nodeId:  44
trainInputDict[data].shape :  torch.Size([1296, 16, 12, 12])
copy.shape :  torch.Size([1296, 2304])
copyLabel.shape :  torch.Size([1296])
Class 0 has 230 instances after oversampling
Class 1 has 230 instances after oversampling
Class 2 has 230 instances after oversampling
Class 3 has 230 instances after oversampling
Class 4 has 230 instances after oversampling
Class 5 has 230 instances after oversampling
Class 6 has 230 instances after oversampling
Class 7 has 230 instances after oversampling
Class 8 has 230 instances after oversampling
Class 9 has 230 instances after oversampling
0 Train Loss: 223.343 | Train Acc: 17.435
1 Train Loss: 187.124 | Train Acc: 34.522
2 Train Loss: 153.634 | Train Acc: 49.478
3 Train Loss: 122.448 | Train Acc: 61.652
4 Train Loss: 98.757 | Train Acc: 69.478
5 Train Loss: 75.374 | Train Acc: 76.870
6 Train Loss: 59.592 | Train Acc: 82.130
7 Train Loss: 44.115 | Train Acc: 87.261
8 Train Loss: 34.348 | Train Acc: 90.609
9 Train Loss: 25.872 | Train Acc: 93.217
10 Train Loss: 20.015 | Train Acc: 95.435
11 Train Loss: 16.635 | Train Acc: 95.913
12 Train Loss: 11.920 | Train Acc: 97.652
13 Train Loss: 8.264 | Train Acc: 98.826
14 Train Loss: 6.444 | Train Acc: 99.522
15 Train Loss: 4.944 | Train Acc: 99.696
16 Train Loss: 3.747 | Train Acc: 99.913
17 Train Loss: 2.892 | Train Acc: 99.826
18 Train Loss: 2.163 | Train Acc: 100.000
19 Train Loss: 1.810 | Train Acc: 100.000
20 Train Loss: 1.425 | Train Acc: 100.000
21 Train Loss: 1.317 | Train Acc: 100.000
22 Train Loss: 1.243 | Train Acc: 100.000
23 Train Loss: 1.187 | Train Acc: 100.000
24 Train Loss: 1.135 | Train Acc: 100.000
25 Train Loss: 1.071 | Train Acc: 100.000
26 Train Loss: 1.017 | Train Acc: 100.000
27 Train Loss: 0.966 | Train Acc: 100.000
28 Train Loss: 0.914 | Train Acc: 100.000
29 Train Loss: 0.873 | Train Acc: 100.000
30 Train Loss: 0.833 | Train Acc: 100.000
31 Train Loss: 0.779 | Train Acc: 100.000
32 Train Loss: 0.738 | Train Acc: 100.000
33 Train Loss: 0.701 | Train Acc: 100.000
34 Train Loss: 0.667 | Train Acc: 100.000
35 Train Loss: 0.626 | Train Acc: 100.000
36 Train Loss: 0.595 | Train Acc: 100.000
37 Train Loss: 0.558 | Train Acc: 100.000
38 Train Loss: 0.534 | Train Acc: 100.000
39 Train Loss: 0.505 | Train Acc: 100.000
40 Train Loss: 0.459 | Train Acc: 100.000
41 Train Loss: 0.447 | Train Acc: 100.000
42 Train Loss: 0.436 | Train Acc: 100.000
43 Train Loss: 0.427 | Train Acc: 100.000
44 Train Loss: 0.418 | Train Acc: 100.000
45 Train Loss: 0.409 | Train Acc: 100.000
46 Train Loss: 0.396 | Train Acc: 100.000
47 Train Loss: 0.389 | Train Acc: 100.000
48 Train Loss: 0.378 | Train Acc: 100.000
49 Train Loss: 0.367 | Train Acc: 100.000
50 Train Loss: 0.359 | Train Acc: 100.000
51 Train Loss: 0.347 | Train Acc: 100.000
52 Train Loss: 0.338 | Train Acc: 100.000
53 Train Loss: 0.327 | Train Acc: 100.000
54 Train Loss: 0.318 | Train Acc: 100.000
55 Train Loss: 0.307 | Train Acc: 100.000
56 Train Loss: 0.301 | Train Acc: 100.000
57 Train Loss: 0.289 | Train Acc: 100.000
58 Train Loss: 0.278 | Train Acc: 100.000
59 Train Loss: 0.268 | Train Acc: 100.000
60 Train Loss: 0.254 | Train Acc: 100.000
61 Train Loss: 0.251 | Train Acc: 100.000
62 Train Loss: 0.246 | Train Acc: 100.000
63 Train Loss: 0.244 | Train Acc: 100.000
64 Train Loss: 0.239 | Train Acc: 100.000
65 Train Loss: 0.236 | Train Acc: 100.000
66 Train Loss: 0.232 | Train Acc: 100.000
67 Train Loss: 0.229 | Train Acc: 100.000
68 Train Loss: 0.224 | Train Acc: 100.000
69 Train Loss: 0.221 | Train Acc: 100.000
70 Train Loss: 0.216 | Train Acc: 100.000
71 Train Loss: 0.212 | Train Acc: 100.000
72 Train Loss: 0.209 | Train Acc: 100.000
73 Train Loss: 0.205 | Train Acc: 100.000
74 Train Loss: 0.201 | Train Acc: 100.000
75 Train Loss: 0.196 | Train Acc: 100.000
76 Train Loss: 0.192 | Train Acc: 100.000
77 Train Loss: 0.187 | Train Acc: 100.000
78 Train Loss: 0.183 | Train Acc: 100.000
79 Train Loss: 0.179 | Train Acc: 100.000
80 Train Loss: 0.172 | Train Acc: 100.000
81 Train Loss: 0.170 | Train Acc: 100.000
82 Train Loss: 0.168 | Train Acc: 100.000
83 Train Loss: 0.167 | Train Acc: 100.000
84 Train Loss: 0.165 | Train Acc: 100.000
85 Train Loss: 0.163 | Train Acc: 100.000
86 Train Loss: 0.161 | Train Acc: 100.000
87 Train Loss: 0.160 | Train Acc: 100.000
88 Train Loss: 0.157 | Train Acc: 100.000
89 Train Loss: 0.156 | Train Acc: 100.000
90 Train Loss: 0.154 | Train Acc: 100.000
91 Train Loss: 0.152 | Train Acc: 100.000
92 Train Loss: 0.150 | Train Acc: 100.000
93 Train Loss: 0.147 | Train Acc: 100.000
94 Train Loss: 0.146 | Train Acc: 100.000
95 Train Loss: 0.144 | Train Acc: 100.000
96 Train Loss: 0.142 | Train Acc: 100.000
97 Train Loss: 0.139 | Train Acc: 100.000
98 Train Loss: 0.137 | Train Acc: 100.000
99 Train Loss: 0.135 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([2300, 1024])
printing expected split from k means
{3: 0, 9: 0, 7: 0, 5: 0, 8: 0, 0: 0, 6: 1, 4: 0, 2: 0, 1: 0}
Printing final_dict items...
{3: 0, 9: 0, 7: 0, 5: 0, 8: 0, 0: 0, 6: 1, 4: 0, 2: 0, 1: 0}
Image Statistics before MLP : L R :  1862 438
expectedMlpLabels.shape :  torch.Size([2300])
0 Loss: 14.103 | Acc: 93.227
1 Loss: 8.346 | Acc: 96.091
2 Loss: 7.139 | Acc: 96.227
3 Loss: 6.014 | Acc: 96.591
4 Loss: 4.079 | Acc: 97.818
5 Loss: 3.647 | Acc: 98.227
6 Loss: 4.032 | Acc: 97.864
7 Loss: 4.485 | Acc: 97.682
8 Loss: 4.165 | Acc: 98.182
9 Loss: 4.387 | Acc: 98.091
10 Loss: 2.067 | Acc: 98.773
11 Loss: 2.614 | Acc: 98.955
12 Loss: 1.288 | Acc: 99.091
13 Loss: 0.679 | Acc: 99.591
14 Loss: 0.955 | Acc: 99.409
15 Loss: 1.465 | Acc: 99.000
16 Loss: 1.419 | Acc: 99.318
17 Loss: 0.619 | Acc: 99.545
18 Loss: 1.263 | Acc: 99.409
19 Loss: 1.055 | Acc: 99.318
20 Loss: 1.310 | Acc: 99.182
21 Loss: 1.067 | Acc: 99.364
22 Loss: 0.944 | Acc: 99.500
23 Loss: 0.491 | Acc: 99.545
24 Loss: 0.338 | Acc: 99.818
25 Loss: 0.378 | Acc: 99.773
26 Loss: 0.357 | Acc: 99.727
27 Loss: 0.389 | Acc: 99.682
28 Loss: 0.537 | Acc: 99.682
29 Loss: 0.542 | Acc: 99.636
30 Loss: 0.376 | Acc: 99.682
31 Loss: 0.190 | Acc: 99.864
32 Loss: 0.166 | Acc: 99.864
33 Loss: 0.328 | Acc: 99.773
34 Loss: 0.263 | Acc: 99.773
35 Loss: 0.198 | Acc: 99.909
36 Loss: 0.309 | Acc: 99.818
37 Loss: 0.130 | Acc: 99.955
38 Loss: 0.130 | Acc: 99.864
39 Loss: 0.235 | Acc: 99.864
40 Loss: 0.303 | Acc: 99.818
41 Loss: 0.149 | Acc: 99.909
42 Loss: 0.257 | Acc: 99.955
43 Loss: 0.072 | Acc: 99.955
44 Loss: 0.269 | Acc: 99.818
45 Loss: 0.138 | Acc: 99.909
46 Loss: 0.108 | Acc: 99.955
47 Loss: 0.132 | Acc: 99.909
48 Loss: 0.138 | Acc: 99.864
49 Loss: 0.147 | Acc: 99.909
50 Loss: 0.167 | Acc: 99.909
51 Loss: 0.070 | Acc: 100.000
52 Loss: 0.134 | Acc: 99.909
53 Loss: 0.140 | Acc: 99.909
54 Loss: 0.268 | Acc: 99.818
55 Loss: 0.321 | Acc: 99.909
56 Loss: 0.057 | Acc: 100.000
57 Loss: 0.070 | Acc: 99.955
58 Loss: 0.060 | Acc: 99.955
59 Loss: 0.127 | Acc: 99.909
MLP trained successfully...
# of Left images:  1062.0
# of Right images:  234.0
giniRightRatio:  0.8715026663744614
giniLeftRatio:  0.8682832022868411
impurityDrop:  0.8568912524383383
giniGain:  0.020676001029120927
lclasses:  [35, 65, 82, 191, 44, 190, 39, 132, 106, 178]
rclasses:  [8, 15, 39, 39, 16, 14, 46, 13, 22, 22]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1062, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([1062])
rTrainDict[data].shape:  torch.Size([234, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([234])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  88 , imgTensorShape :  torch.Size([1062, 16, 8, 8])
nodeId: 88 ,  parentId: 44 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1062
nodeId:  89 , imgTensorShape :  torch.Size([234, 16, 8, 8])
nodeId: 89 ,  parentId: 44 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 234
Running nodeId:  45
trainInputDict[data].shape :  torch.Size([1059, 16, 12, 12])
copy.shape :  torch.Size([1059, 2304])
copyLabel.shape :  torch.Size([1059])
Class 0 has 178 instances after oversampling
Class 1 has 178 instances after oversampling
Class 2 has 178 instances after oversampling
Class 3 has 178 instances after oversampling
Class 4 has 178 instances after oversampling
Class 5 has 178 instances after oversampling
Class 6 has 178 instances after oversampling
Class 7 has 178 instances after oversampling
Class 8 has 178 instances after oversampling
Class 9 has 178 instances after oversampling
0 Train Loss: 222.909 | Train Acc: 17.882
1 Train Loss: 186.775 | Train Acc: 38.235
2 Train Loss: 144.324 | Train Acc: 53.941
3 Train Loss: 111.960 | Train Acc: 67.471
4 Train Loss: 78.184 | Train Acc: 76.941
5 Train Loss: 58.382 | Train Acc: 82.941
6 Train Loss: 40.865 | Train Acc: 89.176
7 Train Loss: 29.202 | Train Acc: 93.412
8 Train Loss: 20.200 | Train Acc: 96.294
9 Train Loss: 14.401 | Train Acc: 97.706
10 Train Loss: 9.325 | Train Acc: 99.235
11 Train Loss: 7.085 | Train Acc: 99.647
12 Train Loss: 4.864 | Train Acc: 99.941
13 Train Loss: 3.533 | Train Acc: 100.000
14 Train Loss: 2.706 | Train Acc: 100.000
15 Train Loss: 2.073 | Train Acc: 100.000
16 Train Loss: 1.711 | Train Acc: 100.000
17 Train Loss: 1.443 | Train Acc: 100.000
18 Train Loss: 1.242 | Train Acc: 100.000
19 Train Loss: 1.100 | Train Acc: 100.000
20 Train Loss: 0.905 | Train Acc: 100.000
21 Train Loss: 0.862 | Train Acc: 100.000
22 Train Loss: 0.820 | Train Acc: 100.000
23 Train Loss: 0.785 | Train Acc: 100.000
24 Train Loss: 0.747 | Train Acc: 100.000
25 Train Loss: 0.718 | Train Acc: 100.000
26 Train Loss: 0.683 | Train Acc: 100.000
27 Train Loss: 0.651 | Train Acc: 100.000
28 Train Loss: 0.621 | Train Acc: 100.000
29 Train Loss: 0.593 | Train Acc: 100.000
30 Train Loss: 0.562 | Train Acc: 100.000
31 Train Loss: 0.534 | Train Acc: 100.000
32 Train Loss: 0.514 | Train Acc: 100.000
33 Train Loss: 0.484 | Train Acc: 100.000
34 Train Loss: 0.459 | Train Acc: 100.000
35 Train Loss: 0.435 | Train Acc: 100.000
36 Train Loss: 0.413 | Train Acc: 100.000
37 Train Loss: 0.392 | Train Acc: 100.000
38 Train Loss: 0.374 | Train Acc: 100.000
39 Train Loss: 0.352 | Train Acc: 100.000
40 Train Loss: 0.326 | Train Acc: 100.000
41 Train Loss: 0.319 | Train Acc: 100.000
42 Train Loss: 0.312 | Train Acc: 100.000
43 Train Loss: 0.305 | Train Acc: 100.000
44 Train Loss: 0.298 | Train Acc: 100.000
45 Train Loss: 0.291 | Train Acc: 100.000
46 Train Loss: 0.284 | Train Acc: 100.000
47 Train Loss: 0.277 | Train Acc: 100.000
48 Train Loss: 0.271 | Train Acc: 100.000
49 Train Loss: 0.263 | Train Acc: 100.000
50 Train Loss: 0.257 | Train Acc: 100.000
51 Train Loss: 0.250 | Train Acc: 100.000
52 Train Loss: 0.242 | Train Acc: 100.000
53 Train Loss: 0.236 | Train Acc: 100.000
54 Train Loss: 0.229 | Train Acc: 100.000
55 Train Loss: 0.222 | Train Acc: 100.000
56 Train Loss: 0.216 | Train Acc: 100.000
57 Train Loss: 0.209 | Train Acc: 100.000
58 Train Loss: 0.201 | Train Acc: 100.000
59 Train Loss: 0.194 | Train Acc: 100.000
60 Train Loss: 0.185 | Train Acc: 100.000
61 Train Loss: 0.182 | Train Acc: 100.000
62 Train Loss: 0.180 | Train Acc: 100.000
63 Train Loss: 0.177 | Train Acc: 100.000
64 Train Loss: 0.175 | Train Acc: 100.000
65 Train Loss: 0.172 | Train Acc: 100.000
66 Train Loss: 0.169 | Train Acc: 100.000
67 Train Loss: 0.166 | Train Acc: 100.000
68 Train Loss: 0.163 | Train Acc: 100.000
69 Train Loss: 0.161 | Train Acc: 100.000
70 Train Loss: 0.158 | Train Acc: 100.000
71 Train Loss: 0.155 | Train Acc: 100.000
72 Train Loss: 0.152 | Train Acc: 100.000
73 Train Loss: 0.149 | Train Acc: 100.000
74 Train Loss: 0.145 | Train Acc: 100.000
75 Train Loss: 0.142 | Train Acc: 100.000
76 Train Loss: 0.140 | Train Acc: 100.000
77 Train Loss: 0.137 | Train Acc: 100.000
78 Train Loss: 0.134 | Train Acc: 100.000
79 Train Loss: 0.130 | Train Acc: 100.000
80 Train Loss: 0.125 | Train Acc: 100.000
81 Train Loss: 0.124 | Train Acc: 100.000
82 Train Loss: 0.123 | Train Acc: 100.000
83 Train Loss: 0.121 | Train Acc: 100.000
84 Train Loss: 0.120 | Train Acc: 100.000
85 Train Loss: 0.119 | Train Acc: 100.000
86 Train Loss: 0.117 | Train Acc: 100.000
87 Train Loss: 0.116 | Train Acc: 100.000
88 Train Loss: 0.115 | Train Acc: 100.000
89 Train Loss: 0.113 | Train Acc: 100.000
90 Train Loss: 0.112 | Train Acc: 100.000
91 Train Loss: 0.110 | Train Acc: 100.000
92 Train Loss: 0.109 | Train Acc: 100.000
93 Train Loss: 0.107 | Train Acc: 100.000
94 Train Loss: 0.106 | Train Acc: 100.000
95 Train Loss: 0.104 | Train Acc: 100.000
96 Train Loss: 0.102 | Train Acc: 100.000
97 Train Loss: 0.100 | Train Acc: 100.000
98 Train Loss: 0.099 | Train Acc: 100.000
99 Train Loss: 0.098 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([1780, 1024])
printing expected split from k means
{3: 1, 1: 0, 7: 1, 0: 0, 8: 0, 5: 1, 9: 1, 2: 1, 4: 1, 6: 1}
Printing final_dict items...
{3: 1, 1: 0, 7: 1, 0: 0, 8: 0, 5: 1, 9: 1, 2: 1, 4: 1, 6: 1}
Image Statistics before MLP : L R :  800 980
expectedMlpLabels.shape :  torch.Size([1780])
0 Loss: 46.212 | Acc: 88.375
1 Loss: 28.333 | Acc: 93.062
2 Loss: 19.470 | Acc: 95.938
3 Loss: 21.756 | Acc: 95.000
4 Loss: 12.445 | Acc: 97.500
5 Loss: 15.612 | Acc: 96.375
6 Loss: 10.473 | Acc: 97.750
7 Loss: 10.441 | Acc: 97.812
8 Loss: 12.986 | Acc: 97.438
9 Loss: 10.305 | Acc: 97.812
10 Loss: 5.688 | Acc: 98.812
11 Loss: 2.538 | Acc: 99.562
12 Loss: 2.559 | Acc: 99.562
13 Loss: 4.350 | Acc: 99.062
14 Loss: 1.914 | Acc: 99.625
15 Loss: 2.164 | Acc: 99.562
16 Loss: 3.928 | Acc: 99.062
17 Loss: 2.397 | Acc: 99.375
18 Loss: 2.359 | Acc: 99.438
19 Loss: 1.896 | Acc: 99.562
20 Loss: 1.667 | Acc: 99.688
21 Loss: 0.945 | Acc: 99.875
22 Loss: 1.001 | Acc: 99.750
23 Loss: 0.801 | Acc: 99.812
24 Loss: 1.561 | Acc: 99.812
25 Loss: 1.043 | Acc: 99.750
26 Loss: 1.011 | Acc: 99.812
27 Loss: 0.612 | Acc: 99.938
28 Loss: 1.237 | Acc: 99.875
29 Loss: 1.210 | Acc: 99.688
30 Loss: 0.414 | Acc: 99.938
31 Loss: 1.100 | Acc: 99.688
32 Loss: 0.800 | Acc: 99.812
33 Loss: 0.359 | Acc: 99.938
34 Loss: 0.580 | Acc: 99.875
35 Loss: 0.641 | Acc: 99.812
36 Loss: 0.383 | Acc: 99.938
37 Loss: 0.503 | Acc: 99.938
38 Loss: 0.232 | Acc: 100.000
39 Loss: 0.392 | Acc: 99.875
40 Loss: 0.301 | Acc: 99.938
41 Loss: 0.497 | Acc: 99.938
42 Loss: 0.520 | Acc: 99.812
43 Loss: 0.195 | Acc: 100.000
44 Loss: 0.564 | Acc: 99.875
45 Loss: 0.267 | Acc: 100.000
46 Loss: 0.441 | Acc: 99.812
47 Loss: 0.535 | Acc: 99.875
48 Loss: 0.243 | Acc: 100.000
49 Loss: 0.170 | Acc: 100.000
50 Loss: 0.399 | Acc: 99.938
51 Loss: 0.496 | Acc: 99.875
52 Loss: 0.447 | Acc: 99.938
53 Loss: 0.244 | Acc: 100.000
54 Loss: 0.205 | Acc: 100.000
55 Loss: 0.285 | Acc: 99.938
56 Loss: 0.319 | Acc: 99.938
57 Loss: 0.213 | Acc: 100.000
58 Loss: 0.241 | Acc: 100.000
59 Loss: 0.316 | Acc: 99.875
MLP trained successfully...
# of Left images:  419.0
# of Right images:  640.0
giniRightRatio:  0.8723876953125
giniLeftRatio:  0.8920204373408672
impurityDrop:  0.8852410061091966
giniGain:  0.005935928676145341
lclasses:  [42, 71, 39, 43, 32, 38, 27, 38, 54, 35]
rclasses:  [28, 38, 47, 60, 63, 63, 46, 109, 43, 143]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([419, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([419])
rTrainDict[data].shape:  torch.Size([640, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([640])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  90 , imgTensorShape :  torch.Size([419, 16, 8, 8])
nodeId: 90 ,  parentId: 45 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 419
nodeId:  91 , imgTensorShape :  torch.Size([640, 16, 8, 8])
nodeId: 91 ,  parentId: 45 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 640
Running nodeId:  46
trainInputDict[data].shape :  torch.Size([795, 16, 12, 12])
copy.shape :  torch.Size([795, 2304])
copyLabel.shape :  torch.Size([795])
Class 0 has 203 instances after oversampling
Class 1 has 1 instances after oversampling
Class 2 has 203 instances after oversampling
Class 3 has 203 instances after oversampling
Class 4 has 203 instances after oversampling
Class 5 has 203 instances after oversampling
Class 6 has 203 instances after oversampling
Class 7 has 203 instances after oversampling
Class 8 has 203 instances after oversampling
Class 9 has 203 instances after oversampling
0 Train Loss: 220.041 | Train Acc: 17.333
1 Train Loss: 153.075 | Train Acc: 47.667
2 Train Loss: 101.672 | Train Acc: 68.333
3 Train Loss: 72.251 | Train Acc: 77.222
4 Train Loss: 60.277 | Train Acc: 80.389
5 Train Loss: 47.180 | Train Acc: 84.278
6 Train Loss: 36.832 | Train Acc: 89.056
7 Train Loss: 30.323 | Train Acc: 90.500
8 Train Loss: 22.961 | Train Acc: 93.444
9 Train Loss: 20.157 | Train Acc: 94.278
10 Train Loss: 16.283 | Train Acc: 95.778
11 Train Loss: 13.219 | Train Acc: 96.611
12 Train Loss: 10.740 | Train Acc: 97.667
13 Train Loss: 7.456 | Train Acc: 98.556
14 Train Loss: 5.262 | Train Acc: 99.389
15 Train Loss: 3.979 | Train Acc: 99.833
16 Train Loss: 3.604 | Train Acc: 99.556
17 Train Loss: 2.944 | Train Acc: 99.833
18 Train Loss: 2.116 | Train Acc: 99.889
19 Train Loss: 1.748 | Train Acc: 99.944
20 Train Loss: 1.234 | Train Acc: 100.000
21 Train Loss: 1.125 | Train Acc: 100.000
22 Train Loss: 1.032 | Train Acc: 100.000
23 Train Loss: 0.994 | Train Acc: 100.000
24 Train Loss: 0.936 | Train Acc: 100.000
25 Train Loss: 0.873 | Train Acc: 100.000
26 Train Loss: 0.812 | Train Acc: 100.000
27 Train Loss: 0.767 | Train Acc: 100.000
28 Train Loss: 0.716 | Train Acc: 100.000
29 Train Loss: 0.678 | Train Acc: 100.000
30 Train Loss: 0.645 | Train Acc: 100.000
31 Train Loss: 0.605 | Train Acc: 100.000
32 Train Loss: 0.565 | Train Acc: 100.000
33 Train Loss: 0.542 | Train Acc: 100.000
34 Train Loss: 0.501 | Train Acc: 100.000
35 Train Loss: 0.469 | Train Acc: 100.000
36 Train Loss: 0.435 | Train Acc: 100.000
37 Train Loss: 0.412 | Train Acc: 100.000
38 Train Loss: 0.393 | Train Acc: 100.000
39 Train Loss: 0.372 | Train Acc: 100.000
40 Train Loss: 0.332 | Train Acc: 100.000
41 Train Loss: 0.323 | Train Acc: 100.000
42 Train Loss: 0.315 | Train Acc: 100.000
43 Train Loss: 0.308 | Train Acc: 100.000
44 Train Loss: 0.299 | Train Acc: 100.000
45 Train Loss: 0.292 | Train Acc: 100.000
46 Train Loss: 0.283 | Train Acc: 100.000
47 Train Loss: 0.275 | Train Acc: 100.000
48 Train Loss: 0.267 | Train Acc: 100.000
49 Train Loss: 0.261 | Train Acc: 100.000
50 Train Loss: 0.253 | Train Acc: 100.000
51 Train Loss: 0.245 | Train Acc: 100.000
52 Train Loss: 0.237 | Train Acc: 100.000
53 Train Loss: 0.230 | Train Acc: 100.000
54 Train Loss: 0.223 | Train Acc: 100.000
55 Train Loss: 0.215 | Train Acc: 100.000
56 Train Loss: 0.208 | Train Acc: 100.000
57 Train Loss: 0.202 | Train Acc: 100.000
58 Train Loss: 0.194 | Train Acc: 100.000
59 Train Loss: 0.187 | Train Acc: 100.000
60 Train Loss: 0.177 | Train Acc: 100.000
61 Train Loss: 0.173 | Train Acc: 100.000
62 Train Loss: 0.170 | Train Acc: 100.000
63 Train Loss: 0.169 | Train Acc: 100.000
64 Train Loss: 0.165 | Train Acc: 100.000
65 Train Loss: 0.162 | Train Acc: 100.000
66 Train Loss: 0.160 | Train Acc: 100.000
67 Train Loss: 0.157 | Train Acc: 100.000
68 Train Loss: 0.154 | Train Acc: 100.000
69 Train Loss: 0.152 | Train Acc: 100.000
70 Train Loss: 0.148 | Train Acc: 100.000
71 Train Loss: 0.145 | Train Acc: 100.000
72 Train Loss: 0.143 | Train Acc: 100.000
73 Train Loss: 0.140 | Train Acc: 100.000
74 Train Loss: 0.137 | Train Acc: 100.000
75 Train Loss: 0.134 | Train Acc: 100.000
76 Train Loss: 0.131 | Train Acc: 100.000
77 Train Loss: 0.128 | Train Acc: 100.000
78 Train Loss: 0.126 | Train Acc: 100.000
79 Train Loss: 0.122 | Train Acc: 100.000
80 Train Loss: 0.117 | Train Acc: 100.000
81 Train Loss: 0.115 | Train Acc: 100.000
82 Train Loss: 0.114 | Train Acc: 100.000
83 Train Loss: 0.113 | Train Acc: 100.000
84 Train Loss: 0.112 | Train Acc: 100.000
85 Train Loss: 0.111 | Train Acc: 100.000
86 Train Loss: 0.109 | Train Acc: 100.000
87 Train Loss: 0.108 | Train Acc: 100.000
88 Train Loss: 0.107 | Train Acc: 100.000
89 Train Loss: 0.105 | Train Acc: 100.000
90 Train Loss: 0.104 | Train Acc: 100.000
91 Train Loss: 0.102 | Train Acc: 100.000
92 Train Loss: 0.101 | Train Acc: 100.000
93 Train Loss: 0.100 | Train Acc: 100.000
94 Train Loss: 0.098 | Train Acc: 100.000
95 Train Loss: 0.097 | Train Acc: 100.000
96 Train Loss: 0.095 | Train Acc: 100.000
97 Train Loss: 0.094 | Train Acc: 100.000
98 Train Loss: 0.092 | Train Acc: 100.000
99 Train Loss: 0.091 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([1828, 1024])
printing expected split from k means
{2: 1, 0: 0, 9: 1, 5: 1, 6: 1, 3: 1, 4: 1, 7: 1, 8: 1, 1: 1}
Printing final_dict items...
{2: 1, 0: 0, 9: 1, 5: 1, 6: 1, 3: 1, 4: 1, 7: 1, 8: 1, 1: 1}
Image Statistics before MLP : L R :  370 1458
expectedMlpLabels.shape :  torch.Size([1828])
0 Loss: 28.958 | Acc: 84.167
1 Loss: 17.849 | Acc: 91.000
2 Loss: 15.035 | Acc: 92.278
3 Loss: 17.531 | Acc: 91.444
4 Loss: 11.996 | Acc: 93.278
5 Loss: 11.512 | Acc: 93.556
6 Loss: 9.168 | Acc: 94.222
7 Loss: 8.982 | Acc: 94.222
8 Loss: 7.949 | Acc: 95.167
9 Loss: 6.876 | Acc: 95.500
10 Loss: 5.179 | Acc: 96.444
11 Loss: 4.665 | Acc: 97.167
12 Loss: 3.836 | Acc: 97.778
13 Loss: 3.545 | Acc: 97.833
14 Loss: 3.638 | Acc: 97.444
15 Loss: 3.249 | Acc: 98.222
16 Loss: 3.668 | Acc: 98.056
17 Loss: 2.616 | Acc: 98.333
18 Loss: 3.163 | Acc: 98.167
19 Loss: 2.992 | Acc: 98.000
20 Loss: 1.915 | Acc: 98.889
21 Loss: 1.822 | Acc: 98.889
22 Loss: 2.096 | Acc: 98.722
23 Loss: 1.941 | Acc: 98.944
24 Loss: 1.973 | Acc: 98.500
25 Loss: 1.603 | Acc: 99.056
26 Loss: 1.430 | Acc: 99.167
27 Loss: 1.234 | Acc: 99.167
28 Loss: 2.570 | Acc: 99.111
29 Loss: 1.797 | Acc: 99.056
30 Loss: 1.374 | Acc: 99.167
31 Loss: 0.931 | Acc: 99.333
32 Loss: 1.416 | Acc: 99.167
33 Loss: 1.350 | Acc: 99.222
34 Loss: 1.655 | Acc: 99.167
35 Loss: 1.111 | Acc: 99.278
36 Loss: 1.468 | Acc: 99.167
37 Loss: 1.130 | Acc: 99.389
38 Loss: 1.196 | Acc: 99.278
39 Loss: 1.115 | Acc: 99.111
40 Loss: 1.055 | Acc: 99.556
41 Loss: 0.868 | Acc: 99.278
42 Loss: 0.924 | Acc: 99.500
43 Loss: 0.946 | Acc: 99.444
44 Loss: 0.842 | Acc: 99.500
45 Loss: 0.694 | Acc: 99.444
46 Loss: 1.555 | Acc: 99.389
47 Loss: 0.840 | Acc: 99.389
48 Loss: 1.166 | Acc: 99.222
49 Loss: 0.743 | Acc: 99.444
50 Loss: 0.868 | Acc: 99.500
51 Loss: 0.768 | Acc: 99.333
52 Loss: 0.750 | Acc: 99.333
53 Loss: 0.696 | Acc: 99.500
54 Loss: 0.760 | Acc: 99.389
55 Loss: 0.812 | Acc: 99.556
56 Loss: 0.939 | Acc: 99.167
57 Loss: 0.689 | Acc: 99.500
58 Loss: 0.831 | Acc: 99.444
59 Loss: 0.604 | Acc: 99.556
MLP trained successfully...
# of Left images:  173.0
# of Right images:  622.0
giniRightRatio:  0.8120728693872065
giniLeftRatio:  0.7322663637274884
impurityDrop:  0.7898758830863524
giniGain:  0.02457607688358554
lclasses:  [13, 0, 79, 33, 14, 15, 6, 4, 5, 4]
rclasses:  [10, 1, 124, 156, 72, 78, 145, 22, 10, 4]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([173, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([173])
rTrainDict[data].shape:  torch.Size([622, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([622])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  92 , imgTensorShape :  torch.Size([173, 16, 8, 8])
nodeId: 92 ,  parentId: 46 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 173
nodeId:  93 , imgTensorShape :  torch.Size([622, 16, 8, 8])
nodeId: 93 ,  parentId: 46 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 622
Running nodeId:  47
trainInputDict[data].shape :  torch.Size([3252, 16, 12, 12])
copy.shape :  torch.Size([3252, 2304])
copyLabel.shape :  torch.Size([3252])
Class 0 has 846 instances after oversampling
Class 1 has 846 instances after oversampling
Class 2 has 846 instances after oversampling
Class 3 has 846 instances after oversampling
Class 4 has 846 instances after oversampling
Class 5 has 846 instances after oversampling
Class 6 has 846 instances after oversampling
Class 7 has 846 instances after oversampling
Class 8 has 846 instances after oversampling
Class 9 has 846 instances after oversampling
0 Train Loss: 223.401 | Train Acc: 17.305
1 Train Loss: 185.092 | Train Acc: 38.038
2 Train Loss: 157.504 | Train Acc: 47.872
3 Train Loss: 135.361 | Train Acc: 54.350
4 Train Loss: 119.808 | Train Acc: 60.638
5 Train Loss: 107.664 | Train Acc: 64.504
6 Train Loss: 94.691 | Train Acc: 68.806
7 Train Loss: 90.918 | Train Acc: 69.835
8 Train Loss: 79.217 | Train Acc: 73.121
9 Train Loss: 74.841 | Train Acc: 75.236
10 Train Loss: 70.138 | Train Acc: 76.501
11 Train Loss: 65.251 | Train Acc: 78.593
12 Train Loss: 57.065 | Train Acc: 81.229
13 Train Loss: 52.171 | Train Acc: 82.955
14 Train Loss: 50.683 | Train Acc: 83.322
15 Train Loss: 45.309 | Train Acc: 84.846
16 Train Loss: 44.873 | Train Acc: 85.095
17 Train Loss: 41.395 | Train Acc: 86.336
18 Train Loss: 36.304 | Train Acc: 88.109
19 Train Loss: 36.985 | Train Acc: 87.896
20 Train Loss: 28.983 | Train Acc: 91.111
21 Train Loss: 27.436 | Train Acc: 91.714
22 Train Loss: 26.274 | Train Acc: 92.317
23 Train Loss: 25.862 | Train Acc: 92.411
24 Train Loss: 24.769 | Train Acc: 92.612
25 Train Loss: 24.493 | Train Acc: 92.754
26 Train Loss: 23.558 | Train Acc: 93.227
27 Train Loss: 23.123 | Train Acc: 93.203
28 Train Loss: 22.033 | Train Acc: 93.853
29 Train Loss: 21.890 | Train Acc: 93.392
30 Train Loss: 21.749 | Train Acc: 93.522
31 Train Loss: 20.582 | Train Acc: 94.232
32 Train Loss: 19.846 | Train Acc: 94.421
33 Train Loss: 19.365 | Train Acc: 94.539
34 Train Loss: 18.397 | Train Acc: 94.870
35 Train Loss: 18.222 | Train Acc: 95.012
36 Train Loss: 17.110 | Train Acc: 95.485
37 Train Loss: 17.478 | Train Acc: 95.106
38 Train Loss: 16.176 | Train Acc: 95.816
39 Train Loss: 16.000 | Train Acc: 95.910
40 Train Loss: 14.156 | Train Acc: 96.903
41 Train Loss: 13.923 | Train Acc: 96.809
42 Train Loss: 13.753 | Train Acc: 97.057
43 Train Loss: 13.534 | Train Acc: 96.844
44 Train Loss: 13.298 | Train Acc: 97.069
45 Train Loss: 13.014 | Train Acc: 97.222
46 Train Loss: 12.894 | Train Acc: 97.057
47 Train Loss: 12.841 | Train Acc: 97.258
48 Train Loss: 12.618 | Train Acc: 97.352
49 Train Loss: 12.402 | Train Acc: 97.340
50 Train Loss: 12.387 | Train Acc: 97.352
51 Train Loss: 12.138 | Train Acc: 97.494
52 Train Loss: 11.817 | Train Acc: 97.577
53 Train Loss: 11.529 | Train Acc: 97.660
54 Train Loss: 11.619 | Train Acc: 97.612
55 Train Loss: 11.296 | Train Acc: 97.778
56 Train Loss: 11.133 | Train Acc: 97.943
57 Train Loss: 10.849 | Train Acc: 98.038
58 Train Loss: 10.907 | Train Acc: 97.896
59 Train Loss: 10.718 | Train Acc: 97.979
60 Train Loss: 10.053 | Train Acc: 98.369
61 Train Loss: 9.912 | Train Acc: 98.369
62 Train Loss: 9.847 | Train Acc: 98.369
63 Train Loss: 9.836 | Train Acc: 98.416
64 Train Loss: 9.745 | Train Acc: 98.357
65 Train Loss: 9.657 | Train Acc: 98.440
66 Train Loss: 9.564 | Train Acc: 98.511
67 Train Loss: 9.495 | Train Acc: 98.416
68 Train Loss: 9.436 | Train Acc: 98.487
69 Train Loss: 9.407 | Train Acc: 98.546
70 Train Loss: 9.330 | Train Acc: 98.629
71 Train Loss: 9.231 | Train Acc: 98.593
72 Train Loss: 9.226 | Train Acc: 98.652
73 Train Loss: 9.081 | Train Acc: 98.534
74 Train Loss: 9.041 | Train Acc: 98.641
75 Train Loss: 9.025 | Train Acc: 98.688
76 Train Loss: 8.927 | Train Acc: 98.723
77 Train Loss: 8.841 | Train Acc: 98.700
78 Train Loss: 8.873 | Train Acc: 98.771
79 Train Loss: 8.650 | Train Acc: 98.842
80 Train Loss: 8.470 | Train Acc: 98.842
81 Train Loss: 8.470 | Train Acc: 98.842
82 Train Loss: 8.400 | Train Acc: 98.853
83 Train Loss: 8.381 | Train Acc: 98.842
84 Train Loss: 8.336 | Train Acc: 98.877
85 Train Loss: 8.333 | Train Acc: 98.889
86 Train Loss: 8.290 | Train Acc: 98.913
87 Train Loss: 8.239 | Train Acc: 98.948
88 Train Loss: 8.231 | Train Acc: 98.983
89 Train Loss: 8.208 | Train Acc: 98.889
90 Train Loss: 8.173 | Train Acc: 98.936
91 Train Loss: 8.155 | Train Acc: 98.972
92 Train Loss: 8.124 | Train Acc: 98.924
93 Train Loss: 8.103 | Train Acc: 98.960
94 Train Loss: 8.078 | Train Acc: 98.913
95 Train Loss: 8.028 | Train Acc: 99.007
96 Train Loss: 8.001 | Train Acc: 98.983
97 Train Loss: 7.990 | Train Acc: 98.983
98 Train Loss: 7.950 | Train Acc: 99.007
99 Train Loss: 7.921 | Train Acc: 99.031
CNN trained successfully...
image_next_flat.shape :  torch.Size([8460, 1024])
printing expected split from k means
{5: 0, 3: 0, 2: 0, 4: 0, 6: 0, 0: 1, 7: 0, 9: 0, 8: 0, 1: 0}
Printing final_dict items...
{5: 0, 3: 0, 2: 0, 4: 0, 6: 0, 0: 1, 7: 0, 9: 0, 8: 0, 1: 0}
Image Statistics before MLP : L R :  6685 1775
expectedMlpLabels.shape :  torch.Size([8460])
0 Loss: 13.480 | Acc: 91.702
1 Loss: 8.576 | Acc: 94.286
2 Loss: 6.992 | Acc: 95.333
3 Loss: 6.586 | Acc: 95.536
4 Loss: 6.464 | Acc: 96.036
5 Loss: 5.696 | Acc: 95.929
6 Loss: 4.877 | Acc: 96.631
7 Loss: 4.443 | Acc: 97.226
8 Loss: 4.197 | Acc: 97.060
9 Loss: 4.087 | Acc: 97.310
10 Loss: 3.381 | Acc: 97.905
11 Loss: 2.668 | Acc: 98.226
12 Loss: 2.198 | Acc: 98.607
13 Loss: 2.228 | Acc: 98.583
14 Loss: 2.111 | Acc: 98.631
15 Loss: 1.750 | Acc: 98.917
16 Loss: 1.792 | Acc: 98.798
17 Loss: 2.036 | Acc: 98.881
18 Loss: 1.964 | Acc: 98.821
19 Loss: 1.921 | Acc: 98.893
20 Loss: 1.461 | Acc: 99.119
21 Loss: 1.255 | Acc: 99.179
22 Loss: 1.315 | Acc: 99.274
23 Loss: 1.274 | Acc: 99.333
24 Loss: 1.145 | Acc: 99.357
25 Loss: 0.954 | Acc: 99.393
26 Loss: 1.049 | Acc: 99.417
27 Loss: 0.946 | Acc: 99.464
28 Loss: 0.892 | Acc: 99.536
29 Loss: 0.880 | Acc: 99.500
30 Loss: 0.748 | Acc: 99.548
31 Loss: 0.664 | Acc: 99.655
32 Loss: 0.821 | Acc: 99.583
33 Loss: 0.624 | Acc: 99.631
34 Loss: 0.741 | Acc: 99.667
35 Loss: 0.645 | Acc: 99.607
36 Loss: 0.692 | Acc: 99.631
37 Loss: 0.635 | Acc: 99.655
38 Loss: 0.535 | Acc: 99.690
39 Loss: 0.631 | Acc: 99.667
40 Loss: 0.570 | Acc: 99.679
41 Loss: 0.583 | Acc: 99.762
42 Loss: 0.525 | Acc: 99.679
43 Loss: 0.546 | Acc: 99.714
44 Loss: 0.595 | Acc: 99.643
45 Loss: 0.496 | Acc: 99.762
46 Loss: 0.616 | Acc: 99.702
47 Loss: 0.619 | Acc: 99.679
48 Loss: 0.561 | Acc: 99.702
49 Loss: 0.514 | Acc: 99.738
50 Loss: 0.483 | Acc: 99.726
51 Loss: 0.432 | Acc: 99.774
52 Loss: 0.494 | Acc: 99.750
53 Loss: 0.521 | Acc: 99.726
54 Loss: 0.491 | Acc: 99.726
55 Loss: 0.416 | Acc: 99.774
56 Loss: 0.578 | Acc: 99.738
57 Loss: 0.470 | Acc: 99.726
58 Loss: 0.567 | Acc: 99.726
59 Loss: 0.567 | Acc: 99.702
MLP trained successfully...
# of Left images:  2460.0
# of Right images:  792.0
giniRightRatio:  0.8244503111927354
giniLeftRatio:  0.8219693965232334
impurityDrop:  0.8167444398707975
giniGain:  0.015239548788277268
lclasses:  [92, 14, 308, 553, 305, 685, 64, 301, 97, 41]
rclasses:  [143, 7, 191, 143, 62, 161, 5, 32, 43, 5]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2460, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([2460])
rTrainDict[data].shape:  torch.Size([792, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([792])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  94 , imgTensorShape :  torch.Size([2460, 16, 8, 8])
nodeId: 94 ,  parentId: 47 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2460
nodeId:  95 , imgTensorShape :  torch.Size([792, 16, 8, 8])
nodeId: 95 ,  parentId: 47 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 792
Running nodeId:  48
trainInputDict[data].shape :  torch.Size([1419, 16, 12, 12])
copy.shape :  torch.Size([1419, 2304])
copyLabel.shape :  torch.Size([1419])
Class 0 has 258 instances after oversampling
Class 1 has 258 instances after oversampling
Class 2 has 258 instances after oversampling
Class 3 has 258 instances after oversampling
Class 4 has 258 instances after oversampling
Class 5 has 258 instances after oversampling
Class 6 has 258 instances after oversampling
Class 7 has 259 instances after oversampling
Class 8 has 258 instances after oversampling
Class 9 has 259 instances after oversampling
0 Train Loss: 222.207 | Train Acc: 19.830
1 Train Loss: 178.771 | Train Acc: 39.969
2 Train Loss: 134.921 | Train Acc: 57.359
3 Train Loss: 104.539 | Train Acc: 66.421
4 Train Loss: 83.220 | Train Acc: 73.703
5 Train Loss: 62.447 | Train Acc: 81.642
6 Train Loss: 48.520 | Train Acc: 86.406
7 Train Loss: 35.747 | Train Acc: 90.085
8 Train Loss: 27.291 | Train Acc: 92.912
9 Train Loss: 21.461 | Train Acc: 94.965
10 Train Loss: 18.290 | Train Acc: 95.778
11 Train Loss: 11.589 | Train Acc: 98.102
12 Train Loss: 8.822 | Train Acc: 98.683
13 Train Loss: 6.810 | Train Acc: 99.535
14 Train Loss: 4.974 | Train Acc: 99.768
15 Train Loss: 3.774 | Train Acc: 99.961
16 Train Loss: 2.956 | Train Acc: 100.000
17 Train Loss: 2.431 | Train Acc: 100.000
18 Train Loss: 1.954 | Train Acc: 100.000
19 Train Loss: 1.658 | Train Acc: 100.000
20 Train Loss: 1.344 | Train Acc: 100.000
21 Train Loss: 1.217 | Train Acc: 100.000
22 Train Loss: 1.163 | Train Acc: 100.000
23 Train Loss: 1.102 | Train Acc: 100.000
24 Train Loss: 1.046 | Train Acc: 100.000
25 Train Loss: 1.000 | Train Acc: 100.000
26 Train Loss: 0.957 | Train Acc: 100.000
27 Train Loss: 0.902 | Train Acc: 100.000
28 Train Loss: 0.858 | Train Acc: 100.000
29 Train Loss: 0.816 | Train Acc: 100.000
30 Train Loss: 0.767 | Train Acc: 100.000
31 Train Loss: 0.740 | Train Acc: 100.000
32 Train Loss: 0.696 | Train Acc: 100.000
33 Train Loss: 0.655 | Train Acc: 100.000
34 Train Loss: 0.619 | Train Acc: 100.000
35 Train Loss: 0.596 | Train Acc: 100.000
36 Train Loss: 0.557 | Train Acc: 100.000
37 Train Loss: 0.534 | Train Acc: 100.000
38 Train Loss: 0.503 | Train Acc: 100.000
39 Train Loss: 0.473 | Train Acc: 100.000
40 Train Loss: 0.431 | Train Acc: 100.000
41 Train Loss: 0.422 | Train Acc: 100.000
42 Train Loss: 0.412 | Train Acc: 100.000
43 Train Loss: 0.404 | Train Acc: 100.000
44 Train Loss: 0.394 | Train Acc: 100.000
45 Train Loss: 0.388 | Train Acc: 100.000
46 Train Loss: 0.375 | Train Acc: 100.000
47 Train Loss: 0.366 | Train Acc: 100.000
48 Train Loss: 0.358 | Train Acc: 100.000
49 Train Loss: 0.347 | Train Acc: 100.000
50 Train Loss: 0.339 | Train Acc: 100.000
51 Train Loss: 0.331 | Train Acc: 100.000
52 Train Loss: 0.321 | Train Acc: 100.000
53 Train Loss: 0.311 | Train Acc: 100.000
54 Train Loss: 0.302 | Train Acc: 100.000
55 Train Loss: 0.293 | Train Acc: 100.000
56 Train Loss: 0.283 | Train Acc: 100.000
57 Train Loss: 0.276 | Train Acc: 100.000
58 Train Loss: 0.266 | Train Acc: 100.000
59 Train Loss: 0.256 | Train Acc: 100.000
60 Train Loss: 0.242 | Train Acc: 100.000
61 Train Loss: 0.237 | Train Acc: 100.000
62 Train Loss: 0.235 | Train Acc: 100.000
63 Train Loss: 0.231 | Train Acc: 100.000
64 Train Loss: 0.228 | Train Acc: 100.000
65 Train Loss: 0.224 | Train Acc: 100.000
66 Train Loss: 0.220 | Train Acc: 100.000
67 Train Loss: 0.218 | Train Acc: 100.000
68 Train Loss: 0.213 | Train Acc: 100.000
69 Train Loss: 0.210 | Train Acc: 100.000
70 Train Loss: 0.206 | Train Acc: 100.000
71 Train Loss: 0.202 | Train Acc: 100.000
72 Train Loss: 0.198 | Train Acc: 100.000
73 Train Loss: 0.194 | Train Acc: 100.000
74 Train Loss: 0.191 | Train Acc: 100.000
75 Train Loss: 0.187 | Train Acc: 100.000
76 Train Loss: 0.183 | Train Acc: 100.000
77 Train Loss: 0.179 | Train Acc: 100.000
78 Train Loss: 0.175 | Train Acc: 100.000
79 Train Loss: 0.171 | Train Acc: 100.000
80 Train Loss: 0.164 | Train Acc: 100.000
81 Train Loss: 0.162 | Train Acc: 100.000
82 Train Loss: 0.160 | Train Acc: 100.000
83 Train Loss: 0.159 | Train Acc: 100.000
84 Train Loss: 0.157 | Train Acc: 100.000
85 Train Loss: 0.155 | Train Acc: 100.000
86 Train Loss: 0.154 | Train Acc: 100.000
87 Train Loss: 0.152 | Train Acc: 100.000
88 Train Loss: 0.150 | Train Acc: 100.000
89 Train Loss: 0.148 | Train Acc: 100.000
90 Train Loss: 0.147 | Train Acc: 100.000
91 Train Loss: 0.145 | Train Acc: 100.000
92 Train Loss: 0.143 | Train Acc: 100.000
93 Train Loss: 0.141 | Train Acc: 100.000
94 Train Loss: 0.139 | Train Acc: 100.000
95 Train Loss: 0.137 | Train Acc: 100.000
96 Train Loss: 0.135 | Train Acc: 100.000
97 Train Loss: 0.133 | Train Acc: 100.000
98 Train Loss: 0.131 | Train Acc: 100.000
99 Train Loss: 0.129 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([2582, 1024])
printing expected split from k means
{3: 1, 4: 0, 7: 0, 9: 0, 1: 0, 6: 0, 5: 1, 2: 0, 0: 0, 8: 1}
Printing final_dict items...
{3: 1, 4: 0, 7: 0, 9: 0, 1: 0, 6: 0, 5: 1, 2: 0, 0: 0, 8: 1}
Image Statistics before MLP : L R :  1533 1049
expectedMlpLabels.shape :  torch.Size([2582])
0 Loss: 29.828 | Acc: 92.250
1 Loss: 15.143 | Acc: 96.125
2 Loss: 10.446 | Acc: 97.708
3 Loss: 13.794 | Acc: 96.792
4 Loss: 10.740 | Acc: 97.375
5 Loss: 8.352 | Acc: 98.125
6 Loss: 5.430 | Acc: 98.917
7 Loss: 6.630 | Acc: 98.583
8 Loss: 4.728 | Acc: 98.708
9 Loss: 3.266 | Acc: 99.125
10 Loss: 3.044 | Acc: 99.333
11 Loss: 2.859 | Acc: 99.458
12 Loss: 1.851 | Acc: 99.417
13 Loss: 1.248 | Acc: 99.667
14 Loss: 4.407 | Acc: 99.375
15 Loss: 2.839 | Acc: 99.500
16 Loss: 1.660 | Acc: 99.625
17 Loss: 0.885 | Acc: 99.792
18 Loss: 0.658 | Acc: 99.833
19 Loss: 2.689 | Acc: 99.417
20 Loss: 1.585 | Acc: 99.750
21 Loss: 0.813 | Acc: 99.833
22 Loss: 0.555 | Acc: 99.917
23 Loss: 0.572 | Acc: 99.917
24 Loss: 1.056 | Acc: 99.875
25 Loss: 0.530 | Acc: 99.875
26 Loss: 0.836 | Acc: 99.833
27 Loss: 1.080 | Acc: 99.833
28 Loss: 1.125 | Acc: 99.750
29 Loss: 0.413 | Acc: 99.875
30 Loss: 0.731 | Acc: 99.750
31 Loss: 0.364 | Acc: 99.958
32 Loss: 1.078 | Acc: 99.750
33 Loss: 0.154 | Acc: 100.000
34 Loss: 0.397 | Acc: 99.917
35 Loss: 0.602 | Acc: 99.833
36 Loss: 0.212 | Acc: 100.000
37 Loss: 0.538 | Acc: 99.875
38 Loss: 0.228 | Acc: 100.000
39 Loss: 0.182 | Acc: 100.000
40 Loss: 0.404 | Acc: 99.875
41 Loss: 0.276 | Acc: 99.875
42 Loss: 0.196 | Acc: 99.958
43 Loss: 0.284 | Acc: 99.917
44 Loss: 0.283 | Acc: 99.917
45 Loss: 0.352 | Acc: 99.917
46 Loss: 0.212 | Acc: 99.958
47 Loss: 0.751 | Acc: 99.750
48 Loss: 0.172 | Acc: 100.000
49 Loss: 0.137 | Acc: 100.000
50 Loss: 0.191 | Acc: 100.000
51 Loss: 0.245 | Acc: 99.917
52 Loss: 0.341 | Acc: 99.958
53 Loss: 0.252 | Acc: 99.958
54 Loss: 0.274 | Acc: 99.917
55 Loss: 0.159 | Acc: 99.958
56 Loss: 0.202 | Acc: 99.917
57 Loss: 0.099 | Acc: 100.000
58 Loss: 0.102 | Acc: 99.958
59 Loss: 0.154 | Acc: 100.000
MLP trained successfully...
# of Left images:  822.0
# of Right images:  597.0
giniRightRatio:  0.8593890726665152
giniLeftRatio:  0.8580697485806974
impurityDrop:  0.8575725158850375
giniGain:  0.013006522942194398
lclasses:  [48, 130, 44, 70, 44, 55, 91, 152, 5, 183]
rclasses:  [27, 37, 37, 130, 42, 98, 35, 107, 9, 75]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([822, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([822])
rTrainDict[data].shape:  torch.Size([597, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([597])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  96 , imgTensorShape :  torch.Size([822, 16, 8, 8])
nodeId: 96 ,  parentId: 48 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 822
nodeId:  97 , imgTensorShape :  torch.Size([597, 16, 8, 8])
nodeId: 97 ,  parentId: 48 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 597
Running nodeId:  49
trainInputDict[data].shape :  torch.Size([974, 16, 12, 12])
copy.shape :  torch.Size([974, 2304])
copyLabel.shape :  torch.Size([974])
Class 0 has 333 instances after oversampling
Class 1 has 333 instances after oversampling
Class 2 has 333 instances after oversampling
Class 3 has 333 instances after oversampling
Class 4 has 333 instances after oversampling
Class 5 has 333 instances after oversampling
Class 6 has 333 instances after oversampling
Class 7 has 333 instances after oversampling
Class 8 has 333 instances after oversampling
Class 9 has 333 instances after oversampling
0 Train Loss: 217.780 | Train Acc: 22.970
1 Train Loss: 153.378 | Train Acc: 50.697
2 Train Loss: 98.191 | Train Acc: 70.697
3 Train Loss: 68.077 | Train Acc: 79.727
4 Train Loss: 47.551 | Train Acc: 86.091
5 Train Loss: 36.136 | Train Acc: 89.939
6 Train Loss: 27.264 | Train Acc: 91.939
7 Train Loss: 19.869 | Train Acc: 95.030
8 Train Loss: 15.997 | Train Acc: 95.697
9 Train Loss: 11.715 | Train Acc: 97.152
10 Train Loss: 8.786 | Train Acc: 98.121
11 Train Loss: 6.544 | Train Acc: 98.485
12 Train Loss: 4.793 | Train Acc: 99.152
13 Train Loss: 3.609 | Train Acc: 99.636
14 Train Loss: 2.320 | Train Acc: 99.909
15 Train Loss: 1.729 | Train Acc: 100.000
16 Train Loss: 1.459 | Train Acc: 100.000
17 Train Loss: 1.228 | Train Acc: 100.000
18 Train Loss: 1.042 | Train Acc: 100.000
19 Train Loss: 0.898 | Train Acc: 100.000
20 Train Loss: 0.699 | Train Acc: 100.000
21 Train Loss: 0.633 | Train Acc: 100.000
22 Train Loss: 0.590 | Train Acc: 100.000
23 Train Loss: 0.569 | Train Acc: 100.000
24 Train Loss: 0.527 | Train Acc: 100.000
25 Train Loss: 0.504 | Train Acc: 100.000
26 Train Loss: 0.484 | Train Acc: 100.000
27 Train Loss: 0.454 | Train Acc: 100.000
28 Train Loss: 0.430 | Train Acc: 100.000
29 Train Loss: 0.404 | Train Acc: 100.000
30 Train Loss: 0.392 | Train Acc: 100.000
31 Train Loss: 0.363 | Train Acc: 100.000
32 Train Loss: 0.345 | Train Acc: 100.000
33 Train Loss: 0.322 | Train Acc: 100.000
34 Train Loss: 0.311 | Train Acc: 100.000
35 Train Loss: 0.293 | Train Acc: 100.000
36 Train Loss: 0.275 | Train Acc: 100.000
37 Train Loss: 0.265 | Train Acc: 100.000
38 Train Loss: 0.253 | Train Acc: 100.000
39 Train Loss: 0.234 | Train Acc: 100.000
40 Train Loss: 0.215 | Train Acc: 100.000
41 Train Loss: 0.208 | Train Acc: 100.000
42 Train Loss: 0.204 | Train Acc: 100.000
43 Train Loss: 0.200 | Train Acc: 100.000
44 Train Loss: 0.194 | Train Acc: 100.000
45 Train Loss: 0.190 | Train Acc: 100.000
46 Train Loss: 0.185 | Train Acc: 100.000
47 Train Loss: 0.182 | Train Acc: 100.000
48 Train Loss: 0.176 | Train Acc: 100.000
49 Train Loss: 0.171 | Train Acc: 100.000
50 Train Loss: 0.167 | Train Acc: 100.000
51 Train Loss: 0.162 | Train Acc: 100.000
52 Train Loss: 0.160 | Train Acc: 100.000
53 Train Loss: 0.153 | Train Acc: 100.000
54 Train Loss: 0.148 | Train Acc: 100.000
55 Train Loss: 0.143 | Train Acc: 100.000
56 Train Loss: 0.140 | Train Acc: 100.000
57 Train Loss: 0.135 | Train Acc: 100.000
58 Train Loss: 0.130 | Train Acc: 100.000
59 Train Loss: 0.125 | Train Acc: 100.000
60 Train Loss: 0.119 | Train Acc: 100.000
61 Train Loss: 0.117 | Train Acc: 100.000
62 Train Loss: 0.115 | Train Acc: 100.000
63 Train Loss: 0.114 | Train Acc: 100.000
64 Train Loss: 0.111 | Train Acc: 100.000
65 Train Loss: 0.110 | Train Acc: 100.000
66 Train Loss: 0.109 | Train Acc: 100.000
67 Train Loss: 0.107 | Train Acc: 100.000
68 Train Loss: 0.104 | Train Acc: 100.000
69 Train Loss: 0.103 | Train Acc: 100.000
70 Train Loss: 0.101 | Train Acc: 100.000
71 Train Loss: 0.099 | Train Acc: 100.000
72 Train Loss: 0.097 | Train Acc: 100.000
73 Train Loss: 0.095 | Train Acc: 100.000
74 Train Loss: 0.093 | Train Acc: 100.000
75 Train Loss: 0.091 | Train Acc: 100.000
76 Train Loss: 0.089 | Train Acc: 100.000
77 Train Loss: 0.087 | Train Acc: 100.000
78 Train Loss: 0.085 | Train Acc: 100.000
79 Train Loss: 0.083 | Train Acc: 100.000
80 Train Loss: 0.080 | Train Acc: 100.000
81 Train Loss: 0.079 | Train Acc: 100.000
82 Train Loss: 0.078 | Train Acc: 100.000
83 Train Loss: 0.077 | Train Acc: 100.000
84 Train Loss: 0.076 | Train Acc: 100.000
85 Train Loss: 0.075 | Train Acc: 100.000
86 Train Loss: 0.075 | Train Acc: 100.000
87 Train Loss: 0.073 | Train Acc: 100.000
88 Train Loss: 0.073 | Train Acc: 100.000
89 Train Loss: 0.072 | Train Acc: 100.000
90 Train Loss: 0.071 | Train Acc: 100.000
91 Train Loss: 0.070 | Train Acc: 100.000
92 Train Loss: 0.069 | Train Acc: 100.000
93 Train Loss: 0.068 | Train Acc: 100.000
94 Train Loss: 0.067 | Train Acc: 100.000
95 Train Loss: 0.066 | Train Acc: 100.000
96 Train Loss: 0.065 | Train Acc: 100.000
97 Train Loss: 0.064 | Train Acc: 100.000
98 Train Loss: 0.063 | Train Acc: 100.000
99 Train Loss: 0.062 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([3330, 1024])
printing expected split from k means
{9: 1, 3: 0, 7: 0, 5: 0, 8: 1, 6: 1, 4: 1, 1: 1, 0: 1, 2: 0}
Printing final_dict items...
{9: 1, 3: 0, 7: 0, 5: 0, 8: 1, 6: 1, 4: 1, 1: 1, 0: 1, 2: 0}
Image Statistics before MLP : L R :  1285 2045
expectedMlpLabels.shape :  torch.Size([3330])
0 Loss: 48.113 | Acc: 85.281
1 Loss: 32.221 | Acc: 90.438
2 Loss: 29.001 | Acc: 91.688
3 Loss: 25.230 | Acc: 92.500
4 Loss: 23.149 | Acc: 93.188
5 Loss: 20.306 | Acc: 94.062
6 Loss: 20.351 | Acc: 94.000
7 Loss: 17.409 | Acc: 94.562
8 Loss: 17.230 | Acc: 94.938
9 Loss: 16.306 | Acc: 95.000
10 Loss: 11.984 | Acc: 96.188
11 Loss: 10.909 | Acc: 96.938
12 Loss: 10.447 | Acc: 97.000
13 Loss: 9.074 | Acc: 97.250
14 Loss: 10.231 | Acc: 97.062
15 Loss: 8.931 | Acc: 97.594
16 Loss: 8.575 | Acc: 97.844
17 Loss: 8.572 | Acc: 97.500
18 Loss: 7.862 | Acc: 98.031
19 Loss: 9.245 | Acc: 97.531
20 Loss: 6.469 | Acc: 98.281
21 Loss: 5.462 | Acc: 98.562
22 Loss: 5.317 | Acc: 98.469
23 Loss: 5.561 | Acc: 98.469
24 Loss: 4.537 | Acc: 98.844
25 Loss: 4.344 | Acc: 98.875
26 Loss: 4.843 | Acc: 98.438
27 Loss: 3.720 | Acc: 98.969
28 Loss: 4.358 | Acc: 99.031
29 Loss: 4.751 | Acc: 98.750
30 Loss: 3.524 | Acc: 98.969
31 Loss: 2.605 | Acc: 99.344
32 Loss: 3.260 | Acc: 99.281
33 Loss: 3.005 | Acc: 99.312
34 Loss: 3.279 | Acc: 99.188
35 Loss: 2.990 | Acc: 99.062
36 Loss: 3.070 | Acc: 99.031
37 Loss: 3.249 | Acc: 99.094
38 Loss: 3.214 | Acc: 99.094
39 Loss: 2.900 | Acc: 99.344
40 Loss: 2.953 | Acc: 99.250
41 Loss: 2.462 | Acc: 99.281
42 Loss: 2.834 | Acc: 99.344
43 Loss: 2.275 | Acc: 99.469
44 Loss: 2.928 | Acc: 99.312
45 Loss: 2.244 | Acc: 99.312
46 Loss: 2.254 | Acc: 99.438
47 Loss: 2.069 | Acc: 99.438
48 Loss: 2.747 | Acc: 99.219
49 Loss: 2.350 | Acc: 99.312
50 Loss: 1.977 | Acc: 99.531
51 Loss: 1.992 | Acc: 99.469
52 Loss: 2.418 | Acc: 99.375
53 Loss: 2.545 | Acc: 99.375
54 Loss: 2.149 | Acc: 99.375
55 Loss: 2.260 | Acc: 99.375
56 Loss: 2.339 | Acc: 99.281
57 Loss: 2.226 | Acc: 99.469
58 Loss: 2.514 | Acc: 99.438
59 Loss: 2.161 | Acc: 99.281
MLP trained successfully...
# of Left images:  502.0
# of Right images:  472.0
giniRightRatio:  0.7844997845446711
giniLeftRatio:  0.8043602482500278
impurityDrop:  0.8056225658584191
giniGain:  0.0029569702529614883
lclasses:  [5, 27, 20, 50, 13, 60, 23, 135, 18, 151]
rclasses:  [11, 89, 11, 18, 18, 28, 39, 59, 17, 182]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([502, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([502])
rTrainDict[data].shape:  torch.Size([472, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([472])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  98 , imgTensorShape :  torch.Size([502, 16, 8, 8])
nodeId: 98 ,  parentId: 49 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 502
nodeId:  99 , imgTensorShape :  torch.Size([472, 16, 8, 8])
nodeId: 99 ,  parentId: 49 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 472
Running nodeId:  50
trainInputDict[data].shape :  torch.Size([690, 16, 12, 12])
copy.shape :  torch.Size([690, 2304])
copyLabel.shape :  torch.Size([690])
Class 0 has 376 instances after oversampling
Class 1 has 376 instances after oversampling
Class 2 has 376 instances after oversampling
Class 3 has 376 instances after oversampling
Class 4 has 376 instances after oversampling
Class 5 has 376 instances after oversampling
Class 6 has 376 instances after oversampling
Class 7 has 376 instances after oversampling
Class 8 has 376 instances after oversampling
0 Train Loss: 185.549 | Train Acc: 37.086
1 Train Loss: 61.617 | Train Acc: 80.674
2 Train Loss: 31.631 | Train Acc: 90.632
3 Train Loss: 18.728 | Train Acc: 93.794
4 Train Loss: 16.272 | Train Acc: 94.888
5 Train Loss: 10.946 | Train Acc: 96.395
6 Train Loss: 8.908 | Train Acc: 97.134
7 Train Loss: 6.576 | Train Acc: 97.961
8 Train Loss: 6.489 | Train Acc: 97.606
9 Train Loss: 6.682 | Train Acc: 97.931
10 Train Loss: 4.240 | Train Acc: 98.729
11 Train Loss: 4.433 | Train Acc: 98.434
12 Train Loss: 3.695 | Train Acc: 98.848
13 Train Loss: 2.620 | Train Acc: 99.232
14 Train Loss: 1.850 | Train Acc: 99.704
15 Train Loss: 1.274 | Train Acc: 99.793
16 Train Loss: 1.663 | Train Acc: 99.645
17 Train Loss: 3.590 | Train Acc: 98.936
18 Train Loss: 4.433 | Train Acc: 98.700
19 Train Loss: 0.885 | Train Acc: 99.882
20 Train Loss: 0.547 | Train Acc: 99.970
21 Train Loss: 0.476 | Train Acc: 100.000
22 Train Loss: 0.435 | Train Acc: 100.000
23 Train Loss: 0.401 | Train Acc: 100.000
24 Train Loss: 0.376 | Train Acc: 100.000
25 Train Loss: 0.352 | Train Acc: 100.000
26 Train Loss: 0.331 | Train Acc: 100.000
27 Train Loss: 0.310 | Train Acc: 100.000
28 Train Loss: 0.294 | Train Acc: 100.000
29 Train Loss: 0.277 | Train Acc: 100.000
30 Train Loss: 0.263 | Train Acc: 100.000
31 Train Loss: 0.250 | Train Acc: 100.000
32 Train Loss: 0.233 | Train Acc: 100.000
33 Train Loss: 0.221 | Train Acc: 100.000
34 Train Loss: 0.208 | Train Acc: 100.000
35 Train Loss: 0.195 | Train Acc: 100.000
36 Train Loss: 0.190 | Train Acc: 100.000
37 Train Loss: 0.176 | Train Acc: 100.000
38 Train Loss: 0.170 | Train Acc: 100.000
39 Train Loss: 0.160 | Train Acc: 100.000
40 Train Loss: 0.146 | Train Acc: 100.000
41 Train Loss: 0.142 | Train Acc: 100.000
42 Train Loss: 0.139 | Train Acc: 100.000
43 Train Loss: 0.136 | Train Acc: 100.000
44 Train Loss: 0.133 | Train Acc: 100.000
45 Train Loss: 0.131 | Train Acc: 100.000
46 Train Loss: 0.126 | Train Acc: 100.000
47 Train Loss: 0.123 | Train Acc: 100.000
48 Train Loss: 0.120 | Train Acc: 100.000
49 Train Loss: 0.117 | Train Acc: 100.000
50 Train Loss: 0.113 | Train Acc: 100.000
51 Train Loss: 0.111 | Train Acc: 100.000
52 Train Loss: 0.108 | Train Acc: 100.000
53 Train Loss: 0.105 | Train Acc: 100.000
54 Train Loss: 0.103 | Train Acc: 100.000
55 Train Loss: 0.099 | Train Acc: 100.000
56 Train Loss: 0.096 | Train Acc: 100.000
57 Train Loss: 0.093 | Train Acc: 100.000
58 Train Loss: 0.088 | Train Acc: 100.000
59 Train Loss: 0.086 | Train Acc: 100.000
60 Train Loss: 0.081 | Train Acc: 100.000
61 Train Loss: 0.080 | Train Acc: 100.000
62 Train Loss: 0.079 | Train Acc: 100.000
63 Train Loss: 0.078 | Train Acc: 100.000
64 Train Loss: 0.077 | Train Acc: 100.000
65 Train Loss: 0.075 | Train Acc: 100.000
66 Train Loss: 0.074 | Train Acc: 100.000
67 Train Loss: 0.073 | Train Acc: 100.000
68 Train Loss: 0.071 | Train Acc: 100.000
69 Train Loss: 0.070 | Train Acc: 100.000
70 Train Loss: 0.069 | Train Acc: 100.000
71 Train Loss: 0.068 | Train Acc: 100.000
72 Train Loss: 0.067 | Train Acc: 100.000
73 Train Loss: 0.066 | Train Acc: 100.000
74 Train Loss: 0.064 | Train Acc: 100.000
75 Train Loss: 0.063 | Train Acc: 100.000
76 Train Loss: 0.061 | Train Acc: 100.000
77 Train Loss: 0.060 | Train Acc: 100.000
78 Train Loss: 0.058 | Train Acc: 100.000
79 Train Loss: 0.057 | Train Acc: 100.000
80 Train Loss: 0.055 | Train Acc: 100.000
81 Train Loss: 0.054 | Train Acc: 100.000
82 Train Loss: 0.054 | Train Acc: 100.000
83 Train Loss: 0.053 | Train Acc: 100.000
84 Train Loss: 0.052 | Train Acc: 100.000
85 Train Loss: 0.052 | Train Acc: 100.000
86 Train Loss: 0.051 | Train Acc: 100.000
87 Train Loss: 0.050 | Train Acc: 100.000
88 Train Loss: 0.050 | Train Acc: 100.000
89 Train Loss: 0.049 | Train Acc: 100.000
90 Train Loss: 0.049 | Train Acc: 100.000
91 Train Loss: 0.048 | Train Acc: 100.000
92 Train Loss: 0.047 | Train Acc: 100.000
93 Train Loss: 0.047 | Train Acc: 100.000
94 Train Loss: 0.046 | Train Acc: 100.000
95 Train Loss: 0.045 | Train Acc: 100.000
96 Train Loss: 0.045 | Train Acc: 100.000
97 Train Loss: 0.044 | Train Acc: 100.000
98 Train Loss: 0.043 | Train Acc: 100.000
99 Train Loss: 0.042 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([3384, 1024])
printing expected split from k means
{1: 0, 8: 0, 6: 1, 0: 0, 5: 0, 7: 0, 2: 0, 3: 1, 4: 0}
Printing final_dict items...
{1: 0, 8: 0, 6: 1, 0: 0, 5: 0, 7: 0, 2: 0, 3: 1, 4: 0}
Image Statistics before MLP : L R :  2322 1062
expectedMlpLabels.shape :  torch.Size([3384])
0 Loss: 30.154 | Acc: 89.953
1 Loss: 16.084 | Acc: 95.035
2 Loss: 14.263 | Acc: 95.597
3 Loss: 13.888 | Acc: 96.011
4 Loss: 10.617 | Acc: 96.602
5 Loss: 8.550 | Acc: 97.193
6 Loss: 9.007 | Acc: 97.311
7 Loss: 9.370 | Acc: 96.927
8 Loss: 6.950 | Acc: 97.665
9 Loss: 8.843 | Acc: 97.163
10 Loss: 6.584 | Acc: 98.138
11 Loss: 5.954 | Acc: 98.197
12 Loss: 5.290 | Acc: 98.316
13 Loss: 4.840 | Acc: 98.463
14 Loss: 4.790 | Acc: 98.404
15 Loss: 4.720 | Acc: 98.522
16 Loss: 3.467 | Acc: 98.818
17 Loss: 3.921 | Acc: 98.877
18 Loss: 4.253 | Acc: 98.522
19 Loss: 3.820 | Acc: 98.788
20 Loss: 2.714 | Acc: 99.143
21 Loss: 2.401 | Acc: 99.291
22 Loss: 2.645 | Acc: 99.350
23 Loss: 2.583 | Acc: 99.173
24 Loss: 2.356 | Acc: 99.409
25 Loss: 2.374 | Acc: 99.173
26 Loss: 1.936 | Acc: 99.261
27 Loss: 2.284 | Acc: 99.232
28 Loss: 1.788 | Acc: 99.468
29 Loss: 2.013 | Acc: 99.498
30 Loss: 1.474 | Acc: 99.616
31 Loss: 1.905 | Acc: 99.261
32 Loss: 1.554 | Acc: 99.468
33 Loss: 1.740 | Acc: 99.350
34 Loss: 1.338 | Acc: 99.557
35 Loss: 1.864 | Acc: 99.409
36 Loss: 1.349 | Acc: 99.586
37 Loss: 1.078 | Acc: 99.675
38 Loss: 1.278 | Acc: 99.439
39 Loss: 1.153 | Acc: 99.645
40 Loss: 1.411 | Acc: 99.557
41 Loss: 1.251 | Acc: 99.675
42 Loss: 0.846 | Acc: 99.823
43 Loss: 1.032 | Acc: 99.675
44 Loss: 0.999 | Acc: 99.734
45 Loss: 0.840 | Acc: 99.764
46 Loss: 1.157 | Acc: 99.675
47 Loss: 1.267 | Acc: 99.645
48 Loss: 0.902 | Acc: 99.734
49 Loss: 0.766 | Acc: 99.764
50 Loss: 0.868 | Acc: 99.764
51 Loss: 0.971 | Acc: 99.675
52 Loss: 0.747 | Acc: 99.823
53 Loss: 0.769 | Acc: 99.793
54 Loss: 0.708 | Acc: 99.823
55 Loss: 1.011 | Acc: 99.675
56 Loss: 0.996 | Acc: 99.616
57 Loss: 0.628 | Acc: 99.911
58 Loss: 0.741 | Acc: 99.734
59 Loss: 0.836 | Acc: 99.704
MLP trained successfully...
# of Left images:  528.0
# of Right images:  162.0
giniRightRatio:  0.6117969821673526
giniLeftRatio:  0.5826159320477502
impurityDrop:  0.51668837437013
giniGain:  0.07837148700353092
lclasses:  [12, 284, 6, 1, 4, 21, 9, 4, 187, 0]
rclasses:  [2, 92, 1, 7, 3, 2, 19, 0, 36, 0]
noOfLeftClasses:  9
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([528, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([528])
rTrainDict[data].shape:  torch.Size([162, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([162])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  100 , imgTensorShape :  torch.Size([528, 16, 8, 8])
nodeId: 100 ,  parentId: 50 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 528
nodeId:  101 , imgTensorShape :  torch.Size([162, 16, 8, 8])
nodeId: 101 ,  parentId: 50 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 162
Running nodeId:  51
trainInputDict[data].shape :  torch.Size([559, 16, 12, 12])
copy.shape :  torch.Size([559, 2304])
copyLabel.shape :  torch.Size([559])
Class 0 has 244 instances after oversampling
Class 1 has 244 instances after oversampling
Class 2 has 1 instances after oversampling
Class 3 has 244 instances after oversampling
Class 4 has 244 instances after oversampling
Class 5 has 244 instances after oversampling
Class 6 has 244 instances after oversampling
Class 7 has 244 instances after oversampling
Class 8 has 244 instances after oversampling
Class 9 has 244 instances after oversampling
0 Train Loss: 199.407 | Train Acc: 31.133
1 Train Loss: 75.347 | Train Acc: 79.426
2 Train Loss: 24.095 | Train Acc: 93.173
3 Train Loss: 16.000 | Train Acc: 95.266
4 Train Loss: 10.497 | Train Acc: 96.586
5 Train Loss: 8.126 | Train Acc: 97.132
6 Train Loss: 6.592 | Train Acc: 97.952
7 Train Loss: 4.387 | Train Acc: 98.543
8 Train Loss: 5.782 | Train Acc: 98.316
9 Train Loss: 3.438 | Train Acc: 99.135
10 Train Loss: 2.024 | Train Acc: 99.545
11 Train Loss: 1.684 | Train Acc: 99.636
12 Train Loss: 1.079 | Train Acc: 99.909
13 Train Loss: 0.735 | Train Acc: 100.000
14 Train Loss: 0.819 | Train Acc: 99.863
15 Train Loss: 9.481 | Train Acc: 97.815
16 Train Loss: 3.133 | Train Acc: 99.044
17 Train Loss: 0.944 | Train Acc: 99.863
18 Train Loss: 0.609 | Train Acc: 99.954
19 Train Loss: 0.362 | Train Acc: 100.000
20 Train Loss: 0.272 | Train Acc: 100.000
21 Train Loss: 0.238 | Train Acc: 100.000
22 Train Loss: 0.219 | Train Acc: 100.000
23 Train Loss: 0.205 | Train Acc: 100.000
24 Train Loss: 0.191 | Train Acc: 100.000
25 Train Loss: 0.179 | Train Acc: 100.000
26 Train Loss: 0.166 | Train Acc: 100.000
27 Train Loss: 0.158 | Train Acc: 100.000
28 Train Loss: 0.146 | Train Acc: 100.000
29 Train Loss: 0.142 | Train Acc: 100.000
30 Train Loss: 0.130 | Train Acc: 100.000
31 Train Loss: 0.123 | Train Acc: 100.000
32 Train Loss: 0.116 | Train Acc: 100.000
33 Train Loss: 0.109 | Train Acc: 100.000
34 Train Loss: 0.103 | Train Acc: 100.000
35 Train Loss: 0.098 | Train Acc: 100.000
36 Train Loss: 0.093 | Train Acc: 100.000
37 Train Loss: 0.088 | Train Acc: 100.000
38 Train Loss: 0.082 | Train Acc: 100.000
39 Train Loss: 0.079 | Train Acc: 100.000
40 Train Loss: 0.073 | Train Acc: 100.000
41 Train Loss: 0.071 | Train Acc: 100.000
42 Train Loss: 0.070 | Train Acc: 100.000
43 Train Loss: 0.068 | Train Acc: 100.000
44 Train Loss: 0.067 | Train Acc: 100.000
45 Train Loss: 0.065 | Train Acc: 100.000
46 Train Loss: 0.064 | Train Acc: 100.000
47 Train Loss: 0.062 | Train Acc: 100.000
48 Train Loss: 0.061 | Train Acc: 100.000
49 Train Loss: 0.059 | Train Acc: 100.000
50 Train Loss: 0.058 | Train Acc: 100.000
51 Train Loss: 0.056 | Train Acc: 100.000
52 Train Loss: 0.054 | Train Acc: 100.000
53 Train Loss: 0.053 | Train Acc: 100.000
54 Train Loss: 0.052 | Train Acc: 100.000
55 Train Loss: 0.050 | Train Acc: 100.000
56 Train Loss: 0.048 | Train Acc: 100.000
57 Train Loss: 0.047 | Train Acc: 100.000
58 Train Loss: 0.045 | Train Acc: 100.000
59 Train Loss: 0.044 | Train Acc: 100.000
60 Train Loss: 0.042 | Train Acc: 100.000
61 Train Loss: 0.041 | Train Acc: 100.000
62 Train Loss: 0.041 | Train Acc: 100.000
63 Train Loss: 0.040 | Train Acc: 100.000
64 Train Loss: 0.040 | Train Acc: 100.000
65 Train Loss: 0.039 | Train Acc: 100.000
66 Train Loss: 0.038 | Train Acc: 100.000
67 Train Loss: 0.038 | Train Acc: 100.000
68 Train Loss: 0.037 | Train Acc: 100.000
69 Train Loss: 0.036 | Train Acc: 100.000
70 Train Loss: 0.036 | Train Acc: 100.000
71 Train Loss: 0.035 | Train Acc: 100.000
72 Train Loss: 0.034 | Train Acc: 100.000
73 Train Loss: 0.033 | Train Acc: 100.000
74 Train Loss: 0.033 | Train Acc: 100.000
75 Train Loss: 0.032 | Train Acc: 100.000
76 Train Loss: 0.031 | Train Acc: 100.000
77 Train Loss: 0.031 | Train Acc: 100.000
78 Train Loss: 0.030 | Train Acc: 100.000
79 Train Loss: 0.029 | Train Acc: 100.000
80 Train Loss: 0.028 | Train Acc: 100.000
81 Train Loss: 0.028 | Train Acc: 100.000
82 Train Loss: 0.028 | Train Acc: 100.000
83 Train Loss: 0.027 | Train Acc: 100.000
84 Train Loss: 0.027 | Train Acc: 100.000
85 Train Loss: 0.027 | Train Acc: 100.000
86 Train Loss: 0.026 | Train Acc: 100.000
87 Train Loss: 0.026 | Train Acc: 100.000
88 Train Loss: 0.026 | Train Acc: 100.000
89 Train Loss: 0.025 | Train Acc: 100.000
90 Train Loss: 0.025 | Train Acc: 100.000
91 Train Loss: 0.025 | Train Acc: 100.000
92 Train Loss: 0.024 | Train Acc: 100.000
93 Train Loss: 0.024 | Train Acc: 100.000
94 Train Loss: 0.024 | Train Acc: 100.000
95 Train Loss: 0.023 | Train Acc: 100.000
96 Train Loss: 0.023 | Train Acc: 100.000
97 Train Loss: 0.023 | Train Acc: 100.000
98 Train Loss: 0.022 | Train Acc: 100.000
99 Train Loss: 0.022 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([2197, 1024])
printing expected split from k means
{9: 0, 1: 1, 8: 0, 0: 1, 6: 0, 5: 0, 3: 0, 7: 0, 4: 0, 2: 0}
Printing final_dict items...
{9: 0, 1: 1, 8: 0, 0: 1, 6: 0, 5: 0, 3: 0, 7: 0, 4: 0, 2: 0}
Image Statistics before MLP : L R :  1728 469
expectedMlpLabels.shape :  torch.Size([2197])
0 Loss: 14.341 | Acc: 92.308
1 Loss: 8.791 | Acc: 95.585
2 Loss: 5.666 | Acc: 96.632
3 Loss: 6.487 | Acc: 96.814
4 Loss: 5.530 | Acc: 97.041
5 Loss: 8.293 | Acc: 96.586
6 Loss: 3.565 | Acc: 97.815
7 Loss: 4.648 | Acc: 97.770
8 Loss: 4.919 | Acc: 97.223
9 Loss: 3.381 | Acc: 98.452
10 Loss: 2.168 | Acc: 98.635
11 Loss: 2.023 | Acc: 98.771
12 Loss: 1.828 | Acc: 98.726
13 Loss: 2.022 | Acc: 98.908
14 Loss: 1.635 | Acc: 98.908
15 Loss: 1.957 | Acc: 98.726
16 Loss: 1.439 | Acc: 99.226
17 Loss: 2.357 | Acc: 98.771
18 Loss: 1.520 | Acc: 98.999
19 Loss: 1.260 | Acc: 99.181
20 Loss: 1.571 | Acc: 99.181
21 Loss: 0.859 | Acc: 99.454
22 Loss: 0.896 | Acc: 99.454
23 Loss: 0.736 | Acc: 99.499
24 Loss: 0.935 | Acc: 99.590
25 Loss: 1.221 | Acc: 99.317
26 Loss: 0.738 | Acc: 99.636
27 Loss: 1.028 | Acc: 99.590
28 Loss: 0.611 | Acc: 99.545
29 Loss: 0.779 | Acc: 99.681
30 Loss: 0.570 | Acc: 99.545
31 Loss: 0.576 | Acc: 99.681
32 Loss: 0.743 | Acc: 99.499
33 Loss: 0.480 | Acc: 99.727
34 Loss: 0.625 | Acc: 99.636
35 Loss: 0.363 | Acc: 99.772
36 Loss: 0.454 | Acc: 99.681
37 Loss: 0.325 | Acc: 99.772
38 Loss: 0.520 | Acc: 99.681
39 Loss: 0.384 | Acc: 99.818
40 Loss: 0.367 | Acc: 99.727
41 Loss: 0.218 | Acc: 99.909
42 Loss: 0.269 | Acc: 99.772
43 Loss: 0.704 | Acc: 99.590
44 Loss: 0.265 | Acc: 99.727
45 Loss: 0.228 | Acc: 99.909
46 Loss: 0.273 | Acc: 99.863
47 Loss: 0.281 | Acc: 99.863
48 Loss: 0.357 | Acc: 99.863
49 Loss: 0.341 | Acc: 99.772
50 Loss: 0.280 | Acc: 99.909
51 Loss: 0.221 | Acc: 99.909
52 Loss: 0.152 | Acc: 99.954
53 Loss: 0.482 | Acc: 99.727
54 Loss: 0.299 | Acc: 99.772
55 Loss: 0.359 | Acc: 99.818
56 Loss: 0.184 | Acc: 99.863
57 Loss: 0.360 | Acc: 99.818
58 Loss: 0.501 | Acc: 99.727
59 Loss: 0.467 | Acc: 99.772
MLP trained successfully...
# of Left images:  375.0
# of Right images:  184.0
giniRightRatio:  0.35532844990548207
giniLeftRatio:  0.5733831111111112
impurityDrop:  0.799733330079998
giniGain:  -0.18177575825963144
lclasses:  [8, 97, 1, 7, 6, 9, 7, 8, 8, 224]
rclasses:  [8, 146, 0, 0, 1, 0, 3, 0, 6, 20]
noOfLeftClasses:  10
noOfRightClasses:  6
lTrainDict[data].shape:  torch.Size([375, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([375])
rTrainDict[data].shape:  torch.Size([184, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([184])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  102 , imgTensorShape :  torch.Size([375, 16, 8, 8])
nodeId: 102 ,  parentId: 51 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 375
nodeId:  103 , imgTensorShape :  torch.Size([184, 16, 8, 8])
nodeId: 103 ,  parentId: 51 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 6 ,  numData: 184
Running nodeId:  52
trainInputDict[data].shape :  torch.Size([1005, 16, 12, 12])
copy.shape :  torch.Size([1005, 2304])
copyLabel.shape :  torch.Size([1005])
Class 0 has 403 instances after oversampling
Class 1 has 403 instances after oversampling
Class 2 has 403 instances after oversampling
Class 3 has 403 instances after oversampling
Class 4 has 403 instances after oversampling
Class 5 has 403 instances after oversampling
Class 6 has 403 instances after oversampling
Class 7 has 403 instances after oversampling
Class 8 has 403 instances after oversampling
Class 9 has 403 instances after oversampling
0 Train Loss: 213.096 | Train Acc: 22.425
1 Train Loss: 137.715 | Train Acc: 55.750
2 Train Loss: 89.466 | Train Acc: 70.225
3 Train Loss: 74.948 | Train Acc: 75.600
4 Train Loss: 58.179 | Train Acc: 81.675
5 Train Loss: 46.619 | Train Acc: 85.875
6 Train Loss: 34.755 | Train Acc: 89.000
7 Train Loss: 28.679 | Train Acc: 90.975
8 Train Loss: 21.265 | Train Acc: 93.400
9 Train Loss: 16.187 | Train Acc: 95.400
10 Train Loss: 12.610 | Train Acc: 96.475
11 Train Loss: 12.689 | Train Acc: 96.450
12 Train Loss: 11.720 | Train Acc: 96.600
13 Train Loss: 7.857 | Train Acc: 98.200
14 Train Loss: 5.798 | Train Acc: 98.925
15 Train Loss: 4.317 | Train Acc: 99.300
16 Train Loss: 4.460 | Train Acc: 99.150
17 Train Loss: 3.673 | Train Acc: 99.450
18 Train Loss: 3.142 | Train Acc: 99.525
19 Train Loss: 2.163 | Train Acc: 99.800
20 Train Loss: 1.367 | Train Acc: 99.975
21 Train Loss: 1.207 | Train Acc: 100.000
22 Train Loss: 1.113 | Train Acc: 100.000
23 Train Loss: 1.034 | Train Acc: 100.000
24 Train Loss: 0.978 | Train Acc: 100.000
25 Train Loss: 0.910 | Train Acc: 100.000
26 Train Loss: 0.844 | Train Acc: 100.000
27 Train Loss: 0.812 | Train Acc: 100.000
28 Train Loss: 0.759 | Train Acc: 100.000
29 Train Loss: 0.706 | Train Acc: 100.000
30 Train Loss: 0.664 | Train Acc: 100.000
31 Train Loss: 0.626 | Train Acc: 100.000
32 Train Loss: 0.616 | Train Acc: 100.000
33 Train Loss: 0.562 | Train Acc: 100.000
34 Train Loss: 0.524 | Train Acc: 100.000
35 Train Loss: 0.496 | Train Acc: 100.000
36 Train Loss: 0.471 | Train Acc: 100.000
37 Train Loss: 0.459 | Train Acc: 100.000
38 Train Loss: 0.409 | Train Acc: 100.000
39 Train Loss: 0.392 | Train Acc: 100.000
40 Train Loss: 0.354 | Train Acc: 100.000
41 Train Loss: 0.346 | Train Acc: 100.000
42 Train Loss: 0.336 | Train Acc: 100.000
43 Train Loss: 0.328 | Train Acc: 100.000
44 Train Loss: 0.320 | Train Acc: 100.000
45 Train Loss: 0.311 | Train Acc: 100.000
46 Train Loss: 0.302 | Train Acc: 100.000
47 Train Loss: 0.297 | Train Acc: 100.000
48 Train Loss: 0.289 | Train Acc: 100.000
49 Train Loss: 0.278 | Train Acc: 100.000
50 Train Loss: 0.272 | Train Acc: 100.000
51 Train Loss: 0.264 | Train Acc: 100.000
52 Train Loss: 0.256 | Train Acc: 100.000
53 Train Loss: 0.249 | Train Acc: 100.000
54 Train Loss: 0.241 | Train Acc: 100.000
55 Train Loss: 0.235 | Train Acc: 100.000
56 Train Loss: 0.225 | Train Acc: 100.000
57 Train Loss: 0.220 | Train Acc: 100.000
58 Train Loss: 0.212 | Train Acc: 100.000
59 Train Loss: 0.203 | Train Acc: 100.000
60 Train Loss: 0.191 | Train Acc: 100.000
61 Train Loss: 0.187 | Train Acc: 100.000
62 Train Loss: 0.185 | Train Acc: 100.000
63 Train Loss: 0.182 | Train Acc: 100.000
64 Train Loss: 0.179 | Train Acc: 100.000
65 Train Loss: 0.176 | Train Acc: 100.000
66 Train Loss: 0.174 | Train Acc: 100.000
67 Train Loss: 0.170 | Train Acc: 100.000
68 Train Loss: 0.168 | Train Acc: 100.000
69 Train Loss: 0.165 | Train Acc: 100.000
70 Train Loss: 0.161 | Train Acc: 100.000
71 Train Loss: 0.159 | Train Acc: 100.000
72 Train Loss: 0.156 | Train Acc: 100.000
73 Train Loss: 0.152 | Train Acc: 100.000
74 Train Loss: 0.150 | Train Acc: 100.000
75 Train Loss: 0.147 | Train Acc: 100.000
76 Train Loss: 0.142 | Train Acc: 100.000
77 Train Loss: 0.140 | Train Acc: 100.000
78 Train Loss: 0.137 | Train Acc: 100.000
79 Train Loss: 0.133 | Train Acc: 100.000
80 Train Loss: 0.128 | Train Acc: 100.000
81 Train Loss: 0.126 | Train Acc: 100.000
82 Train Loss: 0.125 | Train Acc: 100.000
83 Train Loss: 0.124 | Train Acc: 100.000
84 Train Loss: 0.123 | Train Acc: 100.000
85 Train Loss: 0.121 | Train Acc: 100.000
86 Train Loss: 0.120 | Train Acc: 100.000
87 Train Loss: 0.119 | Train Acc: 100.000
88 Train Loss: 0.117 | Train Acc: 100.000
89 Train Loss: 0.115 | Train Acc: 100.000
90 Train Loss: 0.114 | Train Acc: 100.000
91 Train Loss: 0.113 | Train Acc: 100.000
92 Train Loss: 0.111 | Train Acc: 100.000
93 Train Loss: 0.110 | Train Acc: 100.000
94 Train Loss: 0.109 | Train Acc: 100.000
95 Train Loss: 0.107 | Train Acc: 100.000
96 Train Loss: 0.105 | Train Acc: 100.000
97 Train Loss: 0.104 | Train Acc: 100.000
98 Train Loss: 0.102 | Train Acc: 100.000
99 Train Loss: 0.101 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([4030, 1024])
printing expected split from k means
{0: 0, 1: 0, 6: 0, 8: 0, 9: 0, 2: 0, 4: 0, 3: 0, 7: 0, 5: 1}
Printing final_dict items...
{0: 0, 1: 0, 6: 0, 8: 0, 9: 0, 2: 0, 4: 0, 3: 0, 7: 0, 5: 1}
Image Statistics before MLP : L R :  3093 937
expectedMlpLabels.shape :  torch.Size([4030])
0 Loss: 25.097 | Acc: 88.775
1 Loss: 16.817 | Acc: 91.000
2 Loss: 12.417 | Acc: 92.900
3 Loss: 11.751 | Acc: 94.250
4 Loss: 10.715 | Acc: 94.300
5 Loss: 9.885 | Acc: 94.950
6 Loss: 9.323 | Acc: 94.925
7 Loss: 8.660 | Acc: 95.075
8 Loss: 7.551 | Acc: 96.100
9 Loss: 8.811 | Acc: 95.300
10 Loss: 5.813 | Acc: 96.950
11 Loss: 4.417 | Acc: 97.725
12 Loss: 5.056 | Acc: 97.425
13 Loss: 4.362 | Acc: 97.725
14 Loss: 4.819 | Acc: 97.650
15 Loss: 3.805 | Acc: 98.075
16 Loss: 4.364 | Acc: 97.625
17 Loss: 3.931 | Acc: 97.850
18 Loss: 4.229 | Acc: 97.875
19 Loss: 4.549 | Acc: 97.625
20 Loss: 3.286 | Acc: 98.200
21 Loss: 2.810 | Acc: 98.450
22 Loss: 2.497 | Acc: 98.700
23 Loss: 2.840 | Acc: 98.275
24 Loss: 2.541 | Acc: 98.600
25 Loss: 2.291 | Acc: 98.675
26 Loss: 2.643 | Acc: 98.500
27 Loss: 2.580 | Acc: 98.550
28 Loss: 2.243 | Acc: 98.725
29 Loss: 2.396 | Acc: 98.550
30 Loss: 2.102 | Acc: 98.850
31 Loss: 1.973 | Acc: 98.850
32 Loss: 2.270 | Acc: 98.800
33 Loss: 2.189 | Acc: 98.850
34 Loss: 2.044 | Acc: 98.925
35 Loss: 1.999 | Acc: 98.800
36 Loss: 1.982 | Acc: 98.825
37 Loss: 2.107 | Acc: 98.825
38 Loss: 2.122 | Acc: 99.050
39 Loss: 1.768 | Acc: 99.125
40 Loss: 1.575 | Acc: 99.125
41 Loss: 1.652 | Acc: 99.075
42 Loss: 1.717 | Acc: 98.975
43 Loss: 1.670 | Acc: 99.100
44 Loss: 1.594 | Acc: 99.125
45 Loss: 1.473 | Acc: 99.225
46 Loss: 1.501 | Acc: 99.025
47 Loss: 1.700 | Acc: 99.100
48 Loss: 1.544 | Acc: 99.075
49 Loss: 2.019 | Acc: 98.825
50 Loss: 1.872 | Acc: 98.900
51 Loss: 1.603 | Acc: 99.025
52 Loss: 1.521 | Acc: 99.100
53 Loss: 1.789 | Acc: 99.000
54 Loss: 1.548 | Acc: 99.075
55 Loss: 1.720 | Acc: 99.025
56 Loss: 1.768 | Acc: 99.000
57 Loss: 1.544 | Acc: 99.100
58 Loss: 1.545 | Acc: 99.200
59 Loss: 1.445 | Acc: 99.275
MLP trained successfully...
# of Left images:  774.0
# of Right images:  231.0
giniRightRatio:  0.7523097393227263
giniLeftRatio:  0.7687238347054464
impurityDrop:  0.8073076173583338
giniGain:  -0.04096222986792519
lclasses:  [103, 308, 28, 9, 27, 0, 62, 4, 132, 101]
rclasses:  [37, 95, 4, 1, 2, 4, 17, 2, 27, 42]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([774, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([774])
rTrainDict[data].shape:  torch.Size([231, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([231])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  104 , imgTensorShape :  torch.Size([774, 16, 8, 8])
nodeId: 104 ,  parentId: 52 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 774
nodeId:  105 , imgTensorShape :  torch.Size([231, 16, 8, 8])
nodeId: 105 ,  parentId: 52 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 231
Running nodeId:  53
trainInputDict[data].shape :  torch.Size([143, 16, 12, 12])
copy.shape :  torch.Size([143, 2304])
copyLabel.shape :  torch.Size([143])
Class 0 has 59 instances after oversampling
Class 1 has 59 instances after oversampling
Class 2 has 59 instances after oversampling
Class 3 has 59 instances after oversampling
Class 4 has 59 instances after oversampling
Class 5 has 59 instances after oversampling
Class 6 has 59 instances after oversampling
0 Train Loss: 2.019 | Train Acc: 20.339
1 Train Loss: 1.706 | Train Acc: 40.920
2 Train Loss: 1.474 | Train Acc: 56.659
3 Train Loss: 1.273 | Train Acc: 63.680
4 Train Loss: 1.092 | Train Acc: 71.913
5 Train Loss: 0.935 | Train Acc: 78.935
6 Train Loss: 0.803 | Train Acc: 81.598
7 Train Loss: 0.691 | Train Acc: 85.714
8 Train Loss: 0.604 | Train Acc: 86.925
9 Train Loss: 0.529 | Train Acc: 88.136
10 Train Loss: 0.463 | Train Acc: 89.346
11 Train Loss: 0.412 | Train Acc: 89.831
12 Train Loss: 0.365 | Train Acc: 91.041
13 Train Loss: 0.324 | Train Acc: 92.010
14 Train Loss: 0.290 | Train Acc: 92.736
15 Train Loss: 0.258 | Train Acc: 94.189
16 Train Loss: 0.229 | Train Acc: 94.673
17 Train Loss: 0.204 | Train Acc: 94.673
18 Train Loss: 0.183 | Train Acc: 95.884
19 Train Loss: 0.163 | Train Acc: 96.368
20 Train Loss: 0.147 | Train Acc: 97.337
21 Train Loss: 0.140 | Train Acc: 97.337
22 Train Loss: 0.134 | Train Acc: 97.579
23 Train Loss: 0.128 | Train Acc: 97.821
24 Train Loss: 0.122 | Train Acc: 98.063
25 Train Loss: 0.116 | Train Acc: 98.063
26 Train Loss: 0.111 | Train Acc: 98.305
27 Train Loss: 0.106 | Train Acc: 98.305
28 Train Loss: 0.101 | Train Acc: 98.305
29 Train Loss: 0.097 | Train Acc: 98.305
30 Train Loss: 0.093 | Train Acc: 98.305
31 Train Loss: 0.089 | Train Acc: 98.305
32 Train Loss: 0.086 | Train Acc: 98.305
33 Train Loss: 0.082 | Train Acc: 98.789
34 Train Loss: 0.079 | Train Acc: 98.789
35 Train Loss: 0.076 | Train Acc: 98.789
36 Train Loss: 0.073 | Train Acc: 98.789
37 Train Loss: 0.070 | Train Acc: 99.031
38 Train Loss: 0.067 | Train Acc: 99.031
39 Train Loss: 0.064 | Train Acc: 99.516
40 Train Loss: 0.062 | Train Acc: 99.516
41 Train Loss: 0.061 | Train Acc: 99.758
42 Train Loss: 0.060 | Train Acc: 99.758
43 Train Loss: 0.059 | Train Acc: 99.758
44 Train Loss: 0.058 | Train Acc: 99.758
45 Train Loss: 0.057 | Train Acc: 99.758
46 Train Loss: 0.056 | Train Acc: 99.758
47 Train Loss: 0.055 | Train Acc: 99.758
48 Train Loss: 0.054 | Train Acc: 99.758
49 Train Loss: 0.054 | Train Acc: 99.758
50 Train Loss: 0.053 | Train Acc: 99.758
51 Train Loss: 0.052 | Train Acc: 99.758
52 Train Loss: 0.051 | Train Acc: 99.758
53 Train Loss: 0.051 | Train Acc: 99.758
54 Train Loss: 0.050 | Train Acc: 99.758
55 Train Loss: 0.049 | Train Acc: 99.758
56 Train Loss: 0.048 | Train Acc: 99.758
57 Train Loss: 0.048 | Train Acc: 99.758
58 Train Loss: 0.047 | Train Acc: 99.758
59 Train Loss: 0.046 | Train Acc: 99.758
60 Train Loss: 0.046 | Train Acc: 99.758
61 Train Loss: 0.045 | Train Acc: 99.758
62 Train Loss: 0.045 | Train Acc: 99.758
63 Train Loss: 0.045 | Train Acc: 99.758
64 Train Loss: 0.045 | Train Acc: 99.758
65 Train Loss: 0.044 | Train Acc: 99.758
66 Train Loss: 0.044 | Train Acc: 99.758
67 Train Loss: 0.044 | Train Acc: 99.758
68 Train Loss: 0.044 | Train Acc: 99.758
69 Train Loss: 0.043 | Train Acc: 99.758
70 Train Loss: 0.043 | Train Acc: 99.758
71 Train Loss: 0.043 | Train Acc: 99.758
72 Train Loss: 0.043 | Train Acc: 99.758
73 Train Loss: 0.042 | Train Acc: 99.758
74 Train Loss: 0.042 | Train Acc: 99.758
75 Train Loss: 0.042 | Train Acc: 99.758
76 Train Loss: 0.042 | Train Acc: 99.758
77 Train Loss: 0.042 | Train Acc: 99.758
78 Train Loss: 0.041 | Train Acc: 99.758
79 Train Loss: 0.041 | Train Acc: 99.758
80 Train Loss: 0.041 | Train Acc: 99.758
81 Train Loss: 0.041 | Train Acc: 99.758
82 Train Loss: 0.041 | Train Acc: 99.758
83 Train Loss: 0.041 | Train Acc: 99.758
84 Train Loss: 0.041 | Train Acc: 99.758
85 Train Loss: 0.040 | Train Acc: 99.758
86 Train Loss: 0.040 | Train Acc: 99.758
87 Train Loss: 0.040 | Train Acc: 99.758
88 Train Loss: 0.040 | Train Acc: 99.758
89 Train Loss: 0.040 | Train Acc: 99.758
90 Train Loss: 0.040 | Train Acc: 99.758
91 Train Loss: 0.040 | Train Acc: 99.758
92 Train Loss: 0.040 | Train Acc: 99.758
93 Train Loss: 0.040 | Train Acc: 99.758
94 Train Loss: 0.040 | Train Acc: 99.758
95 Train Loss: 0.040 | Train Acc: 99.758
96 Train Loss: 0.039 | Train Acc: 99.758
97 Train Loss: 0.039 | Train Acc: 99.758
98 Train Loss: 0.039 | Train Acc: 100.000
99 Train Loss: 0.039 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([413, 1024])
printing expected split from k means
{1: 0, 0: 0, 5: 0, 2: 0, 4: 0, 6: 0, 3: 1}
Printing final_dict items...
{1: 0, 0: 0, 5: 0, 2: 0, 4: 0, 6: 0, 3: 1}
Image Statistics before MLP : L R :  365 48
expectedMlpLabels.shape :  torch.Size([413])
0 Loss: 0.169 | Acc: 37.046
1 Loss: 0.091 | Acc: 66.828
2 Loss: 0.094 | Acc: 95.642
3 Loss: 0.045 | Acc: 96.852
4 Loss: 0.037 | Acc: 94.431
5 Loss: 0.025 | Acc: 95.400
6 Loss: 0.019 | Acc: 97.337
7 Loss: 0.011 | Acc: 98.547
8 Loss: 0.015 | Acc: 98.063
9 Loss: 0.012 | Acc: 97.337
10 Loss: 0.007 | Acc: 98.547
11 Loss: 0.009 | Acc: 98.305
12 Loss: 0.008 | Acc: 98.305
13 Loss: 0.010 | Acc: 98.547
14 Loss: 0.010 | Acc: 97.821
15 Loss: 0.006 | Acc: 98.789
16 Loss: 0.008 | Acc: 98.789
17 Loss: 0.005 | Acc: 98.789
18 Loss: 0.004 | Acc: 99.516
19 Loss: 0.009 | Acc: 98.789
20 Loss: 0.004 | Acc: 99.031
21 Loss: 0.008 | Acc: 99.031
22 Loss: 0.006 | Acc: 98.789
23 Loss: 0.011 | Acc: 98.305
24 Loss: 0.004 | Acc: 99.274
25 Loss: 0.005 | Acc: 99.031
26 Loss: 0.005 | Acc: 98.789
27 Loss: 0.005 | Acc: 99.031
28 Loss: 0.004 | Acc: 99.274
29 Loss: 0.004 | Acc: 98.789
30 Loss: 0.007 | Acc: 99.031
31 Loss: 0.007 | Acc: 99.031
32 Loss: 0.004 | Acc: 99.274
33 Loss: 0.005 | Acc: 98.789
34 Loss: 0.003 | Acc: 99.274
35 Loss: 0.005 | Acc: 99.031
36 Loss: 0.005 | Acc: 99.031
37 Loss: 0.004 | Acc: 99.031
38 Loss: 0.004 | Acc: 98.789
39 Loss: 0.005 | Acc: 99.031
40 Loss: 0.005 | Acc: 99.031
41 Loss: 0.004 | Acc: 99.274
42 Loss: 0.003 | Acc: 99.031
43 Loss: 0.005 | Acc: 99.031
44 Loss: 0.009 | Acc: 98.305
45 Loss: 0.004 | Acc: 99.516
46 Loss: 0.007 | Acc: 98.789
47 Loss: 0.006 | Acc: 98.789
48 Loss: 0.006 | Acc: 99.031
49 Loss: 0.004 | Acc: 99.274
50 Loss: 0.003 | Acc: 99.274
51 Loss: 0.005 | Acc: 99.031
52 Loss: 0.003 | Acc: 99.031
53 Loss: 0.003 | Acc: 99.274
54 Loss: 0.004 | Acc: 99.031
55 Loss: 0.003 | Acc: 99.031
56 Loss: 0.005 | Acc: 99.274
57 Loss: 0.003 | Acc: 98.789
58 Loss: 0.002 | Acc: 99.516
59 Loss: 0.002 | Acc: 99.274
MLP trained successfully...
# of Left images:  133.0
# of Right images:  10.0
giniRightRatio:  0.4800000000000001
giniLeftRatio:  0.7230482220589066
impurityDrop:  3.7125413533834575
giniGain:  -2.9957336855268384
lclasses:  [42, 52, 7, 1, 4, 14, 13, 0, 0, 0]
rclasses:  [1, 7, 0, 1, 0, 0, 1, 0, 0, 0]
noOfLeftClasses:  7
noOfRightClasses:  4
lTrainDict[data].shape:  torch.Size([133, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([133])
rTrainDict[data].shape:  torch.Size([10, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([10])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
DATANUM THRESHOLD REACHED IN RIGHT 10 100
nodeId:  106 , imgTensorShape :  torch.Size([133, 16, 8, 8])
nodeId: 106 ,  parentId: 53 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 7 ,  numData: 133
nodeId:  107 , imgTensorShape :  torch.Size([10, 16, 8, 8])
nodeId: 107 ,  parentId: 53 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 4 ,  numData: 10
Running nodeId:  54
trainInputDict[data].shape :  torch.Size([904, 16, 12, 12])
copy.shape :  torch.Size([904, 2304])
copyLabel.shape :  torch.Size([904])
Class 0 has 144 instances after oversampling
Class 1 has 144 instances after oversampling
Class 2 has 144 instances after oversampling
Class 3 has 144 instances after oversampling
Class 4 has 144 instances after oversampling
Class 5 has 144 instances after oversampling
Class 6 has 144 instances after oversampling
Class 7 has 144 instances after oversampling
Class 8 has 144 instances after oversampling
Class 9 has 144 instances after oversampling
0 Train Loss: 223.089 | Train Acc: 19.214
1 Train Loss: 177.427 | Train Acc: 41.000
2 Train Loss: 127.565 | Train Acc: 59.357
3 Train Loss: 89.694 | Train Acc: 72.214
4 Train Loss: 61.881 | Train Acc: 81.500
5 Train Loss: 46.468 | Train Acc: 87.571
6 Train Loss: 33.483 | Train Acc: 90.714
7 Train Loss: 20.948 | Train Acc: 95.286
8 Train Loss: 15.760 | Train Acc: 97.000
9 Train Loss: 11.361 | Train Acc: 98.286
10 Train Loss: 6.951 | Train Acc: 99.714
11 Train Loss: 4.813 | Train Acc: 100.000
12 Train Loss: 3.188 | Train Acc: 100.000
13 Train Loss: 2.349 | Train Acc: 100.000
14 Train Loss: 1.858 | Train Acc: 100.000
15 Train Loss: 1.497 | Train Acc: 100.000
16 Train Loss: 1.287 | Train Acc: 100.000
17 Train Loss: 1.091 | Train Acc: 100.000
18 Train Loss: 0.957 | Train Acc: 100.000
19 Train Loss: 0.841 | Train Acc: 100.000
20 Train Loss: 0.707 | Train Acc: 100.000
21 Train Loss: 0.670 | Train Acc: 100.000
22 Train Loss: 0.639 | Train Acc: 100.000
23 Train Loss: 0.611 | Train Acc: 100.000
24 Train Loss: 0.582 | Train Acc: 100.000
25 Train Loss: 0.555 | Train Acc: 100.000
26 Train Loss: 0.539 | Train Acc: 100.000
27 Train Loss: 0.515 | Train Acc: 100.000
28 Train Loss: 0.482 | Train Acc: 100.000
29 Train Loss: 0.465 | Train Acc: 100.000
30 Train Loss: 0.444 | Train Acc: 100.000
31 Train Loss: 0.424 | Train Acc: 100.000
32 Train Loss: 0.399 | Train Acc: 100.000
33 Train Loss: 0.383 | Train Acc: 100.000
34 Train Loss: 0.359 | Train Acc: 100.000
35 Train Loss: 0.342 | Train Acc: 100.000
36 Train Loss: 0.326 | Train Acc: 100.000
37 Train Loss: 0.308 | Train Acc: 100.000
38 Train Loss: 0.292 | Train Acc: 100.000
39 Train Loss: 0.279 | Train Acc: 100.000
40 Train Loss: 0.256 | Train Acc: 100.000
41 Train Loss: 0.252 | Train Acc: 100.000
42 Train Loss: 0.245 | Train Acc: 100.000
43 Train Loss: 0.241 | Train Acc: 100.000
44 Train Loss: 0.235 | Train Acc: 100.000
45 Train Loss: 0.231 | Train Acc: 100.000
46 Train Loss: 0.225 | Train Acc: 100.000
47 Train Loss: 0.219 | Train Acc: 100.000
48 Train Loss: 0.214 | Train Acc: 100.000
49 Train Loss: 0.208 | Train Acc: 100.000
50 Train Loss: 0.203 | Train Acc: 100.000
51 Train Loss: 0.198 | Train Acc: 100.000
52 Train Loss: 0.192 | Train Acc: 100.000
53 Train Loss: 0.187 | Train Acc: 100.000
54 Train Loss: 0.181 | Train Acc: 100.000
55 Train Loss: 0.176 | Train Acc: 100.000
56 Train Loss: 0.170 | Train Acc: 100.000
57 Train Loss: 0.165 | Train Acc: 100.000
58 Train Loss: 0.159 | Train Acc: 100.000
59 Train Loss: 0.155 | Train Acc: 100.000
60 Train Loss: 0.147 | Train Acc: 100.000
61 Train Loss: 0.145 | Train Acc: 100.000
62 Train Loss: 0.143 | Train Acc: 100.000
63 Train Loss: 0.141 | Train Acc: 100.000
64 Train Loss: 0.138 | Train Acc: 100.000
65 Train Loss: 0.137 | Train Acc: 100.000
66 Train Loss: 0.134 | Train Acc: 100.000
67 Train Loss: 0.132 | Train Acc: 100.000
68 Train Loss: 0.130 | Train Acc: 100.000
69 Train Loss: 0.128 | Train Acc: 100.000
70 Train Loss: 0.125 | Train Acc: 100.000
71 Train Loss: 0.123 | Train Acc: 100.000
72 Train Loss: 0.120 | Train Acc: 100.000
73 Train Loss: 0.118 | Train Acc: 100.000
74 Train Loss: 0.116 | Train Acc: 100.000
75 Train Loss: 0.113 | Train Acc: 100.000
76 Train Loss: 0.111 | Train Acc: 100.000
77 Train Loss: 0.109 | Train Acc: 100.000
78 Train Loss: 0.106 | Train Acc: 100.000
79 Train Loss: 0.104 | Train Acc: 100.000
80 Train Loss: 0.099 | Train Acc: 100.000
81 Train Loss: 0.099 | Train Acc: 100.000
82 Train Loss: 0.097 | Train Acc: 100.000
83 Train Loss: 0.096 | Train Acc: 100.000
84 Train Loss: 0.095 | Train Acc: 100.000
85 Train Loss: 0.094 | Train Acc: 100.000
86 Train Loss: 0.093 | Train Acc: 100.000
87 Train Loss: 0.092 | Train Acc: 100.000
88 Train Loss: 0.091 | Train Acc: 100.000
89 Train Loss: 0.090 | Train Acc: 100.000
90 Train Loss: 0.088 | Train Acc: 100.000
91 Train Loss: 0.087 | Train Acc: 100.000
92 Train Loss: 0.086 | Train Acc: 100.000
93 Train Loss: 0.085 | Train Acc: 100.000
94 Train Loss: 0.084 | Train Acc: 100.000
95 Train Loss: 0.082 | Train Acc: 100.000
96 Train Loss: 0.081 | Train Acc: 100.000
97 Train Loss: 0.080 | Train Acc: 100.000
98 Train Loss: 0.079 | Train Acc: 100.000
99 Train Loss: 0.077 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([1440, 1024])
printing expected split from k means
{1: 1, 4: 0, 6: 0, 8: 0, 2: 0, 7: 0, 9: 0, 5: 0, 3: 0, 0: 0}
Printing final_dict items...
{1: 1, 4: 0, 6: 0, 8: 0, 2: 0, 7: 0, 9: 0, 5: 0, 3: 0, 0: 0}
Image Statistics before MLP : L R :  1041 399
expectedMlpLabels.shape :  torch.Size([1440])
0 Loss: 54.159 | Acc: 76.857
1 Loss: 33.395 | Acc: 84.143
2 Loss: 28.846 | Acc: 86.214
3 Loss: 26.218 | Acc: 88.286
4 Loss: 23.134 | Acc: 89.429
5 Loss: 25.823 | Acc: 88.857
6 Loss: 18.778 | Acc: 91.786
7 Loss: 18.518 | Acc: 90.929
8 Loss: 14.135 | Acc: 92.857
9 Loss: 14.667 | Acc: 94.214
10 Loss: 12.281 | Acc: 93.929
11 Loss: 8.297 | Acc: 95.929
12 Loss: 7.405 | Acc: 96.143
13 Loss: 8.188 | Acc: 96.571
14 Loss: 6.890 | Acc: 96.286
15 Loss: 6.589 | Acc: 97.143
16 Loss: 6.744 | Acc: 97.000
17 Loss: 5.498 | Acc: 97.500
18 Loss: 5.667 | Acc: 97.643
19 Loss: 6.388 | Acc: 96.500
20 Loss: 4.325 | Acc: 98.000
21 Loss: 3.766 | Acc: 98.214
22 Loss: 3.095 | Acc: 98.643
23 Loss: 2.814 | Acc: 98.857
24 Loss: 2.407 | Acc: 99.000
25 Loss: 2.152 | Acc: 99.000
26 Loss: 3.031 | Acc: 98.929
27 Loss: 2.714 | Acc: 99.000
28 Loss: 3.620 | Acc: 99.071
29 Loss: 2.087 | Acc: 99.214
30 Loss: 1.733 | Acc: 99.143
31 Loss: 2.795 | Acc: 99.000
32 Loss: 1.957 | Acc: 99.429
33 Loss: 1.488 | Acc: 99.357
34 Loss: 1.604 | Acc: 99.429
35 Loss: 1.709 | Acc: 99.500
36 Loss: 1.847 | Acc: 99.429
37 Loss: 1.456 | Acc: 99.500
38 Loss: 1.562 | Acc: 99.643
39 Loss: 0.995 | Acc: 99.714
40 Loss: 1.192 | Acc: 99.571
41 Loss: 1.018 | Acc: 99.786
42 Loss: 1.112 | Acc: 99.643
43 Loss: 0.822 | Acc: 99.857
44 Loss: 0.935 | Acc: 99.714
45 Loss: 1.057 | Acc: 99.643
46 Loss: 1.099 | Acc: 99.714
47 Loss: 0.853 | Acc: 99.786
48 Loss: 0.893 | Acc: 99.714
49 Loss: 0.693 | Acc: 99.714
50 Loss: 1.198 | Acc: 99.571
51 Loss: 0.574 | Acc: 99.786
52 Loss: 0.909 | Acc: 99.643
53 Loss: 0.600 | Acc: 99.857
54 Loss: 0.846 | Acc: 99.714
55 Loss: 0.648 | Acc: 99.929
56 Loss: 0.948 | Acc: 99.857
57 Loss: 0.601 | Acc: 99.857
58 Loss: 0.783 | Acc: 99.929
59 Loss: 0.899 | Acc: 99.786
MLP trained successfully...
# of Left images:  618.0
# of Right images:  286.0
giniRightRatio:  0.8852511125238398
giniLeftRatio:  0.8763209434337721
impurityDrop:  0.8659544534411061
giniGain:  0.01942958211375334
lclasses:  [23, 64, 56, 85, 34, 37, 122, 44, 52, 101]
rclasses:  [23, 48, 43, 31, 20, 25, 22, 9, 28, 37]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([618, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([618])
rTrainDict[data].shape:  torch.Size([286, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([286])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  108 , imgTensorShape :  torch.Size([618, 16, 8, 8])
nodeId: 108 ,  parentId: 54 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 618
nodeId:  109 , imgTensorShape :  torch.Size([286, 16, 8, 8])
nodeId: 109 ,  parentId: 54 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 286
Running nodeId:  55
trainInputDict[data].shape :  torch.Size([379, 16, 12, 12])
copy.shape :  torch.Size([379, 2304])
copyLabel.shape :  torch.Size([379])
Class 0 has 78 instances after oversampling
Class 1 has 78 instances after oversampling
Class 2 has 78 instances after oversampling
Class 3 has 78 instances after oversampling
Class 4 has 78 instances after oversampling
Class 5 has 78 instances after oversampling
Class 6 has 78 instances after oversampling
Class 7 has 78 instances after oversampling
Class 8 has 78 instances after oversampling
Class 9 has 78 instances after oversampling
0 Train Loss: 217.219 | Train Acc: 22.429
1 Train Loss: 134.496 | Train Acc: 61.000
2 Train Loss: 88.322 | Train Acc: 75.000
3 Train Loss: 43.484 | Train Acc: 88.571
4 Train Loss: 25.161 | Train Acc: 94.143
5 Train Loss: 13.323 | Train Acc: 97.571
6 Train Loss: 5.115 | Train Acc: 99.857
7 Train Loss: 2.613 | Train Acc: 100.000
8 Train Loss: 1.565 | Train Acc: 100.000
9 Train Loss: 1.133 | Train Acc: 100.000
10 Train Loss: 0.858 | Train Acc: 100.000
11 Train Loss: 0.702 | Train Acc: 100.000
12 Train Loss: 0.575 | Train Acc: 100.000
13 Train Loss: 0.477 | Train Acc: 100.000
14 Train Loss: 0.411 | Train Acc: 100.000
15 Train Loss: 0.350 | Train Acc: 100.000
16 Train Loss: 0.307 | Train Acc: 100.000
17 Train Loss: 0.273 | Train Acc: 100.000
18 Train Loss: 0.240 | Train Acc: 100.000
19 Train Loss: 0.219 | Train Acc: 100.000
20 Train Loss: 0.188 | Train Acc: 100.000
21 Train Loss: 0.178 | Train Acc: 100.000
22 Train Loss: 0.171 | Train Acc: 100.000
23 Train Loss: 0.165 | Train Acc: 100.000
24 Train Loss: 0.157 | Train Acc: 100.000
25 Train Loss: 0.151 | Train Acc: 100.000
26 Train Loss: 0.144 | Train Acc: 100.000
27 Train Loss: 0.138 | Train Acc: 100.000
28 Train Loss: 0.131 | Train Acc: 100.000
29 Train Loss: 0.125 | Train Acc: 100.000
30 Train Loss: 0.119 | Train Acc: 100.000
31 Train Loss: 0.114 | Train Acc: 100.000
32 Train Loss: 0.108 | Train Acc: 100.000
33 Train Loss: 0.103 | Train Acc: 100.000
34 Train Loss: 0.098 | Train Acc: 100.000
35 Train Loss: 0.094 | Train Acc: 100.000
36 Train Loss: 0.089 | Train Acc: 100.000
37 Train Loss: 0.084 | Train Acc: 100.000
38 Train Loss: 0.080 | Train Acc: 100.000
39 Train Loss: 0.076 | Train Acc: 100.000
40 Train Loss: 0.071 | Train Acc: 100.000
41 Train Loss: 0.070 | Train Acc: 100.000
42 Train Loss: 0.068 | Train Acc: 100.000
43 Train Loss: 0.067 | Train Acc: 100.000
44 Train Loss: 0.065 | Train Acc: 100.000
45 Train Loss: 0.064 | Train Acc: 100.000
46 Train Loss: 0.062 | Train Acc: 100.000
47 Train Loss: 0.061 | Train Acc: 100.000
48 Train Loss: 0.059 | Train Acc: 100.000
49 Train Loss: 0.058 | Train Acc: 100.000
50 Train Loss: 0.056 | Train Acc: 100.000
51 Train Loss: 0.055 | Train Acc: 100.000
52 Train Loss: 0.053 | Train Acc: 100.000
53 Train Loss: 0.052 | Train Acc: 100.000
54 Train Loss: 0.050 | Train Acc: 100.000
55 Train Loss: 0.049 | Train Acc: 100.000
56 Train Loss: 0.047 | Train Acc: 100.000
57 Train Loss: 0.046 | Train Acc: 100.000
58 Train Loss: 0.044 | Train Acc: 100.000
59 Train Loss: 0.043 | Train Acc: 100.000
60 Train Loss: 0.041 | Train Acc: 100.000
61 Train Loss: 0.040 | Train Acc: 100.000
62 Train Loss: 0.040 | Train Acc: 100.000
63 Train Loss: 0.039 | Train Acc: 100.000
64 Train Loss: 0.039 | Train Acc: 100.000
65 Train Loss: 0.038 | Train Acc: 100.000
66 Train Loss: 0.038 | Train Acc: 100.000
67 Train Loss: 0.037 | Train Acc: 100.000
68 Train Loss: 0.036 | Train Acc: 100.000
69 Train Loss: 0.036 | Train Acc: 100.000
70 Train Loss: 0.035 | Train Acc: 100.000
71 Train Loss: 0.034 | Train Acc: 100.000
72 Train Loss: 0.034 | Train Acc: 100.000
73 Train Loss: 0.033 | Train Acc: 100.000
74 Train Loss: 0.032 | Train Acc: 100.000
75 Train Loss: 0.032 | Train Acc: 100.000
76 Train Loss: 0.031 | Train Acc: 100.000
77 Train Loss: 0.030 | Train Acc: 100.000
78 Train Loss: 0.029 | Train Acc: 100.000
79 Train Loss: 0.029 | Train Acc: 100.000
80 Train Loss: 0.028 | Train Acc: 100.000
81 Train Loss: 0.027 | Train Acc: 100.000
82 Train Loss: 0.027 | Train Acc: 100.000
83 Train Loss: 0.027 | Train Acc: 100.000
84 Train Loss: 0.027 | Train Acc: 100.000
85 Train Loss: 0.026 | Train Acc: 100.000
86 Train Loss: 0.026 | Train Acc: 100.000
87 Train Loss: 0.025 | Train Acc: 100.000
88 Train Loss: 0.025 | Train Acc: 100.000
89 Train Loss: 0.025 | Train Acc: 100.000
90 Train Loss: 0.024 | Train Acc: 100.000
91 Train Loss: 0.024 | Train Acc: 100.000
92 Train Loss: 0.024 | Train Acc: 100.000
93 Train Loss: 0.023 | Train Acc: 100.000
94 Train Loss: 0.023 | Train Acc: 100.000
95 Train Loss: 0.023 | Train Acc: 100.000
96 Train Loss: 0.022 | Train Acc: 100.000
97 Train Loss: 0.022 | Train Acc: 100.000
98 Train Loss: 0.021 | Train Acc: 100.000
99 Train Loss: 0.021 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([780, 1024])
printing expected split from k means
{4: 1, 0: 1, 3: 0, 1: 1, 9: 1, 6: 1, 7: 1, 2: 1, 5: 1, 8: 1}
Printing final_dict items...
{4: 1, 0: 1, 3: 0, 1: 1, 9: 1, 6: 1, 7: 1, 2: 1, 5: 1, 8: 1}
Image Statistics before MLP : L R :  169 611
expectedMlpLabels.shape :  torch.Size([780])
0 Loss: 51.317 | Acc: 75.000
1 Loss: 31.213 | Acc: 84.833
2 Loss: 29.612 | Acc: 84.000
3 Loss: 20.000 | Acc: 90.000
4 Loss: 24.032 | Acc: 87.500
5 Loss: 11.940 | Acc: 93.833
6 Loss: 11.584 | Acc: 92.000
7 Loss: 12.404 | Acc: 94.833
8 Loss: 9.591 | Acc: 94.667
9 Loss: 4.488 | Acc: 98.000
10 Loss: 6.518 | Acc: 97.333
11 Loss: 4.166 | Acc: 98.000
12 Loss: 5.236 | Acc: 96.833
13 Loss: 3.943 | Acc: 97.833
14 Loss: 2.426 | Acc: 98.667
15 Loss: 2.631 | Acc: 98.000
16 Loss: 3.402 | Acc: 98.167
17 Loss: 1.978 | Acc: 98.500
18 Loss: 2.680 | Acc: 98.667
19 Loss: 2.576 | Acc: 98.167
20 Loss: 1.444 | Acc: 99.167
21 Loss: 1.325 | Acc: 99.167
22 Loss: 1.587 | Acc: 99.000
23 Loss: 0.778 | Acc: 99.333
24 Loss: 1.005 | Acc: 99.500
25 Loss: 0.723 | Acc: 99.500
26 Loss: 0.588 | Acc: 99.833
27 Loss: 3.155 | Acc: 98.833
28 Loss: 1.137 | Acc: 99.333
29 Loss: 1.227 | Acc: 98.833
30 Loss: 0.651 | Acc: 99.833
31 Loss: 0.613 | Acc: 99.667
32 Loss: 0.638 | Acc: 99.667
33 Loss: 1.243 | Acc: 99.500
34 Loss: 0.552 | Acc: 99.667
35 Loss: 0.423 | Acc: 99.667
36 Loss: 0.747 | Acc: 99.500
37 Loss: 1.141 | Acc: 99.500
38 Loss: 0.472 | Acc: 99.667
39 Loss: 0.323 | Acc: 100.000
40 Loss: 0.380 | Acc: 100.000
41 Loss: 0.290 | Acc: 99.833
42 Loss: 0.392 | Acc: 99.667
43 Loss: 0.378 | Acc: 99.833
44 Loss: 0.372 | Acc: 99.833
45 Loss: 0.569 | Acc: 99.667
46 Loss: 0.468 | Acc: 99.833
47 Loss: 0.453 | Acc: 99.833
48 Loss: 0.937 | Acc: 99.667
49 Loss: 0.385 | Acc: 99.833
50 Loss: 0.275 | Acc: 99.833
51 Loss: 0.431 | Acc: 99.833
52 Loss: 0.600 | Acc: 99.667
53 Loss: 0.211 | Acc: 99.833
54 Loss: 0.589 | Acc: 99.833
55 Loss: 0.288 | Acc: 99.833
56 Loss: 0.378 | Acc: 100.000
57 Loss: 0.367 | Acc: 99.833
58 Loss: 0.402 | Acc: 99.833
59 Loss: 0.468 | Acc: 99.667
MLP trained successfully...
# of Left images:  97.0
# of Right images:  282.0
giniRightRatio:  0.8623560183089384
giniLeftRatio:  0.8802210649378255
impurityDrop:  0.8685010875394421
giniGain:  0.007864295603253968
lclasses:  [7, 17, 7, 11, 16, 2, 11, 11, 6, 9]
rclasses:  [40, 45, 21, 8, 19, 13, 18, 24, 25, 69]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([97, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([97])
rTrainDict[data].shape:  torch.Size([282, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([282])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
DATANUM THRESHOLD REACHED IN LEFT 97 100
nodeId:  110 , imgTensorShape :  torch.Size([97, 16, 8, 8])
nodeId: 110 ,  parentId: 55 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 97
nodeId:  111 , imgTensorShape :  torch.Size([282, 16, 8, 8])
nodeId: 111 ,  parentId: 55 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 282
Running nodeId:  56
trainInputDict[data].shape :  torch.Size([5526, 16, 12, 12])
copy.shape :  torch.Size([5526, 2304])
copyLabel.shape :  torch.Size([5526])
Class 0 has 1575 instances after oversampling
Class 1 has 1575 instances after oversampling
Class 2 has 1575 instances after oversampling
Class 3 has 1575 instances after oversampling
Class 4 has 1575 instances after oversampling
Class 5 has 1575 instances after oversampling
Class 6 has 1575 instances after oversampling
Class 7 has 1575 instances after oversampling
Class 8 has 1575 instances after oversampling
Class 9 has 1575 instances after oversampling
0 Train Loss: 221.367 | Train Acc: 15.956
1 Train Loss: 175.351 | Train Acc: 40.984
2 Train Loss: 129.000 | Train Acc: 56.279
3 Train Loss: 107.267 | Train Acc: 62.857
4 Train Loss: 96.718 | Train Acc: 64.978
5 Train Loss: 90.351 | Train Acc: 66.775
6 Train Loss: 85.322 | Train Acc: 68.470
7 Train Loss: 80.473 | Train Acc: 70.508
8 Train Loss: 76.905 | Train Acc: 71.530
9 Train Loss: 75.492 | Train Acc: 72.444
10 Train Loss: 72.055 | Train Acc: 73.321
11 Train Loss: 68.357 | Train Acc: 75.403
12 Train Loss: 67.114 | Train Acc: 75.289
13 Train Loss: 68.667 | Train Acc: 74.844
14 Train Loss: 65.985 | Train Acc: 75.740
15 Train Loss: 62.380 | Train Acc: 77.321
16 Train Loss: 62.505 | Train Acc: 77.092
17 Train Loss: 58.772 | Train Acc: 78.737
18 Train Loss: 57.393 | Train Acc: 79.397
19 Train Loss: 57.103 | Train Acc: 79.448
20 Train Loss: 52.027 | Train Acc: 81.473
21 Train Loss: 49.253 | Train Acc: 83.029
22 Train Loss: 49.343 | Train Acc: 82.914
23 Train Loss: 49.733 | Train Acc: 82.438
24 Train Loss: 47.543 | Train Acc: 83.149
25 Train Loss: 46.060 | Train Acc: 84.260
26 Train Loss: 48.960 | Train Acc: 82.533
27 Train Loss: 45.450 | Train Acc: 84.571
28 Train Loss: 45.661 | Train Acc: 84.006
29 Train Loss: 45.338 | Train Acc: 84.197
30 Train Loss: 45.305 | Train Acc: 84.330
31 Train Loss: 43.641 | Train Acc: 84.990
32 Train Loss: 43.439 | Train Acc: 85.308
33 Train Loss: 43.501 | Train Acc: 85.079
34 Train Loss: 43.152 | Train Acc: 84.787
35 Train Loss: 42.583 | Train Acc: 85.435
36 Train Loss: 41.461 | Train Acc: 85.683
37 Train Loss: 41.335 | Train Acc: 85.829
38 Train Loss: 40.885 | Train Acc: 86.076
39 Train Loss: 40.056 | Train Acc: 86.248
40 Train Loss: 37.717 | Train Acc: 87.435
41 Train Loss: 37.492 | Train Acc: 87.676
42 Train Loss: 37.425 | Train Acc: 87.479
43 Train Loss: 37.276 | Train Acc: 87.600
44 Train Loss: 36.868 | Train Acc: 87.778
45 Train Loss: 37.344 | Train Acc: 87.244
46 Train Loss: 36.350 | Train Acc: 88.044
47 Train Loss: 36.012 | Train Acc: 88.114
48 Train Loss: 36.247 | Train Acc: 87.790
49 Train Loss: 35.973 | Train Acc: 88.159
50 Train Loss: 35.701 | Train Acc: 88.248
51 Train Loss: 35.898 | Train Acc: 88.152
52 Train Loss: 35.593 | Train Acc: 88.222
53 Train Loss: 35.166 | Train Acc: 88.432
54 Train Loss: 35.099 | Train Acc: 88.292
55 Train Loss: 35.037 | Train Acc: 88.406
56 Train Loss: 34.875 | Train Acc: 88.610
57 Train Loss: 34.289 | Train Acc: 88.768
58 Train Loss: 34.579 | Train Acc: 88.584
59 Train Loss: 34.676 | Train Acc: 88.406
60 Train Loss: 33.380 | Train Acc: 89.130
61 Train Loss: 33.369 | Train Acc: 89.156
62 Train Loss: 33.150 | Train Acc: 89.308
63 Train Loss: 33.102 | Train Acc: 89.283
64 Train Loss: 32.996 | Train Acc: 89.378
65 Train Loss: 33.037 | Train Acc: 89.384
66 Train Loss: 32.772 | Train Acc: 89.454
67 Train Loss: 32.834 | Train Acc: 89.365
68 Train Loss: 32.769 | Train Acc: 89.397
69 Train Loss: 32.545 | Train Acc: 89.676
70 Train Loss: 32.543 | Train Acc: 89.657
71 Train Loss: 32.731 | Train Acc: 89.486
72 Train Loss: 32.490 | Train Acc: 89.556
73 Train Loss: 32.378 | Train Acc: 89.695
74 Train Loss: 32.313 | Train Acc: 89.549
75 Train Loss: 32.282 | Train Acc: 89.549
76 Train Loss: 32.150 | Train Acc: 89.727
77 Train Loss: 32.198 | Train Acc: 89.727
78 Train Loss: 31.990 | Train Acc: 89.676
79 Train Loss: 31.852 | Train Acc: 89.835
80 Train Loss: 31.628 | Train Acc: 89.867
81 Train Loss: 31.507 | Train Acc: 90.038
82 Train Loss: 31.477 | Train Acc: 90.133
83 Train Loss: 31.518 | Train Acc: 90.051
84 Train Loss: 31.499 | Train Acc: 90.025
85 Train Loss: 31.441 | Train Acc: 90.000
86 Train Loss: 31.452 | Train Acc: 90.076
87 Train Loss: 31.392 | Train Acc: 90.000
88 Train Loss: 31.332 | Train Acc: 90.095
89 Train Loss: 31.274 | Train Acc: 90.165
90 Train Loss: 31.266 | Train Acc: 90.146
91 Train Loss: 31.262 | Train Acc: 90.190
92 Train Loss: 31.281 | Train Acc: 90.210
93 Train Loss: 31.210 | Train Acc: 90.197
94 Train Loss: 31.115 | Train Acc: 90.057
95 Train Loss: 31.182 | Train Acc: 90.210
96 Train Loss: 31.126 | Train Acc: 90.197
97 Train Loss: 31.163 | Train Acc: 90.197
98 Train Loss: 31.086 | Train Acc: 90.273
99 Train Loss: 31.061 | Train Acc: 90.248
CNN trained successfully...
image_next_flat.shape :  torch.Size([15750, 1024])
printing expected split from k means
{2: 0, 6: 1, 3: 0, 5: 0, 7: 0, 4: 0, 9: 0, 0: 0, 8: 0, 1: 0}
Printing final_dict items...
{2: 0, 6: 1, 3: 0, 5: 0, 7: 0, 4: 0, 9: 0, 0: 0, 8: 0, 1: 0}
Image Statistics before MLP : L R :  11125 4625
expectedMlpLabels.shape :  torch.Size([15750])
0 Loss: 24.339 | Acc: 89.060
1 Loss: 16.612 | Acc: 93.092
2 Loss: 14.694 | Acc: 93.683
3 Loss: 13.080 | Acc: 94.444
4 Loss: 11.972 | Acc: 95.035
5 Loss: 11.520 | Acc: 94.914
6 Loss: 10.549 | Acc: 95.606
7 Loss: 10.524 | Acc: 95.549
8 Loss: 9.571 | Acc: 95.892
9 Loss: 8.935 | Acc: 96.229
10 Loss: 6.759 | Acc: 97.156
11 Loss: 6.021 | Acc: 97.448
12 Loss: 6.125 | Acc: 97.568
13 Loss: 5.543 | Acc: 97.594
14 Loss: 5.611 | Acc: 97.619
15 Loss: 4.961 | Acc: 97.886
16 Loss: 5.231 | Acc: 97.841
17 Loss: 4.744 | Acc: 98.032
18 Loss: 4.646 | Acc: 98.152
19 Loss: 4.381 | Acc: 98.330
20 Loss: 3.546 | Acc: 98.521
21 Loss: 3.349 | Acc: 98.705
22 Loss: 3.064 | Acc: 98.825
23 Loss: 3.289 | Acc: 98.635
24 Loss: 2.849 | Acc: 98.876
25 Loss: 3.008 | Acc: 98.775
26 Loss: 3.061 | Acc: 98.781
27 Loss: 2.810 | Acc: 98.927
28 Loss: 2.781 | Acc: 98.921
29 Loss: 2.548 | Acc: 99.054
30 Loss: 2.635 | Acc: 98.908
31 Loss: 2.366 | Acc: 99.035
32 Loss: 2.569 | Acc: 99.022
33 Loss: 2.060 | Acc: 99.194
34 Loss: 2.353 | Acc: 99.092
35 Loss: 2.132 | Acc: 99.175
36 Loss: 2.144 | Acc: 99.149
37 Loss: 2.001 | Acc: 99.206
38 Loss: 1.929 | Acc: 99.295
39 Loss: 2.071 | Acc: 99.194
40 Loss: 1.932 | Acc: 99.295
41 Loss: 1.905 | Acc: 99.270
42 Loss: 1.931 | Acc: 99.302
43 Loss: 1.724 | Acc: 99.378
44 Loss: 1.899 | Acc: 99.346
45 Loss: 1.773 | Acc: 99.403
46 Loss: 1.865 | Acc: 99.314
47 Loss: 1.819 | Acc: 99.302
48 Loss: 1.803 | Acc: 99.378
49 Loss: 1.641 | Acc: 99.397
50 Loss: 1.656 | Acc: 99.467
51 Loss: 1.865 | Acc: 99.327
52 Loss: 1.626 | Acc: 99.365
53 Loss: 1.680 | Acc: 99.441
54 Loss: 1.594 | Acc: 99.390
55 Loss: 1.665 | Acc: 99.435
56 Loss: 1.742 | Acc: 99.340
57 Loss: 1.646 | Acc: 99.416
58 Loss: 1.830 | Acc: 99.352
59 Loss: 1.544 | Acc: 99.403
MLP trained successfully...
# of Left images:  2918.0
# of Right images:  2608.0
giniRightRatio:  0.7229557355376567
giniLeftRatio:  0.8272740255585502
impurityDrop:  0.8396738223018313
giniGain:  -0.031843592187721925
lclasses:  [19, 6, 444, 664, 541, 533, 445, 239, 12, 15]
rclasses:  [12, 5, 414, 257, 593, 115, 1130, 70, 5, 7]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2918, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([2918])
rTrainDict[data].shape:  torch.Size([2608, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([2608])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  112 , imgTensorShape :  torch.Size([2918, 16, 8, 8])
nodeId: 112 ,  parentId: 56 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2918
nodeId:  113 , imgTensorShape :  torch.Size([2608, 16, 8, 8])
nodeId: 113 ,  parentId: 56 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2608
Running nodeId:  57
trainInputDict[data].shape :  torch.Size([1446, 16, 12, 12])
copy.shape :  torch.Size([1446, 2304])
copyLabel.shape :  torch.Size([1446])
Class 0 has 530 instances after oversampling
Class 1 has 530 instances after oversampling
Class 2 has 530 instances after oversampling
Class 3 has 530 instances after oversampling
Class 4 has 531 instances after oversampling
Class 5 has 530 instances after oversampling
Class 6 has 531 instances after oversampling
Class 7 has 530 instances after oversampling
Class 8 has 530 instances after oversampling
Class 9 has 530 instances after oversampling
0 Train Loss: 221.479 | Train Acc: 17.358
1 Train Loss: 186.317 | Train Acc: 38.245
2 Train Loss: 131.462 | Train Acc: 58.981
3 Train Loss: 99.672 | Train Acc: 68.830
4 Train Loss: 77.573 | Train Acc: 75.434
5 Train Loss: 61.458 | Train Acc: 80.830
6 Train Loss: 53.036 | Train Acc: 83.943
7 Train Loss: 43.534 | Train Acc: 87.208
8 Train Loss: 39.617 | Train Acc: 88.038
9 Train Loss: 33.089 | Train Acc: 90.453
10 Train Loss: 28.497 | Train Acc: 91.453
11 Train Loss: 25.408 | Train Acc: 92.566
12 Train Loss: 21.632 | Train Acc: 93.585
13 Train Loss: 19.988 | Train Acc: 94.340
14 Train Loss: 17.525 | Train Acc: 95.377
15 Train Loss: 18.825 | Train Acc: 94.585
16 Train Loss: 13.678 | Train Acc: 96.113
17 Train Loss: 12.174 | Train Acc: 96.887
18 Train Loss: 10.475 | Train Acc: 97.170
19 Train Loss: 12.192 | Train Acc: 96.170
20 Train Loss: 8.527 | Train Acc: 97.925
21 Train Loss: 7.117 | Train Acc: 98.509
22 Train Loss: 6.625 | Train Acc: 98.736
23 Train Loss: 6.310 | Train Acc: 98.906
24 Train Loss: 5.983 | Train Acc: 98.925
25 Train Loss: 5.824 | Train Acc: 98.811
26 Train Loss: 5.309 | Train Acc: 99.208
27 Train Loss: 5.123 | Train Acc: 99.245
28 Train Loss: 4.897 | Train Acc: 99.264
29 Train Loss: 4.576 | Train Acc: 99.358
30 Train Loss: 4.331 | Train Acc: 99.453
31 Train Loss: 4.298 | Train Acc: 99.377
32 Train Loss: 3.972 | Train Acc: 99.509
33 Train Loss: 3.815 | Train Acc: 99.585
34 Train Loss: 3.574 | Train Acc: 99.566
35 Train Loss: 3.262 | Train Acc: 99.774
36 Train Loss: 3.163 | Train Acc: 99.736
37 Train Loss: 3.036 | Train Acc: 99.830
38 Train Loss: 2.951 | Train Acc: 99.736
39 Train Loss: 2.607 | Train Acc: 99.830
40 Train Loss: 2.314 | Train Acc: 99.925
41 Train Loss: 2.217 | Train Acc: 99.906
42 Train Loss: 2.156 | Train Acc: 99.943
43 Train Loss: 2.114 | Train Acc: 99.943
44 Train Loss: 2.051 | Train Acc: 99.943
45 Train Loss: 2.009 | Train Acc: 99.943
46 Train Loss: 1.982 | Train Acc: 99.943
47 Train Loss: 1.908 | Train Acc: 99.943
48 Train Loss: 1.840 | Train Acc: 99.962
49 Train Loss: 1.795 | Train Acc: 99.962
50 Train Loss: 1.729 | Train Acc: 99.981
51 Train Loss: 1.697 | Train Acc: 100.000
52 Train Loss: 1.657 | Train Acc: 99.981
53 Train Loss: 1.625 | Train Acc: 99.981
54 Train Loss: 1.549 | Train Acc: 100.000
55 Train Loss: 1.502 | Train Acc: 100.000
56 Train Loss: 1.448 | Train Acc: 100.000
57 Train Loss: 1.456 | Train Acc: 100.000
58 Train Loss: 1.355 | Train Acc: 100.000
59 Train Loss: 1.351 | Train Acc: 100.000
60 Train Loss: 1.239 | Train Acc: 100.000
61 Train Loss: 1.203 | Train Acc: 100.000
62 Train Loss: 1.196 | Train Acc: 100.000
63 Train Loss: 1.184 | Train Acc: 100.000
64 Train Loss: 1.158 | Train Acc: 100.000
65 Train Loss: 1.145 | Train Acc: 100.000
66 Train Loss: 1.134 | Train Acc: 100.000
67 Train Loss: 1.119 | Train Acc: 100.000
68 Train Loss: 1.094 | Train Acc: 100.000
69 Train Loss: 1.082 | Train Acc: 100.000
70 Train Loss: 1.065 | Train Acc: 100.000
71 Train Loss: 1.037 | Train Acc: 100.000
72 Train Loss: 1.026 | Train Acc: 100.000
73 Train Loss: 1.008 | Train Acc: 100.000
74 Train Loss: 0.990 | Train Acc: 100.000
75 Train Loss: 0.995 | Train Acc: 100.000
76 Train Loss: 0.953 | Train Acc: 100.000
77 Train Loss: 0.949 | Train Acc: 100.000
78 Train Loss: 0.922 | Train Acc: 100.000
79 Train Loss: 0.901 | Train Acc: 100.000
80 Train Loss: 0.875 | Train Acc: 100.000
81 Train Loss: 0.864 | Train Acc: 100.000
82 Train Loss: 0.858 | Train Acc: 100.000
83 Train Loss: 0.849 | Train Acc: 100.000
84 Train Loss: 0.845 | Train Acc: 100.000
85 Train Loss: 0.834 | Train Acc: 100.000
86 Train Loss: 0.829 | Train Acc: 100.000
87 Train Loss: 0.819 | Train Acc: 100.000
88 Train Loss: 0.819 | Train Acc: 100.000
89 Train Loss: 0.809 | Train Acc: 100.000
90 Train Loss: 0.803 | Train Acc: 100.000
91 Train Loss: 0.792 | Train Acc: 100.000
92 Train Loss: 0.793 | Train Acc: 100.000
93 Train Loss: 0.783 | Train Acc: 100.000
94 Train Loss: 0.774 | Train Acc: 100.000
95 Train Loss: 0.766 | Train Acc: 100.000
96 Train Loss: 0.768 | Train Acc: 100.000
97 Train Loss: 0.756 | Train Acc: 100.000
98 Train Loss: 0.747 | Train Acc: 100.000
99 Train Loss: 0.742 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([5302, 1024])
printing expected split from k means
{4: 0, 0: 0, 2: 0, 3: 0, 5: 0, 7: 0, 6: 1, 8: 0, 9: 0, 1: 0}
Printing final_dict items...
{4: 0, 0: 0, 2: 0, 3: 0, 5: 0, 7: 0, 6: 1, 8: 0, 9: 0, 1: 0}
Image Statistics before MLP : L R :  4183 1119
expectedMlpLabels.shape :  torch.Size([5302])
0 Loss: 33.354 | Acc: 79.788
1 Loss: 22.507 | Acc: 86.750
2 Loss: 19.704 | Acc: 87.865
3 Loss: 17.066 | Acc: 89.923
4 Loss: 15.825 | Acc: 90.154
5 Loss: 14.365 | Acc: 91.077
6 Loss: 13.112 | Acc: 92.385
7 Loss: 11.695 | Acc: 92.942
8 Loss: 11.251 | Acc: 93.423
9 Loss: 9.698 | Acc: 94.115
10 Loss: 7.044 | Acc: 95.865
11 Loss: 7.713 | Acc: 95.173
12 Loss: 6.457 | Acc: 95.923
13 Loss: 6.417 | Acc: 96.038
14 Loss: 6.344 | Acc: 96.231
15 Loss: 6.454 | Acc: 96.212
16 Loss: 5.719 | Acc: 96.769
17 Loss: 5.553 | Acc: 97.058
18 Loss: 5.273 | Acc: 96.846
19 Loss: 5.244 | Acc: 96.904
20 Loss: 4.740 | Acc: 97.000
21 Loss: 4.114 | Acc: 97.615
22 Loss: 3.941 | Acc: 97.577
23 Loss: 3.609 | Acc: 97.846
24 Loss: 4.004 | Acc: 97.673
25 Loss: 3.727 | Acc: 97.808
26 Loss: 3.864 | Acc: 97.596
27 Loss: 4.003 | Acc: 97.596
28 Loss: 3.732 | Acc: 97.654
29 Loss: 3.424 | Acc: 98.000
30 Loss: 2.843 | Acc: 98.288
31 Loss: 2.983 | Acc: 98.192
32 Loss: 3.088 | Acc: 98.077
33 Loss: 2.815 | Acc: 98.462
34 Loss: 2.850 | Acc: 98.231
35 Loss: 2.896 | Acc: 98.346
36 Loss: 2.684 | Acc: 98.346
37 Loss: 2.504 | Acc: 98.538
38 Loss: 2.733 | Acc: 98.385
39 Loss: 2.857 | Acc: 98.481
40 Loss: 2.434 | Acc: 98.423
41 Loss: 2.589 | Acc: 98.481
42 Loss: 2.787 | Acc: 98.269
43 Loss: 2.426 | Acc: 98.481
44 Loss: 2.277 | Acc: 98.673
45 Loss: 2.436 | Acc: 98.615
46 Loss: 2.681 | Acc: 98.538
47 Loss: 2.227 | Acc: 98.654
48 Loss: 2.542 | Acc: 98.404
49 Loss: 2.384 | Acc: 98.654
50 Loss: 2.470 | Acc: 98.577
51 Loss: 2.154 | Acc: 98.750
52 Loss: 2.560 | Acc: 98.596
53 Loss: 2.457 | Acc: 98.596
54 Loss: 2.317 | Acc: 98.615
55 Loss: 2.182 | Acc: 98.519
56 Loss: 2.527 | Acc: 98.462
57 Loss: 2.198 | Acc: 98.808
58 Loss: 2.727 | Acc: 98.615
59 Loss: 2.077 | Acc: 98.827
MLP trained successfully...
# of Left images:  746.0
# of Right images:  700.0
giniRightRatio:  0.6844163265306122
giniLeftRatio:  0.823336615658849
impurityDrop:  0.832465663230133
giniGain:  -0.05537753534742518
lclasses:  [55, 7, 144, 62, 186, 39, 180, 40, 16, 17]
rclasses:  [24, 6, 138, 33, 98, 26, 351, 20, 1, 3]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([746, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([746])
rTrainDict[data].shape:  torch.Size([700, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([700])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  114 , imgTensorShape :  torch.Size([746, 16, 8, 8])
nodeId: 114 ,  parentId: 57 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 746
nodeId:  115 , imgTensorShape :  torch.Size([700, 16, 8, 8])
nodeId: 115 ,  parentId: 57 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 700
Running nodeId:  58
trainInputDict[data].shape :  torch.Size([1782, 16, 12, 12])
copy.shape :  torch.Size([1782, 2304])
copyLabel.shape :  torch.Size([1782])
Class 0 has 558 instances after oversampling
Class 1 has 558 instances after oversampling
Class 2 has 558 instances after oversampling
Class 3 has 558 instances after oversampling
Class 4 has 558 instances after oversampling
Class 5 has 558 instances after oversampling
Class 6 has 558 instances after oversampling
Class 7 has 558 instances after oversampling
Class 8 has 558 instances after oversampling
0 Train Loss: 191.465 | Train Acc: 26.560
1 Train Loss: 147.344 | Train Acc: 47.580
2 Train Loss: 118.962 | Train Acc: 58.440
3 Train Loss: 108.054 | Train Acc: 62.500
4 Train Loss: 89.566 | Train Acc: 68.760
5 Train Loss: 80.582 | Train Acc: 72.380
6 Train Loss: 72.060 | Train Acc: 75.720
7 Train Loss: 68.248 | Train Acc: 77.340
8 Train Loss: 59.610 | Train Acc: 80.480
9 Train Loss: 55.452 | Train Acc: 81.840
10 Train Loss: 52.308 | Train Acc: 82.320
11 Train Loss: 54.652 | Train Acc: 81.320
12 Train Loss: 43.480 | Train Acc: 85.400
13 Train Loss: 43.545 | Train Acc: 85.480
14 Train Loss: 38.436 | Train Acc: 87.500
15 Train Loss: 38.156 | Train Acc: 87.100
16 Train Loss: 33.363 | Train Acc: 89.000
17 Train Loss: 32.595 | Train Acc: 89.380
18 Train Loss: 31.210 | Train Acc: 90.040
19 Train Loss: 30.669 | Train Acc: 90.000
20 Train Loss: 24.425 | Train Acc: 92.700
21 Train Loss: 23.131 | Train Acc: 93.220
22 Train Loss: 22.419 | Train Acc: 93.260
23 Train Loss: 21.980 | Train Acc: 93.780
24 Train Loss: 21.531 | Train Acc: 94.000
25 Train Loss: 20.604 | Train Acc: 94.260
26 Train Loss: 20.539 | Train Acc: 94.160
27 Train Loss: 19.542 | Train Acc: 94.420
28 Train Loss: 19.068 | Train Acc: 94.540
29 Train Loss: 18.805 | Train Acc: 94.800
30 Train Loss: 18.634 | Train Acc: 94.560
31 Train Loss: 18.059 | Train Acc: 94.800
32 Train Loss: 17.177 | Train Acc: 95.140
33 Train Loss: 16.374 | Train Acc: 95.740
34 Train Loss: 15.925 | Train Acc: 95.540
35 Train Loss: 15.780 | Train Acc: 95.460
36 Train Loss: 15.182 | Train Acc: 95.980
37 Train Loss: 15.241 | Train Acc: 95.660
38 Train Loss: 14.479 | Train Acc: 96.100
39 Train Loss: 14.036 | Train Acc: 96.140
40 Train Loss: 12.592 | Train Acc: 96.800
41 Train Loss: 12.375 | Train Acc: 96.880
42 Train Loss: 12.152 | Train Acc: 97.020
43 Train Loss: 12.066 | Train Acc: 97.100
44 Train Loss: 11.735 | Train Acc: 97.260
45 Train Loss: 11.740 | Train Acc: 97.160
46 Train Loss: 11.459 | Train Acc: 97.280
47 Train Loss: 11.372 | Train Acc: 97.420
48 Train Loss: 11.500 | Train Acc: 97.080
49 Train Loss: 11.211 | Train Acc: 97.440
50 Train Loss: 11.049 | Train Acc: 97.420
51 Train Loss: 10.716 | Train Acc: 97.680
52 Train Loss: 10.588 | Train Acc: 97.620
53 Train Loss: 10.381 | Train Acc: 97.780
54 Train Loss: 10.483 | Train Acc: 97.700
55 Train Loss: 10.206 | Train Acc: 97.700
56 Train Loss: 9.946 | Train Acc: 97.800
57 Train Loss: 9.809 | Train Acc: 97.880
58 Train Loss: 9.781 | Train Acc: 97.920
59 Train Loss: 9.550 | Train Acc: 97.900
60 Train Loss: 9.088 | Train Acc: 98.160
61 Train Loss: 9.023 | Train Acc: 98.160
62 Train Loss: 8.944 | Train Acc: 98.100
63 Train Loss: 8.883 | Train Acc: 98.280
64 Train Loss: 8.873 | Train Acc: 98.100
65 Train Loss: 8.750 | Train Acc: 98.320
66 Train Loss: 8.702 | Train Acc: 98.200
67 Train Loss: 8.659 | Train Acc: 98.300
68 Train Loss: 8.583 | Train Acc: 98.380
69 Train Loss: 8.544 | Train Acc: 98.260
70 Train Loss: 8.458 | Train Acc: 98.280
71 Train Loss: 8.420 | Train Acc: 98.360
72 Train Loss: 8.419 | Train Acc: 98.340
73 Train Loss: 8.308 | Train Acc: 98.340
74 Train Loss: 8.195 | Train Acc: 98.380
75 Train Loss: 8.159 | Train Acc: 98.400
76 Train Loss: 8.139 | Train Acc: 98.380
77 Train Loss: 8.094 | Train Acc: 98.400
78 Train Loss: 8.007 | Train Acc: 98.500
79 Train Loss: 7.991 | Train Acc: 98.380
80 Train Loss: 7.762 | Train Acc: 98.580
81 Train Loss: 7.688 | Train Acc: 98.560
82 Train Loss: 7.663 | Train Acc: 98.640
83 Train Loss: 7.664 | Train Acc: 98.620
84 Train Loss: 7.640 | Train Acc: 98.520
85 Train Loss: 7.616 | Train Acc: 98.560
86 Train Loss: 7.578 | Train Acc: 98.640
87 Train Loss: 7.571 | Train Acc: 98.560
88 Train Loss: 7.538 | Train Acc: 98.600
89 Train Loss: 7.516 | Train Acc: 98.640
90 Train Loss: 7.486 | Train Acc: 98.640
91 Train Loss: 7.456 | Train Acc: 98.620
92 Train Loss: 7.421 | Train Acc: 98.640
93 Train Loss: 7.426 | Train Acc: 98.680
94 Train Loss: 7.391 | Train Acc: 98.620
95 Train Loss: 7.370 | Train Acc: 98.700
96 Train Loss: 7.363 | Train Acc: 98.640
97 Train Loss: 7.342 | Train Acc: 98.660
98 Train Loss: 7.290 | Train Acc: 98.720
99 Train Loss: 7.262 | Train Acc: 98.700
CNN trained successfully...
image_next_flat.shape :  torch.Size([5022, 1024])
printing expected split from k means
{3: 0, 5: 0, 1: 0, 2: 0, 4: 0, 6: 0, 7: 1, 0: 1, 8: 1}
Printing final_dict items...
{3: 0, 5: 0, 1: 0, 2: 0, 4: 0, 6: 0, 7: 1, 0: 1, 8: 1}
Image Statistics before MLP : L R :  3604 1418
expectedMlpLabels.shape :  torch.Size([5022])
0 Loss: 21.944 | Acc: 90.520
1 Loss: 13.986 | Acc: 94.040
2 Loss: 11.536 | Acc: 95.180
3 Loss: 10.551 | Acc: 95.860
4 Loss: 9.531 | Acc: 96.400
5 Loss: 7.934 | Acc: 96.580
6 Loss: 7.867 | Acc: 96.900
7 Loss: 9.447 | Acc: 96.480
8 Loss: 7.300 | Acc: 96.760
9 Loss: 5.811 | Acc: 97.380
10 Loss: 5.255 | Acc: 97.780
11 Loss: 4.282 | Acc: 98.120
12 Loss: 3.958 | Acc: 98.260
13 Loss: 3.807 | Acc: 98.220
14 Loss: 3.605 | Acc: 98.440
15 Loss: 3.559 | Acc: 98.420
16 Loss: 3.987 | Acc: 98.520
17 Loss: 3.449 | Acc: 98.600
18 Loss: 3.487 | Acc: 98.500
19 Loss: 3.191 | Acc: 98.640
20 Loss: 2.947 | Acc: 98.620
21 Loss: 2.214 | Acc: 99.140
22 Loss: 2.572 | Acc: 98.980
23 Loss: 2.665 | Acc: 98.800
24 Loss: 2.053 | Acc: 99.220
25 Loss: 2.295 | Acc: 99.000
26 Loss: 2.314 | Acc: 99.100
27 Loss: 2.447 | Acc: 99.100
28 Loss: 2.304 | Acc: 99.120
29 Loss: 1.981 | Acc: 99.200
30 Loss: 1.900 | Acc: 99.220
31 Loss: 1.899 | Acc: 99.280
32 Loss: 1.808 | Acc: 99.320
33 Loss: 1.926 | Acc: 99.180
34 Loss: 1.900 | Acc: 99.260
35 Loss: 1.821 | Acc: 99.260
36 Loss: 1.827 | Acc: 99.240
37 Loss: 1.925 | Acc: 99.160
38 Loss: 1.556 | Acc: 99.340
39 Loss: 1.550 | Acc: 99.340
40 Loss: 1.647 | Acc: 99.400
41 Loss: 1.353 | Acc: 99.480
42 Loss: 1.414 | Acc: 99.440
43 Loss: 1.543 | Acc: 99.380
44 Loss: 1.604 | Acc: 99.260
45 Loss: 1.661 | Acc: 99.500
46 Loss: 1.278 | Acc: 99.520
47 Loss: 1.398 | Acc: 99.500
48 Loss: 1.175 | Acc: 99.480
49 Loss: 1.363 | Acc: 99.400
50 Loss: 1.370 | Acc: 99.480
51 Loss: 1.455 | Acc: 99.360
52 Loss: 1.409 | Acc: 99.320
53 Loss: 1.539 | Acc: 99.400
54 Loss: 1.439 | Acc: 99.400
55 Loss: 1.169 | Acc: 99.460
56 Loss: 1.283 | Acc: 99.440
57 Loss: 1.316 | Acc: 99.520
58 Loss: 1.472 | Acc: 99.400
59 Loss: 1.177 | Acc: 99.560
MLP trained successfully...
# of Left images:  1538.0
# of Right images:  244.0
giniRightRatio:  0.8171862402579952
giniLeftRatio:  0.7552172023518628
impurityDrop:  0.42657812427589903
giniGain:  0.352679724192574
lclasses:  [22, 454, 136, 528, 91, 256, 33, 15, 3, 0]
rclasses:  [68, 62, 11, 30, 13, 27, 4, 20, 9, 0]
noOfLeftClasses:  9
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([1538, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([1538])
rTrainDict[data].shape:  torch.Size([244, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([244])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  116 , imgTensorShape :  torch.Size([1538, 16, 8, 8])
nodeId: 116 ,  parentId: 58 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 1538
nodeId:  117 , imgTensorShape :  torch.Size([244, 16, 8, 8])
nodeId: 117 ,  parentId: 58 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 244
Running nodeId:  59
trainInputDict[data].shape :  torch.Size([91, 16, 12, 12])
copy.shape :  torch.Size([91, 2304])
copyLabel.shape :  torch.Size([91])
Class 0 has 48 instances after oversampling
Class 1 has 48 instances after oversampling
Class 2 has 48 instances after oversampling
Class 3 has 48 instances after oversampling
Class 4 has 1 instances after oversampling
Class 5 has 48 instances after oversampling
0 Train Loss: 1.815 | Train Acc: 16.598
1 Train Loss: 1.543 | Train Acc: 59.751
2 Train Loss: 1.343 | Train Acc: 74.689
3 Train Loss: 1.173 | Train Acc: 80.083
4 Train Loss: 1.027 | Train Acc: 82.158
5 Train Loss: 0.896 | Train Acc: 85.477
6 Train Loss: 0.778 | Train Acc: 88.382
7 Train Loss: 0.677 | Train Acc: 90.871
8 Train Loss: 0.593 | Train Acc: 91.701
9 Train Loss: 0.519 | Train Acc: 93.361
10 Train Loss: 0.456 | Train Acc: 93.361
11 Train Loss: 0.407 | Train Acc: 93.361
12 Train Loss: 0.364 | Train Acc: 94.191
13 Train Loss: 0.325 | Train Acc: 95.021
14 Train Loss: 0.292 | Train Acc: 94.606
15 Train Loss: 0.264 | Train Acc: 95.021
16 Train Loss: 0.237 | Train Acc: 95.851
17 Train Loss: 0.212 | Train Acc: 95.851
18 Train Loss: 0.190 | Train Acc: 96.266
19 Train Loss: 0.169 | Train Acc: 96.266
20 Train Loss: 0.148 | Train Acc: 96.680
21 Train Loss: 0.140 | Train Acc: 97.095
22 Train Loss: 0.133 | Train Acc: 97.095
23 Train Loss: 0.125 | Train Acc: 97.095
24 Train Loss: 0.118 | Train Acc: 97.095
25 Train Loss: 0.111 | Train Acc: 97.095
26 Train Loss: 0.105 | Train Acc: 97.095
27 Train Loss: 0.100 | Train Acc: 97.510
28 Train Loss: 0.095 | Train Acc: 97.925
29 Train Loss: 0.091 | Train Acc: 97.925
30 Train Loss: 0.087 | Train Acc: 97.925
31 Train Loss: 0.083 | Train Acc: 98.340
32 Train Loss: 0.079 | Train Acc: 98.755
33 Train Loss: 0.076 | Train Acc: 98.755
34 Train Loss: 0.073 | Train Acc: 98.755
35 Train Loss: 0.070 | Train Acc: 99.170
36 Train Loss: 0.067 | Train Acc: 99.170
37 Train Loss: 0.064 | Train Acc: 99.585
38 Train Loss: 0.061 | Train Acc: 100.000
39 Train Loss: 0.059 | Train Acc: 100.000
40 Train Loss: 0.056 | Train Acc: 100.000
41 Train Loss: 0.055 | Train Acc: 100.000
42 Train Loss: 0.055 | Train Acc: 100.000
43 Train Loss: 0.054 | Train Acc: 100.000
44 Train Loss: 0.053 | Train Acc: 100.000
45 Train Loss: 0.052 | Train Acc: 100.000
46 Train Loss: 0.051 | Train Acc: 100.000
47 Train Loss: 0.050 | Train Acc: 100.000
48 Train Loss: 0.050 | Train Acc: 100.000
49 Train Loss: 0.049 | Train Acc: 100.000
50 Train Loss: 0.048 | Train Acc: 100.000
51 Train Loss: 0.047 | Train Acc: 100.000
52 Train Loss: 0.047 | Train Acc: 100.000
53 Train Loss: 0.046 | Train Acc: 100.000
54 Train Loss: 0.045 | Train Acc: 100.000
55 Train Loss: 0.045 | Train Acc: 100.000
56 Train Loss: 0.044 | Train Acc: 100.000
57 Train Loss: 0.043 | Train Acc: 100.000
58 Train Loss: 0.043 | Train Acc: 100.000
59 Train Loss: 0.042 | Train Acc: 100.000
60 Train Loss: 0.041 | Train Acc: 100.000
61 Train Loss: 0.041 | Train Acc: 100.000
62 Train Loss: 0.041 | Train Acc: 100.000
63 Train Loss: 0.041 | Train Acc: 100.000
64 Train Loss: 0.040 | Train Acc: 100.000
65 Train Loss: 0.040 | Train Acc: 100.000
66 Train Loss: 0.040 | Train Acc: 100.000
67 Train Loss: 0.040 | Train Acc: 100.000
68 Train Loss: 0.040 | Train Acc: 100.000
69 Train Loss: 0.039 | Train Acc: 100.000
70 Train Loss: 0.039 | Train Acc: 100.000
71 Train Loss: 0.039 | Train Acc: 100.000
72 Train Loss: 0.039 | Train Acc: 100.000
73 Train Loss: 0.038 | Train Acc: 100.000
74 Train Loss: 0.038 | Train Acc: 100.000
75 Train Loss: 0.038 | Train Acc: 100.000
76 Train Loss: 0.038 | Train Acc: 100.000
77 Train Loss: 0.038 | Train Acc: 100.000
78 Train Loss: 0.037 | Train Acc: 100.000
79 Train Loss: 0.037 | Train Acc: 100.000
80 Train Loss: 0.037 | Train Acc: 100.000
81 Train Loss: 0.037 | Train Acc: 100.000
82 Train Loss: 0.037 | Train Acc: 100.000
83 Train Loss: 0.037 | Train Acc: 100.000
84 Train Loss: 0.037 | Train Acc: 100.000
85 Train Loss: 0.037 | Train Acc: 100.000
86 Train Loss: 0.036 | Train Acc: 100.000
87 Train Loss: 0.036 | Train Acc: 100.000
88 Train Loss: 0.036 | Train Acc: 100.000
89 Train Loss: 0.036 | Train Acc: 100.000
90 Train Loss: 0.036 | Train Acc: 100.000
91 Train Loss: 0.036 | Train Acc: 100.000
92 Train Loss: 0.036 | Train Acc: 100.000
93 Train Loss: 0.036 | Train Acc: 100.000
94 Train Loss: 0.036 | Train Acc: 100.000
95 Train Loss: 0.036 | Train Acc: 100.000
96 Train Loss: 0.036 | Train Acc: 100.000
97 Train Loss: 0.036 | Train Acc: 100.000
98 Train Loss: 0.035 | Train Acc: 100.000
99 Train Loss: 0.035 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  60
trainInputDict[data].shape :  torch.Size([719, 16, 12, 12])
copy.shape :  torch.Size([719, 2304])
copyLabel.shape :  torch.Size([719])
Class 0 has 175 instances after oversampling
Class 1 has 175 instances after oversampling
Class 2 has 175 instances after oversampling
Class 3 has 175 instances after oversampling
Class 4 has 175 instances after oversampling
Class 5 has 175 instances after oversampling
Class 6 has 175 instances after oversampling
Class 7 has 175 instances after oversampling
Class 8 has 175 instances after oversampling
Class 9 has 175 instances after oversampling
0 Train Loss: 180.605 | Train Acc: 38.176
1 Train Loss: 102.760 | Train Acc: 65.647
2 Train Loss: 67.307 | Train Acc: 78.176
3 Train Loss: 52.223 | Train Acc: 83.000
4 Train Loss: 40.031 | Train Acc: 87.000
5 Train Loss: 30.150 | Train Acc: 91.118
6 Train Loss: 23.881 | Train Acc: 92.941
7 Train Loss: 17.227 | Train Acc: 95.000
8 Train Loss: 12.264 | Train Acc: 96.824
9 Train Loss: 9.310 | Train Acc: 98.118
10 Train Loss: 7.384 | Train Acc: 98.529
11 Train Loss: 4.856 | Train Acc: 99.412
12 Train Loss: 3.726 | Train Acc: 99.647
13 Train Loss: 2.945 | Train Acc: 99.765
14 Train Loss: 2.017 | Train Acc: 100.000
15 Train Loss: 1.417 | Train Acc: 100.000
16 Train Loss: 1.181 | Train Acc: 100.000
17 Train Loss: 0.983 | Train Acc: 100.000
18 Train Loss: 0.855 | Train Acc: 100.000
19 Train Loss: 0.719 | Train Acc: 100.000
20 Train Loss: 0.607 | Train Acc: 100.000
21 Train Loss: 0.568 | Train Acc: 100.000
22 Train Loss: 0.539 | Train Acc: 100.000
23 Train Loss: 0.521 | Train Acc: 100.000
24 Train Loss: 0.494 | Train Acc: 100.000
25 Train Loss: 0.482 | Train Acc: 100.000
26 Train Loss: 0.447 | Train Acc: 100.000
27 Train Loss: 0.428 | Train Acc: 100.000
28 Train Loss: 0.406 | Train Acc: 100.000
29 Train Loss: 0.383 | Train Acc: 100.000
30 Train Loss: 0.371 | Train Acc: 100.000
31 Train Loss: 0.349 | Train Acc: 100.000
32 Train Loss: 0.331 | Train Acc: 100.000
33 Train Loss: 0.317 | Train Acc: 100.000
34 Train Loss: 0.303 | Train Acc: 100.000
35 Train Loss: 0.286 | Train Acc: 100.000
36 Train Loss: 0.271 | Train Acc: 100.000
37 Train Loss: 0.261 | Train Acc: 100.000
38 Train Loss: 0.244 | Train Acc: 100.000
39 Train Loss: 0.230 | Train Acc: 100.000
40 Train Loss: 0.212 | Train Acc: 100.000
41 Train Loss: 0.206 | Train Acc: 100.000
42 Train Loss: 0.202 | Train Acc: 100.000
43 Train Loss: 0.198 | Train Acc: 100.000
44 Train Loss: 0.194 | Train Acc: 100.000
45 Train Loss: 0.189 | Train Acc: 100.000
46 Train Loss: 0.186 | Train Acc: 100.000
47 Train Loss: 0.180 | Train Acc: 100.000
48 Train Loss: 0.176 | Train Acc: 100.000
49 Train Loss: 0.171 | Train Acc: 100.000
50 Train Loss: 0.167 | Train Acc: 100.000
51 Train Loss: 0.162 | Train Acc: 100.000
52 Train Loss: 0.157 | Train Acc: 100.000
53 Train Loss: 0.154 | Train Acc: 100.000
54 Train Loss: 0.148 | Train Acc: 100.000
55 Train Loss: 0.143 | Train Acc: 100.000
56 Train Loss: 0.139 | Train Acc: 100.000
57 Train Loss: 0.135 | Train Acc: 100.000
58 Train Loss: 0.131 | Train Acc: 100.000
59 Train Loss: 0.127 | Train Acc: 100.000
60 Train Loss: 0.120 | Train Acc: 100.000
61 Train Loss: 0.118 | Train Acc: 100.000
62 Train Loss: 0.116 | Train Acc: 100.000
63 Train Loss: 0.115 | Train Acc: 100.000
64 Train Loss: 0.113 | Train Acc: 100.000
65 Train Loss: 0.112 | Train Acc: 100.000
66 Train Loss: 0.109 | Train Acc: 100.000
67 Train Loss: 0.108 | Train Acc: 100.000
68 Train Loss: 0.106 | Train Acc: 100.000
69 Train Loss: 0.104 | Train Acc: 100.000
70 Train Loss: 0.102 | Train Acc: 100.000
71 Train Loss: 0.100 | Train Acc: 100.000
72 Train Loss: 0.098 | Train Acc: 100.000
73 Train Loss: 0.096 | Train Acc: 100.000
74 Train Loss: 0.094 | Train Acc: 100.000
75 Train Loss: 0.092 | Train Acc: 100.000
76 Train Loss: 0.090 | Train Acc: 100.000
77 Train Loss: 0.088 | Train Acc: 100.000
78 Train Loss: 0.086 | Train Acc: 100.000
79 Train Loss: 0.084 | Train Acc: 100.000
80 Train Loss: 0.081 | Train Acc: 100.000
81 Train Loss: 0.080 | Train Acc: 100.000
82 Train Loss: 0.079 | Train Acc: 100.000
83 Train Loss: 0.078 | Train Acc: 100.000
84 Train Loss: 0.077 | Train Acc: 100.000
85 Train Loss: 0.076 | Train Acc: 100.000
86 Train Loss: 0.076 | Train Acc: 100.000
87 Train Loss: 0.075 | Train Acc: 100.000
88 Train Loss: 0.074 | Train Acc: 100.000
89 Train Loss: 0.073 | Train Acc: 100.000
90 Train Loss: 0.072 | Train Acc: 100.000
91 Train Loss: 0.071 | Train Acc: 100.000
92 Train Loss: 0.070 | Train Acc: 100.000
93 Train Loss: 0.069 | Train Acc: 100.000
94 Train Loss: 0.068 | Train Acc: 100.000
95 Train Loss: 0.067 | Train Acc: 100.000
96 Train Loss: 0.065 | Train Acc: 100.000
97 Train Loss: 0.065 | Train Acc: 100.000
98 Train Loss: 0.063 | Train Acc: 100.000
99 Train Loss: 0.062 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([1750, 1024])
printing expected split from k means
{7: 1, 6: 0, 2: 0, 3: 0, 4: 0, 5: 0, 8: 0, 0: 0, 1: 0, 9: 1}
Printing final_dict items...
{7: 1, 6: 0, 2: 0, 3: 0, 4: 0, 5: 0, 8: 0, 0: 0, 1: 0, 9: 1}
Image Statistics before MLP : L R :  1264 486
expectedMlpLabels.shape :  torch.Size([1750])
0 Loss: 41.964 | Acc: 81.562
1 Loss: 35.146 | Acc: 87.125
2 Loss: 21.329 | Acc: 91.250
3 Loss: 21.411 | Acc: 90.500
4 Loss: 20.290 | Acc: 91.938
5 Loss: 16.303 | Acc: 93.312
6 Loss: 14.614 | Acc: 94.062
7 Loss: 15.185 | Acc: 93.875
8 Loss: 12.403 | Acc: 94.500
9 Loss: 10.595 | Acc: 95.312
10 Loss: 9.313 | Acc: 95.688
11 Loss: 6.511 | Acc: 97.000
12 Loss: 6.480 | Acc: 97.500
13 Loss: 6.756 | Acc: 97.062
14 Loss: 4.689 | Acc: 97.688
15 Loss: 5.032 | Acc: 97.938
16 Loss: 3.229 | Acc: 98.625
17 Loss: 4.621 | Acc: 98.375
18 Loss: 4.385 | Acc: 98.125
19 Loss: 4.235 | Acc: 97.938
20 Loss: 3.414 | Acc: 98.875
21 Loss: 2.780 | Acc: 99.250
22 Loss: 2.272 | Acc: 99.250
23 Loss: 1.750 | Acc: 99.312
24 Loss: 1.599 | Acc: 99.562
25 Loss: 2.123 | Acc: 99.062
26 Loss: 1.462 | Acc: 99.500
27 Loss: 1.335 | Acc: 99.500
28 Loss: 0.717 | Acc: 99.812
29 Loss: 2.009 | Acc: 99.438
30 Loss: 1.180 | Acc: 99.500
31 Loss: 1.020 | Acc: 99.750
32 Loss: 0.509 | Acc: 99.875
33 Loss: 0.603 | Acc: 99.812
34 Loss: 0.754 | Acc: 99.875
35 Loss: 1.681 | Acc: 99.500
36 Loss: 0.650 | Acc: 99.812
37 Loss: 1.115 | Acc: 99.875
38 Loss: 0.521 | Acc: 99.875
39 Loss: 0.482 | Acc: 99.938
40 Loss: 0.343 | Acc: 100.000
41 Loss: 0.619 | Acc: 99.875
42 Loss: 0.604 | Acc: 99.875
43 Loss: 0.457 | Acc: 99.938
44 Loss: 0.388 | Acc: 99.938
45 Loss: 0.383 | Acc: 99.938
46 Loss: 0.330 | Acc: 100.000
47 Loss: 0.561 | Acc: 99.812
48 Loss: 0.239 | Acc: 100.000
49 Loss: 1.791 | Acc: 99.812
50 Loss: 0.332 | Acc: 99.938
51 Loss: 0.287 | Acc: 100.000
52 Loss: 0.300 | Acc: 99.938
53 Loss: 0.375 | Acc: 99.938
54 Loss: 0.220 | Acc: 99.938
55 Loss: 0.344 | Acc: 99.938
56 Loss: 0.490 | Acc: 99.812
57 Loss: 0.394 | Acc: 99.938
58 Loss: 0.348 | Acc: 99.938
59 Loss: 0.289 | Acc: 100.000
MLP trained successfully...
# of Left images:  460.0
# of Right images:  259.0
giniRightRatio:  0.7533578807710081
giniLeftRatio:  0.8287145557655955
impurityDrop:  0.8871959908000051
giniGain:  -0.06608569427860422
lclasses:  [21, 6, 127, 81, 42, 72, 42, 66, 3, 0]
rclasses:  [5, 1, 48, 22, 11, 74, 3, 90, 0, 5]
noOfLeftClasses:  9
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([460, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([460])
rTrainDict[data].shape:  torch.Size([259, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([259])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  118 , imgTensorShape :  torch.Size([460, 16, 8, 8])
nodeId: 118 ,  parentId: 60 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 460
nodeId:  119 , imgTensorShape :  torch.Size([259, 16, 8, 8])
nodeId: 119 ,  parentId: 60 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 259
Running nodeId:  61
trainInputDict[data].shape :  torch.Size([1110, 16, 12, 12])
copy.shape :  torch.Size([1110, 2304])
copyLabel.shape :  torch.Size([1110])
Class 0 has 247 instances after oversampling
Class 1 has 246 instances after oversampling
Class 2 has 247 instances after oversampling
Class 3 has 247 instances after oversampling
Class 4 has 247 instances after oversampling
Class 5 has 247 instances after oversampling
Class 6 has 247 instances after oversampling
Class 7 has 247 instances after oversampling
Class 8 has 246 instances after oversampling
Class 9 has 246 instances after oversampling
0 Train Loss: 221.493 | Train Acc: 17.042
1 Train Loss: 172.520 | Train Acc: 40.500
2 Train Loss: 122.731 | Train Acc: 59.042
3 Train Loss: 89.688 | Train Acc: 71.125
4 Train Loss: 65.404 | Train Acc: 79.833
5 Train Loss: 49.487 | Train Acc: 85.250
6 Train Loss: 41.407 | Train Acc: 87.208
7 Train Loss: 30.433 | Train Acc: 91.458
8 Train Loss: 25.582 | Train Acc: 93.167
9 Train Loss: 20.751 | Train Acc: 94.542
10 Train Loss: 18.982 | Train Acc: 95.042
11 Train Loss: 12.844 | Train Acc: 96.667
12 Train Loss: 10.021 | Train Acc: 98.083
13 Train Loss: 8.325 | Train Acc: 98.708
14 Train Loss: 6.143 | Train Acc: 99.208
15 Train Loss: 5.305 | Train Acc: 99.625
16 Train Loss: 5.284 | Train Acc: 99.375
17 Train Loss: 3.162 | Train Acc: 100.000
18 Train Loss: 2.479 | Train Acc: 100.000
19 Train Loss: 2.289 | Train Acc: 99.917
20 Train Loss: 1.670 | Train Acc: 100.000
21 Train Loss: 1.441 | Train Acc: 100.000
22 Train Loss: 1.363 | Train Acc: 100.000
23 Train Loss: 1.262 | Train Acc: 100.000
24 Train Loss: 1.209 | Train Acc: 100.000
25 Train Loss: 1.131 | Train Acc: 100.000
26 Train Loss: 1.066 | Train Acc: 100.000
27 Train Loss: 1.046 | Train Acc: 100.000
28 Train Loss: 0.965 | Train Acc: 100.000
29 Train Loss: 0.904 | Train Acc: 100.000
30 Train Loss: 0.860 | Train Acc: 100.000
31 Train Loss: 0.814 | Train Acc: 100.000
32 Train Loss: 0.768 | Train Acc: 100.000
33 Train Loss: 0.720 | Train Acc: 100.000
34 Train Loss: 0.684 | Train Acc: 100.000
35 Train Loss: 0.651 | Train Acc: 100.000
36 Train Loss: 0.617 | Train Acc: 100.000
37 Train Loss: 0.573 | Train Acc: 100.000
38 Train Loss: 0.542 | Train Acc: 100.000
39 Train Loss: 0.511 | Train Acc: 100.000
40 Train Loss: 0.463 | Train Acc: 100.000
41 Train Loss: 0.451 | Train Acc: 100.000
42 Train Loss: 0.442 | Train Acc: 100.000
43 Train Loss: 0.430 | Train Acc: 100.000
44 Train Loss: 0.418 | Train Acc: 100.000
45 Train Loss: 0.410 | Train Acc: 100.000
46 Train Loss: 0.398 | Train Acc: 100.000
47 Train Loss: 0.391 | Train Acc: 100.000
48 Train Loss: 0.378 | Train Acc: 100.000
49 Train Loss: 0.369 | Train Acc: 100.000
50 Train Loss: 0.357 | Train Acc: 100.000
51 Train Loss: 0.347 | Train Acc: 100.000
52 Train Loss: 0.340 | Train Acc: 100.000
53 Train Loss: 0.327 | Train Acc: 100.000
54 Train Loss: 0.317 | Train Acc: 100.000
55 Train Loss: 0.308 | Train Acc: 100.000
56 Train Loss: 0.298 | Train Acc: 100.000
57 Train Loss: 0.287 | Train Acc: 100.000
58 Train Loss: 0.278 | Train Acc: 100.000
59 Train Loss: 0.270 | Train Acc: 100.000
60 Train Loss: 0.253 | Train Acc: 100.000
61 Train Loss: 0.248 | Train Acc: 100.000
62 Train Loss: 0.246 | Train Acc: 100.000
63 Train Loss: 0.241 | Train Acc: 100.000
64 Train Loss: 0.239 | Train Acc: 100.000
65 Train Loss: 0.235 | Train Acc: 100.000
66 Train Loss: 0.231 | Train Acc: 100.000
67 Train Loss: 0.226 | Train Acc: 100.000
68 Train Loss: 0.223 | Train Acc: 100.000
69 Train Loss: 0.218 | Train Acc: 100.000
70 Train Loss: 0.214 | Train Acc: 100.000
71 Train Loss: 0.210 | Train Acc: 100.000
72 Train Loss: 0.207 | Train Acc: 100.000
73 Train Loss: 0.202 | Train Acc: 100.000
74 Train Loss: 0.199 | Train Acc: 100.000
75 Train Loss: 0.195 | Train Acc: 100.000
76 Train Loss: 0.190 | Train Acc: 100.000
77 Train Loss: 0.185 | Train Acc: 100.000
78 Train Loss: 0.181 | Train Acc: 100.000
79 Train Loss: 0.180 | Train Acc: 100.000
80 Train Loss: 0.170 | Train Acc: 100.000
81 Train Loss: 0.168 | Train Acc: 100.000
82 Train Loss: 0.166 | Train Acc: 100.000
83 Train Loss: 0.165 | Train Acc: 100.000
84 Train Loss: 0.163 | Train Acc: 100.000
85 Train Loss: 0.161 | Train Acc: 100.000
86 Train Loss: 0.160 | Train Acc: 100.000
87 Train Loss: 0.157 | Train Acc: 100.000
88 Train Loss: 0.156 | Train Acc: 100.000
89 Train Loss: 0.154 | Train Acc: 100.000
90 Train Loss: 0.152 | Train Acc: 100.000
91 Train Loss: 0.150 | Train Acc: 100.000
92 Train Loss: 0.148 | Train Acc: 100.000
93 Train Loss: 0.146 | Train Acc: 100.000
94 Train Loss: 0.144 | Train Acc: 100.000
95 Train Loss: 0.142 | Train Acc: 100.000
96 Train Loss: 0.140 | Train Acc: 100.000
97 Train Loss: 0.138 | Train Acc: 100.000
98 Train Loss: 0.136 | Train Acc: 100.000
99 Train Loss: 0.134 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([2467, 1024])
printing expected split from k means
{7: 0, 4: 1, 2: 1, 6: 1, 0: 1, 5: 1, 3: 1, 1: 1, 9: 1, 8: 1}
Printing final_dict items...
{7: 0, 4: 1, 2: 1, 6: 1, 0: 1, 5: 1, 3: 1, 1: 1, 9: 1, 8: 1}
Image Statistics before MLP : L R :  503 1964
expectedMlpLabels.shape :  torch.Size([2467])
0 Loss: 32.168 | Acc: 80.500
1 Loss: 24.933 | Acc: 85.292
2 Loss: 19.226 | Acc: 86.333
3 Loss: 17.753 | Acc: 88.667
4 Loss: 16.453 | Acc: 89.583
5 Loss: 15.578 | Acc: 89.417
6 Loss: 11.615 | Acc: 92.375
7 Loss: 12.824 | Acc: 91.667
8 Loss: 12.207 | Acc: 92.375
9 Loss: 10.697 | Acc: 92.958
10 Loss: 8.165 | Acc: 94.500
11 Loss: 6.852 | Acc: 95.500
12 Loss: 6.292 | Acc: 95.583
13 Loss: 5.848 | Acc: 96.042
14 Loss: 6.233 | Acc: 96.000
15 Loss: 5.101 | Acc: 96.792
16 Loss: 4.387 | Acc: 97.292
17 Loss: 4.808 | Acc: 97.292
18 Loss: 4.540 | Acc: 97.250
19 Loss: 4.993 | Acc: 96.958
20 Loss: 3.562 | Acc: 97.750
21 Loss: 2.746 | Acc: 98.208
22 Loss: 3.115 | Acc: 98.167
23 Loss: 2.243 | Acc: 98.792
24 Loss: 2.946 | Acc: 98.417
25 Loss: 2.595 | Acc: 98.500
26 Loss: 2.713 | Acc: 98.375
27 Loss: 2.736 | Acc: 98.375
28 Loss: 2.554 | Acc: 98.208
29 Loss: 2.542 | Acc: 98.708
30 Loss: 2.116 | Acc: 98.792
31 Loss: 2.102 | Acc: 98.875
32 Loss: 1.705 | Acc: 99.083
33 Loss: 1.656 | Acc: 99.208
34 Loss: 1.883 | Acc: 98.875
35 Loss: 2.185 | Acc: 99.125
36 Loss: 1.384 | Acc: 99.208
37 Loss: 1.825 | Acc: 99.042
38 Loss: 1.640 | Acc: 98.958
39 Loss: 1.252 | Acc: 99.375
40 Loss: 1.455 | Acc: 99.333
41 Loss: 1.342 | Acc: 99.458
42 Loss: 1.531 | Acc: 99.125
43 Loss: 1.530 | Acc: 99.125
44 Loss: 1.421 | Acc: 99.375
45 Loss: 1.433 | Acc: 99.375
46 Loss: 1.294 | Acc: 99.250
47 Loss: 1.461 | Acc: 99.333
48 Loss: 1.398 | Acc: 99.208
49 Loss: 1.383 | Acc: 99.333
50 Loss: 1.308 | Acc: 99.417
51 Loss: 1.586 | Acc: 99.208
52 Loss: 0.987 | Acc: 99.458
53 Loss: 1.571 | Acc: 99.292
54 Loss: 1.554 | Acc: 99.250
55 Loss: 1.078 | Acc: 99.333
56 Loss: 1.003 | Acc: 99.458
57 Loss: 1.342 | Acc: 99.417
58 Loss: 1.104 | Acc: 99.375
59 Loss: 0.837 | Acc: 99.625
MLP trained successfully...
# of Left images:  381.0
# of Right images:  729.0
giniRightRatio:  0.8478721062168708
giniLeftRatio:  0.7304441275549217
impurityDrop:  0.7865002819779098
giniGain:  0.057082219442429416
lclasses:  [14, 7, 46, 17, 79, 28, 14, 171, 1, 4]
rclasses:  [57, 24, 197, 69, 114, 58, 104, 76, 10, 20]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([381, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([381])
rTrainDict[data].shape:  torch.Size([729, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([729])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  120 , imgTensorShape :  torch.Size([381, 16, 8, 8])
nodeId: 120 ,  parentId: 61 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 381
nodeId:  121 , imgTensorShape :  torch.Size([729, 16, 8, 8])
nodeId: 121 ,  parentId: 61 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 729
Running nodeId:  62
trainInputDict[data].shape :  torch.Size([3337, 16, 12, 12])
copy.shape :  torch.Size([3337, 2304])
copyLabel.shape :  torch.Size([3337])
Class 0 has 1224 instances after oversampling
Class 1 has 1224 instances after oversampling
Class 2 has 1224 instances after oversampling
Class 3 has 1224 instances after oversampling
Class 4 has 1224 instances after oversampling
Class 5 has 1224 instances after oversampling
Class 6 has 1224 instances after oversampling
Class 7 has 1224 instances after oversampling
Class 8 has 1224 instances after oversampling
Class 9 has 1224 instances after oversampling
0 Train Loss: 209.249 | Train Acc: 26.029
1 Train Loss: 151.505 | Train Acc: 47.990
2 Train Loss: 114.235 | Train Acc: 61.814
3 Train Loss: 96.825 | Train Acc: 66.430
4 Train Loss: 85.017 | Train Acc: 70.335
5 Train Loss: 78.194 | Train Acc: 73.088
6 Train Loss: 71.476 | Train Acc: 74.722
7 Train Loss: 65.523 | Train Acc: 77.092
8 Train Loss: 62.027 | Train Acc: 78.407
9 Train Loss: 59.771 | Train Acc: 79.641
10 Train Loss: 59.133 | Train Acc: 79.265
11 Train Loss: 52.516 | Train Acc: 82.623
12 Train Loss: 50.630 | Train Acc: 82.443
13 Train Loss: 47.148 | Train Acc: 84.493
14 Train Loss: 43.414 | Train Acc: 85.629
15 Train Loss: 38.090 | Train Acc: 88.105
16 Train Loss: 37.194 | Train Acc: 87.851
17 Train Loss: 37.330 | Train Acc: 87.990
18 Train Loss: 32.376 | Train Acc: 89.984
19 Train Loss: 29.830 | Train Acc: 90.613
20 Train Loss: 26.957 | Train Acc: 92.320
21 Train Loss: 23.965 | Train Acc: 93.194
22 Train Loss: 22.983 | Train Acc: 93.897
23 Train Loss: 23.096 | Train Acc: 93.709
24 Train Loss: 21.743 | Train Acc: 94.273
25 Train Loss: 21.265 | Train Acc: 94.134
26 Train Loss: 21.408 | Train Acc: 94.158
27 Train Loss: 20.795 | Train Acc: 94.542
28 Train Loss: 20.518 | Train Acc: 94.322
29 Train Loss: 19.418 | Train Acc: 95.155
30 Train Loss: 18.367 | Train Acc: 95.139
31 Train Loss: 17.699 | Train Acc: 95.253
32 Train Loss: 17.627 | Train Acc: 95.498
33 Train Loss: 17.481 | Train Acc: 95.237
34 Train Loss: 16.470 | Train Acc: 96.021
35 Train Loss: 15.906 | Train Acc: 95.972
36 Train Loss: 15.276 | Train Acc: 96.103
37 Train Loss: 14.632 | Train Acc: 96.601
38 Train Loss: 14.324 | Train Acc: 96.397
39 Train Loss: 14.162 | Train Acc: 96.593
40 Train Loss: 12.392 | Train Acc: 97.337
41 Train Loss: 12.429 | Train Acc: 97.386
42 Train Loss: 12.049 | Train Acc: 97.402
43 Train Loss: 11.744 | Train Acc: 97.574
44 Train Loss: 11.746 | Train Acc: 97.459
45 Train Loss: 11.686 | Train Acc: 97.467
46 Train Loss: 11.274 | Train Acc: 97.696
47 Train Loss: 11.068 | Train Acc: 97.704
48 Train Loss: 11.011 | Train Acc: 97.753
49 Train Loss: 11.052 | Train Acc: 97.672
50 Train Loss: 10.917 | Train Acc: 97.786
51 Train Loss: 10.506 | Train Acc: 97.998
52 Train Loss: 10.311 | Train Acc: 97.949
53 Train Loss: 10.075 | Train Acc: 98.015
54 Train Loss: 9.937 | Train Acc: 98.039
55 Train Loss: 10.050 | Train Acc: 98.039
56 Train Loss: 9.704 | Train Acc: 98.203
57 Train Loss: 9.439 | Train Acc: 98.235
58 Train Loss: 9.360 | Train Acc: 98.129
59 Train Loss: 9.264 | Train Acc: 98.243
60 Train Loss: 8.871 | Train Acc: 98.505
61 Train Loss: 8.700 | Train Acc: 98.497
62 Train Loss: 8.729 | Train Acc: 98.505
63 Train Loss: 8.524 | Train Acc: 98.627
64 Train Loss: 8.518 | Train Acc: 98.627
65 Train Loss: 8.419 | Train Acc: 98.595
66 Train Loss: 8.381 | Train Acc: 98.636
67 Train Loss: 8.357 | Train Acc: 98.611
68 Train Loss: 8.270 | Train Acc: 98.750
69 Train Loss: 8.198 | Train Acc: 98.652
70 Train Loss: 8.116 | Train Acc: 98.750
71 Train Loss: 8.119 | Train Acc: 98.619
72 Train Loss: 8.059 | Train Acc: 98.725
73 Train Loss: 8.000 | Train Acc: 98.725
74 Train Loss: 7.914 | Train Acc: 98.742
75 Train Loss: 7.870 | Train Acc: 98.717
76 Train Loss: 7.735 | Train Acc: 98.799
77 Train Loss: 7.721 | Train Acc: 98.742
78 Train Loss: 7.644 | Train Acc: 98.889
79 Train Loss: 7.628 | Train Acc: 98.881
80 Train Loss: 7.396 | Train Acc: 98.897
81 Train Loss: 7.355 | Train Acc: 98.987
82 Train Loss: 7.331 | Train Acc: 98.938
83 Train Loss: 7.313 | Train Acc: 98.954
84 Train Loss: 7.303 | Train Acc: 98.946
85 Train Loss: 7.246 | Train Acc: 99.011
86 Train Loss: 7.247 | Train Acc: 98.962
87 Train Loss: 7.223 | Train Acc: 99.003
88 Train Loss: 7.183 | Train Acc: 98.962
89 Train Loss: 7.176 | Train Acc: 99.003
90 Train Loss: 7.136 | Train Acc: 99.044
91 Train Loss: 7.118 | Train Acc: 99.028
92 Train Loss: 7.068 | Train Acc: 99.052
93 Train Loss: 7.065 | Train Acc: 98.995
94 Train Loss: 7.038 | Train Acc: 99.052
95 Train Loss: 6.986 | Train Acc: 99.077
96 Train Loss: 7.003 | Train Acc: 99.069
97 Train Loss: 6.956 | Train Acc: 99.052
98 Train Loss: 6.955 | Train Acc: 99.044
99 Train Loss: 6.947 | Train Acc: 99.044
CNN trained successfully...
image_next_flat.shape :  torch.Size([12240, 1024])
printing expected split from k means
{7: 0, 3: 0, 2: 0, 5: 0, 4: 0, 6: 0, 9: 0, 8: 0, 0: 0, 1: 1}
Printing final_dict items...
{7: 0, 3: 0, 2: 0, 5: 0, 4: 0, 6: 0, 9: 0, 8: 0, 0: 0, 1: 1}
Image Statistics before MLP : L R :  11008 1232
expectedMlpLabels.shape :  torch.Size([12240])
0 Loss: 4.273 | Acc: 96.967
1 Loss: 1.707 | Acc: 98.516
2 Loss: 1.454 | Acc: 98.893
3 Loss: 1.075 | Acc: 98.975
4 Loss: 1.167 | Acc: 98.861
5 Loss: 0.858 | Acc: 99.115
6 Loss: 0.725 | Acc: 99.156
7 Loss: 0.572 | Acc: 99.369
8 Loss: 0.475 | Acc: 99.541
9 Loss: 1.065 | Acc: 99.098
10 Loss: 0.651 | Acc: 99.262
11 Loss: 0.559 | Acc: 99.377
12 Loss: 0.371 | Acc: 99.500
13 Loss: 0.327 | Acc: 99.623
14 Loss: 0.399 | Acc: 99.516
15 Loss: 0.373 | Acc: 99.590
16 Loss: 0.345 | Acc: 99.574
17 Loss: 0.396 | Acc: 99.516
18 Loss: 0.324 | Acc: 99.582
19 Loss: 0.322 | Acc: 99.607
20 Loss: 0.319 | Acc: 99.557
21 Loss: 0.230 | Acc: 99.664
22 Loss: 0.209 | Acc: 99.705
23 Loss: 0.224 | Acc: 99.689
24 Loss: 0.201 | Acc: 99.721
25 Loss: 0.198 | Acc: 99.738
26 Loss: 0.201 | Acc: 99.730
27 Loss: 0.211 | Acc: 99.754
28 Loss: 0.260 | Acc: 99.689
29 Loss: 0.220 | Acc: 99.705
30 Loss: 0.201 | Acc: 99.697
31 Loss: 0.155 | Acc: 99.811
32 Loss: 0.141 | Acc: 99.770
33 Loss: 0.153 | Acc: 99.811
34 Loss: 0.180 | Acc: 99.787
35 Loss: 0.210 | Acc: 99.754
36 Loss: 0.154 | Acc: 99.779
37 Loss: 0.161 | Acc: 99.836
38 Loss: 0.159 | Acc: 99.803
39 Loss: 0.189 | Acc: 99.811
40 Loss: 0.143 | Acc: 99.877
41 Loss: 0.113 | Acc: 99.861
42 Loss: 0.140 | Acc: 99.836
43 Loss: 0.154 | Acc: 99.811
44 Loss: 0.142 | Acc: 99.828
45 Loss: 0.122 | Acc: 99.844
46 Loss: 0.137 | Acc: 99.828
47 Loss: 0.158 | Acc: 99.828
48 Loss: 0.110 | Acc: 99.902
49 Loss: 0.120 | Acc: 99.828
50 Loss: 0.122 | Acc: 99.844
51 Loss: 0.129 | Acc: 99.828
52 Loss: 0.112 | Acc: 99.869
53 Loss: 0.151 | Acc: 99.803
54 Loss: 0.107 | Acc: 99.828
55 Loss: 0.116 | Acc: 99.861
56 Loss: 0.106 | Acc: 99.852
57 Loss: 0.106 | Acc: 99.877
58 Loss: 0.144 | Acc: 99.861
59 Loss: 0.126 | Acc: 99.844
MLP trained successfully...
# of Left images:  3226.0
# of Right images:  111.0
giniRightRatio:  0.8041555068582095
giniLeftRatio:  0.7843486489384722
impurityDrop:  0.22850754605575574
giniGain:  0.556787394867335
lclasses:  [11, 1, 301, 321, 573, 391, 393, 1189, 16, 30]
rclasses:  [0, 3, 13, 16, 23, 12, 9, 35, 0, 0]
noOfLeftClasses:  10
noOfRightClasses:  7
lTrainDict[data].shape:  torch.Size([3226, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([3226])
rTrainDict[data].shape:  torch.Size([111, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([111])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  122 , imgTensorShape :  torch.Size([3226, 16, 8, 8])
nodeId: 122 ,  parentId: 62 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3226
nodeId:  123 , imgTensorShape :  torch.Size([111, 16, 8, 8])
nodeId: 123 ,  parentId: 62 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 7 ,  numData: 111
Running nodeId:  63
trainInputDict[data].shape :  torch.Size([5694, 16, 12, 12])
copy.shape :  torch.Size([5694, 2304])
copyLabel.shape :  torch.Size([5694])
Class 0 has 1615 instances after oversampling
Class 1 has 1615 instances after oversampling
Class 2 has 1615 instances after oversampling
Class 3 has 1615 instances after oversampling
Class 4 has 1615 instances after oversampling
Class 5 has 1615 instances after oversampling
Class 6 has 1615 instances after oversampling
Class 7 has 1615 instances after oversampling
Class 8 has 1615 instances after oversampling
Class 9 has 1615 instances after oversampling
0 Train Loss: 228.232 | Train Acc: 15.375
1 Train Loss: 194.167 | Train Acc: 30.502
2 Train Loss: 160.040 | Train Acc: 44.861
3 Train Loss: 129.934 | Train Acc: 55.115
4 Train Loss: 117.419 | Train Acc: 59.635
5 Train Loss: 106.797 | Train Acc: 62.204
6 Train Loss: 99.464 | Train Acc: 64.167
7 Train Loss: 94.646 | Train Acc: 66.396
8 Train Loss: 89.210 | Train Acc: 68.341
9 Train Loss: 82.646 | Train Acc: 70.192
10 Train Loss: 81.119 | Train Acc: 71.375
11 Train Loss: 78.971 | Train Acc: 72.012
12 Train Loss: 73.598 | Train Acc: 74.161
13 Train Loss: 70.987 | Train Acc: 74.854
14 Train Loss: 72.077 | Train Acc: 74.285
15 Train Loss: 67.210 | Train Acc: 76.594
16 Train Loss: 66.494 | Train Acc: 76.650
17 Train Loss: 63.703 | Train Acc: 77.740
18 Train Loss: 62.549 | Train Acc: 77.870
19 Train Loss: 58.748 | Train Acc: 79.529
20 Train Loss: 54.110 | Train Acc: 81.443
21 Train Loss: 52.733 | Train Acc: 81.740
22 Train Loss: 52.575 | Train Acc: 82.211
23 Train Loss: 51.706 | Train Acc: 82.328
24 Train Loss: 51.129 | Train Acc: 82.582
25 Train Loss: 50.223 | Train Acc: 83.034
26 Train Loss: 50.698 | Train Acc: 82.786
27 Train Loss: 49.962 | Train Acc: 83.300
28 Train Loss: 50.469 | Train Acc: 83.214
29 Train Loss: 49.616 | Train Acc: 82.954
30 Train Loss: 48.453 | Train Acc: 83.628
31 Train Loss: 47.455 | Train Acc: 84.155
32 Train Loss: 47.364 | Train Acc: 84.155
33 Train Loss: 46.393 | Train Acc: 84.074
34 Train Loss: 44.990 | Train Acc: 85.090
35 Train Loss: 44.461 | Train Acc: 85.158
36 Train Loss: 44.046 | Train Acc: 85.325
37 Train Loss: 43.766 | Train Acc: 85.492
38 Train Loss: 43.940 | Train Acc: 85.282
39 Train Loss: 43.551 | Train Acc: 85.393
40 Train Loss: 40.448 | Train Acc: 86.848
41 Train Loss: 40.531 | Train Acc: 86.848
42 Train Loss: 40.023 | Train Acc: 86.941
43 Train Loss: 39.762 | Train Acc: 87.158
44 Train Loss: 39.657 | Train Acc: 87.183
45 Train Loss: 39.129 | Train Acc: 87.307
46 Train Loss: 39.105 | Train Acc: 87.461
47 Train Loss: 38.796 | Train Acc: 87.362
48 Train Loss: 38.962 | Train Acc: 87.412
49 Train Loss: 38.754 | Train Acc: 87.505
50 Train Loss: 38.205 | Train Acc: 87.740
51 Train Loss: 37.866 | Train Acc: 87.802
52 Train Loss: 37.383 | Train Acc: 88.080
53 Train Loss: 37.781 | Train Acc: 87.981
54 Train Loss: 37.383 | Train Acc: 88.068
55 Train Loss: 37.193 | Train Acc: 88.180
56 Train Loss: 36.783 | Train Acc: 88.297
57 Train Loss: 36.468 | Train Acc: 88.452
58 Train Loss: 36.614 | Train Acc: 88.062
59 Train Loss: 36.188 | Train Acc: 88.533
60 Train Loss: 35.311 | Train Acc: 88.799
61 Train Loss: 35.129 | Train Acc: 88.954
62 Train Loss: 35.081 | Train Acc: 88.854
63 Train Loss: 34.953 | Train Acc: 89.071
64 Train Loss: 34.894 | Train Acc: 88.991
65 Train Loss: 34.901 | Train Acc: 88.978
66 Train Loss: 34.745 | Train Acc: 89.115
67 Train Loss: 34.698 | Train Acc: 88.985
68 Train Loss: 34.464 | Train Acc: 89.152
69 Train Loss: 34.415 | Train Acc: 89.170
70 Train Loss: 34.427 | Train Acc: 89.133
71 Train Loss: 34.336 | Train Acc: 89.269
72 Train Loss: 34.129 | Train Acc: 89.245
73 Train Loss: 34.098 | Train Acc: 89.294
74 Train Loss: 34.055 | Train Acc: 89.269
75 Train Loss: 33.917 | Train Acc: 89.406
76 Train Loss: 33.927 | Train Acc: 89.461
77 Train Loss: 33.792 | Train Acc: 89.424
78 Train Loss: 33.701 | Train Acc: 89.430
79 Train Loss: 33.795 | Train Acc: 89.455
80 Train Loss: 33.257 | Train Acc: 89.579
81 Train Loss: 33.231 | Train Acc: 89.560
82 Train Loss: 33.144 | Train Acc: 89.641
83 Train Loss: 33.186 | Train Acc: 89.628
84 Train Loss: 33.096 | Train Acc: 89.697
85 Train Loss: 33.062 | Train Acc: 89.728
86 Train Loss: 33.029 | Train Acc: 89.734
87 Train Loss: 33.090 | Train Acc: 89.690
88 Train Loss: 32.978 | Train Acc: 89.728
89 Train Loss: 32.920 | Train Acc: 89.777
90 Train Loss: 32.908 | Train Acc: 89.845
91 Train Loss: 32.888 | Train Acc: 89.734
92 Train Loss: 32.815 | Train Acc: 89.833
93 Train Loss: 32.818 | Train Acc: 89.808
94 Train Loss: 32.810 | Train Acc: 89.827
95 Train Loss: 32.755 | Train Acc: 89.889
96 Train Loss: 32.823 | Train Acc: 89.721
97 Train Loss: 32.693 | Train Acc: 89.765
98 Train Loss: 32.604 | Train Acc: 89.820
99 Train Loss: 32.610 | Train Acc: 89.827
CNN trained successfully...
image_next_flat.shape :  torch.Size([16150, 1024])
printing expected split from k means
{6: 0, 3: 1, 7: 0, 5: 1, 4: 0, 2: 0, 1: 0, 9: 0, 0: 0, 8: 1}
Printing final_dict items...
{6: 0, 3: 1, 7: 0, 5: 1, 4: 0, 2: 0, 1: 0, 9: 0, 0: 0, 8: 1}
Image Statistics before MLP : L R :  11487 4663
expectedMlpLabels.shape :  torch.Size([16150])
0 Loss: 14.383 | Acc: 94.693
1 Loss: 7.658 | Acc: 96.836
2 Loss: 6.143 | Acc: 97.455
3 Loss: 5.722 | Acc: 97.802
4 Loss: 5.514 | Acc: 97.783
5 Loss: 4.834 | Acc: 98.050
6 Loss: 4.654 | Acc: 98.019
7 Loss: 4.385 | Acc: 98.217
8 Loss: 3.778 | Acc: 98.446
9 Loss: 3.779 | Acc: 98.359
10 Loss: 2.517 | Acc: 98.898
11 Loss: 1.886 | Acc: 99.288
12 Loss: 1.850 | Acc: 99.238
13 Loss: 1.843 | Acc: 99.251
14 Loss: 1.671 | Acc: 99.350
15 Loss: 1.839 | Acc: 99.232
16 Loss: 1.433 | Acc: 99.393
17 Loss: 1.563 | Acc: 99.375
18 Loss: 1.734 | Acc: 99.288
19 Loss: 1.651 | Acc: 99.424
20 Loss: 1.256 | Acc: 99.498
21 Loss: 0.989 | Acc: 99.610
22 Loss: 0.964 | Acc: 99.684
23 Loss: 1.104 | Acc: 99.598
24 Loss: 0.826 | Acc: 99.721
25 Loss: 0.718 | Acc: 99.746
26 Loss: 0.748 | Acc: 99.703
27 Loss: 0.770 | Acc: 99.715
28 Loss: 0.753 | Acc: 99.690
29 Loss: 0.737 | Acc: 99.728
30 Loss: 0.671 | Acc: 99.752
31 Loss: 0.572 | Acc: 99.765
32 Loss: 0.574 | Acc: 99.796
33 Loss: 0.572 | Acc: 99.796
34 Loss: 0.567 | Acc: 99.783
35 Loss: 0.529 | Acc: 99.814
36 Loss: 0.534 | Acc: 99.802
37 Loss: 0.471 | Acc: 99.833
38 Loss: 0.413 | Acc: 99.864
39 Loss: 0.642 | Acc: 99.759
40 Loss: 0.476 | Acc: 99.833
41 Loss: 0.462 | Acc: 99.839
42 Loss: 0.536 | Acc: 99.820
43 Loss: 0.441 | Acc: 99.870
44 Loss: 0.481 | Acc: 99.851
45 Loss: 0.554 | Acc: 99.802
46 Loss: 0.443 | Acc: 99.839
47 Loss: 0.478 | Acc: 99.814
48 Loss: 0.450 | Acc: 99.851
49 Loss: 0.421 | Acc: 99.833
50 Loss: 0.358 | Acc: 99.858
51 Loss: 0.451 | Acc: 99.858
52 Loss: 0.378 | Acc: 99.876
53 Loss: 0.382 | Acc: 99.864
54 Loss: 0.368 | Acc: 99.901
55 Loss: 0.417 | Acc: 99.845
56 Loss: 0.333 | Acc: 99.889
57 Loss: 0.359 | Acc: 99.870
58 Loss: 0.400 | Acc: 99.864
59 Loss: 0.305 | Acc: 99.913
MLP trained successfully...
# of Left images:  3528.0
# of Right images:  2166.0
giniRightRatio:  0.7190663396109949
giniLeftRatio:  0.8334440446624606
impurityDrop:  0.905365759473216
giniGain:  -0.09038282647131557
lclasses:  [35, 22, 291, 543, 518, 698, 721, 643, 2, 55]
rclasses:  [11, 8, 148, 615, 123, 917, 109, 223, 5, 7]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([3528, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([3528])
rTrainDict[data].shape:  torch.Size([2166, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([2166])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
nodeId:  124 , imgTensorShape :  torch.Size([3528, 16, 8, 8])
nodeId: 124 ,  parentId: 63 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3528
nodeId:  125 , imgTensorShape :  torch.Size([2166, 16, 8, 8])
nodeId: 125 ,  parentId: 63 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2166
Running nodeId:  64
trainInputDict[data].shape :  torch.Size([637, 16, 8, 8])
copy.shape :  torch.Size([637, 1024])
copyLabel.shape :  torch.Size([637])
Class 0 has 218 instances after oversampling
Class 1 has 218 instances after oversampling
Class 2 has 218 instances after oversampling
Class 3 has 218 instances after oversampling
Class 4 has 218 instances after oversampling
Class 5 has 218 instances after oversampling
Class 6 has 218 instances after oversampling
Class 7 has 218 instances after oversampling
Class 8 has 218 instances after oversampling
Class 9 has 218 instances after oversampling
0 Train Loss: 218.985 | Train Acc: 21.330
1 Train Loss: 171.511 | Train Acc: 40.000
2 Train Loss: 114.448 | Train Acc: 63.028
3 Train Loss: 82.011 | Train Acc: 73.394
4 Train Loss: 64.216 | Train Acc: 78.899
5 Train Loss: 48.808 | Train Acc: 84.541
6 Train Loss: 40.152 | Train Acc: 86.881
7 Train Loss: 31.277 | Train Acc: 90.642
8 Train Loss: 27.411 | Train Acc: 90.872
9 Train Loss: 23.326 | Train Acc: 92.936
10 Train Loss: 18.969 | Train Acc: 94.541
11 Train Loss: 16.905 | Train Acc: 94.862
12 Train Loss: 14.706 | Train Acc: 95.826
13 Train Loss: 12.717 | Train Acc: 96.697
14 Train Loss: 12.063 | Train Acc: 96.789
15 Train Loss: 8.841 | Train Acc: 97.706
16 Train Loss: 8.884 | Train Acc: 97.477
17 Train Loss: 7.218 | Train Acc: 98.578
18 Train Loss: 5.762 | Train Acc: 98.991
19 Train Loss: 5.143 | Train Acc: 99.220
20 Train Loss: 3.884 | Train Acc: 99.725
21 Train Loss: 3.414 | Train Acc: 99.771
22 Train Loss: 3.289 | Train Acc: 99.817
23 Train Loss: 3.112 | Train Acc: 99.633
24 Train Loss: 2.898 | Train Acc: 99.817
25 Train Loss: 2.818 | Train Acc: 99.817
26 Train Loss: 2.713 | Train Acc: 99.771
27 Train Loss: 2.474 | Train Acc: 99.817
28 Train Loss: 2.663 | Train Acc: 99.771
29 Train Loss: 2.242 | Train Acc: 99.817
30 Train Loss: 2.145 | Train Acc: 99.862
31 Train Loss: 2.083 | Train Acc: 99.862
32 Train Loss: 1.998 | Train Acc: 99.862
33 Train Loss: 1.838 | Train Acc: 99.817
34 Train Loss: 1.706 | Train Acc: 99.862
35 Train Loss: 1.573 | Train Acc: 99.862
36 Train Loss: 1.639 | Train Acc: 99.862
37 Train Loss: 1.450 | Train Acc: 99.862
38 Train Loss: 1.457 | Train Acc: 99.817
39 Train Loss: 1.378 | Train Acc: 99.908
40 Train Loss: 1.202 | Train Acc: 99.908
41 Train Loss: 1.137 | Train Acc: 99.908
42 Train Loss: 1.075 | Train Acc: 99.862
43 Train Loss: 1.098 | Train Acc: 99.862
44 Train Loss: 1.086 | Train Acc: 99.908
45 Train Loss: 1.032 | Train Acc: 99.908
46 Train Loss: 1.040 | Train Acc: 99.862
47 Train Loss: 0.990 | Train Acc: 99.908
48 Train Loss: 0.977 | Train Acc: 99.817
49 Train Loss: 1.008 | Train Acc: 99.908
50 Train Loss: 0.949 | Train Acc: 99.908
51 Train Loss: 0.901 | Train Acc: 99.908
52 Train Loss: 0.907 | Train Acc: 99.908
53 Train Loss: 0.836 | Train Acc: 99.954
54 Train Loss: 0.854 | Train Acc: 99.954
55 Train Loss: 0.790 | Train Acc: 99.954
56 Train Loss: 0.825 | Train Acc: 99.817
57 Train Loss: 0.826 | Train Acc: 99.908
58 Train Loss: 0.737 | Train Acc: 99.862
59 Train Loss: 0.756 | Train Acc: 99.908
60 Train Loss: 0.655 | Train Acc: 99.954
61 Train Loss: 0.634 | Train Acc: 99.954
62 Train Loss: 0.623 | Train Acc: 99.954
63 Train Loss: 0.615 | Train Acc: 99.954
64 Train Loss: 0.618 | Train Acc: 99.954
65 Train Loss: 0.603 | Train Acc: 100.000
66 Train Loss: 0.590 | Train Acc: 99.954
67 Train Loss: 0.586 | Train Acc: 99.954
68 Train Loss: 0.596 | Train Acc: 99.954
69 Train Loss: 0.573 | Train Acc: 99.954
70 Train Loss: 0.574 | Train Acc: 99.954
71 Train Loss: 0.565 | Train Acc: 99.954
72 Train Loss: 0.547 | Train Acc: 99.954
73 Train Loss: 0.547 | Train Acc: 99.954
74 Train Loss: 0.521 | Train Acc: 100.000
75 Train Loss: 0.512 | Train Acc: 99.954
76 Train Loss: 0.527 | Train Acc: 99.954
77 Train Loss: 0.502 | Train Acc: 99.954
78 Train Loss: 0.505 | Train Acc: 99.954
79 Train Loss: 0.470 | Train Acc: 100.000
80 Train Loss: 0.460 | Train Acc: 99.954
81 Train Loss: 0.450 | Train Acc: 99.954
82 Train Loss: 0.451 | Train Acc: 100.000
83 Train Loss: 0.440 | Train Acc: 100.000
84 Train Loss: 0.442 | Train Acc: 99.954
85 Train Loss: 0.436 | Train Acc: 100.000
86 Train Loss: 0.428 | Train Acc: 100.000
87 Train Loss: 0.430 | Train Acc: 100.000
88 Train Loss: 0.431 | Train Acc: 99.954
89 Train Loss: 0.424 | Train Acc: 100.000
90 Train Loss: 0.422 | Train Acc: 99.954
91 Train Loss: 0.414 | Train Acc: 100.000
92 Train Loss: 0.416 | Train Acc: 100.000
93 Train Loss: 0.413 | Train Acc: 99.954
94 Train Loss: 0.403 | Train Acc: 100.000
95 Train Loss: 0.402 | Train Acc: 99.954
96 Train Loss: 0.397 | Train Acc: 100.000
97 Train Loss: 0.391 | Train Acc: 100.000
98 Train Loss: 0.390 | Train Acc: 100.000
99 Train Loss: 0.380 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  65
trainInputDict[data].shape :  torch.Size([821, 16, 8, 8])
copy.shape :  torch.Size([821, 1024])
copyLabel.shape :  torch.Size([821])
Class 0 has 390 instances after oversampling
Class 1 has 389 instances after oversampling
Class 2 has 390 instances after oversampling
Class 3 has 390 instances after oversampling
Class 4 has 390 instances after oversampling
Class 5 has 389 instances after oversampling
Class 6 has 390 instances after oversampling
Class 7 has 389 instances after oversampling
Class 8 has 390 instances after oversampling
Class 9 has 390 instances after oversampling
0 Train Loss: 186.911 | Train Acc: 35.540
1 Train Loss: 105.277 | Train Acc: 67.744
2 Train Loss: 66.707 | Train Acc: 79.831
3 Train Loss: 56.816 | Train Acc: 82.089
4 Train Loss: 39.421 | Train Acc: 87.555
5 Train Loss: 33.482 | Train Acc: 88.940
6 Train Loss: 26.461 | Train Acc: 91.583
7 Train Loss: 23.959 | Train Acc: 92.250
8 Train Loss: 18.955 | Train Acc: 94.380
9 Train Loss: 15.982 | Train Acc: 95.176
10 Train Loss: 15.964 | Train Acc: 95.073
11 Train Loss: 13.181 | Train Acc: 95.971
12 Train Loss: 10.490 | Train Acc: 96.844
13 Train Loss: 9.247 | Train Acc: 97.639
14 Train Loss: 11.035 | Train Acc: 96.459
15 Train Loss: 7.476 | Train Acc: 98.255
16 Train Loss: 6.869 | Train Acc: 98.563
17 Train Loss: 6.781 | Train Acc: 98.409
18 Train Loss: 6.047 | Train Acc: 98.435
19 Train Loss: 5.027 | Train Acc: 98.974
20 Train Loss: 2.973 | Train Acc: 99.666
21 Train Loss: 2.715 | Train Acc: 99.795
22 Train Loss: 2.561 | Train Acc: 99.795
23 Train Loss: 2.374 | Train Acc: 99.769
24 Train Loss: 2.485 | Train Acc: 99.692
25 Train Loss: 2.160 | Train Acc: 99.795
26 Train Loss: 2.070 | Train Acc: 99.846
27 Train Loss: 1.989 | Train Acc: 99.846
28 Train Loss: 1.850 | Train Acc: 99.846
29 Train Loss: 1.693 | Train Acc: 99.872
30 Train Loss: 1.654 | Train Acc: 99.846
31 Train Loss: 1.524 | Train Acc: 99.872
32 Train Loss: 1.496 | Train Acc: 99.897
33 Train Loss: 1.332 | Train Acc: 99.872
34 Train Loss: 1.309 | Train Acc: 99.923
35 Train Loss: 1.207 | Train Acc: 99.949
36 Train Loss: 1.119 | Train Acc: 99.949
37 Train Loss: 1.079 | Train Acc: 99.923
38 Train Loss: 1.051 | Train Acc: 99.949
39 Train Loss: 0.918 | Train Acc: 99.974
40 Train Loss: 0.803 | Train Acc: 100.000
41 Train Loss: 0.757 | Train Acc: 100.000
42 Train Loss: 0.745 | Train Acc: 100.000
43 Train Loss: 0.726 | Train Acc: 100.000
44 Train Loss: 0.707 | Train Acc: 100.000
45 Train Loss: 0.696 | Train Acc: 100.000
46 Train Loss: 0.675 | Train Acc: 100.000
47 Train Loss: 0.654 | Train Acc: 100.000
48 Train Loss: 0.625 | Train Acc: 100.000
49 Train Loss: 0.621 | Train Acc: 100.000
50 Train Loss: 0.604 | Train Acc: 100.000
51 Train Loss: 0.585 | Train Acc: 100.000
52 Train Loss: 0.555 | Train Acc: 100.000
53 Train Loss: 0.560 | Train Acc: 100.000
54 Train Loss: 0.529 | Train Acc: 100.000
55 Train Loss: 0.504 | Train Acc: 100.000
56 Train Loss: 0.496 | Train Acc: 100.000
57 Train Loss: 0.484 | Train Acc: 100.000
58 Train Loss: 0.471 | Train Acc: 100.000
59 Train Loss: 0.447 | Train Acc: 100.000
60 Train Loss: 0.414 | Train Acc: 100.000
61 Train Loss: 0.402 | Train Acc: 100.000
62 Train Loss: 0.400 | Train Acc: 100.000
63 Train Loss: 0.393 | Train Acc: 100.000
64 Train Loss: 0.384 | Train Acc: 100.000
65 Train Loss: 0.380 | Train Acc: 100.000
66 Train Loss: 0.371 | Train Acc: 100.000
67 Train Loss: 0.369 | Train Acc: 100.000
68 Train Loss: 0.364 | Train Acc: 100.000
69 Train Loss: 0.353 | Train Acc: 100.000
70 Train Loss: 0.347 | Train Acc: 100.000
71 Train Loss: 0.343 | Train Acc: 100.000
72 Train Loss: 0.344 | Train Acc: 100.000
73 Train Loss: 0.331 | Train Acc: 100.000
74 Train Loss: 0.321 | Train Acc: 100.000
75 Train Loss: 0.316 | Train Acc: 100.000
76 Train Loss: 0.308 | Train Acc: 100.000
77 Train Loss: 0.299 | Train Acc: 100.000
78 Train Loss: 0.302 | Train Acc: 100.000
79 Train Loss: 0.290 | Train Acc: 100.000
80 Train Loss: 0.275 | Train Acc: 100.000
81 Train Loss: 0.273 | Train Acc: 100.000
82 Train Loss: 0.270 | Train Acc: 100.000
83 Train Loss: 0.269 | Train Acc: 100.000
84 Train Loss: 0.267 | Train Acc: 100.000
85 Train Loss: 0.263 | Train Acc: 100.000
86 Train Loss: 0.262 | Train Acc: 100.000
87 Train Loss: 0.257 | Train Acc: 100.000
88 Train Loss: 0.254 | Train Acc: 100.000
89 Train Loss: 0.251 | Train Acc: 100.000
90 Train Loss: 0.249 | Train Acc: 100.000
91 Train Loss: 0.246 | Train Acc: 100.000
92 Train Loss: 0.244 | Train Acc: 100.000
93 Train Loss: 0.241 | Train Acc: 100.000
94 Train Loss: 0.237 | Train Acc: 100.000
95 Train Loss: 0.234 | Train Acc: 100.000
96 Train Loss: 0.233 | Train Acc: 100.000
97 Train Loss: 0.229 | Train Acc: 100.000
98 Train Loss: 0.228 | Train Acc: 100.000
99 Train Loss: 0.224 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  66
trainInputDict[data].shape :  torch.Size([274, 16, 8, 8])
copy.shape :  torch.Size([274, 1024])
copyLabel.shape :  torch.Size([274])
Class 0 has 85 instances after oversampling
Class 1 has 85 instances after oversampling
Class 2 has 85 instances after oversampling
Class 3 has 85 instances after oversampling
Class 4 has 85 instances after oversampling
Class 5 has 85 instances after oversampling
Class 6 has 85 instances after oversampling
Class 7 has 85 instances after oversampling
Class 8 has 85 instances after oversampling
Class 9 has 85 instances after oversampling
0 Train Loss: 214.499 | Train Acc: 25.375
1 Train Loss: 121.658 | Train Acc: 59.375
2 Train Loss: 77.380 | Train Acc: 77.625
3 Train Loss: 46.149 | Train Acc: 87.625
4 Train Loss: 34.274 | Train Acc: 90.875
5 Train Loss: 26.107 | Train Acc: 92.375
6 Train Loss: 16.658 | Train Acc: 96.375
7 Train Loss: 12.698 | Train Acc: 97.000
8 Train Loss: 9.693 | Train Acc: 97.875
9 Train Loss: 7.382 | Train Acc: 98.750
10 Train Loss: 5.990 | Train Acc: 98.875
11 Train Loss: 5.323 | Train Acc: 99.000
12 Train Loss: 4.157 | Train Acc: 99.375
13 Train Loss: 2.944 | Train Acc: 99.625
14 Train Loss: 2.313 | Train Acc: 99.750
15 Train Loss: 2.268 | Train Acc: 99.875
16 Train Loss: 1.645 | Train Acc: 100.000
17 Train Loss: 1.123 | Train Acc: 100.000
18 Train Loss: 0.944 | Train Acc: 100.000
19 Train Loss: 0.801 | Train Acc: 100.000
20 Train Loss: 0.671 | Train Acc: 100.000
21 Train Loss: 0.644 | Train Acc: 100.000
22 Train Loss: 0.605 | Train Acc: 100.000
23 Train Loss: 0.578 | Train Acc: 100.000
24 Train Loss: 0.551 | Train Acc: 100.000
25 Train Loss: 0.524 | Train Acc: 100.000
26 Train Loss: 0.502 | Train Acc: 100.000
27 Train Loss: 0.466 | Train Acc: 100.000
28 Train Loss: 0.447 | Train Acc: 100.000
29 Train Loss: 0.424 | Train Acc: 100.000
30 Train Loss: 0.404 | Train Acc: 100.000
31 Train Loss: 0.384 | Train Acc: 100.000
32 Train Loss: 0.373 | Train Acc: 100.000
33 Train Loss: 0.354 | Train Acc: 100.000
34 Train Loss: 0.323 | Train Acc: 100.000
35 Train Loss: 0.330 | Train Acc: 100.000
36 Train Loss: 0.291 | Train Acc: 100.000
37 Train Loss: 0.275 | Train Acc: 100.000
38 Train Loss: 0.261 | Train Acc: 100.000
39 Train Loss: 0.254 | Train Acc: 100.000
40 Train Loss: 0.232 | Train Acc: 100.000
41 Train Loss: 0.223 | Train Acc: 100.000
42 Train Loss: 0.218 | Train Acc: 100.000
43 Train Loss: 0.214 | Train Acc: 100.000
44 Train Loss: 0.207 | Train Acc: 100.000
45 Train Loss: 0.203 | Train Acc: 100.000
46 Train Loss: 0.198 | Train Acc: 100.000
47 Train Loss: 0.191 | Train Acc: 100.000
48 Train Loss: 0.188 | Train Acc: 100.000
49 Train Loss: 0.185 | Train Acc: 100.000
50 Train Loss: 0.180 | Train Acc: 100.000
51 Train Loss: 0.174 | Train Acc: 100.000
52 Train Loss: 0.167 | Train Acc: 100.000
53 Train Loss: 0.165 | Train Acc: 100.000
54 Train Loss: 0.156 | Train Acc: 100.000
55 Train Loss: 0.153 | Train Acc: 100.000
56 Train Loss: 0.147 | Train Acc: 100.000
57 Train Loss: 0.144 | Train Acc: 100.000
58 Train Loss: 0.139 | Train Acc: 100.000
59 Train Loss: 0.135 | Train Acc: 100.000
60 Train Loss: 0.126 | Train Acc: 100.000
61 Train Loss: 0.125 | Train Acc: 100.000
62 Train Loss: 0.123 | Train Acc: 100.000
63 Train Loss: 0.121 | Train Acc: 100.000
64 Train Loss: 0.120 | Train Acc: 100.000
65 Train Loss: 0.117 | Train Acc: 100.000
66 Train Loss: 0.115 | Train Acc: 100.000
67 Train Loss: 0.113 | Train Acc: 100.000
68 Train Loss: 0.112 | Train Acc: 100.000
69 Train Loss: 0.109 | Train Acc: 100.000
70 Train Loss: 0.107 | Train Acc: 100.000
71 Train Loss: 0.106 | Train Acc: 100.000
72 Train Loss: 0.103 | Train Acc: 100.000
73 Train Loss: 0.100 | Train Acc: 100.000
74 Train Loss: 0.099 | Train Acc: 100.000
75 Train Loss: 0.097 | Train Acc: 100.000
76 Train Loss: 0.094 | Train Acc: 100.000
77 Train Loss: 0.092 | Train Acc: 100.000
78 Train Loss: 0.090 | Train Acc: 100.000
79 Train Loss: 0.088 | Train Acc: 100.000
80 Train Loss: 0.085 | Train Acc: 100.000
81 Train Loss: 0.084 | Train Acc: 100.000
82 Train Loss: 0.082 | Train Acc: 100.000
83 Train Loss: 0.082 | Train Acc: 100.000
84 Train Loss: 0.080 | Train Acc: 100.000
85 Train Loss: 0.080 | Train Acc: 100.000
86 Train Loss: 0.079 | Train Acc: 100.000
87 Train Loss: 0.078 | Train Acc: 100.000
88 Train Loss: 0.077 | Train Acc: 100.000
89 Train Loss: 0.076 | Train Acc: 100.000
90 Train Loss: 0.075 | Train Acc: 100.000
91 Train Loss: 0.074 | Train Acc: 100.000
92 Train Loss: 0.073 | Train Acc: 100.000
93 Train Loss: 0.072 | Train Acc: 100.000
94 Train Loss: 0.070 | Train Acc: 100.000
95 Train Loss: 0.069 | Train Acc: 100.000
96 Train Loss: 0.069 | Train Acc: 100.000
97 Train Loss: 0.067 | Train Acc: 100.000
98 Train Loss: 0.066 | Train Acc: 100.000
99 Train Loss: 0.065 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  67
trainInputDict[data].shape :  torch.Size([247, 16, 8, 8])
copy.shape :  torch.Size([247, 1024])
copyLabel.shape :  torch.Size([247])
Class 0 has 86 instances after oversampling
Class 1 has 86 instances after oversampling
Class 2 has 86 instances after oversampling
Class 3 has 86 instances after oversampling
Class 4 has 86 instances after oversampling
Class 5 has 86 instances after oversampling
Class 6 has 86 instances after oversampling
Class 7 has 86 instances after oversampling
Class 8 has 86 instances after oversampling
Class 9 has 86 instances after oversampling
0 Train Loss: 182.047 | Train Acc: 44.125
1 Train Loss: 86.938 | Train Acc: 73.250
2 Train Loss: 56.228 | Train Acc: 83.250
3 Train Loss: 37.620 | Train Acc: 88.750
4 Train Loss: 28.271 | Train Acc: 92.000
5 Train Loss: 24.544 | Train Acc: 92.500
6 Train Loss: 16.048 | Train Acc: 96.000
7 Train Loss: 12.610 | Train Acc: 96.875
8 Train Loss: 11.893 | Train Acc: 97.375
9 Train Loss: 8.991 | Train Acc: 98.375
10 Train Loss: 6.974 | Train Acc: 99.000
11 Train Loss: 6.069 | Train Acc: 98.375
12 Train Loss: 3.935 | Train Acc: 99.750
13 Train Loss: 2.798 | Train Acc: 99.625
14 Train Loss: 1.918 | Train Acc: 100.000
15 Train Loss: 1.671 | Train Acc: 100.000
16 Train Loss: 1.267 | Train Acc: 100.000
17 Train Loss: 1.041 | Train Acc: 100.000
18 Train Loss: 0.950 | Train Acc: 100.000
19 Train Loss: 0.796 | Train Acc: 100.000
20 Train Loss: 0.646 | Train Acc: 100.000
21 Train Loss: 0.598 | Train Acc: 100.000
22 Train Loss: 0.573 | Train Acc: 100.000
23 Train Loss: 0.537 | Train Acc: 100.000
24 Train Loss: 0.518 | Train Acc: 100.000
25 Train Loss: 0.490 | Train Acc: 100.000
26 Train Loss: 0.460 | Train Acc: 100.000
27 Train Loss: 0.445 | Train Acc: 100.000
28 Train Loss: 0.421 | Train Acc: 100.000
29 Train Loss: 0.396 | Train Acc: 100.000
30 Train Loss: 0.375 | Train Acc: 100.000
31 Train Loss: 0.373 | Train Acc: 100.000
32 Train Loss: 0.341 | Train Acc: 100.000
33 Train Loss: 0.320 | Train Acc: 100.000
34 Train Loss: 0.303 | Train Acc: 100.000
35 Train Loss: 0.291 | Train Acc: 100.000
36 Train Loss: 0.281 | Train Acc: 100.000
37 Train Loss: 0.261 | Train Acc: 100.000
38 Train Loss: 0.242 | Train Acc: 100.000
39 Train Loss: 0.235 | Train Acc: 100.000
40 Train Loss: 0.212 | Train Acc: 100.000
41 Train Loss: 0.207 | Train Acc: 100.000
42 Train Loss: 0.202 | Train Acc: 100.000
43 Train Loss: 0.197 | Train Acc: 100.000
44 Train Loss: 0.193 | Train Acc: 100.000
45 Train Loss: 0.188 | Train Acc: 100.000
46 Train Loss: 0.184 | Train Acc: 100.000
47 Train Loss: 0.179 | Train Acc: 100.000
48 Train Loss: 0.173 | Train Acc: 100.000
49 Train Loss: 0.170 | Train Acc: 100.000
50 Train Loss: 0.167 | Train Acc: 100.000
51 Train Loss: 0.160 | Train Acc: 100.000
52 Train Loss: 0.156 | Train Acc: 100.000
53 Train Loss: 0.152 | Train Acc: 100.000
54 Train Loss: 0.146 | Train Acc: 100.000
55 Train Loss: 0.141 | Train Acc: 100.000
56 Train Loss: 0.140 | Train Acc: 100.000
57 Train Loss: 0.133 | Train Acc: 100.000
58 Train Loss: 0.128 | Train Acc: 100.000
59 Train Loss: 0.125 | Train Acc: 100.000
60 Train Loss: 0.118 | Train Acc: 100.000
61 Train Loss: 0.115 | Train Acc: 100.000
62 Train Loss: 0.113 | Train Acc: 100.000
63 Train Loss: 0.112 | Train Acc: 100.000
64 Train Loss: 0.110 | Train Acc: 100.000
65 Train Loss: 0.109 | Train Acc: 100.000
66 Train Loss: 0.107 | Train Acc: 100.000
67 Train Loss: 0.105 | Train Acc: 100.000
68 Train Loss: 0.103 | Train Acc: 100.000
69 Train Loss: 0.101 | Train Acc: 100.000
70 Train Loss: 0.099 | Train Acc: 100.000
71 Train Loss: 0.099 | Train Acc: 100.000
72 Train Loss: 0.095 | Train Acc: 100.000
73 Train Loss: 0.095 | Train Acc: 100.000
74 Train Loss: 0.092 | Train Acc: 100.000
75 Train Loss: 0.090 | Train Acc: 100.000
76 Train Loss: 0.087 | Train Acc: 100.000
77 Train Loss: 0.086 | Train Acc: 100.000
78 Train Loss: 0.085 | Train Acc: 100.000
79 Train Loss: 0.081 | Train Acc: 100.000
80 Train Loss: 0.079 | Train Acc: 100.000
81 Train Loss: 0.078 | Train Acc: 100.000
82 Train Loss: 0.077 | Train Acc: 100.000
83 Train Loss: 0.076 | Train Acc: 100.000
84 Train Loss: 0.076 | Train Acc: 100.000
85 Train Loss: 0.074 | Train Acc: 100.000
86 Train Loss: 0.073 | Train Acc: 100.000
87 Train Loss: 0.073 | Train Acc: 100.000
88 Train Loss: 0.071 | Train Acc: 100.000
89 Train Loss: 0.071 | Train Acc: 100.000
90 Train Loss: 0.070 | Train Acc: 100.000
91 Train Loss: 0.069 | Train Acc: 100.000
92 Train Loss: 0.068 | Train Acc: 100.000
93 Train Loss: 0.067 | Train Acc: 100.000
94 Train Loss: 0.066 | Train Acc: 100.000
95 Train Loss: 0.065 | Train Acc: 100.000
96 Train Loss: 0.064 | Train Acc: 100.000
97 Train Loss: 0.063 | Train Acc: 100.000
98 Train Loss: 0.062 | Train Acc: 100.000
99 Train Loss: 0.061 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  68
trainInputDict[data].shape :  torch.Size([542, 16, 8, 8])
copy.shape :  torch.Size([542, 1024])
copyLabel.shape :  torch.Size([542])
Class 0 has 365 instances after oversampling
Class 1 has 364 instances after oversampling
Class 2 has 365 instances after oversampling
Class 3 has 364 instances after oversampling
Class 4 has 364 instances after oversampling
Class 5 has 1 instances after oversampling
Class 6 has 364 instances after oversampling
Class 7 has 365 instances after oversampling
Class 8 has 364 instances after oversampling
0 Train Loss: 158.837 | Train Acc: 45.517
1 Train Loss: 76.254 | Train Acc: 72.966
2 Train Loss: 42.022 | Train Acc: 85.724
3 Train Loss: 26.781 | Train Acc: 90.897
4 Train Loss: 24.170 | Train Acc: 91.724
5 Train Loss: 13.989 | Train Acc: 95.724
6 Train Loss: 10.964 | Train Acc: 96.862
7 Train Loss: 9.435 | Train Acc: 97.379
8 Train Loss: 7.179 | Train Acc: 98.069
9 Train Loss: 6.499 | Train Acc: 98.448
10 Train Loss: 5.558 | Train Acc: 98.517
11 Train Loss: 4.609 | Train Acc: 98.828
12 Train Loss: 4.831 | Train Acc: 98.655
13 Train Loss: 3.067 | Train Acc: 99.207
14 Train Loss: 2.300 | Train Acc: 99.552
15 Train Loss: 1.981 | Train Acc: 99.655
16 Train Loss: 1.590 | Train Acc: 99.793
17 Train Loss: 1.567 | Train Acc: 99.793
18 Train Loss: 1.346 | Train Acc: 99.793
19 Train Loss: 0.827 | Train Acc: 100.000
20 Train Loss: 0.657 | Train Acc: 100.000
21 Train Loss: 0.607 | Train Acc: 100.000
22 Train Loss: 0.599 | Train Acc: 100.000
23 Train Loss: 0.577 | Train Acc: 100.000
24 Train Loss: 0.548 | Train Acc: 100.000
25 Train Loss: 0.504 | Train Acc: 100.000
26 Train Loss: 0.480 | Train Acc: 100.000
27 Train Loss: 0.480 | Train Acc: 100.000
28 Train Loss: 0.453 | Train Acc: 100.000
29 Train Loss: 0.414 | Train Acc: 100.000
30 Train Loss: 0.379 | Train Acc: 100.000
31 Train Loss: 0.374 | Train Acc: 100.000
32 Train Loss: 0.339 | Train Acc: 100.000
33 Train Loss: 0.315 | Train Acc: 100.000
34 Train Loss: 0.319 | Train Acc: 100.000
35 Train Loss: 0.304 | Train Acc: 100.000
36 Train Loss: 0.268 | Train Acc: 100.000
37 Train Loss: 0.258 | Train Acc: 100.000
38 Train Loss: 0.235 | Train Acc: 100.000
39 Train Loss: 0.237 | Train Acc: 100.000
40 Train Loss: 0.209 | Train Acc: 100.000
41 Train Loss: 0.206 | Train Acc: 100.000
42 Train Loss: 0.198 | Train Acc: 100.000
43 Train Loss: 0.197 | Train Acc: 100.000
44 Train Loss: 0.189 | Train Acc: 100.000
45 Train Loss: 0.188 | Train Acc: 100.000
46 Train Loss: 0.181 | Train Acc: 100.000
47 Train Loss: 0.176 | Train Acc: 100.000
48 Train Loss: 0.172 | Train Acc: 100.000
49 Train Loss: 0.167 | Train Acc: 100.000
50 Train Loss: 0.164 | Train Acc: 100.000
51 Train Loss: 0.159 | Train Acc: 100.000
52 Train Loss: 0.154 | Train Acc: 100.000
53 Train Loss: 0.149 | Train Acc: 100.000
54 Train Loss: 0.145 | Train Acc: 100.000
55 Train Loss: 0.139 | Train Acc: 100.000
56 Train Loss: 0.137 | Train Acc: 100.000
57 Train Loss: 0.131 | Train Acc: 100.000
58 Train Loss: 0.129 | Train Acc: 100.000
59 Train Loss: 0.122 | Train Acc: 100.000
60 Train Loss: 0.117 | Train Acc: 100.000
61 Train Loss: 0.112 | Train Acc: 100.000
62 Train Loss: 0.112 | Train Acc: 100.000
63 Train Loss: 0.111 | Train Acc: 100.000
64 Train Loss: 0.108 | Train Acc: 100.000
65 Train Loss: 0.106 | Train Acc: 100.000
66 Train Loss: 0.105 | Train Acc: 100.000
67 Train Loss: 0.104 | Train Acc: 100.000
68 Train Loss: 0.101 | Train Acc: 100.000
69 Train Loss: 0.100 | Train Acc: 100.000
70 Train Loss: 0.099 | Train Acc: 100.000
71 Train Loss: 0.096 | Train Acc: 100.000
72 Train Loss: 0.094 | Train Acc: 100.000
73 Train Loss: 0.092 | Train Acc: 100.000
74 Train Loss: 0.091 | Train Acc: 100.000
75 Train Loss: 0.088 | Train Acc: 100.000
76 Train Loss: 0.087 | Train Acc: 100.000
77 Train Loss: 0.085 | Train Acc: 100.000
78 Train Loss: 0.083 | Train Acc: 100.000
79 Train Loss: 0.081 | Train Acc: 100.000
80 Train Loss: 0.077 | Train Acc: 100.000
81 Train Loss: 0.077 | Train Acc: 100.000
82 Train Loss: 0.076 | Train Acc: 100.000
83 Train Loss: 0.075 | Train Acc: 100.000
84 Train Loss: 0.074 | Train Acc: 100.000
85 Train Loss: 0.073 | Train Acc: 100.000
86 Train Loss: 0.073 | Train Acc: 100.000
87 Train Loss: 0.072 | Train Acc: 100.000
88 Train Loss: 0.071 | Train Acc: 100.000
89 Train Loss: 0.070 | Train Acc: 100.000
90 Train Loss: 0.069 | Train Acc: 100.000
91 Train Loss: 0.069 | Train Acc: 100.000
92 Train Loss: 0.067 | Train Acc: 100.000
93 Train Loss: 0.067 | Train Acc: 100.000
94 Train Loss: 0.066 | Train Acc: 100.000
95 Train Loss: 0.064 | Train Acc: 100.000
96 Train Loss: 0.064 | Train Acc: 100.000
97 Train Loss: 0.063 | Train Acc: 100.000
98 Train Loss: 0.062 | Train Acc: 100.000
99 Train Loss: 0.061 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  69
trainInputDict[data].shape :  torch.Size([414, 16, 8, 8])
copy.shape :  torch.Size([414, 1024])
copyLabel.shape :  torch.Size([414])
Class 0 has 210 instances after oversampling
Class 1 has 209 instances after oversampling
Class 2 has 210 instances after oversampling
Class 3 has 1 instances after oversampling
Class 4 has 1 instances after oversampling
Class 5 has 210 instances after oversampling
Class 6 has 209 instances after oversampling
0 Train Loss: 121.443 | Train Acc: 58.900
1 Train Loss: 40.975 | Train Acc: 87.300
2 Train Loss: 26.255 | Train Acc: 92.400
3 Train Loss: 20.901 | Train Acc: 93.600
4 Train Loss: 18.068 | Train Acc: 94.200
5 Train Loss: 12.775 | Train Acc: 95.500
6 Train Loss: 10.040 | Train Acc: 96.400
7 Train Loss: 9.837 | Train Acc: 96.500
8 Train Loss: 8.792 | Train Acc: 97.300
9 Train Loss: 7.064 | Train Acc: 97.600
10 Train Loss: 5.515 | Train Acc: 98.000
11 Train Loss: 4.949 | Train Acc: 98.400
12 Train Loss: 3.851 | Train Acc: 99.000
13 Train Loss: 3.422 | Train Acc: 99.000
14 Train Loss: 3.504 | Train Acc: 99.000
15 Train Loss: 2.309 | Train Acc: 99.400
16 Train Loss: 3.398 | Train Acc: 99.100
17 Train Loss: 1.419 | Train Acc: 100.000
18 Train Loss: 1.072 | Train Acc: 100.000
19 Train Loss: 2.012 | Train Acc: 99.600
20 Train Loss: 1.111 | Train Acc: 99.700
21 Train Loss: 0.616 | Train Acc: 100.000
22 Train Loss: 0.523 | Train Acc: 100.000
23 Train Loss: 0.462 | Train Acc: 100.000
24 Train Loss: 0.432 | Train Acc: 100.000
25 Train Loss: 0.408 | Train Acc: 100.000
26 Train Loss: 0.373 | Train Acc: 100.000
27 Train Loss: 0.356 | Train Acc: 100.000
28 Train Loss: 0.339 | Train Acc: 100.000
29 Train Loss: 0.334 | Train Acc: 100.000
30 Train Loss: 0.316 | Train Acc: 100.000
31 Train Loss: 0.285 | Train Acc: 100.000
32 Train Loss: 0.277 | Train Acc: 100.000
33 Train Loss: 0.274 | Train Acc: 100.000
34 Train Loss: 0.256 | Train Acc: 100.000
35 Train Loss: 0.219 | Train Acc: 100.000
36 Train Loss: 0.250 | Train Acc: 100.000
37 Train Loss: 0.214 | Train Acc: 100.000
38 Train Loss: 0.190 | Train Acc: 100.000
39 Train Loss: 0.190 | Train Acc: 100.000
40 Train Loss: 0.163 | Train Acc: 100.000
41 Train Loss: 0.160 | Train Acc: 100.000
42 Train Loss: 0.156 | Train Acc: 100.000
43 Train Loss: 0.152 | Train Acc: 100.000
44 Train Loss: 0.150 | Train Acc: 100.000
45 Train Loss: 0.144 | Train Acc: 100.000
46 Train Loss: 0.143 | Train Acc: 100.000
47 Train Loss: 0.142 | Train Acc: 100.000
48 Train Loss: 0.137 | Train Acc: 100.000
49 Train Loss: 0.130 | Train Acc: 100.000
50 Train Loss: 0.130 | Train Acc: 100.000
51 Train Loss: 0.124 | Train Acc: 100.000
52 Train Loss: 0.118 | Train Acc: 100.000
53 Train Loss: 0.119 | Train Acc: 100.000
54 Train Loss: 0.114 | Train Acc: 100.000
55 Train Loss: 0.110 | Train Acc: 100.000
56 Train Loss: 0.107 | Train Acc: 100.000
57 Train Loss: 0.105 | Train Acc: 100.000
58 Train Loss: 0.099 | Train Acc: 100.000
59 Train Loss: 0.097 | Train Acc: 100.000
60 Train Loss: 0.091 | Train Acc: 100.000
61 Train Loss: 0.090 | Train Acc: 100.000
62 Train Loss: 0.088 | Train Acc: 100.000
63 Train Loss: 0.087 | Train Acc: 100.000
64 Train Loss: 0.085 | Train Acc: 100.000
65 Train Loss: 0.084 | Train Acc: 100.000
66 Train Loss: 0.082 | Train Acc: 100.000
67 Train Loss: 0.081 | Train Acc: 100.000
68 Train Loss: 0.079 | Train Acc: 100.000
69 Train Loss: 0.079 | Train Acc: 100.000
70 Train Loss: 0.076 | Train Acc: 100.000
71 Train Loss: 0.076 | Train Acc: 100.000
72 Train Loss: 0.073 | Train Acc: 100.000
73 Train Loss: 0.072 | Train Acc: 100.000
74 Train Loss: 0.070 | Train Acc: 100.000
75 Train Loss: 0.070 | Train Acc: 100.000
76 Train Loss: 0.067 | Train Acc: 100.000
77 Train Loss: 0.067 | Train Acc: 100.000
78 Train Loss: 0.065 | Train Acc: 100.000
79 Train Loss: 0.063 | Train Acc: 100.000
80 Train Loss: 0.061 | Train Acc: 100.000
81 Train Loss: 0.060 | Train Acc: 100.000
82 Train Loss: 0.059 | Train Acc: 100.000
83 Train Loss: 0.059 | Train Acc: 100.000
84 Train Loss: 0.058 | Train Acc: 100.000
85 Train Loss: 0.057 | Train Acc: 100.000
86 Train Loss: 0.057 | Train Acc: 100.000
87 Train Loss: 0.056 | Train Acc: 100.000
88 Train Loss: 0.055 | Train Acc: 100.000
89 Train Loss: 0.054 | Train Acc: 100.000
90 Train Loss: 0.055 | Train Acc: 100.000
91 Train Loss: 0.053 | Train Acc: 100.000
92 Train Loss: 0.052 | Train Acc: 100.000
93 Train Loss: 0.052 | Train Acc: 100.000
94 Train Loss: 0.051 | Train Acc: 100.000
95 Train Loss: 0.050 | Train Acc: 100.000
96 Train Loss: 0.050 | Train Acc: 100.000
97 Train Loss: 0.049 | Train Acc: 100.000
98 Train Loss: 0.048 | Train Acc: 100.000
99 Train Loss: 0.048 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  70
trainInputDict[data].shape :  torch.Size([275, 16, 8, 8])
copy.shape :  torch.Size([275, 1024])
copyLabel.shape :  torch.Size([275])
Class 0 has 135 instances after oversampling
Class 1 has 135 instances after oversampling
Class 2 has 135 instances after oversampling
Class 3 has 135 instances after oversampling
Class 4 has 135 instances after oversampling
Class 5 has 1 instances after oversampling
Class 6 has 135 instances after oversampling
Class 7 has 135 instances after oversampling
0 Train Loss: 157.410 | Train Acc: 39.556
1 Train Loss: 72.925 | Train Acc: 75.667
2 Train Loss: 41.647 | Train Acc: 88.333
3 Train Loss: 26.756 | Train Acc: 91.444
4 Train Loss: 21.793 | Train Acc: 92.778
5 Train Loss: 15.534 | Train Acc: 95.778
6 Train Loss: 16.075 | Train Acc: 94.556
7 Train Loss: 12.720 | Train Acc: 95.778
8 Train Loss: 8.842 | Train Acc: 97.889
9 Train Loss: 6.669 | Train Acc: 97.444
10 Train Loss: 6.857 | Train Acc: 97.778
11 Train Loss: 7.123 | Train Acc: 97.444
12 Train Loss: 6.991 | Train Acc: 97.444
13 Train Loss: 3.970 | Train Acc: 99.444
14 Train Loss: 5.099 | Train Acc: 98.333
15 Train Loss: 3.866 | Train Acc: 99.000
16 Train Loss: 2.124 | Train Acc: 99.778
17 Train Loss: 1.979 | Train Acc: 99.889
18 Train Loss: 1.600 | Train Acc: 99.889
19 Train Loss: 1.423 | Train Acc: 99.778
20 Train Loss: 1.045 | Train Acc: 99.889
21 Train Loss: 0.894 | Train Acc: 99.889
22 Train Loss: 0.818 | Train Acc: 99.889
23 Train Loss: 0.777 | Train Acc: 99.889
24 Train Loss: 0.726 | Train Acc: 100.000
25 Train Loss: 0.686 | Train Acc: 100.000
26 Train Loss: 0.761 | Train Acc: 99.889
27 Train Loss: 0.628 | Train Acc: 100.000
28 Train Loss: 0.614 | Train Acc: 100.000
29 Train Loss: 0.583 | Train Acc: 100.000
30 Train Loss: 0.577 | Train Acc: 100.000
31 Train Loss: 0.503 | Train Acc: 100.000
32 Train Loss: 0.495 | Train Acc: 100.000
33 Train Loss: 0.443 | Train Acc: 100.000
34 Train Loss: 0.456 | Train Acc: 100.000
35 Train Loss: 0.391 | Train Acc: 100.000
36 Train Loss: 0.438 | Train Acc: 100.000
37 Train Loss: 0.590 | Train Acc: 100.000
38 Train Loss: 0.374 | Train Acc: 100.000
39 Train Loss: 0.326 | Train Acc: 100.000
40 Train Loss: 0.277 | Train Acc: 100.000
41 Train Loss: 0.260 | Train Acc: 100.000
42 Train Loss: 0.260 | Train Acc: 100.000
43 Train Loss: 0.253 | Train Acc: 100.000
44 Train Loss: 0.246 | Train Acc: 100.000
45 Train Loss: 0.238 | Train Acc: 100.000
46 Train Loss: 0.239 | Train Acc: 100.000
47 Train Loss: 0.225 | Train Acc: 100.000
48 Train Loss: 0.220 | Train Acc: 100.000
49 Train Loss: 0.217 | Train Acc: 100.000
50 Train Loss: 0.206 | Train Acc: 100.000
51 Train Loss: 0.202 | Train Acc: 100.000
52 Train Loss: 0.198 | Train Acc: 100.000
53 Train Loss: 0.192 | Train Acc: 100.000
54 Train Loss: 0.190 | Train Acc: 100.000
55 Train Loss: 0.187 | Train Acc: 100.000
56 Train Loss: 0.175 | Train Acc: 100.000
57 Train Loss: 0.171 | Train Acc: 100.000
58 Train Loss: 0.169 | Train Acc: 100.000
59 Train Loss: 0.160 | Train Acc: 100.000
60 Train Loss: 0.149 | Train Acc: 100.000
61 Train Loss: 0.146 | Train Acc: 100.000
62 Train Loss: 0.144 | Train Acc: 100.000
63 Train Loss: 0.142 | Train Acc: 100.000
64 Train Loss: 0.139 | Train Acc: 100.000
65 Train Loss: 0.137 | Train Acc: 100.000
66 Train Loss: 0.135 | Train Acc: 100.000
67 Train Loss: 0.135 | Train Acc: 100.000
68 Train Loss: 0.133 | Train Acc: 100.000
69 Train Loss: 0.129 | Train Acc: 100.000
70 Train Loss: 0.127 | Train Acc: 100.000
71 Train Loss: 0.125 | Train Acc: 100.000
72 Train Loss: 0.124 | Train Acc: 100.000
73 Train Loss: 0.120 | Train Acc: 100.000
74 Train Loss: 0.116 | Train Acc: 100.000
75 Train Loss: 0.115 | Train Acc: 100.000
76 Train Loss: 0.111 | Train Acc: 100.000
77 Train Loss: 0.114 | Train Acc: 100.000
78 Train Loss: 0.106 | Train Acc: 100.000
79 Train Loss: 0.103 | Train Acc: 100.000
80 Train Loss: 0.101 | Train Acc: 100.000
81 Train Loss: 0.098 | Train Acc: 100.000
82 Train Loss: 0.098 | Train Acc: 100.000
83 Train Loss: 0.097 | Train Acc: 100.000
84 Train Loss: 0.095 | Train Acc: 100.000
85 Train Loss: 0.095 | Train Acc: 100.000
86 Train Loss: 0.094 | Train Acc: 100.000
87 Train Loss: 0.092 | Train Acc: 100.000
88 Train Loss: 0.091 | Train Acc: 100.000
89 Train Loss: 0.091 | Train Acc: 100.000
90 Train Loss: 0.089 | Train Acc: 100.000
91 Train Loss: 0.088 | Train Acc: 100.000
92 Train Loss: 0.087 | Train Acc: 100.000
93 Train Loss: 0.086 | Train Acc: 100.000
94 Train Loss: 0.084 | Train Acc: 100.000
95 Train Loss: 0.083 | Train Acc: 100.000
96 Train Loss: 0.082 | Train Acc: 100.000
97 Train Loss: 0.082 | Train Acc: 100.000
98 Train Loss: 0.079 | Train Acc: 100.000
99 Train Loss: 0.078 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  71
trainInputDict[data].shape :  torch.Size([842, 16, 8, 8])
copy.shape :  torch.Size([842, 1024])
copyLabel.shape :  torch.Size([842])
Class 0 has 413 instances after oversampling
Class 1 has 413 instances after oversampling
Class 2 has 413 instances after oversampling
Class 3 has 413 instances after oversampling
Class 4 has 413 instances after oversampling
Class 5 has 413 instances after oversampling
Class 6 has 413 instances after oversampling
Class 7 has 413 instances after oversampling
Class 8 has 413 instances after oversampling
Class 9 has 413 instances after oversampling
0 Train Loss: 190.446 | Train Acc: 38.195
1 Train Loss: 112.564 | Train Acc: 63.780
2 Train Loss: 76.496 | Train Acc: 76.122
3 Train Loss: 55.072 | Train Acc: 82.098
4 Train Loss: 46.006 | Train Acc: 85.585
5 Train Loss: 33.327 | Train Acc: 90.000
6 Train Loss: 28.612 | Train Acc: 91.561
7 Train Loss: 23.723 | Train Acc: 92.683
8 Train Loss: 20.862 | Train Acc: 94.098
9 Train Loss: 19.002 | Train Acc: 93.976
10 Train Loss: 16.284 | Train Acc: 95.171
11 Train Loss: 14.209 | Train Acc: 96.195
12 Train Loss: 13.176 | Train Acc: 96.195
13 Train Loss: 10.418 | Train Acc: 97.171
14 Train Loss: 9.675 | Train Acc: 97.341
15 Train Loss: 8.942 | Train Acc: 98.049
16 Train Loss: 7.587 | Train Acc: 98.268
17 Train Loss: 6.698 | Train Acc: 98.195
18 Train Loss: 5.822 | Train Acc: 98.561
19 Train Loss: 5.408 | Train Acc: 98.854
20 Train Loss: 4.610 | Train Acc: 98.976
21 Train Loss: 3.862 | Train Acc: 99.463
22 Train Loss: 3.515 | Train Acc: 99.463
23 Train Loss: 3.490 | Train Acc: 99.537
24 Train Loss: 3.226 | Train Acc: 99.659
25 Train Loss: 3.054 | Train Acc: 99.610
26 Train Loss: 3.097 | Train Acc: 99.683
27 Train Loss: 2.836 | Train Acc: 99.707
28 Train Loss: 2.713 | Train Acc: 99.683
29 Train Loss: 2.709 | Train Acc: 99.683
30 Train Loss: 3.149 | Train Acc: 99.293
31 Train Loss: 2.443 | Train Acc: 99.756
32 Train Loss: 2.161 | Train Acc: 99.854
33 Train Loss: 2.434 | Train Acc: 99.683
34 Train Loss: 1.960 | Train Acc: 99.902
35 Train Loss: 1.886 | Train Acc: 99.927
36 Train Loss: 1.731 | Train Acc: 99.927
37 Train Loss: 1.693 | Train Acc: 99.927
38 Train Loss: 1.545 | Train Acc: 99.902
39 Train Loss: 1.487 | Train Acc: 99.927
40 Train Loss: 1.282 | Train Acc: 99.976
41 Train Loss: 1.225 | Train Acc: 99.976
42 Train Loss: 1.176 | Train Acc: 99.976
43 Train Loss: 1.203 | Train Acc: 99.976
44 Train Loss: 1.170 | Train Acc: 99.976
45 Train Loss: 1.130 | Train Acc: 99.976
46 Train Loss: 1.081 | Train Acc: 99.976
47 Train Loss: 1.079 | Train Acc: 99.976
48 Train Loss: 1.037 | Train Acc: 99.976
49 Train Loss: 1.046 | Train Acc: 99.976
50 Train Loss: 0.988 | Train Acc: 99.976
51 Train Loss: 0.944 | Train Acc: 99.976
52 Train Loss: 0.921 | Train Acc: 100.000
53 Train Loss: 0.919 | Train Acc: 99.976
54 Train Loss: 0.875 | Train Acc: 100.000
55 Train Loss: 0.851 | Train Acc: 100.000
56 Train Loss: 0.814 | Train Acc: 100.000
57 Train Loss: 0.779 | Train Acc: 100.000
58 Train Loss: 0.747 | Train Acc: 100.000
59 Train Loss: 0.735 | Train Acc: 100.000
60 Train Loss: 0.684 | Train Acc: 100.000
61 Train Loss: 0.677 | Train Acc: 100.000
62 Train Loss: 0.657 | Train Acc: 100.000
63 Train Loss: 0.652 | Train Acc: 100.000
64 Train Loss: 0.655 | Train Acc: 100.000
65 Train Loss: 0.632 | Train Acc: 100.000
66 Train Loss: 0.621 | Train Acc: 100.000
67 Train Loss: 0.607 | Train Acc: 100.000
68 Train Loss: 0.603 | Train Acc: 100.000
69 Train Loss: 0.596 | Train Acc: 100.000
70 Train Loss: 0.586 | Train Acc: 100.000
71 Train Loss: 0.577 | Train Acc: 100.000
72 Train Loss: 0.562 | Train Acc: 100.000
73 Train Loss: 0.555 | Train Acc: 100.000
74 Train Loss: 0.553 | Train Acc: 100.000
75 Train Loss: 0.528 | Train Acc: 100.000
76 Train Loss: 0.522 | Train Acc: 100.000
77 Train Loss: 0.518 | Train Acc: 100.000
78 Train Loss: 0.499 | Train Acc: 100.000
79 Train Loss: 0.490 | Train Acc: 100.000
80 Train Loss: 0.468 | Train Acc: 100.000
81 Train Loss: 0.463 | Train Acc: 100.000
82 Train Loss: 0.462 | Train Acc: 100.000
83 Train Loss: 0.456 | Train Acc: 100.000
84 Train Loss: 0.456 | Train Acc: 100.000
85 Train Loss: 0.451 | Train Acc: 100.000
86 Train Loss: 0.443 | Train Acc: 100.000
87 Train Loss: 0.442 | Train Acc: 100.000
88 Train Loss: 0.436 | Train Acc: 100.000
89 Train Loss: 0.435 | Train Acc: 100.000
90 Train Loss: 0.428 | Train Acc: 100.000
91 Train Loss: 0.425 | Train Acc: 100.000
92 Train Loss: 0.419 | Train Acc: 100.000
93 Train Loss: 0.416 | Train Acc: 100.000
94 Train Loss: 0.412 | Train Acc: 100.000
95 Train Loss: 0.409 | Train Acc: 100.000
96 Train Loss: 0.399 | Train Acc: 100.000
97 Train Loss: 0.397 | Train Acc: 100.000
98 Train Loss: 0.395 | Train Acc: 100.000
99 Train Loss: 0.388 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  72
trainInputDict[data].shape :  torch.Size([1245, 16, 8, 8])
copy.shape :  torch.Size([1245, 1024])
copyLabel.shape :  torch.Size([1245])
Class 0 has 643 instances after oversampling
Class 1 has 643 instances after oversampling
Class 2 has 643 instances after oversampling
Class 3 has 643 instances after oversampling
Class 4 has 643 instances after oversampling
Class 5 has 643 instances after oversampling
Class 6 has 643 instances after oversampling
Class 7 has 643 instances after oversampling
Class 8 has 643 instances after oversampling
Class 9 has 643 instances after oversampling
0 Train Loss: 226.145 | Train Acc: 18.922
1 Train Loss: 153.093 | Train Acc: 49.391
2 Train Loss: 108.608 | Train Acc: 62.328
3 Train Loss: 82.323 | Train Acc: 73.203
4 Train Loss: 68.827 | Train Acc: 78.703
5 Train Loss: 55.682 | Train Acc: 83.516
6 Train Loss: 49.556 | Train Acc: 85.266
7 Train Loss: 42.068 | Train Acc: 87.797
8 Train Loss: 36.491 | Train Acc: 89.562
9 Train Loss: 30.766 | Train Acc: 91.672
10 Train Loss: 27.467 | Train Acc: 92.172
11 Train Loss: 26.058 | Train Acc: 92.516
12 Train Loss: 25.168 | Train Acc: 92.859
13 Train Loss: 26.731 | Train Acc: 92.141
14 Train Loss: 21.206 | Train Acc: 93.938
15 Train Loss: 18.128 | Train Acc: 94.547
16 Train Loss: 18.691 | Train Acc: 94.234
17 Train Loss: 14.229 | Train Acc: 96.047
18 Train Loss: 13.043 | Train Acc: 96.344
19 Train Loss: 14.874 | Train Acc: 95.656
20 Train Loss: 11.666 | Train Acc: 96.812
21 Train Loss: 9.744 | Train Acc: 97.594
22 Train Loss: 9.020 | Train Acc: 97.562
23 Train Loss: 8.350 | Train Acc: 97.953
24 Train Loss: 7.904 | Train Acc: 98.203
25 Train Loss: 8.033 | Train Acc: 97.984
26 Train Loss: 7.541 | Train Acc: 98.094
27 Train Loss: 7.060 | Train Acc: 98.312
28 Train Loss: 6.518 | Train Acc: 98.438
29 Train Loss: 6.599 | Train Acc: 98.469
30 Train Loss: 6.009 | Train Acc: 98.641
31 Train Loss: 5.929 | Train Acc: 98.703
32 Train Loss: 5.545 | Train Acc: 98.797
33 Train Loss: 5.401 | Train Acc: 98.734
34 Train Loss: 5.259 | Train Acc: 98.734
35 Train Loss: 4.955 | Train Acc: 98.828
36 Train Loss: 4.833 | Train Acc: 98.984
37 Train Loss: 4.535 | Train Acc: 99.000
38 Train Loss: 4.243 | Train Acc: 99.141
39 Train Loss: 3.864 | Train Acc: 99.234
40 Train Loss: 3.463 | Train Acc: 99.406
41 Train Loss: 3.336 | Train Acc: 99.406
42 Train Loss: 3.308 | Train Acc: 99.438
43 Train Loss: 3.194 | Train Acc: 99.422
44 Train Loss: 3.277 | Train Acc: 99.516
45 Train Loss: 3.008 | Train Acc: 99.531
46 Train Loss: 3.047 | Train Acc: 99.562
47 Train Loss: 2.971 | Train Acc: 99.484
48 Train Loss: 2.871 | Train Acc: 99.562
49 Train Loss: 2.815 | Train Acc: 99.578
50 Train Loss: 2.743 | Train Acc: 99.609
51 Train Loss: 2.662 | Train Acc: 99.656
52 Train Loss: 2.555 | Train Acc: 99.656
53 Train Loss: 2.570 | Train Acc: 99.562
54 Train Loss: 2.439 | Train Acc: 99.688
55 Train Loss: 2.338 | Train Acc: 99.734
56 Train Loss: 2.249 | Train Acc: 99.766
57 Train Loss: 2.235 | Train Acc: 99.766
58 Train Loss: 2.141 | Train Acc: 99.797
59 Train Loss: 2.077 | Train Acc: 99.797
60 Train Loss: 1.948 | Train Acc: 99.859
61 Train Loss: 1.923 | Train Acc: 99.844
62 Train Loss: 1.888 | Train Acc: 99.891
63 Train Loss: 1.861 | Train Acc: 99.859
64 Train Loss: 1.839 | Train Acc: 99.875
65 Train Loss: 1.844 | Train Acc: 99.828
66 Train Loss: 1.776 | Train Acc: 99.891
67 Train Loss: 1.765 | Train Acc: 99.891
68 Train Loss: 1.736 | Train Acc: 99.875
69 Train Loss: 1.708 | Train Acc: 99.859
70 Train Loss: 1.682 | Train Acc: 99.922
71 Train Loss: 1.653 | Train Acc: 99.922
72 Train Loss: 1.627 | Train Acc: 99.922
73 Train Loss: 1.627 | Train Acc: 99.891
74 Train Loss: 1.579 | Train Acc: 99.938
75 Train Loss: 1.581 | Train Acc: 99.906
76 Train Loss: 1.521 | Train Acc: 99.922
77 Train Loss: 1.530 | Train Acc: 99.906
78 Train Loss: 1.507 | Train Acc: 99.938
79 Train Loss: 1.452 | Train Acc: 99.922
80 Train Loss: 1.414 | Train Acc: 99.953
81 Train Loss: 1.414 | Train Acc: 99.938
82 Train Loss: 1.397 | Train Acc: 99.938
83 Train Loss: 1.374 | Train Acc: 99.953
84 Train Loss: 1.383 | Train Acc: 99.938
85 Train Loss: 1.368 | Train Acc: 99.953
86 Train Loss: 1.357 | Train Acc: 99.938
87 Train Loss: 1.355 | Train Acc: 99.938
88 Train Loss: 1.333 | Train Acc: 99.953
89 Train Loss: 1.323 | Train Acc: 99.984
90 Train Loss: 1.319 | Train Acc: 99.953
91 Train Loss: 1.310 | Train Acc: 99.969
92 Train Loss: 1.295 | Train Acc: 99.984
93 Train Loss: 1.279 | Train Acc: 99.953
94 Train Loss: 1.278 | Train Acc: 99.969
95 Train Loss: 1.261 | Train Acc: 99.984
96 Train Loss: 1.256 | Train Acc: 99.953
97 Train Loss: 1.251 | Train Acc: 99.984
98 Train Loss: 1.234 | Train Acc: 99.969
99 Train Loss: 1.239 | Train Acc: 99.969
CNN trained successfully...
Running nodeId:  73
trainInputDict[data].shape :  torch.Size([1315, 16, 8, 8])
copy.shape :  torch.Size([1315, 1024])
copyLabel.shape :  torch.Size([1315])
Class 0 has 433 instances after oversampling
Class 1 has 434 instances after oversampling
Class 2 has 433 instances after oversampling
Class 3 has 433 instances after oversampling
Class 4 has 433 instances after oversampling
Class 5 has 433 instances after oversampling
Class 6 has 433 instances after oversampling
Class 7 has 433 instances after oversampling
Class 8 has 433 instances after oversampling
Class 9 has 434 instances after oversampling
0 Train Loss: 230.540 | Train Acc: 14.535
1 Train Loss: 196.982 | Train Acc: 33.930
2 Train Loss: 158.725 | Train Acc: 49.209
3 Train Loss: 128.308 | Train Acc: 59.070
4 Train Loss: 97.757 | Train Acc: 69.791
5 Train Loss: 76.790 | Train Acc: 76.209
6 Train Loss: 64.576 | Train Acc: 80.442
7 Train Loss: 55.828 | Train Acc: 83.349
8 Train Loss: 49.328 | Train Acc: 84.814
9 Train Loss: 44.758 | Train Acc: 85.953
10 Train Loss: 41.806 | Train Acc: 87.442
11 Train Loss: 35.948 | Train Acc: 88.558
12 Train Loss: 32.523 | Train Acc: 89.837
13 Train Loss: 29.391 | Train Acc: 91.047
14 Train Loss: 26.778 | Train Acc: 91.628
15 Train Loss: 24.248 | Train Acc: 92.488
16 Train Loss: 24.716 | Train Acc: 92.116
17 Train Loss: 21.109 | Train Acc: 93.605
18 Train Loss: 19.324 | Train Acc: 94.140
19 Train Loss: 17.115 | Train Acc: 94.698
20 Train Loss: 14.937 | Train Acc: 96.070
21 Train Loss: 14.229 | Train Acc: 95.930
22 Train Loss: 13.629 | Train Acc: 96.326
23 Train Loss: 13.200 | Train Acc: 96.256
24 Train Loss: 12.716 | Train Acc: 96.419
25 Train Loss: 12.055 | Train Acc: 96.837
26 Train Loss: 11.854 | Train Acc: 97.302
27 Train Loss: 11.128 | Train Acc: 97.558
28 Train Loss: 10.660 | Train Acc: 97.442
29 Train Loss: 10.357 | Train Acc: 97.395
30 Train Loss: 9.672 | Train Acc: 97.698
31 Train Loss: 9.138 | Train Acc: 98.279
32 Train Loss: 9.371 | Train Acc: 97.791
33 Train Loss: 8.444 | Train Acc: 98.023
34 Train Loss: 8.085 | Train Acc: 98.465
35 Train Loss: 7.537 | Train Acc: 98.535
36 Train Loss: 7.214 | Train Acc: 98.605
37 Train Loss: 6.647 | Train Acc: 98.860
38 Train Loss: 6.182 | Train Acc: 98.977
39 Train Loss: 5.812 | Train Acc: 99.209
40 Train Loss: 5.220 | Train Acc: 99.302
41 Train Loss: 5.057 | Train Acc: 99.442
42 Train Loss: 4.860 | Train Acc: 99.512
43 Train Loss: 4.714 | Train Acc: 99.651
44 Train Loss: 4.613 | Train Acc: 99.558
45 Train Loss: 4.488 | Train Acc: 99.651
46 Train Loss: 4.392 | Train Acc: 99.628
47 Train Loss: 4.262 | Train Acc: 99.721
48 Train Loss: 4.163 | Train Acc: 99.698
49 Train Loss: 4.047 | Train Acc: 99.721
50 Train Loss: 3.917 | Train Acc: 99.744
51 Train Loss: 3.805 | Train Acc: 99.744
52 Train Loss: 3.709 | Train Acc: 99.767
53 Train Loss: 3.598 | Train Acc: 99.814
54 Train Loss: 3.471 | Train Acc: 99.791
55 Train Loss: 3.320 | Train Acc: 99.837
56 Train Loss: 3.216 | Train Acc: 99.860
57 Train Loss: 3.100 | Train Acc: 99.837
58 Train Loss: 3.086 | Train Acc: 99.860
59 Train Loss: 2.934 | Train Acc: 99.814
60 Train Loss: 2.704 | Train Acc: 99.884
61 Train Loss: 2.682 | Train Acc: 99.884
62 Train Loss: 2.636 | Train Acc: 99.884
63 Train Loss: 2.620 | Train Acc: 99.884
64 Train Loss: 2.562 | Train Acc: 99.907
65 Train Loss: 2.534 | Train Acc: 99.907
66 Train Loss: 2.476 | Train Acc: 99.884
67 Train Loss: 2.457 | Train Acc: 99.930
68 Train Loss: 2.425 | Train Acc: 99.907
69 Train Loss: 2.383 | Train Acc: 99.907
70 Train Loss: 2.334 | Train Acc: 99.977
71 Train Loss: 2.303 | Train Acc: 99.953
72 Train Loss: 2.256 | Train Acc: 100.000
73 Train Loss: 2.216 | Train Acc: 99.977
74 Train Loss: 2.175 | Train Acc: 99.977
75 Train Loss: 2.145 | Train Acc: 99.977
76 Train Loss: 2.150 | Train Acc: 99.953
77 Train Loss: 2.098 | Train Acc: 99.953
78 Train Loss: 2.046 | Train Acc: 100.000
79 Train Loss: 2.017 | Train Acc: 100.000
80 Train Loss: 1.939 | Train Acc: 100.000
81 Train Loss: 1.925 | Train Acc: 100.000
82 Train Loss: 1.905 | Train Acc: 100.000
83 Train Loss: 1.893 | Train Acc: 100.000
84 Train Loss: 1.882 | Train Acc: 100.000
85 Train Loss: 1.864 | Train Acc: 100.000
86 Train Loss: 1.860 | Train Acc: 100.000
87 Train Loss: 1.842 | Train Acc: 100.000
88 Train Loss: 1.828 | Train Acc: 100.000
89 Train Loss: 1.811 | Train Acc: 100.000
90 Train Loss: 1.791 | Train Acc: 100.000
91 Train Loss: 1.784 | Train Acc: 100.000
92 Train Loss: 1.766 | Train Acc: 100.000
93 Train Loss: 1.755 | Train Acc: 100.000
94 Train Loss: 1.738 | Train Acc: 100.000
95 Train Loss: 1.723 | Train Acc: 100.000
96 Train Loss: 1.715 | Train Acc: 100.000
97 Train Loss: 1.701 | Train Acc: 100.000
98 Train Loss: 1.683 | Train Acc: 100.000
99 Train Loss: 1.677 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  74
trainInputDict[data].shape :  torch.Size([661, 16, 8, 8])
copy.shape :  torch.Size([661, 1024])
copyLabel.shape :  torch.Size([661])
Class 0 has 400 instances after oversampling
Class 1 has 400 instances after oversampling
Class 2 has 399 instances after oversampling
Class 3 has 399 instances after oversampling
Class 4 has 399 instances after oversampling
Class 5 has 1 instances after oversampling
Class 6 has 399 instances after oversampling
Class 7 has 399 instances after oversampling
Class 8 has 399 instances after oversampling
Class 9 has 400 instances after oversampling
0 Train Loss: 172.574 | Train Acc: 42.253
1 Train Loss: 76.115 | Train Acc: 75.994
2 Train Loss: 42.085 | Train Acc: 86.926
3 Train Loss: 26.291 | Train Acc: 92.017
4 Train Loss: 23.296 | Train Acc: 92.879
5 Train Loss: 14.531 | Train Acc: 95.967
6 Train Loss: 12.679 | Train Acc: 96.245
7 Train Loss: 10.457 | Train Acc: 96.912
8 Train Loss: 8.089 | Train Acc: 97.636
9 Train Loss: 7.690 | Train Acc: 97.886
10 Train Loss: 7.156 | Train Acc: 97.830
11 Train Loss: 4.806 | Train Acc: 98.804
12 Train Loss: 4.304 | Train Acc: 98.915
13 Train Loss: 5.060 | Train Acc: 98.637
14 Train Loss: 3.147 | Train Acc: 99.360
15 Train Loss: 2.995 | Train Acc: 99.166
16 Train Loss: 2.259 | Train Acc: 99.611
17 Train Loss: 1.670 | Train Acc: 99.750
18 Train Loss: 1.611 | Train Acc: 99.833
19 Train Loss: 1.382 | Train Acc: 99.805
20 Train Loss: 0.954 | Train Acc: 100.000
21 Train Loss: 0.838 | Train Acc: 100.000
22 Train Loss: 0.792 | Train Acc: 100.000
23 Train Loss: 0.807 | Train Acc: 99.972
24 Train Loss: 0.697 | Train Acc: 100.000
25 Train Loss: 0.672 | Train Acc: 100.000
26 Train Loss: 0.631 | Train Acc: 100.000
27 Train Loss: 0.575 | Train Acc: 100.000
28 Train Loss: 0.589 | Train Acc: 100.000
29 Train Loss: 0.548 | Train Acc: 100.000
30 Train Loss: 0.541 | Train Acc: 100.000
31 Train Loss: 0.458 | Train Acc: 100.000
32 Train Loss: 0.444 | Train Acc: 100.000
33 Train Loss: 0.391 | Train Acc: 100.000
34 Train Loss: 0.373 | Train Acc: 100.000
35 Train Loss: 0.358 | Train Acc: 100.000
36 Train Loss: 0.346 | Train Acc: 100.000
37 Train Loss: 0.314 | Train Acc: 100.000
38 Train Loss: 0.287 | Train Acc: 100.000
39 Train Loss: 0.275 | Train Acc: 100.000
40 Train Loss: 0.245 | Train Acc: 100.000
41 Train Loss: 0.243 | Train Acc: 100.000
42 Train Loss: 0.237 | Train Acc: 100.000
43 Train Loss: 0.228 | Train Acc: 100.000
44 Train Loss: 0.224 | Train Acc: 100.000
45 Train Loss: 0.215 | Train Acc: 100.000
46 Train Loss: 0.215 | Train Acc: 100.000
47 Train Loss: 0.205 | Train Acc: 100.000
48 Train Loss: 0.201 | Train Acc: 100.000
49 Train Loss: 0.197 | Train Acc: 100.000
50 Train Loss: 0.188 | Train Acc: 100.000
51 Train Loss: 0.186 | Train Acc: 100.000
52 Train Loss: 0.177 | Train Acc: 100.000
53 Train Loss: 0.173 | Train Acc: 100.000
54 Train Loss: 0.168 | Train Acc: 100.000
55 Train Loss: 0.160 | Train Acc: 100.000
56 Train Loss: 0.156 | Train Acc: 100.000
57 Train Loss: 0.151 | Train Acc: 100.000
58 Train Loss: 0.144 | Train Acc: 100.000
59 Train Loss: 0.138 | Train Acc: 100.000
60 Train Loss: 0.134 | Train Acc: 100.000
61 Train Loss: 0.129 | Train Acc: 100.000
62 Train Loss: 0.127 | Train Acc: 100.000
63 Train Loss: 0.124 | Train Acc: 100.000
64 Train Loss: 0.126 | Train Acc: 100.000
65 Train Loss: 0.121 | Train Acc: 100.000
66 Train Loss: 0.118 | Train Acc: 100.000
67 Train Loss: 0.119 | Train Acc: 100.000
68 Train Loss: 0.115 | Train Acc: 100.000
69 Train Loss: 0.112 | Train Acc: 100.000
70 Train Loss: 0.110 | Train Acc: 100.000
71 Train Loss: 0.108 | Train Acc: 100.000
72 Train Loss: 0.107 | Train Acc: 100.000
73 Train Loss: 0.103 | Train Acc: 100.000
74 Train Loss: 0.102 | Train Acc: 100.000
75 Train Loss: 0.099 | Train Acc: 100.000
76 Train Loss: 0.097 | Train Acc: 100.000
77 Train Loss: 0.094 | Train Acc: 100.000
78 Train Loss: 0.092 | Train Acc: 100.000
79 Train Loss: 0.090 | Train Acc: 100.000
80 Train Loss: 0.087 | Train Acc: 100.000
81 Train Loss: 0.086 | Train Acc: 100.000
82 Train Loss: 0.084 | Train Acc: 100.000
83 Train Loss: 0.084 | Train Acc: 100.000
84 Train Loss: 0.083 | Train Acc: 100.000
85 Train Loss: 0.082 | Train Acc: 100.000
86 Train Loss: 0.081 | Train Acc: 100.000
87 Train Loss: 0.080 | Train Acc: 100.000
88 Train Loss: 0.079 | Train Acc: 100.000
89 Train Loss: 0.078 | Train Acc: 100.000
90 Train Loss: 0.077 | Train Acc: 100.000
91 Train Loss: 0.076 | Train Acc: 100.000
92 Train Loss: 0.075 | Train Acc: 100.000
93 Train Loss: 0.074 | Train Acc: 100.000
94 Train Loss: 0.073 | Train Acc: 100.000
95 Train Loss: 0.071 | Train Acc: 100.000
96 Train Loss: 0.070 | Train Acc: 100.000
97 Train Loss: 0.069 | Train Acc: 100.000
98 Train Loss: 0.067 | Train Acc: 100.000
99 Train Loss: 0.067 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  75
trainInputDict[data].shape :  torch.Size([1415, 16, 8, 8])
copy.shape :  torch.Size([1415, 1024])
copyLabel.shape :  torch.Size([1415])
Class 0 has 532 instances after oversampling
Class 1 has 532 instances after oversampling
Class 2 has 532 instances after oversampling
Class 3 has 532 instances after oversampling
Class 4 has 532 instances after oversampling
Class 5 has 532 instances after oversampling
Class 6 has 532 instances after oversampling
Class 7 has 532 instances after oversampling
Class 8 has 532 instances after oversampling
Class 9 has 532 instances after oversampling
0 Train Loss: 212.529 | Train Acc: 26.434
1 Train Loss: 134.706 | Train Acc: 56.547
2 Train Loss: 89.862 | Train Acc: 72.868
3 Train Loss: 67.746 | Train Acc: 79.434
4 Train Loss: 53.335 | Train Acc: 83.377
5 Train Loss: 45.539 | Train Acc: 85.358
6 Train Loss: 34.569 | Train Acc: 88.849
7 Train Loss: 33.143 | Train Acc: 89.396
8 Train Loss: 25.757 | Train Acc: 91.792
9 Train Loss: 26.267 | Train Acc: 91.151
10 Train Loss: 23.003 | Train Acc: 92.774
11 Train Loss: 19.860 | Train Acc: 93.887
12 Train Loss: 17.349 | Train Acc: 94.660
13 Train Loss: 17.165 | Train Acc: 94.925
14 Train Loss: 14.423 | Train Acc: 95.698
15 Train Loss: 11.520 | Train Acc: 96.925
16 Train Loss: 11.765 | Train Acc: 96.660
17 Train Loss: 9.085 | Train Acc: 97.566
18 Train Loss: 9.376 | Train Acc: 97.264
19 Train Loss: 8.368 | Train Acc: 97.717
20 Train Loss: 6.103 | Train Acc: 98.887
21 Train Loss: 5.682 | Train Acc: 99.113
22 Train Loss: 5.488 | Train Acc: 99.038
23 Train Loss: 5.196 | Train Acc: 99.226
24 Train Loss: 5.111 | Train Acc: 99.113
25 Train Loss: 4.687 | Train Acc: 99.245
26 Train Loss: 4.780 | Train Acc: 99.170
27 Train Loss: 4.566 | Train Acc: 99.245
28 Train Loss: 4.093 | Train Acc: 99.453
29 Train Loss: 3.804 | Train Acc: 99.528
30 Train Loss: 3.652 | Train Acc: 99.566
31 Train Loss: 3.503 | Train Acc: 99.585
32 Train Loss: 3.280 | Train Acc: 99.642
33 Train Loss: 3.135 | Train Acc: 99.679
34 Train Loss: 3.088 | Train Acc: 99.623
35 Train Loss: 3.043 | Train Acc: 99.642
36 Train Loss: 2.895 | Train Acc: 99.698
37 Train Loss: 2.537 | Train Acc: 99.868
38 Train Loss: 2.329 | Train Acc: 99.792
39 Train Loss: 2.256 | Train Acc: 99.830
40 Train Loss: 1.931 | Train Acc: 99.925
41 Train Loss: 1.870 | Train Acc: 99.925
42 Train Loss: 1.819 | Train Acc: 99.906
43 Train Loss: 1.782 | Train Acc: 99.906
44 Train Loss: 1.736 | Train Acc: 99.925
45 Train Loss: 1.704 | Train Acc: 99.925
46 Train Loss: 1.653 | Train Acc: 99.925
47 Train Loss: 1.600 | Train Acc: 99.925
48 Train Loss: 1.548 | Train Acc: 99.943
49 Train Loss: 1.530 | Train Acc: 99.943
50 Train Loss: 1.469 | Train Acc: 99.962
51 Train Loss: 1.411 | Train Acc: 99.962
52 Train Loss: 1.407 | Train Acc: 99.943
53 Train Loss: 1.345 | Train Acc: 99.962
54 Train Loss: 1.335 | Train Acc: 99.962
55 Train Loss: 1.269 | Train Acc: 99.962
56 Train Loss: 1.250 | Train Acc: 99.962
57 Train Loss: 1.189 | Train Acc: 99.962
58 Train Loss: 1.166 | Train Acc: 99.962
59 Train Loss: 1.088 | Train Acc: 99.962
60 Train Loss: 1.037 | Train Acc: 99.962
61 Train Loss: 1.008 | Train Acc: 99.962
62 Train Loss: 1.002 | Train Acc: 99.962
63 Train Loss: 0.984 | Train Acc: 99.962
64 Train Loss: 0.968 | Train Acc: 99.962
65 Train Loss: 0.955 | Train Acc: 99.981
66 Train Loss: 0.942 | Train Acc: 99.962
67 Train Loss: 0.917 | Train Acc: 99.981
68 Train Loss: 0.908 | Train Acc: 99.981
69 Train Loss: 0.899 | Train Acc: 99.981
70 Train Loss: 0.880 | Train Acc: 100.000
71 Train Loss: 0.874 | Train Acc: 99.981
72 Train Loss: 0.852 | Train Acc: 100.000
73 Train Loss: 0.843 | Train Acc: 100.000
74 Train Loss: 0.821 | Train Acc: 99.981
75 Train Loss: 0.821 | Train Acc: 100.000
76 Train Loss: 0.793 | Train Acc: 100.000
77 Train Loss: 0.785 | Train Acc: 100.000
78 Train Loss: 0.761 | Train Acc: 100.000
79 Train Loss: 0.760 | Train Acc: 100.000
80 Train Loss: 0.722 | Train Acc: 100.000
81 Train Loss: 0.717 | Train Acc: 100.000
82 Train Loss: 0.709 | Train Acc: 100.000
83 Train Loss: 0.706 | Train Acc: 100.000
84 Train Loss: 0.700 | Train Acc: 100.000
85 Train Loss: 0.692 | Train Acc: 100.000
86 Train Loss: 0.687 | Train Acc: 100.000
87 Train Loss: 0.681 | Train Acc: 100.000
88 Train Loss: 0.672 | Train Acc: 100.000
89 Train Loss: 0.668 | Train Acc: 100.000
90 Train Loss: 0.665 | Train Acc: 100.000
91 Train Loss: 0.652 | Train Acc: 100.000
92 Train Loss: 0.649 | Train Acc: 100.000
93 Train Loss: 0.643 | Train Acc: 100.000
94 Train Loss: 0.639 | Train Acc: 100.000
95 Train Loss: 0.632 | Train Acc: 100.000
96 Train Loss: 0.626 | Train Acc: 100.000
97 Train Loss: 0.625 | Train Acc: 100.000
98 Train Loss: 0.617 | Train Acc: 100.000
99 Train Loss: 0.611 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  76
trainInputDict[data].shape :  torch.Size([285, 16, 8, 8])
copy.shape :  torch.Size([285, 1024])
copyLabel.shape :  torch.Size([285])
Class 0 has 92 instances after oversampling
Class 1 has 92 instances after oversampling
Class 2 has 92 instances after oversampling
Class 3 has 92 instances after oversampling
Class 4 has 92 instances after oversampling
Class 5 has 91 instances after oversampling
Class 6 has 92 instances after oversampling
Class 7 has 92 instances after oversampling
0 Train Loss: 159.786 | Train Acc: 43.143
1 Train Loss: 87.083 | Train Acc: 69.143
2 Train Loss: 55.052 | Train Acc: 82.143
3 Train Loss: 40.753 | Train Acc: 86.000
4 Train Loss: 25.446 | Train Acc: 92.286
5 Train Loss: 18.129 | Train Acc: 94.286
6 Train Loss: 14.193 | Train Acc: 96.429
7 Train Loss: 11.169 | Train Acc: 96.714
8 Train Loss: 7.624 | Train Acc: 98.286
9 Train Loss: 5.470 | Train Acc: 99.286
10 Train Loss: 4.500 | Train Acc: 99.571
11 Train Loss: 3.269 | Train Acc: 99.714
12 Train Loss: 2.197 | Train Acc: 99.857
13 Train Loss: 1.578 | Train Acc: 100.000
14 Train Loss: 1.402 | Train Acc: 100.000
15 Train Loss: 0.992 | Train Acc: 100.000
16 Train Loss: 0.786 | Train Acc: 100.000
17 Train Loss: 0.671 | Train Acc: 100.000
18 Train Loss: 0.616 | Train Acc: 100.000
19 Train Loss: 0.516 | Train Acc: 100.000
20 Train Loss: 0.444 | Train Acc: 100.000
21 Train Loss: 0.407 | Train Acc: 100.000
22 Train Loss: 0.385 | Train Acc: 100.000
23 Train Loss: 0.374 | Train Acc: 100.000
24 Train Loss: 0.353 | Train Acc: 100.000
25 Train Loss: 0.339 | Train Acc: 100.000
26 Train Loss: 0.321 | Train Acc: 100.000
27 Train Loss: 0.307 | Train Acc: 100.000
28 Train Loss: 0.294 | Train Acc: 100.000
29 Train Loss: 0.281 | Train Acc: 100.000
30 Train Loss: 0.264 | Train Acc: 100.000
31 Train Loss: 0.249 | Train Acc: 100.000
32 Train Loss: 0.239 | Train Acc: 100.000
33 Train Loss: 0.226 | Train Acc: 100.000
34 Train Loss: 0.217 | Train Acc: 100.000
35 Train Loss: 0.202 | Train Acc: 100.000
36 Train Loss: 0.191 | Train Acc: 100.000
37 Train Loss: 0.185 | Train Acc: 100.000
38 Train Loss: 0.172 | Train Acc: 100.000
39 Train Loss: 0.163 | Train Acc: 100.000
40 Train Loss: 0.151 | Train Acc: 100.000
41 Train Loss: 0.148 | Train Acc: 100.000
42 Train Loss: 0.145 | Train Acc: 100.000
43 Train Loss: 0.142 | Train Acc: 100.000
44 Train Loss: 0.138 | Train Acc: 100.000
45 Train Loss: 0.134 | Train Acc: 100.000
46 Train Loss: 0.133 | Train Acc: 100.000
47 Train Loss: 0.128 | Train Acc: 100.000
48 Train Loss: 0.125 | Train Acc: 100.000
49 Train Loss: 0.123 | Train Acc: 100.000
50 Train Loss: 0.118 | Train Acc: 100.000
51 Train Loss: 0.115 | Train Acc: 100.000
52 Train Loss: 0.112 | Train Acc: 100.000
53 Train Loss: 0.109 | Train Acc: 100.000
54 Train Loss: 0.105 | Train Acc: 100.000
55 Train Loss: 0.101 | Train Acc: 100.000
56 Train Loss: 0.099 | Train Acc: 100.000
57 Train Loss: 0.096 | Train Acc: 100.000
58 Train Loss: 0.092 | Train Acc: 100.000
59 Train Loss: 0.090 | Train Acc: 100.000
60 Train Loss: 0.085 | Train Acc: 100.000
61 Train Loss: 0.084 | Train Acc: 100.000
62 Train Loss: 0.083 | Train Acc: 100.000
63 Train Loss: 0.081 | Train Acc: 100.000
64 Train Loss: 0.080 | Train Acc: 100.000
65 Train Loss: 0.079 | Train Acc: 100.000
66 Train Loss: 0.077 | Train Acc: 100.000
67 Train Loss: 0.076 | Train Acc: 100.000
68 Train Loss: 0.075 | Train Acc: 100.000
69 Train Loss: 0.073 | Train Acc: 100.000
70 Train Loss: 0.072 | Train Acc: 100.000
71 Train Loss: 0.071 | Train Acc: 100.000
72 Train Loss: 0.069 | Train Acc: 100.000
73 Train Loss: 0.068 | Train Acc: 100.000
74 Train Loss: 0.066 | Train Acc: 100.000
75 Train Loss: 0.065 | Train Acc: 100.000
76 Train Loss: 0.064 | Train Acc: 100.000
77 Train Loss: 0.062 | Train Acc: 100.000
78 Train Loss: 0.061 | Train Acc: 100.000
79 Train Loss: 0.059 | Train Acc: 100.000
80 Train Loss: 0.057 | Train Acc: 100.000
81 Train Loss: 0.056 | Train Acc: 100.000
82 Train Loss: 0.055 | Train Acc: 100.000
83 Train Loss: 0.055 | Train Acc: 100.000
84 Train Loss: 0.054 | Train Acc: 100.000
85 Train Loss: 0.054 | Train Acc: 100.000
86 Train Loss: 0.053 | Train Acc: 100.000
87 Train Loss: 0.052 | Train Acc: 100.000
88 Train Loss: 0.052 | Train Acc: 100.000
89 Train Loss: 0.051 | Train Acc: 100.000
90 Train Loss: 0.050 | Train Acc: 100.000
91 Train Loss: 0.050 | Train Acc: 100.000
92 Train Loss: 0.049 | Train Acc: 100.000
93 Train Loss: 0.048 | Train Acc: 100.000
94 Train Loss: 0.047 | Train Acc: 100.000
95 Train Loss: 0.047 | Train Acc: 100.000
96 Train Loss: 0.046 | Train Acc: 100.000
97 Train Loss: 0.045 | Train Acc: 100.000
98 Train Loss: 0.044 | Train Acc: 100.000
99 Train Loss: 0.044 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  77
trainInputDict[data].shape :  torch.Size([2382, 16, 8, 8])
copy.shape :  torch.Size([2382, 1024])
copyLabel.shape :  torch.Size([2382])
Class 0 has 1058 instances after oversampling
Class 1 has 1058 instances after oversampling
Class 2 has 1058 instances after oversampling
Class 3 has 1058 instances after oversampling
Class 4 has 1058 instances after oversampling
Class 5 has 1058 instances after oversampling
Class 6 has 1 instances after oversampling
Class 7 has 1058 instances after oversampling
Class 8 has 1058 instances after oversampling
Class 9 has 1058 instances after oversampling
0 Train Loss: 174.255 | Train Acc: 42.151
1 Train Loss: 86.102 | Train Acc: 69.379
2 Train Loss: 55.740 | Train Acc: 80.416
3 Train Loss: 48.937 | Train Acc: 80.951
4 Train Loss: 40.392 | Train Acc: 84.868
5 Train Loss: 36.011 | Train Acc: 86.916
6 Train Loss: 33.764 | Train Acc: 87.483
7 Train Loss: 29.985 | Train Acc: 89.394
8 Train Loss: 24.723 | Train Acc: 91.421
9 Train Loss: 21.910 | Train Acc: 92.702
10 Train Loss: 25.000 | Train Acc: 91.463
11 Train Loss: 20.329 | Train Acc: 92.985
12 Train Loss: 17.730 | Train Acc: 93.867
13 Train Loss: 16.023 | Train Acc: 94.886
14 Train Loss: 14.890 | Train Acc: 95.117
15 Train Loss: 15.420 | Train Acc: 94.676
16 Train Loss: 13.678 | Train Acc: 95.527
17 Train Loss: 13.428 | Train Acc: 95.516
18 Train Loss: 11.508 | Train Acc: 96.115
19 Train Loss: 10.681 | Train Acc: 96.577
20 Train Loss: 8.834 | Train Acc: 97.322
21 Train Loss: 8.326 | Train Acc: 97.616
22 Train Loss: 7.957 | Train Acc: 97.679
23 Train Loss: 7.959 | Train Acc: 97.606
24 Train Loss: 7.553 | Train Acc: 97.816
25 Train Loss: 7.370 | Train Acc: 97.795
26 Train Loss: 7.217 | Train Acc: 97.826
27 Train Loss: 6.911 | Train Acc: 98.026
28 Train Loss: 6.587 | Train Acc: 98.089
29 Train Loss: 6.611 | Train Acc: 98.036
30 Train Loss: 6.213 | Train Acc: 98.204
31 Train Loss: 5.911 | Train Acc: 98.372
32 Train Loss: 6.003 | Train Acc: 98.320
33 Train Loss: 5.606 | Train Acc: 98.551
34 Train Loss: 5.591 | Train Acc: 98.488
35 Train Loss: 6.207 | Train Acc: 98.246
36 Train Loss: 5.416 | Train Acc: 98.488
37 Train Loss: 5.218 | Train Acc: 98.509
38 Train Loss: 4.856 | Train Acc: 98.729
39 Train Loss: 4.662 | Train Acc: 98.876
40 Train Loss: 4.249 | Train Acc: 99.181
41 Train Loss: 4.091 | Train Acc: 99.076
42 Train Loss: 4.078 | Train Acc: 99.107
43 Train Loss: 4.009 | Train Acc: 99.034
44 Train Loss: 4.006 | Train Acc: 99.107
45 Train Loss: 3.784 | Train Acc: 99.254
46 Train Loss: 4.205 | Train Acc: 98.992
47 Train Loss: 3.940 | Train Acc: 99.097
48 Train Loss: 3.715 | Train Acc: 99.149
49 Train Loss: 3.673 | Train Acc: 99.181
50 Train Loss: 3.653 | Train Acc: 99.233
51 Train Loss: 3.555 | Train Acc: 99.296
52 Train Loss: 3.548 | Train Acc: 99.254
53 Train Loss: 3.497 | Train Acc: 99.265
54 Train Loss: 3.438 | Train Acc: 99.391
55 Train Loss: 3.295 | Train Acc: 99.370
56 Train Loss: 3.293 | Train Acc: 99.317
57 Train Loss: 3.194 | Train Acc: 99.328
58 Train Loss: 3.119 | Train Acc: 99.443
59 Train Loss: 3.167 | Train Acc: 99.412
60 Train Loss: 2.935 | Train Acc: 99.496
61 Train Loss: 2.862 | Train Acc: 99.548
62 Train Loss: 2.810 | Train Acc: 99.548
63 Train Loss: 2.819 | Train Acc: 99.559
64 Train Loss: 2.765 | Train Acc: 99.527
65 Train Loss: 2.754 | Train Acc: 99.569
66 Train Loss: 2.767 | Train Acc: 99.548
67 Train Loss: 2.745 | Train Acc: 99.538
68 Train Loss: 2.691 | Train Acc: 99.590
69 Train Loss: 2.679 | Train Acc: 99.569
70 Train Loss: 2.631 | Train Acc: 99.622
71 Train Loss: 2.612 | Train Acc: 99.601
72 Train Loss: 2.598 | Train Acc: 99.601
73 Train Loss: 2.574 | Train Acc: 99.632
74 Train Loss: 2.565 | Train Acc: 99.611
75 Train Loss: 2.559 | Train Acc: 99.653
76 Train Loss: 2.521 | Train Acc: 99.601
77 Train Loss: 2.555 | Train Acc: 99.653
78 Train Loss: 2.482 | Train Acc: 99.632
79 Train Loss: 2.434 | Train Acc: 99.611
80 Train Loss: 2.355 | Train Acc: 99.685
81 Train Loss: 2.350 | Train Acc: 99.685
82 Train Loss: 2.348 | Train Acc: 99.685
83 Train Loss: 2.341 | Train Acc: 99.674
84 Train Loss: 2.317 | Train Acc: 99.737
85 Train Loss: 2.323 | Train Acc: 99.706
86 Train Loss: 2.295 | Train Acc: 99.695
87 Train Loss: 2.302 | Train Acc: 99.716
88 Train Loss: 2.291 | Train Acc: 99.706
89 Train Loss: 2.283 | Train Acc: 99.716
90 Train Loss: 2.285 | Train Acc: 99.716
91 Train Loss: 2.261 | Train Acc: 99.695
92 Train Loss: 2.249 | Train Acc: 99.685
93 Train Loss: 2.238 | Train Acc: 99.748
94 Train Loss: 2.227 | Train Acc: 99.737
95 Train Loss: 2.224 | Train Acc: 99.727
96 Train Loss: 2.211 | Train Acc: 99.716
97 Train Loss: 2.190 | Train Acc: 99.737
98 Train Loss: 2.199 | Train Acc: 99.737
99 Train Loss: 2.175 | Train Acc: 99.727
CNN trained successfully...
Running nodeId:  78
trainInputDict[data].shape :  torch.Size([493, 16, 8, 8])
copy.shape :  torch.Size([493, 1024])
copyLabel.shape :  torch.Size([493])
Class 0 has 149 instances after oversampling
Class 1 has 149 instances after oversampling
Class 2 has 149 instances after oversampling
Class 3 has 149 instances after oversampling
Class 4 has 149 instances after oversampling
Class 5 has 149 instances after oversampling
Class 6 has 149 instances after oversampling
Class 7 has 149 instances after oversampling
Class 8 has 149 instances after oversampling
0 Train Loss: 188.570 | Train Acc: 30.538
1 Train Loss: 109.238 | Train Acc: 64.615
2 Train Loss: 79.232 | Train Acc: 74.154
3 Train Loss: 59.105 | Train Acc: 81.000
4 Train Loss: 40.929 | Train Acc: 87.615
5 Train Loss: 37.230 | Train Acc: 89.769
6 Train Loss: 28.543 | Train Acc: 91.308
7 Train Loss: 24.720 | Train Acc: 92.308
8 Train Loss: 21.342 | Train Acc: 93.538
9 Train Loss: 19.131 | Train Acc: 95.154
10 Train Loss: 14.505 | Train Acc: 96.231
11 Train Loss: 15.911 | Train Acc: 95.000
12 Train Loss: 12.671 | Train Acc: 96.846
13 Train Loss: 9.090 | Train Acc: 97.692
14 Train Loss: 7.559 | Train Acc: 98.154
15 Train Loss: 6.363 | Train Acc: 98.692
16 Train Loss: 4.884 | Train Acc: 99.308
17 Train Loss: 4.033 | Train Acc: 99.462
18 Train Loss: 4.994 | Train Acc: 99.000
19 Train Loss: 3.351 | Train Acc: 99.615
20 Train Loss: 2.192 | Train Acc: 99.923
21 Train Loss: 1.849 | Train Acc: 100.000
22 Train Loss: 1.720 | Train Acc: 100.000
23 Train Loss: 1.600 | Train Acc: 100.000
24 Train Loss: 1.497 | Train Acc: 100.000
25 Train Loss: 1.413 | Train Acc: 100.000
26 Train Loss: 1.285 | Train Acc: 100.000
27 Train Loss: 1.229 | Train Acc: 100.000
28 Train Loss: 1.154 | Train Acc: 100.000
29 Train Loss: 1.094 | Train Acc: 100.000
30 Train Loss: 1.050 | Train Acc: 100.000
31 Train Loss: 1.008 | Train Acc: 100.000
32 Train Loss: 0.942 | Train Acc: 100.000
33 Train Loss: 0.878 | Train Acc: 100.000
34 Train Loss: 0.805 | Train Acc: 100.000
35 Train Loss: 0.765 | Train Acc: 100.000
36 Train Loss: 0.723 | Train Acc: 100.000
37 Train Loss: 0.672 | Train Acc: 100.000
38 Train Loss: 0.658 | Train Acc: 100.000
39 Train Loss: 0.603 | Train Acc: 100.000
40 Train Loss: 0.544 | Train Acc: 100.000
41 Train Loss: 0.523 | Train Acc: 100.000
42 Train Loss: 0.509 | Train Acc: 100.000
43 Train Loss: 0.499 | Train Acc: 100.000
44 Train Loss: 0.490 | Train Acc: 100.000
45 Train Loss: 0.477 | Train Acc: 100.000
46 Train Loss: 0.463 | Train Acc: 100.000
47 Train Loss: 0.450 | Train Acc: 100.000
48 Train Loss: 0.440 | Train Acc: 100.000
49 Train Loss: 0.434 | Train Acc: 100.000
50 Train Loss: 0.417 | Train Acc: 100.000
51 Train Loss: 0.407 | Train Acc: 100.000
52 Train Loss: 0.393 | Train Acc: 100.000
53 Train Loss: 0.380 | Train Acc: 100.000
54 Train Loss: 0.369 | Train Acc: 100.000
55 Train Loss: 0.363 | Train Acc: 100.000
56 Train Loss: 0.347 | Train Acc: 100.000
57 Train Loss: 0.334 | Train Acc: 100.000
58 Train Loss: 0.322 | Train Acc: 100.000
59 Train Loss: 0.315 | Train Acc: 100.000
60 Train Loss: 0.294 | Train Acc: 100.000
61 Train Loss: 0.289 | Train Acc: 100.000
62 Train Loss: 0.284 | Train Acc: 100.000
63 Train Loss: 0.279 | Train Acc: 100.000
64 Train Loss: 0.277 | Train Acc: 100.000
65 Train Loss: 0.272 | Train Acc: 100.000
66 Train Loss: 0.268 | Train Acc: 100.000
67 Train Loss: 0.262 | Train Acc: 100.000
68 Train Loss: 0.257 | Train Acc: 100.000
69 Train Loss: 0.255 | Train Acc: 100.000
70 Train Loss: 0.249 | Train Acc: 100.000
71 Train Loss: 0.245 | Train Acc: 100.000
72 Train Loss: 0.240 | Train Acc: 100.000
73 Train Loss: 0.236 | Train Acc: 100.000
74 Train Loss: 0.231 | Train Acc: 100.000
75 Train Loss: 0.227 | Train Acc: 100.000
76 Train Loss: 0.223 | Train Acc: 100.000
77 Train Loss: 0.220 | Train Acc: 100.000
78 Train Loss: 0.211 | Train Acc: 100.000
79 Train Loss: 0.207 | Train Acc: 100.000
80 Train Loss: 0.198 | Train Acc: 100.000
81 Train Loss: 0.196 | Train Acc: 100.000
82 Train Loss: 0.194 | Train Acc: 100.000
83 Train Loss: 0.192 | Train Acc: 100.000
84 Train Loss: 0.190 | Train Acc: 100.000
85 Train Loss: 0.189 | Train Acc: 100.000
86 Train Loss: 0.187 | Train Acc: 100.000
87 Train Loss: 0.185 | Train Acc: 100.000
88 Train Loss: 0.182 | Train Acc: 100.000
89 Train Loss: 0.179 | Train Acc: 100.000
90 Train Loss: 0.180 | Train Acc: 100.000
91 Train Loss: 0.176 | Train Acc: 100.000
92 Train Loss: 0.174 | Train Acc: 100.000
93 Train Loss: 0.171 | Train Acc: 100.000
94 Train Loss: 0.169 | Train Acc: 100.000
95 Train Loss: 0.168 | Train Acc: 100.000
96 Train Loss: 0.165 | Train Acc: 100.000
97 Train Loss: 0.162 | Train Acc: 100.000
98 Train Loss: 0.161 | Train Acc: 100.000
99 Train Loss: 0.158 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  79
trainInputDict[data].shape :  torch.Size([1989, 16, 8, 8])
copy.shape :  torch.Size([1989, 1024])
copyLabel.shape :  torch.Size([1989])
Class 0 has 633 instances after oversampling
Class 1 has 633 instances after oversampling
Class 2 has 633 instances after oversampling
Class 3 has 633 instances after oversampling
Class 4 has 633 instances after oversampling
Class 5 has 1 instances after oversampling
Class 6 has 633 instances after oversampling
Class 7 has 633 instances after oversampling
Class 8 has 633 instances after oversampling
Class 9 has 633 instances after oversampling
0 Train Loss: 187.382 | Train Acc: 37.522
1 Train Loss: 98.521 | Train Acc: 69.112
2 Train Loss: 65.286 | Train Acc: 79.115
3 Train Loss: 55.313 | Train Acc: 80.677
4 Train Loss: 49.419 | Train Acc: 81.713
5 Train Loss: 46.255 | Train Acc: 82.713
6 Train Loss: 38.996 | Train Acc: 85.837
7 Train Loss: 36.761 | Train Acc: 86.644
8 Train Loss: 32.521 | Train Acc: 88.329
9 Train Loss: 33.539 | Train Acc: 87.785
10 Train Loss: 28.344 | Train Acc: 89.768
11 Train Loss: 27.402 | Train Acc: 90.172
12 Train Loss: 24.848 | Train Acc: 90.874
13 Train Loss: 24.256 | Train Acc: 91.313
14 Train Loss: 20.290 | Train Acc: 93.577
15 Train Loss: 19.023 | Train Acc: 93.173
16 Train Loss: 18.350 | Train Acc: 93.717
17 Train Loss: 17.149 | Train Acc: 94.366
18 Train Loss: 15.198 | Train Acc: 95.174
19 Train Loss: 16.032 | Train Acc: 94.507
20 Train Loss: 11.875 | Train Acc: 96.701
21 Train Loss: 11.369 | Train Acc: 96.859
22 Train Loss: 10.484 | Train Acc: 97.280
23 Train Loss: 10.241 | Train Acc: 97.174
24 Train Loss: 10.061 | Train Acc: 97.438
25 Train Loss: 9.406 | Train Acc: 97.666
26 Train Loss: 9.106 | Train Acc: 97.736
27 Train Loss: 8.914 | Train Acc: 97.754
28 Train Loss: 8.439 | Train Acc: 97.929
29 Train Loss: 8.311 | Train Acc: 98.017
30 Train Loss: 7.947 | Train Acc: 98.175
31 Train Loss: 7.845 | Train Acc: 98.122
32 Train Loss: 7.206 | Train Acc: 98.508
33 Train Loss: 7.024 | Train Acc: 98.385
34 Train Loss: 6.567 | Train Acc: 98.666
35 Train Loss: 6.511 | Train Acc: 98.771
36 Train Loss: 6.287 | Train Acc: 98.701
37 Train Loss: 5.896 | Train Acc: 98.771
38 Train Loss: 5.470 | Train Acc: 99.158
39 Train Loss: 5.332 | Train Acc: 99.087
40 Train Loss: 4.731 | Train Acc: 99.421
41 Train Loss: 4.567 | Train Acc: 99.421
42 Train Loss: 4.499 | Train Acc: 99.438
43 Train Loss: 4.411 | Train Acc: 99.438
44 Train Loss: 4.336 | Train Acc: 99.456
45 Train Loss: 4.285 | Train Acc: 99.509
46 Train Loss: 4.222 | Train Acc: 99.509
47 Train Loss: 4.127 | Train Acc: 99.491
48 Train Loss: 4.027 | Train Acc: 99.579
49 Train Loss: 3.912 | Train Acc: 99.561
50 Train Loss: 3.799 | Train Acc: 99.631
51 Train Loss: 3.765 | Train Acc: 99.596
52 Train Loss: 3.685 | Train Acc: 99.579
53 Train Loss: 3.555 | Train Acc: 99.649
54 Train Loss: 3.520 | Train Acc: 99.719
55 Train Loss: 3.397 | Train Acc: 99.702
56 Train Loss: 3.349 | Train Acc: 99.684
57 Train Loss: 3.236 | Train Acc: 99.702
58 Train Loss: 3.177 | Train Acc: 99.754
59 Train Loss: 3.068 | Train Acc: 99.772
60 Train Loss: 2.909 | Train Acc: 99.824
61 Train Loss: 2.841 | Train Acc: 99.860
62 Train Loss: 2.817 | Train Acc: 99.824
63 Train Loss: 2.794 | Train Acc: 99.860
64 Train Loss: 2.786 | Train Acc: 99.842
65 Train Loss: 2.744 | Train Acc: 99.860
66 Train Loss: 2.714 | Train Acc: 99.895
67 Train Loss: 2.675 | Train Acc: 99.860
68 Train Loss: 2.630 | Train Acc: 99.877
69 Train Loss: 2.602 | Train Acc: 99.842
70 Train Loss: 2.574 | Train Acc: 99.895
71 Train Loss: 2.574 | Train Acc: 99.860
72 Train Loss: 2.536 | Train Acc: 99.895
73 Train Loss: 2.470 | Train Acc: 99.912
74 Train Loss: 2.443 | Train Acc: 99.895
75 Train Loss: 2.440 | Train Acc: 99.895
76 Train Loss: 2.421 | Train Acc: 99.912
77 Train Loss: 2.382 | Train Acc: 99.877
78 Train Loss: 2.329 | Train Acc: 99.912
79 Train Loss: 2.341 | Train Acc: 99.895
80 Train Loss: 2.250 | Train Acc: 99.912
81 Train Loss: 2.213 | Train Acc: 99.912
82 Train Loss: 2.206 | Train Acc: 99.912
83 Train Loss: 2.193 | Train Acc: 99.930
84 Train Loss: 2.184 | Train Acc: 99.912
85 Train Loss: 2.174 | Train Acc: 99.930
86 Train Loss: 2.166 | Train Acc: 99.912
87 Train Loss: 2.145 | Train Acc: 99.930
88 Train Loss: 2.135 | Train Acc: 99.930
89 Train Loss: 2.123 | Train Acc: 99.930
90 Train Loss: 2.105 | Train Acc: 99.930
91 Train Loss: 2.096 | Train Acc: 99.930
92 Train Loss: 2.083 | Train Acc: 99.930
93 Train Loss: 2.090 | Train Acc: 99.930
94 Train Loss: 2.070 | Train Acc: 99.930
95 Train Loss: 2.045 | Train Acc: 99.947
96 Train Loss: 2.039 | Train Acc: 99.930
97 Train Loss: 2.019 | Train Acc: 99.947
98 Train Loss: 2.016 | Train Acc: 99.930
99 Train Loss: 1.998 | Train Acc: 99.930
CNN trained successfully...
Running nodeId:  80
trainInputDict[data].shape :  torch.Size([435, 16, 8, 8])
copy.shape :  torch.Size([435, 1024])
copyLabel.shape :  torch.Size([435])
Class 0 has 80 instances after oversampling
Class 1 has 80 instances after oversampling
Class 2 has 80 instances after oversampling
Class 3 has 80 instances after oversampling
Class 4 has 80 instances after oversampling
Class 5 has 80 instances after oversampling
Class 6 has 80 instances after oversampling
Class 7 has 80 instances after oversampling
Class 8 has 80 instances after oversampling
Class 9 has 80 instances after oversampling
0 Train Loss: 227.746 | Train Acc: 16.375
1 Train Loss: 167.395 | Train Acc: 44.625
2 Train Loss: 110.229 | Train Acc: 64.750
3 Train Loss: 81.566 | Train Acc: 73.750
4 Train Loss: 61.161 | Train Acc: 79.625
5 Train Loss: 45.651 | Train Acc: 84.875
6 Train Loss: 33.709 | Train Acc: 90.000
7 Train Loss: 27.305 | Train Acc: 92.375
8 Train Loss: 19.916 | Train Acc: 95.250
9 Train Loss: 14.027 | Train Acc: 96.750
10 Train Loss: 10.005 | Train Acc: 98.750
11 Train Loss: 6.976 | Train Acc: 99.125
12 Train Loss: 5.761 | Train Acc: 99.500
13 Train Loss: 3.704 | Train Acc: 100.000
14 Train Loss: 2.744 | Train Acc: 99.875
15 Train Loss: 1.707 | Train Acc: 100.000
16 Train Loss: 1.338 | Train Acc: 100.000
17 Train Loss: 1.088 | Train Acc: 100.000
18 Train Loss: 0.951 | Train Acc: 100.000
19 Train Loss: 0.822 | Train Acc: 100.000
20 Train Loss: 0.675 | Train Acc: 100.000
21 Train Loss: 0.634 | Train Acc: 100.000
22 Train Loss: 0.609 | Train Acc: 100.000
23 Train Loss: 0.577 | Train Acc: 100.000
24 Train Loss: 0.551 | Train Acc: 100.000
25 Train Loss: 0.525 | Train Acc: 100.000
26 Train Loss: 0.496 | Train Acc: 100.000
27 Train Loss: 0.475 | Train Acc: 100.000
28 Train Loss: 0.448 | Train Acc: 100.000
29 Train Loss: 0.433 | Train Acc: 100.000
30 Train Loss: 0.411 | Train Acc: 100.000
31 Train Loss: 0.388 | Train Acc: 100.000
32 Train Loss: 0.367 | Train Acc: 100.000
33 Train Loss: 0.352 | Train Acc: 100.000
34 Train Loss: 0.332 | Train Acc: 100.000
35 Train Loss: 0.315 | Train Acc: 100.000
36 Train Loss: 0.297 | Train Acc: 100.000
37 Train Loss: 0.283 | Train Acc: 100.000
38 Train Loss: 0.268 | Train Acc: 100.000
39 Train Loss: 0.256 | Train Acc: 100.000
40 Train Loss: 0.235 | Train Acc: 100.000
41 Train Loss: 0.230 | Train Acc: 100.000
42 Train Loss: 0.225 | Train Acc: 100.000
43 Train Loss: 0.219 | Train Acc: 100.000
44 Train Loss: 0.215 | Train Acc: 100.000
45 Train Loss: 0.210 | Train Acc: 100.000
46 Train Loss: 0.204 | Train Acc: 100.000
47 Train Loss: 0.200 | Train Acc: 100.000
48 Train Loss: 0.194 | Train Acc: 100.000
49 Train Loss: 0.189 | Train Acc: 100.000
50 Train Loss: 0.184 | Train Acc: 100.000
51 Train Loss: 0.178 | Train Acc: 100.000
52 Train Loss: 0.175 | Train Acc: 100.000
53 Train Loss: 0.169 | Train Acc: 100.000
54 Train Loss: 0.164 | Train Acc: 100.000
55 Train Loss: 0.159 | Train Acc: 100.000
56 Train Loss: 0.153 | Train Acc: 100.000
57 Train Loss: 0.150 | Train Acc: 100.000
58 Train Loss: 0.144 | Train Acc: 100.000
59 Train Loss: 0.139 | Train Acc: 100.000
60 Train Loss: 0.132 | Train Acc: 100.000
61 Train Loss: 0.131 | Train Acc: 100.000
62 Train Loss: 0.128 | Train Acc: 100.000
63 Train Loss: 0.127 | Train Acc: 100.000
64 Train Loss: 0.125 | Train Acc: 100.000
65 Train Loss: 0.123 | Train Acc: 100.000
66 Train Loss: 0.121 | Train Acc: 100.000
67 Train Loss: 0.119 | Train Acc: 100.000
68 Train Loss: 0.117 | Train Acc: 100.000
69 Train Loss: 0.115 | Train Acc: 100.000
70 Train Loss: 0.113 | Train Acc: 100.000
71 Train Loss: 0.110 | Train Acc: 100.000
72 Train Loss: 0.108 | Train Acc: 100.000
73 Train Loss: 0.106 | Train Acc: 100.000
74 Train Loss: 0.104 | Train Acc: 100.000
75 Train Loss: 0.102 | Train Acc: 100.000
76 Train Loss: 0.099 | Train Acc: 100.000
77 Train Loss: 0.097 | Train Acc: 100.000
78 Train Loss: 0.095 | Train Acc: 100.000
79 Train Loss: 0.093 | Train Acc: 100.000
80 Train Loss: 0.089 | Train Acc: 100.000
81 Train Loss: 0.088 | Train Acc: 100.000
82 Train Loss: 0.087 | Train Acc: 100.000
83 Train Loss: 0.086 | Train Acc: 100.000
84 Train Loss: 0.085 | Train Acc: 100.000
85 Train Loss: 0.084 | Train Acc: 100.000
86 Train Loss: 0.083 | Train Acc: 100.000
87 Train Loss: 0.082 | Train Acc: 100.000
88 Train Loss: 0.081 | Train Acc: 100.000
89 Train Loss: 0.080 | Train Acc: 100.000
90 Train Loss: 0.079 | Train Acc: 100.000
91 Train Loss: 0.078 | Train Acc: 100.000
92 Train Loss: 0.077 | Train Acc: 100.000
93 Train Loss: 0.076 | Train Acc: 100.000
94 Train Loss: 0.075 | Train Acc: 100.000
95 Train Loss: 0.073 | Train Acc: 100.000
96 Train Loss: 0.072 | Train Acc: 100.000
97 Train Loss: 0.071 | Train Acc: 100.000
98 Train Loss: 0.070 | Train Acc: 100.000
99 Train Loss: 0.069 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  81
trainInputDict[data].shape :  torch.Size([1148, 16, 8, 8])
copy.shape :  torch.Size([1148, 1024])
copyLabel.shape :  torch.Size([1148])
Class 0 has 518 instances after oversampling
Class 1 has 518 instances after oversampling
Class 2 has 518 instances after oversampling
Class 3 has 518 instances after oversampling
Class 4 has 518 instances after oversampling
Class 5 has 518 instances after oversampling
Class 6 has 518 instances after oversampling
Class 7 has 518 instances after oversampling
Class 8 has 518 instances after oversampling
Class 9 has 518 instances after oversampling
0 Train Loss: 227.585 | Train Acc: 17.104
1 Train Loss: 185.953 | Train Acc: 35.541
2 Train Loss: 146.918 | Train Acc: 52.278
3 Train Loss: 109.305 | Train Acc: 66.583
4 Train Loss: 83.051 | Train Acc: 74.942
5 Train Loss: 62.578 | Train Acc: 82.490
6 Train Loss: 49.451 | Train Acc: 86.525
7 Train Loss: 43.019 | Train Acc: 88.012
8 Train Loss: 33.322 | Train Acc: 90.598
9 Train Loss: 28.796 | Train Acc: 92.008
10 Train Loss: 21.108 | Train Acc: 94.710
11 Train Loss: 17.012 | Train Acc: 96.274
12 Train Loss: 15.578 | Train Acc: 96.120
13 Train Loss: 12.654 | Train Acc: 96.892
14 Train Loss: 9.828 | Train Acc: 98.031
15 Train Loss: 9.815 | Train Acc: 97.857
16 Train Loss: 7.117 | Train Acc: 98.784
17 Train Loss: 5.962 | Train Acc: 99.151
18 Train Loss: 5.155 | Train Acc: 99.131
19 Train Loss: 4.313 | Train Acc: 99.440
20 Train Loss: 3.404 | Train Acc: 99.749
21 Train Loss: 2.968 | Train Acc: 99.788
22 Train Loss: 2.830 | Train Acc: 99.826
23 Train Loss: 2.725 | Train Acc: 99.865
24 Train Loss: 2.579 | Train Acc: 99.865
25 Train Loss: 2.397 | Train Acc: 99.923
26 Train Loss: 2.238 | Train Acc: 99.942
27 Train Loss: 2.120 | Train Acc: 99.942
28 Train Loss: 2.006 | Train Acc: 99.942
29 Train Loss: 1.872 | Train Acc: 99.942
30 Train Loss: 1.776 | Train Acc: 99.942
31 Train Loss: 1.643 | Train Acc: 99.961
32 Train Loss: 1.522 | Train Acc: 99.981
33 Train Loss: 1.444 | Train Acc: 100.000
34 Train Loss: 1.328 | Train Acc: 100.000
35 Train Loss: 1.405 | Train Acc: 99.981
36 Train Loss: 1.218 | Train Acc: 100.000
37 Train Loss: 1.132 | Train Acc: 100.000
38 Train Loss: 1.008 | Train Acc: 100.000
39 Train Loss: 1.004 | Train Acc: 100.000
40 Train Loss: 0.875 | Train Acc: 100.000
41 Train Loss: 0.841 | Train Acc: 100.000
42 Train Loss: 0.835 | Train Acc: 100.000
43 Train Loss: 0.817 | Train Acc: 100.000
44 Train Loss: 0.771 | Train Acc: 100.000
45 Train Loss: 0.777 | Train Acc: 100.000
46 Train Loss: 0.738 | Train Acc: 100.000
47 Train Loss: 0.717 | Train Acc: 100.000
48 Train Loss: 0.697 | Train Acc: 100.000
49 Train Loss: 0.681 | Train Acc: 100.000
50 Train Loss: 0.658 | Train Acc: 100.000
51 Train Loss: 0.651 | Train Acc: 100.000
52 Train Loss: 0.633 | Train Acc: 100.000
53 Train Loss: 0.606 | Train Acc: 100.000
54 Train Loss: 0.576 | Train Acc: 100.000
55 Train Loss: 0.583 | Train Acc: 100.000
56 Train Loss: 0.547 | Train Acc: 100.000
57 Train Loss: 0.527 | Train Acc: 100.000
58 Train Loss: 0.506 | Train Acc: 100.000
59 Train Loss: 0.494 | Train Acc: 100.000
60 Train Loss: 0.459 | Train Acc: 100.000
61 Train Loss: 0.455 | Train Acc: 100.000
62 Train Loss: 0.445 | Train Acc: 100.000
63 Train Loss: 0.437 | Train Acc: 100.000
64 Train Loss: 0.433 | Train Acc: 100.000
65 Train Loss: 0.431 | Train Acc: 100.000
66 Train Loss: 0.420 | Train Acc: 100.000
67 Train Loss: 0.411 | Train Acc: 100.000
68 Train Loss: 0.407 | Train Acc: 100.000
69 Train Loss: 0.400 | Train Acc: 100.000
70 Train Loss: 0.392 | Train Acc: 100.000
71 Train Loss: 0.384 | Train Acc: 100.000
72 Train Loss: 0.377 | Train Acc: 100.000
73 Train Loss: 0.371 | Train Acc: 100.000
74 Train Loss: 0.364 | Train Acc: 100.000
75 Train Loss: 0.354 | Train Acc: 100.000
76 Train Loss: 0.354 | Train Acc: 100.000
77 Train Loss: 0.344 | Train Acc: 100.000
78 Train Loss: 0.337 | Train Acc: 100.000
79 Train Loss: 0.328 | Train Acc: 100.000
80 Train Loss: 0.313 | Train Acc: 100.000
81 Train Loss: 0.311 | Train Acc: 100.000
82 Train Loss: 0.306 | Train Acc: 100.000
83 Train Loss: 0.306 | Train Acc: 100.000
84 Train Loss: 0.300 | Train Acc: 100.000
85 Train Loss: 0.299 | Train Acc: 100.000
86 Train Loss: 0.295 | Train Acc: 100.000
87 Train Loss: 0.293 | Train Acc: 100.000
88 Train Loss: 0.290 | Train Acc: 100.000
89 Train Loss: 0.287 | Train Acc: 100.000
90 Train Loss: 0.284 | Train Acc: 100.000
91 Train Loss: 0.280 | Train Acc: 100.000
92 Train Loss: 0.277 | Train Acc: 100.000
93 Train Loss: 0.272 | Train Acc: 100.000
94 Train Loss: 0.269 | Train Acc: 100.000
95 Train Loss: 0.267 | Train Acc: 100.000
96 Train Loss: 0.264 | Train Acc: 100.000
97 Train Loss: 0.260 | Train Acc: 100.000
98 Train Loss: 0.258 | Train Acc: 100.000
99 Train Loss: 0.254 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  82
trainInputDict[data].shape :  torch.Size([675, 16, 8, 8])
copy.shape :  torch.Size([675, 1024])
copyLabel.shape :  torch.Size([675])
Class 0 has 237 instances after oversampling
Class 1 has 237 instances after oversampling
Class 2 has 237 instances after oversampling
Class 3 has 237 instances after oversampling
Class 4 has 237 instances after oversampling
Class 5 has 237 instances after oversampling
Class 6 has 237 instances after oversampling
Class 7 has 237 instances after oversampling
Class 8 has 237 instances after oversampling
Class 9 has 237 instances after oversampling
0 Train Loss: 215.973 | Train Acc: 22.609
1 Train Loss: 143.299 | Train Acc: 50.261
2 Train Loss: 100.626 | Train Acc: 66.304
3 Train Loss: 74.541 | Train Acc: 76.435
4 Train Loss: 59.772 | Train Acc: 81.174
5 Train Loss: 50.014 | Train Acc: 85.739
6 Train Loss: 36.510 | Train Acc: 89.783
7 Train Loss: 28.089 | Train Acc: 92.391
8 Train Loss: 25.647 | Train Acc: 92.609
9 Train Loss: 18.007 | Train Acc: 95.522
10 Train Loss: 14.127 | Train Acc: 96.783
11 Train Loss: 14.142 | Train Acc: 96.478
12 Train Loss: 9.682 | Train Acc: 98.130
13 Train Loss: 8.102 | Train Acc: 98.609
14 Train Loss: 6.511 | Train Acc: 98.609
15 Train Loss: 6.501 | Train Acc: 98.696
16 Train Loss: 4.889 | Train Acc: 99.087
17 Train Loss: 3.389 | Train Acc: 99.696
18 Train Loss: 2.947 | Train Acc: 99.783
19 Train Loss: 2.014 | Train Acc: 99.913
20 Train Loss: 1.506 | Train Acc: 99.957
21 Train Loss: 1.345 | Train Acc: 100.000
22 Train Loss: 1.297 | Train Acc: 100.000
23 Train Loss: 1.225 | Train Acc: 100.000
24 Train Loss: 1.119 | Train Acc: 100.000
25 Train Loss: 1.059 | Train Acc: 100.000
26 Train Loss: 0.978 | Train Acc: 100.000
27 Train Loss: 0.944 | Train Acc: 100.000
28 Train Loss: 0.886 | Train Acc: 100.000
29 Train Loss: 0.819 | Train Acc: 100.000
30 Train Loss: 0.784 | Train Acc: 100.000
31 Train Loss: 0.738 | Train Acc: 100.000
32 Train Loss: 0.684 | Train Acc: 100.000
33 Train Loss: 0.642 | Train Acc: 100.000
34 Train Loss: 0.609 | Train Acc: 100.000
35 Train Loss: 0.572 | Train Acc: 100.000
36 Train Loss: 0.546 | Train Acc: 100.000
37 Train Loss: 0.502 | Train Acc: 100.000
38 Train Loss: 0.476 | Train Acc: 100.000
39 Train Loss: 0.451 | Train Acc: 100.000
40 Train Loss: 0.408 | Train Acc: 100.000
41 Train Loss: 0.398 | Train Acc: 100.000
42 Train Loss: 0.388 | Train Acc: 100.000
43 Train Loss: 0.379 | Train Acc: 100.000
44 Train Loss: 0.369 | Train Acc: 100.000
45 Train Loss: 0.359 | Train Acc: 100.000
46 Train Loss: 0.350 | Train Acc: 100.000
47 Train Loss: 0.339 | Train Acc: 100.000
48 Train Loss: 0.330 | Train Acc: 100.000
49 Train Loss: 0.318 | Train Acc: 100.000
50 Train Loss: 0.314 | Train Acc: 100.000
51 Train Loss: 0.301 | Train Acc: 100.000
52 Train Loss: 0.295 | Train Acc: 100.000
53 Train Loss: 0.285 | Train Acc: 100.000
54 Train Loss: 0.274 | Train Acc: 100.000
55 Train Loss: 0.266 | Train Acc: 100.000
56 Train Loss: 0.257 | Train Acc: 100.000
57 Train Loss: 0.248 | Train Acc: 100.000
58 Train Loss: 0.240 | Train Acc: 100.000
59 Train Loss: 0.232 | Train Acc: 100.000
60 Train Loss: 0.218 | Train Acc: 100.000
61 Train Loss: 0.215 | Train Acc: 100.000
62 Train Loss: 0.212 | Train Acc: 100.000
63 Train Loss: 0.208 | Train Acc: 100.000
64 Train Loss: 0.205 | Train Acc: 100.000
65 Train Loss: 0.202 | Train Acc: 100.000
66 Train Loss: 0.198 | Train Acc: 100.000
67 Train Loss: 0.195 | Train Acc: 100.000
68 Train Loss: 0.192 | Train Acc: 100.000
69 Train Loss: 0.188 | Train Acc: 100.000
70 Train Loss: 0.184 | Train Acc: 100.000
71 Train Loss: 0.180 | Train Acc: 100.000
72 Train Loss: 0.178 | Train Acc: 100.000
73 Train Loss: 0.175 | Train Acc: 100.000
74 Train Loss: 0.171 | Train Acc: 100.000
75 Train Loss: 0.165 | Train Acc: 100.000
76 Train Loss: 0.162 | Train Acc: 100.000
77 Train Loss: 0.159 | Train Acc: 100.000
78 Train Loss: 0.155 | Train Acc: 100.000
79 Train Loss: 0.152 | Train Acc: 100.000
80 Train Loss: 0.146 | Train Acc: 100.000
81 Train Loss: 0.144 | Train Acc: 100.000
82 Train Loss: 0.142 | Train Acc: 100.000
83 Train Loss: 0.141 | Train Acc: 100.000
84 Train Loss: 0.139 | Train Acc: 100.000
85 Train Loss: 0.138 | Train Acc: 100.000
86 Train Loss: 0.136 | Train Acc: 100.000
87 Train Loss: 0.135 | Train Acc: 100.000
88 Train Loss: 0.133 | Train Acc: 100.000
89 Train Loss: 0.132 | Train Acc: 100.000
90 Train Loss: 0.130 | Train Acc: 100.000
91 Train Loss: 0.128 | Train Acc: 100.000
92 Train Loss: 0.126 | Train Acc: 100.000
93 Train Loss: 0.124 | Train Acc: 100.000
94 Train Loss: 0.122 | Train Acc: 100.000
95 Train Loss: 0.121 | Train Acc: 100.000
96 Train Loss: 0.119 | Train Acc: 100.000
97 Train Loss: 0.118 | Train Acc: 100.000
98 Train Loss: 0.116 | Train Acc: 100.000
99 Train Loss: 0.114 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  83
trainInputDict[data].shape :  torch.Size([755, 16, 8, 8])
copy.shape :  torch.Size([755, 1024])
copyLabel.shape :  torch.Size([755])
Class 0 has 127 instances after oversampling
Class 1 has 126 instances after oversampling
Class 2 has 126 instances after oversampling
Class 3 has 127 instances after oversampling
Class 4 has 126 instances after oversampling
Class 5 has 126 instances after oversampling
Class 6 has 127 instances after oversampling
Class 7 has 127 instances after oversampling
Class 8 has 126 instances after oversampling
Class 9 has 127 instances after oversampling
0 Train Loss: 213.881 | Train Acc: 24.500
1 Train Loss: 170.333 | Train Acc: 43.333
2 Train Loss: 138.651 | Train Acc: 55.667
3 Train Loss: 107.469 | Train Acc: 65.500
4 Train Loss: 85.236 | Train Acc: 74.000
5 Train Loss: 65.672 | Train Acc: 79.667
6 Train Loss: 52.672 | Train Acc: 84.583
7 Train Loss: 38.884 | Train Acc: 89.167
8 Train Loss: 30.105 | Train Acc: 92.167
9 Train Loss: 24.567 | Train Acc: 93.917
10 Train Loss: 19.356 | Train Acc: 95.333
11 Train Loss: 15.083 | Train Acc: 97.333
12 Train Loss: 11.490 | Train Acc: 98.667
13 Train Loss: 9.773 | Train Acc: 98.250
14 Train Loss: 8.225 | Train Acc: 98.667
15 Train Loss: 5.652 | Train Acc: 99.667
16 Train Loss: 4.641 | Train Acc: 100.000
17 Train Loss: 4.523 | Train Acc: 99.667
18 Train Loss: 3.107 | Train Acc: 100.000
19 Train Loss: 2.497 | Train Acc: 100.000
20 Train Loss: 1.905 | Train Acc: 100.000
21 Train Loss: 1.773 | Train Acc: 100.000
22 Train Loss: 1.680 | Train Acc: 100.000
23 Train Loss: 1.592 | Train Acc: 100.000
24 Train Loss: 1.531 | Train Acc: 100.000
25 Train Loss: 1.431 | Train Acc: 100.000
26 Train Loss: 1.366 | Train Acc: 100.000
27 Train Loss: 1.306 | Train Acc: 100.000
28 Train Loss: 1.227 | Train Acc: 100.000
29 Train Loss: 1.176 | Train Acc: 100.000
30 Train Loss: 1.114 | Train Acc: 100.000
31 Train Loss: 1.059 | Train Acc: 100.000
32 Train Loss: 1.010 | Train Acc: 100.000
33 Train Loss: 0.952 | Train Acc: 100.000
34 Train Loss: 0.903 | Train Acc: 100.000
35 Train Loss: 0.853 | Train Acc: 100.000
36 Train Loss: 0.800 | Train Acc: 100.000
37 Train Loss: 0.772 | Train Acc: 100.000
38 Train Loss: 0.732 | Train Acc: 100.000
39 Train Loss: 0.685 | Train Acc: 100.000
40 Train Loss: 0.624 | Train Acc: 100.000
41 Train Loss: 0.607 | Train Acc: 100.000
42 Train Loss: 0.593 | Train Acc: 100.000
43 Train Loss: 0.581 | Train Acc: 100.000
44 Train Loss: 0.569 | Train Acc: 100.000
45 Train Loss: 0.549 | Train Acc: 100.000
46 Train Loss: 0.543 | Train Acc: 100.000
47 Train Loss: 0.525 | Train Acc: 100.000
48 Train Loss: 0.516 | Train Acc: 100.000
49 Train Loss: 0.498 | Train Acc: 100.000
50 Train Loss: 0.488 | Train Acc: 100.000
51 Train Loss: 0.475 | Train Acc: 100.000
52 Train Loss: 0.461 | Train Acc: 100.000
53 Train Loss: 0.446 | Train Acc: 100.000
54 Train Loss: 0.432 | Train Acc: 100.000
55 Train Loss: 0.423 | Train Acc: 100.000
56 Train Loss: 0.410 | Train Acc: 100.000
57 Train Loss: 0.399 | Train Acc: 100.000
58 Train Loss: 0.383 | Train Acc: 100.000
59 Train Loss: 0.371 | Train Acc: 100.000
60 Train Loss: 0.349 | Train Acc: 100.000
61 Train Loss: 0.343 | Train Acc: 100.000
62 Train Loss: 0.339 | Train Acc: 100.000
63 Train Loss: 0.335 | Train Acc: 100.000
64 Train Loss: 0.329 | Train Acc: 100.000
65 Train Loss: 0.324 | Train Acc: 100.000
66 Train Loss: 0.318 | Train Acc: 100.000
67 Train Loss: 0.314 | Train Acc: 100.000
68 Train Loss: 0.309 | Train Acc: 100.000
69 Train Loss: 0.304 | Train Acc: 100.000
70 Train Loss: 0.298 | Train Acc: 100.000
71 Train Loss: 0.293 | Train Acc: 100.000
72 Train Loss: 0.288 | Train Acc: 100.000
73 Train Loss: 0.282 | Train Acc: 100.000
74 Train Loss: 0.275 | Train Acc: 100.000
75 Train Loss: 0.271 | Train Acc: 100.000
76 Train Loss: 0.266 | Train Acc: 100.000
77 Train Loss: 0.258 | Train Acc: 100.000
78 Train Loss: 0.254 | Train Acc: 100.000
79 Train Loss: 0.249 | Train Acc: 100.000
80 Train Loss: 0.238 | Train Acc: 100.000
81 Train Loss: 0.236 | Train Acc: 100.000
82 Train Loss: 0.233 | Train Acc: 100.000
83 Train Loss: 0.231 | Train Acc: 100.000
84 Train Loss: 0.229 | Train Acc: 100.000
85 Train Loss: 0.227 | Train Acc: 100.000
86 Train Loss: 0.224 | Train Acc: 100.000
87 Train Loss: 0.222 | Train Acc: 100.000
88 Train Loss: 0.219 | Train Acc: 100.000
89 Train Loss: 0.216 | Train Acc: 100.000
90 Train Loss: 0.214 | Train Acc: 100.000
91 Train Loss: 0.211 | Train Acc: 100.000
92 Train Loss: 0.209 | Train Acc: 100.000
93 Train Loss: 0.206 | Train Acc: 100.000
94 Train Loss: 0.204 | Train Acc: 100.000
95 Train Loss: 0.201 | Train Acc: 100.000
96 Train Loss: 0.198 | Train Acc: 100.000
97 Train Loss: 0.196 | Train Acc: 100.000
98 Train Loss: 0.192 | Train Acc: 100.000
99 Train Loss: 0.190 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  84
trainInputDict[data].shape :  torch.Size([66, 16, 8, 8])
copy.shape :  torch.Size([66, 1024])
copyLabel.shape :  torch.Size([66])
Class 0 has 39 instances after oversampling
Class 1 has 39 instances after oversampling
Class 2 has 39 instances after oversampling
Class 3 has 1 instances after oversampling
Class 4 has 39 instances after oversampling
Class 5 has 39 instances after oversampling
Class 6 has 1 instances after oversampling
Class 7 has 39 instances after oversampling
0 Train Loss: 2.628 | Train Acc: 11.864
1 Train Loss: 2.087 | Train Acc: 14.407
2 Train Loss: 1.733 | Train Acc: 42.373
3 Train Loss: 1.460 | Train Acc: 59.746
4 Train Loss: 1.240 | Train Acc: 70.763
5 Train Loss: 1.071 | Train Acc: 74.153
6 Train Loss: 0.923 | Train Acc: 78.390
7 Train Loss: 0.785 | Train Acc: 81.780
8 Train Loss: 0.669 | Train Acc: 86.017
9 Train Loss: 0.588 | Train Acc: 86.441
10 Train Loss: 0.529 | Train Acc: 83.898
11 Train Loss: 0.467 | Train Acc: 88.559
12 Train Loss: 0.407 | Train Acc: 91.102
13 Train Loss: 0.368 | Train Acc: 93.220
14 Train Loss: 0.341 | Train Acc: 92.797
15 Train Loss: 0.309 | Train Acc: 94.068
16 Train Loss: 0.277 | Train Acc: 94.068
17 Train Loss: 0.252 | Train Acc: 94.915
18 Train Loss: 0.235 | Train Acc: 95.763
19 Train Loss: 0.219 | Train Acc: 96.186
20 Train Loss: 0.200 | Train Acc: 95.763
21 Train Loss: 0.193 | Train Acc: 96.186
22 Train Loss: 0.186 | Train Acc: 96.186
23 Train Loss: 0.179 | Train Acc: 96.186
24 Train Loss: 0.174 | Train Acc: 96.186
25 Train Loss: 0.168 | Train Acc: 96.186
26 Train Loss: 0.162 | Train Acc: 96.186
27 Train Loss: 0.155 | Train Acc: 96.610
28 Train Loss: 0.149 | Train Acc: 97.458
29 Train Loss: 0.144 | Train Acc: 97.881
30 Train Loss: 0.140 | Train Acc: 97.881
31 Train Loss: 0.136 | Train Acc: 98.305
32 Train Loss: 0.132 | Train Acc: 98.305
33 Train Loss: 0.127 | Train Acc: 98.305
34 Train Loss: 0.123 | Train Acc: 98.305
35 Train Loss: 0.119 | Train Acc: 98.305
36 Train Loss: 0.115 | Train Acc: 98.305
37 Train Loss: 0.111 | Train Acc: 98.305
38 Train Loss: 0.107 | Train Acc: 98.305
39 Train Loss: 0.104 | Train Acc: 98.305
40 Train Loss: 0.100 | Train Acc: 98.305
41 Train Loss: 0.098 | Train Acc: 98.305
42 Train Loss: 0.097 | Train Acc: 98.305
43 Train Loss: 0.095 | Train Acc: 98.305
44 Train Loss: 0.094 | Train Acc: 98.729
45 Train Loss: 0.093 | Train Acc: 98.729
46 Train Loss: 0.092 | Train Acc: 98.729
47 Train Loss: 0.090 | Train Acc: 98.729
48 Train Loss: 0.089 | Train Acc: 98.729
49 Train Loss: 0.088 | Train Acc: 98.729
50 Train Loss: 0.087 | Train Acc: 98.729
51 Train Loss: 0.086 | Train Acc: 98.729
52 Train Loss: 0.084 | Train Acc: 98.729
53 Train Loss: 0.083 | Train Acc: 98.729
54 Train Loss: 0.082 | Train Acc: 98.729
55 Train Loss: 0.081 | Train Acc: 98.729
56 Train Loss: 0.080 | Train Acc: 98.729
57 Train Loss: 0.079 | Train Acc: 98.729
58 Train Loss: 0.078 | Train Acc: 98.729
59 Train Loss: 0.077 | Train Acc: 98.729
60 Train Loss: 0.076 | Train Acc: 98.729
61 Train Loss: 0.076 | Train Acc: 98.729
62 Train Loss: 0.075 | Train Acc: 98.729
63 Train Loss: 0.075 | Train Acc: 98.729
64 Train Loss: 0.075 | Train Acc: 99.153
65 Train Loss: 0.074 | Train Acc: 99.153
66 Train Loss: 0.074 | Train Acc: 99.153
67 Train Loss: 0.073 | Train Acc: 99.153
68 Train Loss: 0.073 | Train Acc: 99.153
69 Train Loss: 0.073 | Train Acc: 99.153
70 Train Loss: 0.072 | Train Acc: 99.153
71 Train Loss: 0.072 | Train Acc: 99.153
72 Train Loss: 0.072 | Train Acc: 99.153
73 Train Loss: 0.071 | Train Acc: 99.153
74 Train Loss: 0.071 | Train Acc: 99.153
75 Train Loss: 0.070 | Train Acc: 99.153
76 Train Loss: 0.070 | Train Acc: 99.153
77 Train Loss: 0.070 | Train Acc: 99.153
78 Train Loss: 0.069 | Train Acc: 99.153
79 Train Loss: 0.069 | Train Acc: 99.153
80 Train Loss: 0.069 | Train Acc: 99.153
81 Train Loss: 0.068 | Train Acc: 99.153
82 Train Loss: 0.068 | Train Acc: 99.153
83 Train Loss: 0.068 | Train Acc: 99.153
84 Train Loss: 0.068 | Train Acc: 99.153
85 Train Loss: 0.068 | Train Acc: 99.153
86 Train Loss: 0.068 | Train Acc: 99.153
87 Train Loss: 0.068 | Train Acc: 99.153
88 Train Loss: 0.067 | Train Acc: 99.153
89 Train Loss: 0.067 | Train Acc: 99.153
90 Train Loss: 0.067 | Train Acc: 99.153
91 Train Loss: 0.067 | Train Acc: 99.153
92 Train Loss: 0.067 | Train Acc: 99.153
93 Train Loss: 0.067 | Train Acc: 99.153
94 Train Loss: 0.067 | Train Acc: 99.153
95 Train Loss: 0.066 | Train Acc: 99.153
96 Train Loss: 0.066 | Train Acc: 99.153
97 Train Loss: 0.066 | Train Acc: 99.153
98 Train Loss: 0.066 | Train Acc: 99.153
99 Train Loss: 0.066 | Train Acc: 99.153
CNN trained successfully...
Running nodeId:  85
trainInputDict[data].shape :  torch.Size([431, 16, 8, 8])
copy.shape :  torch.Size([431, 1024])
copyLabel.shape :  torch.Size([431])
Class 0 has 102 instances after oversampling
Class 1 has 102 instances after oversampling
Class 2 has 101 instances after oversampling
Class 3 has 102 instances after oversampling
Class 4 has 101 instances after oversampling
Class 5 has 101 instances after oversampling
Class 6 has 102 instances after oversampling
Class 7 has 101 instances after oversampling
Class 8 has 101 instances after oversampling
0 Train Loss: 183.704 | Train Acc: 34.556
1 Train Loss: 104.108 | Train Acc: 63.333
2 Train Loss: 71.518 | Train Acc: 74.444
3 Train Loss: 47.688 | Train Acc: 84.333
4 Train Loss: 40.879 | Train Acc: 88.333
5 Train Loss: 31.899 | Train Acc: 90.333
6 Train Loss: 22.502 | Train Acc: 93.333
7 Train Loss: 16.596 | Train Acc: 95.111
8 Train Loss: 13.920 | Train Acc: 96.333
9 Train Loss: 10.264 | Train Acc: 97.111
10 Train Loss: 7.131 | Train Acc: 98.556
11 Train Loss: 5.652 | Train Acc: 99.444
12 Train Loss: 3.629 | Train Acc: 99.778
13 Train Loss: 3.043 | Train Acc: 100.000
14 Train Loss: 2.659 | Train Acc: 99.889
15 Train Loss: 3.228 | Train Acc: 99.444
16 Train Loss: 2.256 | Train Acc: 99.667
17 Train Loss: 1.524 | Train Acc: 100.000
18 Train Loss: 0.980 | Train Acc: 100.000
19 Train Loss: 0.786 | Train Acc: 100.000
20 Train Loss: 0.600 | Train Acc: 100.000
21 Train Loss: 0.557 | Train Acc: 100.000
22 Train Loss: 0.524 | Train Acc: 100.000
23 Train Loss: 0.502 | Train Acc: 100.000
24 Train Loss: 0.480 | Train Acc: 100.000
25 Train Loss: 0.453 | Train Acc: 100.000
26 Train Loss: 0.436 | Train Acc: 100.000
27 Train Loss: 0.414 | Train Acc: 100.000
28 Train Loss: 0.394 | Train Acc: 100.000
29 Train Loss: 0.382 | Train Acc: 100.000
30 Train Loss: 0.360 | Train Acc: 100.000
31 Train Loss: 0.346 | Train Acc: 100.000
32 Train Loss: 0.322 | Train Acc: 100.000
33 Train Loss: 0.311 | Train Acc: 100.000
34 Train Loss: 0.301 | Train Acc: 100.000
35 Train Loss: 0.283 | Train Acc: 100.000
36 Train Loss: 0.268 | Train Acc: 100.000
37 Train Loss: 0.251 | Train Acc: 100.000
38 Train Loss: 0.243 | Train Acc: 100.000
39 Train Loss: 0.231 | Train Acc: 100.000
40 Train Loss: 0.213 | Train Acc: 100.000
41 Train Loss: 0.208 | Train Acc: 100.000
42 Train Loss: 0.204 | Train Acc: 100.000
43 Train Loss: 0.200 | Train Acc: 100.000
44 Train Loss: 0.195 | Train Acc: 100.000
45 Train Loss: 0.190 | Train Acc: 100.000
46 Train Loss: 0.187 | Train Acc: 100.000
47 Train Loss: 0.183 | Train Acc: 100.000
48 Train Loss: 0.178 | Train Acc: 100.000
49 Train Loss: 0.175 | Train Acc: 100.000
50 Train Loss: 0.170 | Train Acc: 100.000
51 Train Loss: 0.165 | Train Acc: 100.000
52 Train Loss: 0.160 | Train Acc: 100.000
53 Train Loss: 0.156 | Train Acc: 100.000
54 Train Loss: 0.152 | Train Acc: 100.000
55 Train Loss: 0.147 | Train Acc: 100.000
56 Train Loss: 0.142 | Train Acc: 100.000
57 Train Loss: 0.140 | Train Acc: 100.000
58 Train Loss: 0.135 | Train Acc: 100.000
59 Train Loss: 0.130 | Train Acc: 100.000
60 Train Loss: 0.124 | Train Acc: 100.000
61 Train Loss: 0.122 | Train Acc: 100.000
62 Train Loss: 0.120 | Train Acc: 100.000
63 Train Loss: 0.118 | Train Acc: 100.000
64 Train Loss: 0.117 | Train Acc: 100.000
65 Train Loss: 0.115 | Train Acc: 100.000
66 Train Loss: 0.113 | Train Acc: 100.000
67 Train Loss: 0.111 | Train Acc: 100.000
68 Train Loss: 0.110 | Train Acc: 100.000
69 Train Loss: 0.107 | Train Acc: 100.000
70 Train Loss: 0.106 | Train Acc: 100.000
71 Train Loss: 0.104 | Train Acc: 100.000
72 Train Loss: 0.103 | Train Acc: 100.000
73 Train Loss: 0.099 | Train Acc: 100.000
74 Train Loss: 0.098 | Train Acc: 100.000
75 Train Loss: 0.096 | Train Acc: 100.000
76 Train Loss: 0.094 | Train Acc: 100.000
77 Train Loss: 0.092 | Train Acc: 100.000
78 Train Loss: 0.090 | Train Acc: 100.000
79 Train Loss: 0.088 | Train Acc: 100.000
80 Train Loss: 0.084 | Train Acc: 100.000
81 Train Loss: 0.083 | Train Acc: 100.000
82 Train Loss: 0.083 | Train Acc: 100.000
83 Train Loss: 0.082 | Train Acc: 100.000
84 Train Loss: 0.081 | Train Acc: 100.000
85 Train Loss: 0.080 | Train Acc: 100.000
86 Train Loss: 0.079 | Train Acc: 100.000
87 Train Loss: 0.078 | Train Acc: 100.000
88 Train Loss: 0.077 | Train Acc: 100.000
89 Train Loss: 0.076 | Train Acc: 100.000
90 Train Loss: 0.075 | Train Acc: 100.000
91 Train Loss: 0.074 | Train Acc: 100.000
92 Train Loss: 0.073 | Train Acc: 100.000
93 Train Loss: 0.073 | Train Acc: 100.000
94 Train Loss: 0.071 | Train Acc: 100.000
95 Train Loss: 0.070 | Train Acc: 100.000
96 Train Loss: 0.069 | Train Acc: 100.000
97 Train Loss: 0.068 | Train Acc: 100.000
98 Train Loss: 0.067 | Train Acc: 100.000
99 Train Loss: 0.066 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  86
trainInputDict[data].shape :  torch.Size([225, 16, 8, 8])
copy.shape :  torch.Size([225, 1024])
copyLabel.shape :  torch.Size([225])
Class 0 has 84 instances after oversampling
Class 1 has 84 instances after oversampling
Class 2 has 84 instances after oversampling
Class 3 has 84 instances after oversampling
Class 4 has 84 instances after oversampling
Class 5 has 84 instances after oversampling
Class 6 has 84 instances after oversampling
Class 7 has 84 instances after oversampling
Class 8 has 84 instances after oversampling
Class 9 has 84 instances after oversampling
0 Train Loss: 221.328 | Train Acc: 22.500
1 Train Loss: 146.355 | Train Acc: 49.250
2 Train Loss: 87.953 | Train Acc: 72.750
3 Train Loss: 56.227 | Train Acc: 84.250
4 Train Loss: 39.923 | Train Acc: 87.250
5 Train Loss: 27.319 | Train Acc: 92.875
6 Train Loss: 20.972 | Train Acc: 94.625
7 Train Loss: 16.527 | Train Acc: 95.875
8 Train Loss: 13.651 | Train Acc: 96.375
9 Train Loss: 10.347 | Train Acc: 97.875
10 Train Loss: 9.959 | Train Acc: 97.500
11 Train Loss: 6.383 | Train Acc: 99.250
12 Train Loss: 5.560 | Train Acc: 99.250
13 Train Loss: 4.223 | Train Acc: 99.125
14 Train Loss: 3.338 | Train Acc: 99.625
15 Train Loss: 3.304 | Train Acc: 99.375
16 Train Loss: 2.149 | Train Acc: 99.875
17 Train Loss: 1.702 | Train Acc: 99.875
18 Train Loss: 1.674 | Train Acc: 100.000
19 Train Loss: 1.403 | Train Acc: 100.000
20 Train Loss: 0.978 | Train Acc: 100.000
21 Train Loss: 0.834 | Train Acc: 100.000
22 Train Loss: 0.788 | Train Acc: 100.000
23 Train Loss: 0.737 | Train Acc: 100.000
24 Train Loss: 0.702 | Train Acc: 100.000
25 Train Loss: 0.656 | Train Acc: 100.000
26 Train Loss: 0.625 | Train Acc: 100.000
27 Train Loss: 0.594 | Train Acc: 100.000
28 Train Loss: 0.568 | Train Acc: 100.000
29 Train Loss: 0.537 | Train Acc: 100.000
30 Train Loss: 0.503 | Train Acc: 100.000
31 Train Loss: 0.484 | Train Acc: 100.000
32 Train Loss: 0.456 | Train Acc: 100.000
33 Train Loss: 0.422 | Train Acc: 100.000
34 Train Loss: 0.405 | Train Acc: 100.000
35 Train Loss: 0.379 | Train Acc: 100.000
36 Train Loss: 0.359 | Train Acc: 100.000
37 Train Loss: 0.338 | Train Acc: 100.000
38 Train Loss: 0.326 | Train Acc: 100.000
39 Train Loss: 0.303 | Train Acc: 100.000
40 Train Loss: 0.282 | Train Acc: 100.000
41 Train Loss: 0.274 | Train Acc: 100.000
42 Train Loss: 0.266 | Train Acc: 100.000
43 Train Loss: 0.260 | Train Acc: 100.000
44 Train Loss: 0.254 | Train Acc: 100.000
45 Train Loss: 0.247 | Train Acc: 100.000
46 Train Loss: 0.242 | Train Acc: 100.000
47 Train Loss: 0.236 | Train Acc: 100.000
48 Train Loss: 0.228 | Train Acc: 100.000
49 Train Loss: 0.223 | Train Acc: 100.000
50 Train Loss: 0.217 | Train Acc: 100.000
51 Train Loss: 0.212 | Train Acc: 100.000
52 Train Loss: 0.204 | Train Acc: 100.000
53 Train Loss: 0.198 | Train Acc: 100.000
54 Train Loss: 0.192 | Train Acc: 100.000
55 Train Loss: 0.185 | Train Acc: 100.000
56 Train Loss: 0.177 | Train Acc: 100.000
57 Train Loss: 0.174 | Train Acc: 100.000
58 Train Loss: 0.168 | Train Acc: 100.000
59 Train Loss: 0.163 | Train Acc: 100.000
60 Train Loss: 0.152 | Train Acc: 100.000
61 Train Loss: 0.150 | Train Acc: 100.000
62 Train Loss: 0.147 | Train Acc: 100.000
63 Train Loss: 0.145 | Train Acc: 100.000
64 Train Loss: 0.143 | Train Acc: 100.000
65 Train Loss: 0.140 | Train Acc: 100.000
66 Train Loss: 0.138 | Train Acc: 100.000
67 Train Loss: 0.136 | Train Acc: 100.000
68 Train Loss: 0.134 | Train Acc: 100.000
69 Train Loss: 0.131 | Train Acc: 100.000
70 Train Loss: 0.128 | Train Acc: 100.000
71 Train Loss: 0.126 | Train Acc: 100.000
72 Train Loss: 0.123 | Train Acc: 100.000
73 Train Loss: 0.121 | Train Acc: 100.000
74 Train Loss: 0.118 | Train Acc: 100.000
75 Train Loss: 0.116 | Train Acc: 100.000
76 Train Loss: 0.113 | Train Acc: 100.000
77 Train Loss: 0.110 | Train Acc: 100.000
78 Train Loss: 0.107 | Train Acc: 100.000
79 Train Loss: 0.105 | Train Acc: 100.000
80 Train Loss: 0.101 | Train Acc: 100.000
81 Train Loss: 0.100 | Train Acc: 100.000
82 Train Loss: 0.099 | Train Acc: 100.000
83 Train Loss: 0.098 | Train Acc: 100.000
84 Train Loss: 0.096 | Train Acc: 100.000
85 Train Loss: 0.095 | Train Acc: 100.000
86 Train Loss: 0.094 | Train Acc: 100.000
87 Train Loss: 0.093 | Train Acc: 100.000
88 Train Loss: 0.092 | Train Acc: 100.000
89 Train Loss: 0.091 | Train Acc: 100.000
90 Train Loss: 0.090 | Train Acc: 100.000
91 Train Loss: 0.088 | Train Acc: 100.000
92 Train Loss: 0.087 | Train Acc: 100.000
93 Train Loss: 0.085 | Train Acc: 100.000
94 Train Loss: 0.085 | Train Acc: 100.000
95 Train Loss: 0.083 | Train Acc: 100.000
96 Train Loss: 0.082 | Train Acc: 100.000
97 Train Loss: 0.081 | Train Acc: 100.000
98 Train Loss: 0.079 | Train Acc: 100.000
99 Train Loss: 0.078 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  87
trainInputDict[data].shape :  torch.Size([248, 16, 8, 8])
copy.shape :  torch.Size([248, 1024])
copyLabel.shape :  torch.Size([248])
Class 0 has 113 instances after oversampling
Class 1 has 113 instances after oversampling
Class 2 has 113 instances after oversampling
Class 3 has 113 instances after oversampling
Class 4 has 113 instances after oversampling
Class 5 has 113 instances after oversampling
Class 6 has 113 instances after oversampling
Class 7 has 113 instances after oversampling
Class 8 has 113 instances after oversampling
Class 9 has 113 instances after oversampling
0 Train Loss: 214.399 | Train Acc: 24.091
1 Train Loss: 123.416 | Train Acc: 59.364
2 Train Loss: 67.194 | Train Acc: 81.000
3 Train Loss: 39.097 | Train Acc: 88.545
4 Train Loss: 25.790 | Train Acc: 93.545
5 Train Loss: 17.352 | Train Acc: 95.545
6 Train Loss: 13.125 | Train Acc: 97.000
7 Train Loss: 8.574 | Train Acc: 98.273
8 Train Loss: 6.709 | Train Acc: 98.455
9 Train Loss: 4.641 | Train Acc: 99.182
10 Train Loss: 5.033 | Train Acc: 98.636
11 Train Loss: 3.733 | Train Acc: 99.091
12 Train Loss: 3.968 | Train Acc: 99.000
13 Train Loss: 2.138 | Train Acc: 99.818
14 Train Loss: 1.266 | Train Acc: 100.000
15 Train Loss: 0.913 | Train Acc: 100.000
16 Train Loss: 0.751 | Train Acc: 100.000
17 Train Loss: 0.691 | Train Acc: 100.000
18 Train Loss: 0.591 | Train Acc: 100.000
19 Train Loss: 0.517 | Train Acc: 100.000
20 Train Loss: 0.423 | Train Acc: 100.000
21 Train Loss: 0.393 | Train Acc: 100.000
22 Train Loss: 0.370 | Train Acc: 100.000
23 Train Loss: 0.358 | Train Acc: 100.000
24 Train Loss: 0.342 | Train Acc: 100.000
25 Train Loss: 0.328 | Train Acc: 100.000
26 Train Loss: 0.311 | Train Acc: 100.000
27 Train Loss: 0.299 | Train Acc: 100.000
28 Train Loss: 0.283 | Train Acc: 100.000
29 Train Loss: 0.270 | Train Acc: 100.000
30 Train Loss: 0.265 | Train Acc: 100.000
31 Train Loss: 0.250 | Train Acc: 100.000
32 Train Loss: 0.237 | Train Acc: 100.000
33 Train Loss: 0.230 | Train Acc: 100.000
34 Train Loss: 0.212 | Train Acc: 100.000
35 Train Loss: 0.201 | Train Acc: 100.000
36 Train Loss: 0.196 | Train Acc: 100.000
37 Train Loss: 0.182 | Train Acc: 100.000
38 Train Loss: 0.173 | Train Acc: 100.000
39 Train Loss: 0.165 | Train Acc: 100.000
40 Train Loss: 0.152 | Train Acc: 100.000
41 Train Loss: 0.149 | Train Acc: 100.000
42 Train Loss: 0.146 | Train Acc: 100.000
43 Train Loss: 0.142 | Train Acc: 100.000
44 Train Loss: 0.138 | Train Acc: 100.000
45 Train Loss: 0.136 | Train Acc: 100.000
46 Train Loss: 0.133 | Train Acc: 100.000
47 Train Loss: 0.129 | Train Acc: 100.000
48 Train Loss: 0.127 | Train Acc: 100.000
49 Train Loss: 0.123 | Train Acc: 100.000
50 Train Loss: 0.120 | Train Acc: 100.000
51 Train Loss: 0.117 | Train Acc: 100.000
52 Train Loss: 0.113 | Train Acc: 100.000
53 Train Loss: 0.110 | Train Acc: 100.000
54 Train Loss: 0.107 | Train Acc: 100.000
55 Train Loss: 0.105 | Train Acc: 100.000
56 Train Loss: 0.100 | Train Acc: 100.000
57 Train Loss: 0.099 | Train Acc: 100.000
58 Train Loss: 0.095 | Train Acc: 100.000
59 Train Loss: 0.091 | Train Acc: 100.000
60 Train Loss: 0.087 | Train Acc: 100.000
61 Train Loss: 0.086 | Train Acc: 100.000
62 Train Loss: 0.085 | Train Acc: 100.000
63 Train Loss: 0.083 | Train Acc: 100.000
64 Train Loss: 0.082 | Train Acc: 100.000
65 Train Loss: 0.080 | Train Acc: 100.000
66 Train Loss: 0.080 | Train Acc: 100.000
67 Train Loss: 0.078 | Train Acc: 100.000
68 Train Loss: 0.077 | Train Acc: 100.000
69 Train Loss: 0.076 | Train Acc: 100.000
70 Train Loss: 0.074 | Train Acc: 100.000
71 Train Loss: 0.073 | Train Acc: 100.000
72 Train Loss: 0.071 | Train Acc: 100.000
73 Train Loss: 0.070 | Train Acc: 100.000
74 Train Loss: 0.068 | Train Acc: 100.000
75 Train Loss: 0.067 | Train Acc: 100.000
76 Train Loss: 0.066 | Train Acc: 100.000
77 Train Loss: 0.064 | Train Acc: 100.000
78 Train Loss: 0.063 | Train Acc: 100.000
79 Train Loss: 0.061 | Train Acc: 100.000
80 Train Loss: 0.059 | Train Acc: 100.000
81 Train Loss: 0.058 | Train Acc: 100.000
82 Train Loss: 0.058 | Train Acc: 100.000
83 Train Loss: 0.057 | Train Acc: 100.000
84 Train Loss: 0.056 | Train Acc: 100.000
85 Train Loss: 0.056 | Train Acc: 100.000
86 Train Loss: 0.055 | Train Acc: 100.000
87 Train Loss: 0.054 | Train Acc: 100.000
88 Train Loss: 0.054 | Train Acc: 100.000
89 Train Loss: 0.053 | Train Acc: 100.000
90 Train Loss: 0.052 | Train Acc: 100.000
91 Train Loss: 0.052 | Train Acc: 100.000
92 Train Loss: 0.051 | Train Acc: 100.000
93 Train Loss: 0.050 | Train Acc: 100.000
94 Train Loss: 0.050 | Train Acc: 100.000
95 Train Loss: 0.049 | Train Acc: 100.000
96 Train Loss: 0.048 | Train Acc: 100.000
97 Train Loss: 0.047 | Train Acc: 100.000
98 Train Loss: 0.046 | Train Acc: 100.000
99 Train Loss: 0.046 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  88
trainInputDict[data].shape :  torch.Size([1062, 16, 8, 8])
copy.shape :  torch.Size([1062, 1024])
copyLabel.shape :  torch.Size([1062])
Class 0 has 191 instances after oversampling
Class 1 has 191 instances after oversampling
Class 2 has 191 instances after oversampling
Class 3 has 191 instances after oversampling
Class 4 has 191 instances after oversampling
Class 5 has 191 instances after oversampling
Class 6 has 191 instances after oversampling
Class 7 has 191 instances after oversampling
Class 8 has 191 instances after oversampling
Class 9 has 191 instances after oversampling
0 Train Loss: 225.630 | Train Acc: 15.105
1 Train Loss: 183.698 | Train Acc: 35.842
2 Train Loss: 142.757 | Train Acc: 51.947
3 Train Loss: 114.278 | Train Acc: 62.737
4 Train Loss: 95.714 | Train Acc: 71.053
5 Train Loss: 82.623 | Train Acc: 74.895
6 Train Loss: 67.843 | Train Acc: 79.053
7 Train Loss: 54.988 | Train Acc: 83.000
8 Train Loss: 49.354 | Train Acc: 84.316
9 Train Loss: 40.650 | Train Acc: 88.632
10 Train Loss: 34.320 | Train Acc: 90.842
11 Train Loss: 29.912 | Train Acc: 91.421
12 Train Loss: 24.766 | Train Acc: 93.895
13 Train Loss: 20.365 | Train Acc: 95.368
14 Train Loss: 17.396 | Train Acc: 96.000
15 Train Loss: 14.320 | Train Acc: 97.474
16 Train Loss: 11.316 | Train Acc: 98.737
17 Train Loss: 10.557 | Train Acc: 98.526
18 Train Loss: 8.838 | Train Acc: 98.947
19 Train Loss: 9.268 | Train Acc: 98.474
20 Train Loss: 5.482 | Train Acc: 99.737
21 Train Loss: 4.557 | Train Acc: 99.737
22 Train Loss: 4.151 | Train Acc: 99.737
23 Train Loss: 3.842 | Train Acc: 99.789
24 Train Loss: 3.573 | Train Acc: 99.842
25 Train Loss: 3.417 | Train Acc: 99.895
26 Train Loss: 3.110 | Train Acc: 99.895
27 Train Loss: 2.959 | Train Acc: 99.947
28 Train Loss: 2.785 | Train Acc: 99.895
29 Train Loss: 2.574 | Train Acc: 99.947
30 Train Loss: 2.407 | Train Acc: 99.947
31 Train Loss: 2.319 | Train Acc: 100.000
32 Train Loss: 2.148 | Train Acc: 100.000
33 Train Loss: 2.055 | Train Acc: 100.000
34 Train Loss: 1.916 | Train Acc: 100.000
35 Train Loss: 1.792 | Train Acc: 99.947
36 Train Loss: 1.689 | Train Acc: 100.000
37 Train Loss: 1.566 | Train Acc: 100.000
38 Train Loss: 1.451 | Train Acc: 100.000
39 Train Loss: 1.407 | Train Acc: 100.000
40 Train Loss: 1.219 | Train Acc: 100.000
41 Train Loss: 1.184 | Train Acc: 100.000
42 Train Loss: 1.152 | Train Acc: 100.000
43 Train Loss: 1.130 | Train Acc: 100.000
44 Train Loss: 1.091 | Train Acc: 100.000
45 Train Loss: 1.072 | Train Acc: 100.000
46 Train Loss: 1.045 | Train Acc: 100.000
47 Train Loss: 1.023 | Train Acc: 100.000
48 Train Loss: 0.986 | Train Acc: 100.000
49 Train Loss: 0.958 | Train Acc: 100.000
50 Train Loss: 0.937 | Train Acc: 100.000
51 Train Loss: 0.910 | Train Acc: 100.000
52 Train Loss: 0.873 | Train Acc: 100.000
53 Train Loss: 0.861 | Train Acc: 100.000
54 Train Loss: 0.831 | Train Acc: 100.000
55 Train Loss: 0.798 | Train Acc: 100.000
56 Train Loss: 0.777 | Train Acc: 100.000
57 Train Loss: 0.756 | Train Acc: 100.000
58 Train Loss: 0.727 | Train Acc: 100.000
59 Train Loss: 0.704 | Train Acc: 100.000
60 Train Loss: 0.652 | Train Acc: 100.000
61 Train Loss: 0.640 | Train Acc: 100.000
62 Train Loss: 0.634 | Train Acc: 100.000
63 Train Loss: 0.623 | Train Acc: 100.000
64 Train Loss: 0.613 | Train Acc: 100.000
65 Train Loss: 0.608 | Train Acc: 100.000
66 Train Loss: 0.598 | Train Acc: 100.000
67 Train Loss: 0.590 | Train Acc: 100.000
68 Train Loss: 0.579 | Train Acc: 100.000
69 Train Loss: 0.566 | Train Acc: 100.000
70 Train Loss: 0.560 | Train Acc: 100.000
71 Train Loss: 0.548 | Train Acc: 100.000
72 Train Loss: 0.537 | Train Acc: 100.000
73 Train Loss: 0.530 | Train Acc: 100.000
74 Train Loss: 0.518 | Train Acc: 100.000
75 Train Loss: 0.504 | Train Acc: 100.000
76 Train Loss: 0.496 | Train Acc: 100.000
77 Train Loss: 0.489 | Train Acc: 100.000
78 Train Loss: 0.474 | Train Acc: 100.000
79 Train Loss: 0.468 | Train Acc: 100.000
80 Train Loss: 0.447 | Train Acc: 100.000
81 Train Loss: 0.441 | Train Acc: 100.000
82 Train Loss: 0.437 | Train Acc: 100.000
83 Train Loss: 0.433 | Train Acc: 100.000
84 Train Loss: 0.428 | Train Acc: 100.000
85 Train Loss: 0.425 | Train Acc: 100.000
86 Train Loss: 0.421 | Train Acc: 100.000
87 Train Loss: 0.416 | Train Acc: 100.000
88 Train Loss: 0.412 | Train Acc: 100.000
89 Train Loss: 0.408 | Train Acc: 100.000
90 Train Loss: 0.402 | Train Acc: 100.000
91 Train Loss: 0.398 | Train Acc: 100.000
92 Train Loss: 0.395 | Train Acc: 100.000
93 Train Loss: 0.389 | Train Acc: 100.000
94 Train Loss: 0.386 | Train Acc: 100.000
95 Train Loss: 0.382 | Train Acc: 100.000
96 Train Loss: 0.375 | Train Acc: 100.000
97 Train Loss: 0.371 | Train Acc: 100.000
98 Train Loss: 0.367 | Train Acc: 100.000
99 Train Loss: 0.363 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  89
trainInputDict[data].shape :  torch.Size([234, 16, 8, 8])
copy.shape :  torch.Size([234, 1024])
copyLabel.shape :  torch.Size([234])
Class 0 has 45 instances after oversampling
Class 1 has 45 instances after oversampling
Class 2 has 46 instances after oversampling
Class 3 has 46 instances after oversampling
Class 4 has 45 instances after oversampling
Class 5 has 45 instances after oversampling
Class 6 has 46 instances after oversampling
Class 7 has 45 instances after oversampling
Class 8 has 46 instances after oversampling
Class 9 has 46 instances after oversampling
0 Train Loss: 2.380 | Train Acc: 10.549
1 Train Loss: 2.240 | Train Acc: 17.802
2 Train Loss: 2.130 | Train Acc: 26.813
3 Train Loss: 2.034 | Train Acc: 33.626
4 Train Loss: 1.939 | Train Acc: 39.121
5 Train Loss: 1.844 | Train Acc: 42.198
6 Train Loss: 1.747 | Train Acc: 45.055
7 Train Loss: 1.652 | Train Acc: 48.571
8 Train Loss: 1.562 | Train Acc: 51.868
9 Train Loss: 1.475 | Train Acc: 54.286
10 Train Loss: 1.390 | Train Acc: 56.484
11 Train Loss: 1.311 | Train Acc: 60.220
12 Train Loss: 1.239 | Train Acc: 60.659
13 Train Loss: 1.175 | Train Acc: 63.736
14 Train Loss: 1.114 | Train Acc: 67.033
15 Train Loss: 1.054 | Train Acc: 68.132
16 Train Loss: 0.997 | Train Acc: 69.890
17 Train Loss: 0.945 | Train Acc: 72.088
18 Train Loss: 0.896 | Train Acc: 74.945
19 Train Loss: 0.846 | Train Acc: 76.264
20 Train Loss: 0.798 | Train Acc: 77.143
21 Train Loss: 0.779 | Train Acc: 78.242
22 Train Loss: 0.760 | Train Acc: 78.901
23 Train Loss: 0.741 | Train Acc: 79.121
24 Train Loss: 0.723 | Train Acc: 79.560
25 Train Loss: 0.705 | Train Acc: 80.440
26 Train Loss: 0.687 | Train Acc: 81.538
27 Train Loss: 0.669 | Train Acc: 82.637
28 Train Loss: 0.652 | Train Acc: 83.736
29 Train Loss: 0.634 | Train Acc: 84.396
30 Train Loss: 0.617 | Train Acc: 84.835
31 Train Loss: 0.601 | Train Acc: 85.934
32 Train Loss: 0.585 | Train Acc: 86.154
33 Train Loss: 0.570 | Train Acc: 86.813
34 Train Loss: 0.554 | Train Acc: 87.912
35 Train Loss: 0.539 | Train Acc: 88.791
36 Train Loss: 0.524 | Train Acc: 89.670
37 Train Loss: 0.510 | Train Acc: 90.549
38 Train Loss: 0.497 | Train Acc: 90.769
39 Train Loss: 0.483 | Train Acc: 91.429
40 Train Loss: 0.470 | Train Acc: 91.868
41 Train Loss: 0.465 | Train Acc: 92.088
42 Train Loss: 0.460 | Train Acc: 92.308
43 Train Loss: 0.455 | Train Acc: 92.308
44 Train Loss: 0.450 | Train Acc: 92.527
45 Train Loss: 0.445 | Train Acc: 92.967
46 Train Loss: 0.440 | Train Acc: 93.187
47 Train Loss: 0.435 | Train Acc: 93.407
48 Train Loss: 0.430 | Train Acc: 93.846
49 Train Loss: 0.426 | Train Acc: 93.846
50 Train Loss: 0.421 | Train Acc: 93.846
51 Train Loss: 0.416 | Train Acc: 94.066
52 Train Loss: 0.412 | Train Acc: 94.286
53 Train Loss: 0.407 | Train Acc: 94.286
54 Train Loss: 0.403 | Train Acc: 94.505
55 Train Loss: 0.398 | Train Acc: 94.945
56 Train Loss: 0.394 | Train Acc: 95.165
57 Train Loss: 0.389 | Train Acc: 95.385
58 Train Loss: 0.385 | Train Acc: 95.604
59 Train Loss: 0.381 | Train Acc: 95.604
60 Train Loss: 0.377 | Train Acc: 95.604
61 Train Loss: 0.375 | Train Acc: 95.604
62 Train Loss: 0.373 | Train Acc: 95.604
63 Train Loss: 0.372 | Train Acc: 95.824
64 Train Loss: 0.370 | Train Acc: 95.824
65 Train Loss: 0.368 | Train Acc: 95.824
66 Train Loss: 0.367 | Train Acc: 95.824
67 Train Loss: 0.365 | Train Acc: 95.824
68 Train Loss: 0.363 | Train Acc: 95.824
69 Train Loss: 0.362 | Train Acc: 95.824
70 Train Loss: 0.360 | Train Acc: 96.044
71 Train Loss: 0.359 | Train Acc: 96.044
72 Train Loss: 0.357 | Train Acc: 96.044
73 Train Loss: 0.355 | Train Acc: 96.264
74 Train Loss: 0.354 | Train Acc: 96.484
75 Train Loss: 0.352 | Train Acc: 96.484
76 Train Loss: 0.351 | Train Acc: 96.484
77 Train Loss: 0.349 | Train Acc: 96.484
78 Train Loss: 0.348 | Train Acc: 96.484
79 Train Loss: 0.346 | Train Acc: 96.484
80 Train Loss: 0.344 | Train Acc: 96.484
81 Train Loss: 0.344 | Train Acc: 96.484
82 Train Loss: 0.343 | Train Acc: 96.484
83 Train Loss: 0.343 | Train Acc: 96.484
84 Train Loss: 0.342 | Train Acc: 96.484
85 Train Loss: 0.341 | Train Acc: 96.484
86 Train Loss: 0.341 | Train Acc: 96.484
87 Train Loss: 0.340 | Train Acc: 96.484
88 Train Loss: 0.339 | Train Acc: 96.484
89 Train Loss: 0.339 | Train Acc: 96.484
90 Train Loss: 0.338 | Train Acc: 96.484
91 Train Loss: 0.338 | Train Acc: 96.484
92 Train Loss: 0.337 | Train Acc: 96.484
93 Train Loss: 0.336 | Train Acc: 96.484
94 Train Loss: 0.336 | Train Acc: 96.484
95 Train Loss: 0.335 | Train Acc: 96.484
96 Train Loss: 0.334 | Train Acc: 96.484
97 Train Loss: 0.334 | Train Acc: 96.484
98 Train Loss: 0.333 | Train Acc: 96.484
99 Train Loss: 0.333 | Train Acc: 96.484
CNN trained successfully...
Running nodeId:  90
trainInputDict[data].shape :  torch.Size([419, 16, 8, 8])
copy.shape :  torch.Size([419, 1024])
copyLabel.shape :  torch.Size([419])
Class 0 has 71 instances after oversampling
Class 1 has 71 instances after oversampling
Class 2 has 71 instances after oversampling
Class 3 has 71 instances after oversampling
Class 4 has 71 instances after oversampling
Class 5 has 71 instances after oversampling
Class 6 has 71 instances after oversampling
Class 7 has 71 instances after oversampling
Class 8 has 71 instances after oversampling
Class 9 has 71 instances after oversampling
0 Train Loss: 219.943 | Train Acc: 21.714
1 Train Loss: 175.881 | Train Acc: 43.143
2 Train Loss: 127.304 | Train Acc: 62.000
3 Train Loss: 88.727 | Train Acc: 74.000
4 Train Loss: 58.983 | Train Acc: 84.714
5 Train Loss: 40.946 | Train Acc: 90.286
6 Train Loss: 27.454 | Train Acc: 94.286
7 Train Loss: 20.458 | Train Acc: 96.143
8 Train Loss: 15.695 | Train Acc: 97.429
9 Train Loss: 9.415 | Train Acc: 99.286
10 Train Loss: 6.866 | Train Acc: 99.429
11 Train Loss: 4.605 | Train Acc: 100.000
12 Train Loss: 3.438 | Train Acc: 100.000
13 Train Loss: 2.708 | Train Acc: 100.000
14 Train Loss: 2.117 | Train Acc: 100.000
15 Train Loss: 1.672 | Train Acc: 100.000
16 Train Loss: 1.387 | Train Acc: 100.000
17 Train Loss: 1.194 | Train Acc: 100.000
18 Train Loss: 1.015 | Train Acc: 100.000
19 Train Loss: 0.896 | Train Acc: 100.000
20 Train Loss: 0.776 | Train Acc: 100.000
21 Train Loss: 0.736 | Train Acc: 100.000
22 Train Loss: 0.703 | Train Acc: 100.000
23 Train Loss: 0.673 | Train Acc: 100.000
24 Train Loss: 0.643 | Train Acc: 100.000
25 Train Loss: 0.610 | Train Acc: 100.000
26 Train Loss: 0.590 | Train Acc: 100.000
27 Train Loss: 0.557 | Train Acc: 100.000
28 Train Loss: 0.535 | Train Acc: 100.000
29 Train Loss: 0.512 | Train Acc: 100.000
30 Train Loss: 0.483 | Train Acc: 100.000
31 Train Loss: 0.462 | Train Acc: 100.000
32 Train Loss: 0.441 | Train Acc: 100.000
33 Train Loss: 0.417 | Train Acc: 100.000
34 Train Loss: 0.399 | Train Acc: 100.000
35 Train Loss: 0.377 | Train Acc: 100.000
36 Train Loss: 0.360 | Train Acc: 100.000
37 Train Loss: 0.341 | Train Acc: 100.000
38 Train Loss: 0.322 | Train Acc: 100.000
39 Train Loss: 0.305 | Train Acc: 100.000
40 Train Loss: 0.284 | Train Acc: 100.000
41 Train Loss: 0.277 | Train Acc: 100.000
42 Train Loss: 0.271 | Train Acc: 100.000
43 Train Loss: 0.266 | Train Acc: 100.000
44 Train Loss: 0.259 | Train Acc: 100.000
45 Train Loss: 0.254 | Train Acc: 100.000
46 Train Loss: 0.247 | Train Acc: 100.000
47 Train Loss: 0.241 | Train Acc: 100.000
48 Train Loss: 0.236 | Train Acc: 100.000
49 Train Loss: 0.228 | Train Acc: 100.000
50 Train Loss: 0.224 | Train Acc: 100.000
51 Train Loss: 0.217 | Train Acc: 100.000
52 Train Loss: 0.211 | Train Acc: 100.000
53 Train Loss: 0.206 | Train Acc: 100.000
54 Train Loss: 0.199 | Train Acc: 100.000
55 Train Loss: 0.193 | Train Acc: 100.000
56 Train Loss: 0.188 | Train Acc: 100.000
57 Train Loss: 0.182 | Train Acc: 100.000
58 Train Loss: 0.177 | Train Acc: 100.000
59 Train Loss: 0.171 | Train Acc: 100.000
60 Train Loss: 0.162 | Train Acc: 100.000
61 Train Loss: 0.159 | Train Acc: 100.000
62 Train Loss: 0.157 | Train Acc: 100.000
63 Train Loss: 0.155 | Train Acc: 100.000
64 Train Loss: 0.153 | Train Acc: 100.000
65 Train Loss: 0.150 | Train Acc: 100.000
66 Train Loss: 0.148 | Train Acc: 100.000
67 Train Loss: 0.145 | Train Acc: 100.000
68 Train Loss: 0.143 | Train Acc: 100.000
69 Train Loss: 0.140 | Train Acc: 100.000
70 Train Loss: 0.138 | Train Acc: 100.000
71 Train Loss: 0.135 | Train Acc: 100.000
72 Train Loss: 0.132 | Train Acc: 100.000
73 Train Loss: 0.130 | Train Acc: 100.000
74 Train Loss: 0.127 | Train Acc: 100.000
75 Train Loss: 0.124 | Train Acc: 100.000
76 Train Loss: 0.122 | Train Acc: 100.000
77 Train Loss: 0.119 | Train Acc: 100.000
78 Train Loss: 0.116 | Train Acc: 100.000
79 Train Loss: 0.114 | Train Acc: 100.000
80 Train Loss: 0.109 | Train Acc: 100.000
81 Train Loss: 0.108 | Train Acc: 100.000
82 Train Loss: 0.107 | Train Acc: 100.000
83 Train Loss: 0.106 | Train Acc: 100.000
84 Train Loss: 0.105 | Train Acc: 100.000
85 Train Loss: 0.103 | Train Acc: 100.000
86 Train Loss: 0.102 | Train Acc: 100.000
87 Train Loss: 0.101 | Train Acc: 100.000
88 Train Loss: 0.100 | Train Acc: 100.000
89 Train Loss: 0.099 | Train Acc: 100.000
90 Train Loss: 0.097 | Train Acc: 100.000
91 Train Loss: 0.096 | Train Acc: 100.000
92 Train Loss: 0.095 | Train Acc: 100.000
93 Train Loss: 0.093 | Train Acc: 100.000
94 Train Loss: 0.092 | Train Acc: 100.000
95 Train Loss: 0.090 | Train Acc: 100.000
96 Train Loss: 0.089 | Train Acc: 100.000
97 Train Loss: 0.088 | Train Acc: 100.000
98 Train Loss: 0.086 | Train Acc: 100.000
99 Train Loss: 0.085 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  91
trainInputDict[data].shape :  torch.Size([640, 16, 8, 8])
copy.shape :  torch.Size([640, 1024])
copyLabel.shape :  torch.Size([640])
Class 0 has 143 instances after oversampling
Class 1 has 143 instances after oversampling
Class 2 has 143 instances after oversampling
Class 3 has 143 instances after oversampling
Class 4 has 143 instances after oversampling
Class 5 has 143 instances after oversampling
Class 6 has 143 instances after oversampling
Class 7 has 143 instances after oversampling
Class 8 has 143 instances after oversampling
Class 9 has 143 instances after oversampling
0 Train Loss: 227.184 | Train Acc: 16.214
1 Train Loss: 201.009 | Train Acc: 27.643
2 Train Loss: 156.897 | Train Acc: 46.786
3 Train Loss: 121.766 | Train Acc: 59.429
4 Train Loss: 96.096 | Train Acc: 69.571
5 Train Loss: 72.129 | Train Acc: 78.071
6 Train Loss: 56.881 | Train Acc: 83.786
7 Train Loss: 39.952 | Train Acc: 89.500
8 Train Loss: 30.417 | Train Acc: 92.214
9 Train Loss: 24.892 | Train Acc: 93.929
10 Train Loss: 18.175 | Train Acc: 96.571
11 Train Loss: 15.200 | Train Acc: 97.143
12 Train Loss: 12.010 | Train Acc: 98.143
13 Train Loss: 8.724 | Train Acc: 99.071
14 Train Loss: 7.097 | Train Acc: 99.286
15 Train Loss: 5.254 | Train Acc: 99.571
16 Train Loss: 4.029 | Train Acc: 99.929
17 Train Loss: 3.091 | Train Acc: 100.000
18 Train Loss: 2.608 | Train Acc: 100.000
19 Train Loss: 2.144 | Train Acc: 100.000
20 Train Loss: 1.697 | Train Acc: 100.000
21 Train Loss: 1.563 | Train Acc: 100.000
22 Train Loss: 1.481 | Train Acc: 100.000
23 Train Loss: 1.394 | Train Acc: 100.000
24 Train Loss: 1.350 | Train Acc: 100.000
25 Train Loss: 1.273 | Train Acc: 100.000
26 Train Loss: 1.210 | Train Acc: 100.000
27 Train Loss: 1.129 | Train Acc: 100.000
28 Train Loss: 1.084 | Train Acc: 100.000
29 Train Loss: 1.026 | Train Acc: 100.000
30 Train Loss: 0.970 | Train Acc: 100.000
31 Train Loss: 0.919 | Train Acc: 100.000
32 Train Loss: 0.866 | Train Acc: 100.000
33 Train Loss: 0.840 | Train Acc: 100.000
34 Train Loss: 0.781 | Train Acc: 100.000
35 Train Loss: 0.736 | Train Acc: 100.000
36 Train Loss: 0.708 | Train Acc: 100.000
37 Train Loss: 0.661 | Train Acc: 100.000
38 Train Loss: 0.633 | Train Acc: 100.000
39 Train Loss: 0.593 | Train Acc: 100.000
40 Train Loss: 0.543 | Train Acc: 100.000
41 Train Loss: 0.529 | Train Acc: 100.000
42 Train Loss: 0.520 | Train Acc: 100.000
43 Train Loss: 0.509 | Train Acc: 100.000
44 Train Loss: 0.496 | Train Acc: 100.000
45 Train Loss: 0.484 | Train Acc: 100.000
46 Train Loss: 0.472 | Train Acc: 100.000
47 Train Loss: 0.462 | Train Acc: 100.000
48 Train Loss: 0.449 | Train Acc: 100.000
49 Train Loss: 0.434 | Train Acc: 100.000
50 Train Loss: 0.424 | Train Acc: 100.000
51 Train Loss: 0.414 | Train Acc: 100.000
52 Train Loss: 0.398 | Train Acc: 100.000
53 Train Loss: 0.392 | Train Acc: 100.000
54 Train Loss: 0.379 | Train Acc: 100.000
55 Train Loss: 0.365 | Train Acc: 100.000
56 Train Loss: 0.355 | Train Acc: 100.000
57 Train Loss: 0.344 | Train Acc: 100.000
58 Train Loss: 0.331 | Train Acc: 100.000
59 Train Loss: 0.323 | Train Acc: 100.000
60 Train Loss: 0.302 | Train Acc: 100.000
61 Train Loss: 0.297 | Train Acc: 100.000
62 Train Loss: 0.294 | Train Acc: 100.000
63 Train Loss: 0.289 | Train Acc: 100.000
64 Train Loss: 0.286 | Train Acc: 100.000
65 Train Loss: 0.281 | Train Acc: 100.000
66 Train Loss: 0.277 | Train Acc: 100.000
67 Train Loss: 0.272 | Train Acc: 100.000
68 Train Loss: 0.267 | Train Acc: 100.000
69 Train Loss: 0.262 | Train Acc: 100.000
70 Train Loss: 0.260 | Train Acc: 100.000
71 Train Loss: 0.253 | Train Acc: 100.000
72 Train Loss: 0.248 | Train Acc: 100.000
73 Train Loss: 0.244 | Train Acc: 100.000
74 Train Loss: 0.239 | Train Acc: 100.000
75 Train Loss: 0.233 | Train Acc: 100.000
76 Train Loss: 0.230 | Train Acc: 100.000
77 Train Loss: 0.223 | Train Acc: 100.000
78 Train Loss: 0.219 | Train Acc: 100.000
79 Train Loss: 0.214 | Train Acc: 100.000
80 Train Loss: 0.206 | Train Acc: 100.000
81 Train Loss: 0.204 | Train Acc: 100.000
82 Train Loss: 0.202 | Train Acc: 100.000
83 Train Loss: 0.200 | Train Acc: 100.000
84 Train Loss: 0.197 | Train Acc: 100.000
85 Train Loss: 0.195 | Train Acc: 100.000
86 Train Loss: 0.194 | Train Acc: 100.000
87 Train Loss: 0.191 | Train Acc: 100.000
88 Train Loss: 0.189 | Train Acc: 100.000
89 Train Loss: 0.186 | Train Acc: 100.000
90 Train Loss: 0.184 | Train Acc: 100.000
91 Train Loss: 0.182 | Train Acc: 100.000
92 Train Loss: 0.180 | Train Acc: 100.000
93 Train Loss: 0.177 | Train Acc: 100.000
94 Train Loss: 0.174 | Train Acc: 100.000
95 Train Loss: 0.173 | Train Acc: 100.000
96 Train Loss: 0.170 | Train Acc: 100.000
97 Train Loss: 0.168 | Train Acc: 100.000
98 Train Loss: 0.165 | Train Acc: 100.000
99 Train Loss: 0.163 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  92
trainInputDict[data].shape :  torch.Size([173, 16, 8, 8])
copy.shape :  torch.Size([173, 1024])
copyLabel.shape :  torch.Size([173])
Class 0 has 79 instances after oversampling
Class 1 has 79 instances after oversampling
Class 2 has 79 instances after oversampling
Class 3 has 79 instances after oversampling
Class 4 has 79 instances after oversampling
Class 5 has 79 instances after oversampling
Class 6 has 79 instances after oversampling
Class 7 has 79 instances after oversampling
Class 8 has 79 instances after oversampling
0 Train Loss: 152.206 | Train Acc: 52.571
1 Train Loss: 60.130 | Train Acc: 82.714
2 Train Loss: 29.390 | Train Acc: 92.143
3 Train Loss: 15.324 | Train Acc: 97.000
4 Train Loss: 9.083 | Train Acc: 98.286
5 Train Loss: 4.885 | Train Acc: 99.429
6 Train Loss: 3.739 | Train Acc: 99.571
7 Train Loss: 2.277 | Train Acc: 99.857
8 Train Loss: 1.600 | Train Acc: 99.857
9 Train Loss: 1.007 | Train Acc: 100.000
10 Train Loss: 0.818 | Train Acc: 100.000
11 Train Loss: 0.554 | Train Acc: 100.000
12 Train Loss: 0.450 | Train Acc: 100.000
13 Train Loss: 0.388 | Train Acc: 100.000
14 Train Loss: 0.319 | Train Acc: 100.000
15 Train Loss: 0.276 | Train Acc: 100.000
16 Train Loss: 0.241 | Train Acc: 100.000
17 Train Loss: 0.218 | Train Acc: 100.000
18 Train Loss: 0.192 | Train Acc: 100.000
19 Train Loss: 0.164 | Train Acc: 100.000
20 Train Loss: 0.149 | Train Acc: 100.000
21 Train Loss: 0.141 | Train Acc: 100.000
22 Train Loss: 0.136 | Train Acc: 100.000
23 Train Loss: 0.129 | Train Acc: 100.000
24 Train Loss: 0.122 | Train Acc: 100.000
25 Train Loss: 0.119 | Train Acc: 100.000
26 Train Loss: 0.113 | Train Acc: 100.000
27 Train Loss: 0.107 | Train Acc: 100.000
28 Train Loss: 0.102 | Train Acc: 100.000
29 Train Loss: 0.099 | Train Acc: 100.000
30 Train Loss: 0.094 | Train Acc: 100.000
31 Train Loss: 0.088 | Train Acc: 100.000
32 Train Loss: 0.085 | Train Acc: 100.000
33 Train Loss: 0.081 | Train Acc: 100.000
34 Train Loss: 0.076 | Train Acc: 100.000
35 Train Loss: 0.073 | Train Acc: 100.000
36 Train Loss: 0.069 | Train Acc: 100.000
37 Train Loss: 0.066 | Train Acc: 100.000
38 Train Loss: 0.063 | Train Acc: 100.000
39 Train Loss: 0.060 | Train Acc: 100.000
40 Train Loss: 0.055 | Train Acc: 100.000
41 Train Loss: 0.054 | Train Acc: 100.000
42 Train Loss: 0.053 | Train Acc: 100.000
43 Train Loss: 0.052 | Train Acc: 100.000
44 Train Loss: 0.050 | Train Acc: 100.000
45 Train Loss: 0.050 | Train Acc: 100.000
46 Train Loss: 0.048 | Train Acc: 100.000
47 Train Loss: 0.047 | Train Acc: 100.000
48 Train Loss: 0.046 | Train Acc: 100.000
49 Train Loss: 0.045 | Train Acc: 100.000
50 Train Loss: 0.043 | Train Acc: 100.000
51 Train Loss: 0.042 | Train Acc: 100.000
52 Train Loss: 0.041 | Train Acc: 100.000
53 Train Loss: 0.040 | Train Acc: 100.000
54 Train Loss: 0.038 | Train Acc: 100.000
55 Train Loss: 0.038 | Train Acc: 100.000
56 Train Loss: 0.036 | Train Acc: 100.000
57 Train Loss: 0.035 | Train Acc: 100.000
58 Train Loss: 0.034 | Train Acc: 100.000
59 Train Loss: 0.033 | Train Acc: 100.000
60 Train Loss: 0.032 | Train Acc: 100.000
61 Train Loss: 0.031 | Train Acc: 100.000
62 Train Loss: 0.031 | Train Acc: 100.000
63 Train Loss: 0.030 | Train Acc: 100.000
64 Train Loss: 0.030 | Train Acc: 100.000
65 Train Loss: 0.029 | Train Acc: 100.000
66 Train Loss: 0.029 | Train Acc: 100.000
67 Train Loss: 0.028 | Train Acc: 100.000
68 Train Loss: 0.028 | Train Acc: 100.000
69 Train Loss: 0.027 | Train Acc: 100.000
70 Train Loss: 0.027 | Train Acc: 100.000
71 Train Loss: 0.026 | Train Acc: 100.000
72 Train Loss: 0.026 | Train Acc: 100.000
73 Train Loss: 0.025 | Train Acc: 100.000
74 Train Loss: 0.025 | Train Acc: 100.000
75 Train Loss: 0.024 | Train Acc: 100.000
76 Train Loss: 0.024 | Train Acc: 100.000
77 Train Loss: 0.023 | Train Acc: 100.000
78 Train Loss: 0.023 | Train Acc: 100.000
79 Train Loss: 0.022 | Train Acc: 100.000
80 Train Loss: 0.021 | Train Acc: 100.000
81 Train Loss: 0.021 | Train Acc: 100.000
82 Train Loss: 0.021 | Train Acc: 100.000
83 Train Loss: 0.021 | Train Acc: 100.000
84 Train Loss: 0.020 | Train Acc: 100.000
85 Train Loss: 0.020 | Train Acc: 100.000
86 Train Loss: 0.020 | Train Acc: 100.000
87 Train Loss: 0.020 | Train Acc: 100.000
88 Train Loss: 0.019 | Train Acc: 100.000
89 Train Loss: 0.019 | Train Acc: 100.000
90 Train Loss: 0.019 | Train Acc: 100.000
91 Train Loss: 0.019 | Train Acc: 100.000
92 Train Loss: 0.018 | Train Acc: 100.000
93 Train Loss: 0.018 | Train Acc: 100.000
94 Train Loss: 0.018 | Train Acc: 100.000
95 Train Loss: 0.017 | Train Acc: 100.000
96 Train Loss: 0.017 | Train Acc: 100.000
97 Train Loss: 0.017 | Train Acc: 100.000
98 Train Loss: 0.016 | Train Acc: 100.000
99 Train Loss: 0.016 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  93
trainInputDict[data].shape :  torch.Size([622, 16, 8, 8])
copy.shape :  torch.Size([622, 1024])
copyLabel.shape :  torch.Size([622])
Class 0 has 156 instances after oversampling
Class 1 has 1 instances after oversampling
Class 2 has 156 instances after oversampling
Class 3 has 156 instances after oversampling
Class 4 has 156 instances after oversampling
Class 5 has 156 instances after oversampling
Class 6 has 156 instances after oversampling
Class 7 has 156 instances after oversampling
Class 8 has 156 instances after oversampling
Class 9 has 156 instances after oversampling
0 Train Loss: 209.046 | Train Acc: 24.929
1 Train Loss: 135.631 | Train Acc: 55.000
2 Train Loss: 95.590 | Train Acc: 70.429
3 Train Loss: 75.219 | Train Acc: 74.286
4 Train Loss: 60.590 | Train Acc: 80.357
5 Train Loss: 53.196 | Train Acc: 84.143
6 Train Loss: 41.280 | Train Acc: 86.786
7 Train Loss: 34.600 | Train Acc: 89.071
8 Train Loss: 27.933 | Train Acc: 91.714
9 Train Loss: 26.310 | Train Acc: 91.714
10 Train Loss: 21.131 | Train Acc: 93.786
11 Train Loss: 16.299 | Train Acc: 96.071
12 Train Loss: 14.114 | Train Acc: 96.500
13 Train Loss: 11.091 | Train Acc: 97.929
14 Train Loss: 8.442 | Train Acc: 98.929
15 Train Loss: 6.786 | Train Acc: 99.286
16 Train Loss: 5.745 | Train Acc: 99.429
17 Train Loss: 4.540 | Train Acc: 99.786
18 Train Loss: 3.856 | Train Acc: 99.929
19 Train Loss: 3.506 | Train Acc: 99.714
20 Train Loss: 2.311 | Train Acc: 100.000
21 Train Loss: 2.173 | Train Acc: 100.000
22 Train Loss: 2.023 | Train Acc: 100.000
23 Train Loss: 1.864 | Train Acc: 100.000
24 Train Loss: 1.760 | Train Acc: 100.000
25 Train Loss: 1.636 | Train Acc: 100.000
26 Train Loss: 1.590 | Train Acc: 100.000
27 Train Loss: 1.445 | Train Acc: 100.000
28 Train Loss: 1.372 | Train Acc: 100.000
29 Train Loss: 1.282 | Train Acc: 100.000
30 Train Loss: 1.204 | Train Acc: 100.000
31 Train Loss: 1.151 | Train Acc: 100.000
32 Train Loss: 1.055 | Train Acc: 100.000
33 Train Loss: 1.010 | Train Acc: 100.000
34 Train Loss: 0.941 | Train Acc: 100.000
35 Train Loss: 0.905 | Train Acc: 100.000
36 Train Loss: 0.816 | Train Acc: 100.000
37 Train Loss: 0.791 | Train Acc: 100.000
38 Train Loss: 0.733 | Train Acc: 100.000
39 Train Loss: 0.689 | Train Acc: 100.000
40 Train Loss: 0.621 | Train Acc: 100.000
41 Train Loss: 0.601 | Train Acc: 100.000
42 Train Loss: 0.582 | Train Acc: 100.000
43 Train Loss: 0.574 | Train Acc: 100.000
44 Train Loss: 0.556 | Train Acc: 100.000
45 Train Loss: 0.546 | Train Acc: 100.000
46 Train Loss: 0.528 | Train Acc: 100.000
47 Train Loss: 0.511 | Train Acc: 100.000
48 Train Loss: 0.493 | Train Acc: 100.000
49 Train Loss: 0.487 | Train Acc: 100.000
50 Train Loss: 0.470 | Train Acc: 100.000
51 Train Loss: 0.456 | Train Acc: 100.000
52 Train Loss: 0.444 | Train Acc: 100.000
53 Train Loss: 0.424 | Train Acc: 100.000
54 Train Loss: 0.409 | Train Acc: 100.000
55 Train Loss: 0.398 | Train Acc: 100.000
56 Train Loss: 0.387 | Train Acc: 100.000
57 Train Loss: 0.373 | Train Acc: 100.000
58 Train Loss: 0.359 | Train Acc: 100.000
59 Train Loss: 0.346 | Train Acc: 100.000
60 Train Loss: 0.326 | Train Acc: 100.000
61 Train Loss: 0.320 | Train Acc: 100.000
62 Train Loss: 0.316 | Train Acc: 100.000
63 Train Loss: 0.311 | Train Acc: 100.000
64 Train Loss: 0.307 | Train Acc: 100.000
65 Train Loss: 0.301 | Train Acc: 100.000
66 Train Loss: 0.297 | Train Acc: 100.000
67 Train Loss: 0.292 | Train Acc: 100.000
68 Train Loss: 0.286 | Train Acc: 100.000
69 Train Loss: 0.281 | Train Acc: 100.000
70 Train Loss: 0.275 | Train Acc: 100.000
71 Train Loss: 0.272 | Train Acc: 100.000
72 Train Loss: 0.264 | Train Acc: 100.000
73 Train Loss: 0.260 | Train Acc: 100.000
74 Train Loss: 0.255 | Train Acc: 100.000
75 Train Loss: 0.247 | Train Acc: 100.000
76 Train Loss: 0.244 | Train Acc: 100.000
77 Train Loss: 0.237 | Train Acc: 100.000
78 Train Loss: 0.232 | Train Acc: 100.000
79 Train Loss: 0.228 | Train Acc: 100.000
80 Train Loss: 0.218 | Train Acc: 100.000
81 Train Loss: 0.216 | Train Acc: 100.000
82 Train Loss: 0.214 | Train Acc: 100.000
83 Train Loss: 0.211 | Train Acc: 100.000
84 Train Loss: 0.209 | Train Acc: 100.000
85 Train Loss: 0.208 | Train Acc: 100.000
86 Train Loss: 0.205 | Train Acc: 100.000
87 Train Loss: 0.202 | Train Acc: 100.000
88 Train Loss: 0.201 | Train Acc: 100.000
89 Train Loss: 0.198 | Train Acc: 100.000
90 Train Loss: 0.196 | Train Acc: 100.000
91 Train Loss: 0.193 | Train Acc: 100.000
92 Train Loss: 0.191 | Train Acc: 100.000
93 Train Loss: 0.188 | Train Acc: 100.000
94 Train Loss: 0.186 | Train Acc: 100.000
95 Train Loss: 0.183 | Train Acc: 100.000
96 Train Loss: 0.181 | Train Acc: 100.000
97 Train Loss: 0.178 | Train Acc: 100.000
98 Train Loss: 0.176 | Train Acc: 100.000
99 Train Loss: 0.173 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  94
trainInputDict[data].shape :  torch.Size([2460, 16, 8, 8])
copy.shape :  torch.Size([2460, 1024])
copyLabel.shape :  torch.Size([2460])
Class 0 has 685 instances after oversampling
Class 1 has 685 instances after oversampling
Class 2 has 685 instances after oversampling
Class 3 has 685 instances after oversampling
Class 4 has 685 instances after oversampling
Class 5 has 685 instances after oversampling
Class 6 has 685 instances after oversampling
Class 7 has 685 instances after oversampling
Class 8 has 685 instances after oversampling
Class 9 has 685 instances after oversampling
0 Train Loss: 225.781 | Train Acc: 15.168
1 Train Loss: 190.791 | Train Acc: 33.533
2 Train Loss: 161.098 | Train Acc: 44.336
3 Train Loss: 139.324 | Train Acc: 52.350
4 Train Loss: 123.191 | Train Acc: 57.693
5 Train Loss: 109.480 | Train Acc: 62.336
6 Train Loss: 98.077 | Train Acc: 66.146
7 Train Loss: 90.594 | Train Acc: 68.365
8 Train Loss: 79.168 | Train Acc: 72.555
9 Train Loss: 77.335 | Train Acc: 73.431
10 Train Loss: 68.128 | Train Acc: 76.511
11 Train Loss: 63.252 | Train Acc: 78.905
12 Train Loss: 60.475 | Train Acc: 79.533
13 Train Loss: 55.817 | Train Acc: 81.431
14 Train Loss: 52.447 | Train Acc: 82.219
15 Train Loss: 51.365 | Train Acc: 82.526
16 Train Loss: 46.260 | Train Acc: 84.730
17 Train Loss: 46.723 | Train Acc: 84.044
18 Train Loss: 40.620 | Train Acc: 86.788
19 Train Loss: 37.638 | Train Acc: 87.854
20 Train Loss: 32.747 | Train Acc: 89.606
21 Train Loss: 31.521 | Train Acc: 89.985
22 Train Loss: 30.196 | Train Acc: 90.978
23 Train Loss: 29.823 | Train Acc: 90.657
24 Train Loss: 28.688 | Train Acc: 91.168
25 Train Loss: 28.146 | Train Acc: 91.825
26 Train Loss: 26.975 | Train Acc: 92.175
27 Train Loss: 26.495 | Train Acc: 92.117
28 Train Loss: 25.461 | Train Acc: 92.555
29 Train Loss: 25.175 | Train Acc: 92.759
30 Train Loss: 24.676 | Train Acc: 92.686
31 Train Loss: 23.697 | Train Acc: 93.095
32 Train Loss: 22.966 | Train Acc: 93.285
33 Train Loss: 21.990 | Train Acc: 93.854
34 Train Loss: 21.448 | Train Acc: 94.029
35 Train Loss: 21.152 | Train Acc: 94.263
36 Train Loss: 20.431 | Train Acc: 94.628
37 Train Loss: 20.641 | Train Acc: 94.161
38 Train Loss: 19.855 | Train Acc: 94.161
39 Train Loss: 19.275 | Train Acc: 94.701
40 Train Loss: 17.469 | Train Acc: 95.474
41 Train Loss: 17.274 | Train Acc: 95.577
42 Train Loss: 16.765 | Train Acc: 95.854
43 Train Loss: 16.622 | Train Acc: 95.883
44 Train Loss: 16.412 | Train Acc: 96.015
45 Train Loss: 16.184 | Train Acc: 96.161
46 Train Loss: 16.199 | Train Acc: 95.766
47 Train Loss: 15.737 | Train Acc: 96.248
48 Train Loss: 15.765 | Train Acc: 96.146
49 Train Loss: 15.493 | Train Acc: 96.438
50 Train Loss: 15.208 | Train Acc: 96.438
51 Train Loss: 15.061 | Train Acc: 96.394
52 Train Loss: 15.051 | Train Acc: 96.569
53 Train Loss: 14.622 | Train Acc: 96.672
54 Train Loss: 14.687 | Train Acc: 96.482
55 Train Loss: 14.238 | Train Acc: 96.934
56 Train Loss: 14.080 | Train Acc: 96.496
57 Train Loss: 13.866 | Train Acc: 96.818
58 Train Loss: 13.553 | Train Acc: 96.876
59 Train Loss: 13.608 | Train Acc: 97.007
60 Train Loss: 12.905 | Train Acc: 97.197
61 Train Loss: 12.834 | Train Acc: 97.255
62 Train Loss: 12.748 | Train Acc: 97.343
63 Train Loss: 12.680 | Train Acc: 97.431
64 Train Loss: 12.628 | Train Acc: 97.314
65 Train Loss: 12.571 | Train Acc: 97.387
66 Train Loss: 12.455 | Train Acc: 97.285
67 Train Loss: 12.440 | Train Acc: 97.387
68 Train Loss: 12.268 | Train Acc: 97.445
69 Train Loss: 12.257 | Train Acc: 97.577
70 Train Loss: 12.201 | Train Acc: 97.489
71 Train Loss: 12.097 | Train Acc: 97.504
72 Train Loss: 11.999 | Train Acc: 97.591
73 Train Loss: 11.966 | Train Acc: 97.577
74 Train Loss: 11.853 | Train Acc: 97.591
75 Train Loss: 11.773 | Train Acc: 97.591
76 Train Loss: 11.727 | Train Acc: 97.664
77 Train Loss: 11.608 | Train Acc: 97.766
78 Train Loss: 11.533 | Train Acc: 97.766
79 Train Loss: 11.497 | Train Acc: 97.664
80 Train Loss: 11.272 | Train Acc: 97.839
81 Train Loss: 11.211 | Train Acc: 97.869
82 Train Loss: 11.194 | Train Acc: 97.883
83 Train Loss: 11.148 | Train Acc: 97.883
84 Train Loss: 11.110 | Train Acc: 97.869
85 Train Loss: 11.109 | Train Acc: 97.854
86 Train Loss: 11.048 | Train Acc: 97.869
87 Train Loss: 11.034 | Train Acc: 97.956
88 Train Loss: 11.021 | Train Acc: 97.883
89 Train Loss: 11.007 | Train Acc: 98.000
90 Train Loss: 10.941 | Train Acc: 97.956
91 Train Loss: 10.903 | Train Acc: 97.912
92 Train Loss: 10.900 | Train Acc: 97.971
93 Train Loss: 10.847 | Train Acc: 97.956
94 Train Loss: 10.821 | Train Acc: 97.971
95 Train Loss: 10.804 | Train Acc: 98.015
96 Train Loss: 10.754 | Train Acc: 97.985
97 Train Loss: 10.746 | Train Acc: 98.015
98 Train Loss: 10.696 | Train Acc: 98.000
99 Train Loss: 10.671 | Train Acc: 98.000
CNN trained successfully...
Running nodeId:  95
trainInputDict[data].shape :  torch.Size([792, 16, 8, 8])
copy.shape :  torch.Size([792, 1024])
copyLabel.shape :  torch.Size([792])
Class 0 has 191 instances after oversampling
Class 1 has 191 instances after oversampling
Class 2 has 191 instances after oversampling
Class 3 has 191 instances after oversampling
Class 4 has 191 instances after oversampling
Class 5 has 191 instances after oversampling
Class 6 has 191 instances after oversampling
Class 7 has 191 instances after oversampling
Class 8 has 191 instances after oversampling
Class 9 has 191 instances after oversampling
0 Train Loss: 187.554 | Train Acc: 38.316
1 Train Loss: 115.401 | Train Acc: 62.684
2 Train Loss: 92.623 | Train Acc: 67.947
3 Train Loss: 74.153 | Train Acc: 74.263
4 Train Loss: 58.868 | Train Acc: 81.053
5 Train Loss: 54.537 | Train Acc: 81.895
6 Train Loss: 43.782 | Train Acc: 86.316
7 Train Loss: 36.965 | Train Acc: 87.947
8 Train Loss: 31.854 | Train Acc: 90.053
9 Train Loss: 29.678 | Train Acc: 90.947
10 Train Loss: 22.462 | Train Acc: 93.579
11 Train Loss: 21.235 | Train Acc: 94.263
12 Train Loss: 17.744 | Train Acc: 95.263
13 Train Loss: 16.138 | Train Acc: 96.263
14 Train Loss: 13.736 | Train Acc: 96.316
15 Train Loss: 11.984 | Train Acc: 97.316
16 Train Loss: 10.466 | Train Acc: 97.895
17 Train Loss: 8.732 | Train Acc: 98.368
18 Train Loss: 6.836 | Train Acc: 99.158
19 Train Loss: 6.134 | Train Acc: 99.211
20 Train Loss: 4.865 | Train Acc: 99.526
21 Train Loss: 4.358 | Train Acc: 99.737
22 Train Loss: 4.124 | Train Acc: 99.684
23 Train Loss: 3.932 | Train Acc: 99.789
24 Train Loss: 3.708 | Train Acc: 99.737
25 Train Loss: 3.523 | Train Acc: 99.789
26 Train Loss: 3.266 | Train Acc: 99.895
27 Train Loss: 3.116 | Train Acc: 99.842
28 Train Loss: 2.997 | Train Acc: 99.842
29 Train Loss: 2.850 | Train Acc: 99.895
30 Train Loss: 2.629 | Train Acc: 99.842
31 Train Loss: 2.480 | Train Acc: 99.947
32 Train Loss: 2.314 | Train Acc: 99.947
33 Train Loss: 2.220 | Train Acc: 99.947
34 Train Loss: 2.155 | Train Acc: 99.947
35 Train Loss: 2.013 | Train Acc: 99.947
36 Train Loss: 1.838 | Train Acc: 99.947
37 Train Loss: 1.735 | Train Acc: 99.947
38 Train Loss: 1.660 | Train Acc: 100.000
39 Train Loss: 1.631 | Train Acc: 99.947
40 Train Loss: 1.377 | Train Acc: 100.000
41 Train Loss: 1.328 | Train Acc: 100.000
42 Train Loss: 1.278 | Train Acc: 100.000
43 Train Loss: 1.284 | Train Acc: 100.000
44 Train Loss: 1.230 | Train Acc: 100.000
45 Train Loss: 1.192 | Train Acc: 100.000
46 Train Loss: 1.170 | Train Acc: 100.000
47 Train Loss: 1.140 | Train Acc: 100.000
48 Train Loss: 1.119 | Train Acc: 100.000
49 Train Loss: 1.082 | Train Acc: 100.000
50 Train Loss: 1.052 | Train Acc: 100.000
51 Train Loss: 1.033 | Train Acc: 100.000
52 Train Loss: 1.002 | Train Acc: 100.000
53 Train Loss: 0.963 | Train Acc: 100.000
54 Train Loss: 0.931 | Train Acc: 100.000
55 Train Loss: 0.894 | Train Acc: 100.000
56 Train Loss: 0.864 | Train Acc: 100.000
57 Train Loss: 0.844 | Train Acc: 100.000
58 Train Loss: 0.811 | Train Acc: 100.000
59 Train Loss: 0.778 | Train Acc: 100.000
60 Train Loss: 0.730 | Train Acc: 100.000
61 Train Loss: 0.715 | Train Acc: 100.000
62 Train Loss: 0.704 | Train Acc: 100.000
63 Train Loss: 0.694 | Train Acc: 100.000
64 Train Loss: 0.692 | Train Acc: 100.000
65 Train Loss: 0.673 | Train Acc: 100.000
66 Train Loss: 0.669 | Train Acc: 100.000
67 Train Loss: 0.652 | Train Acc: 100.000
68 Train Loss: 0.643 | Train Acc: 100.000
69 Train Loss: 0.630 | Train Acc: 100.000
70 Train Loss: 0.619 | Train Acc: 100.000
71 Train Loss: 0.610 | Train Acc: 100.000
72 Train Loss: 0.597 | Train Acc: 100.000
73 Train Loss: 0.590 | Train Acc: 100.000
74 Train Loss: 0.571 | Train Acc: 100.000
75 Train Loss: 0.564 | Train Acc: 100.000
76 Train Loss: 0.557 | Train Acc: 100.000
77 Train Loss: 0.542 | Train Acc: 100.000
78 Train Loss: 0.534 | Train Acc: 100.000
79 Train Loss: 0.524 | Train Acc: 100.000
80 Train Loss: 0.499 | Train Acc: 100.000
81 Train Loss: 0.494 | Train Acc: 100.000
82 Train Loss: 0.490 | Train Acc: 100.000
83 Train Loss: 0.486 | Train Acc: 100.000
84 Train Loss: 0.480 | Train Acc: 100.000
85 Train Loss: 0.481 | Train Acc: 100.000
86 Train Loss: 0.473 | Train Acc: 100.000
87 Train Loss: 0.470 | Train Acc: 100.000
88 Train Loss: 0.464 | Train Acc: 100.000
89 Train Loss: 0.457 | Train Acc: 100.000
90 Train Loss: 0.454 | Train Acc: 100.000
91 Train Loss: 0.446 | Train Acc: 100.000
92 Train Loss: 0.443 | Train Acc: 100.000
93 Train Loss: 0.441 | Train Acc: 100.000
94 Train Loss: 0.434 | Train Acc: 100.000
95 Train Loss: 0.430 | Train Acc: 100.000
96 Train Loss: 0.424 | Train Acc: 100.000
97 Train Loss: 0.421 | Train Acc: 100.000
98 Train Loss: 0.416 | Train Acc: 100.000
99 Train Loss: 0.411 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  96
trainInputDict[data].shape :  torch.Size([822, 16, 8, 8])
copy.shape :  torch.Size([822, 1024])
copyLabel.shape :  torch.Size([822])
Class 0 has 183 instances after oversampling
Class 1 has 183 instances after oversampling
Class 2 has 183 instances after oversampling
Class 3 has 183 instances after oversampling
Class 4 has 183 instances after oversampling
Class 5 has 183 instances after oversampling
Class 6 has 183 instances after oversampling
Class 7 has 183 instances after oversampling
Class 8 has 183 instances after oversampling
Class 9 has 183 instances after oversampling
0 Train Loss: 230.658 | Train Acc: 16.222
1 Train Loss: 207.711 | Train Acc: 27.333
2 Train Loss: 173.562 | Train Acc: 41.722
3 Train Loss: 149.281 | Train Acc: 48.444
4 Train Loss: 126.834 | Train Acc: 59.000
5 Train Loss: 107.566 | Train Acc: 64.556
6 Train Loss: 87.287 | Train Acc: 72.500
7 Train Loss: 72.129 | Train Acc: 77.278
8 Train Loss: 59.788 | Train Acc: 81.889
9 Train Loss: 50.595 | Train Acc: 85.667
10 Train Loss: 42.812 | Train Acc: 87.944
11 Train Loss: 35.895 | Train Acc: 89.167
12 Train Loss: 29.277 | Train Acc: 92.278
13 Train Loss: 24.516 | Train Acc: 93.722
14 Train Loss: 19.530 | Train Acc: 95.222
15 Train Loss: 15.793 | Train Acc: 96.278
16 Train Loss: 12.456 | Train Acc: 97.944
17 Train Loss: 10.493 | Train Acc: 98.167
18 Train Loss: 8.068 | Train Acc: 99.056
19 Train Loss: 6.411 | Train Acc: 99.278
20 Train Loss: 4.673 | Train Acc: 99.667
21 Train Loss: 4.117 | Train Acc: 99.889
22 Train Loss: 3.844 | Train Acc: 99.944
23 Train Loss: 3.519 | Train Acc: 99.944
24 Train Loss: 3.332 | Train Acc: 100.000
25 Train Loss: 3.164 | Train Acc: 99.944
26 Train Loss: 2.838 | Train Acc: 100.000
27 Train Loss: 2.647 | Train Acc: 100.000
28 Train Loss: 2.474 | Train Acc: 100.000
29 Train Loss: 2.306 | Train Acc: 100.000
30 Train Loss: 2.163 | Train Acc: 100.000
31 Train Loss: 2.052 | Train Acc: 100.000
32 Train Loss: 1.876 | Train Acc: 100.000
33 Train Loss: 1.778 | Train Acc: 100.000
34 Train Loss: 1.662 | Train Acc: 100.000
35 Train Loss: 1.538 | Train Acc: 100.000
36 Train Loss: 1.466 | Train Acc: 100.000
37 Train Loss: 1.338 | Train Acc: 100.000
38 Train Loss: 1.254 | Train Acc: 100.000
39 Train Loss: 1.173 | Train Acc: 100.000
40 Train Loss: 1.059 | Train Acc: 100.000
41 Train Loss: 1.018 | Train Acc: 100.000
42 Train Loss: 0.998 | Train Acc: 100.000
43 Train Loss: 0.972 | Train Acc: 100.000
44 Train Loss: 0.946 | Train Acc: 100.000
45 Train Loss: 0.913 | Train Acc: 100.000
46 Train Loss: 0.896 | Train Acc: 100.000
47 Train Loss: 0.871 | Train Acc: 100.000
48 Train Loss: 0.851 | Train Acc: 100.000
49 Train Loss: 0.822 | Train Acc: 100.000
50 Train Loss: 0.795 | Train Acc: 100.000
51 Train Loss: 0.776 | Train Acc: 100.000
52 Train Loss: 0.752 | Train Acc: 100.000
53 Train Loss: 0.725 | Train Acc: 100.000
54 Train Loss: 0.702 | Train Acc: 100.000
55 Train Loss: 0.677 | Train Acc: 100.000
56 Train Loss: 0.655 | Train Acc: 100.000
57 Train Loss: 0.637 | Train Acc: 100.000
58 Train Loss: 0.610 | Train Acc: 100.000
59 Train Loss: 0.589 | Train Acc: 100.000
60 Train Loss: 0.554 | Train Acc: 100.000
61 Train Loss: 0.546 | Train Acc: 100.000
62 Train Loss: 0.537 | Train Acc: 100.000
63 Train Loss: 0.529 | Train Acc: 100.000
64 Train Loss: 0.522 | Train Acc: 100.000
65 Train Loss: 0.513 | Train Acc: 100.000
66 Train Loss: 0.508 | Train Acc: 100.000
67 Train Loss: 0.495 | Train Acc: 100.000
68 Train Loss: 0.488 | Train Acc: 100.000
69 Train Loss: 0.478 | Train Acc: 100.000
70 Train Loss: 0.472 | Train Acc: 100.000
71 Train Loss: 0.460 | Train Acc: 100.000
72 Train Loss: 0.455 | Train Acc: 100.000
73 Train Loss: 0.446 | Train Acc: 100.000
74 Train Loss: 0.435 | Train Acc: 100.000
75 Train Loss: 0.427 | Train Acc: 100.000
76 Train Loss: 0.415 | Train Acc: 100.000
77 Train Loss: 0.408 | Train Acc: 100.000
78 Train Loss: 0.399 | Train Acc: 100.000
79 Train Loss: 0.391 | Train Acc: 100.000
80 Train Loss: 0.376 | Train Acc: 100.000
81 Train Loss: 0.371 | Train Acc: 100.000
82 Train Loss: 0.369 | Train Acc: 100.000
83 Train Loss: 0.365 | Train Acc: 100.000
84 Train Loss: 0.362 | Train Acc: 100.000
85 Train Loss: 0.358 | Train Acc: 100.000
86 Train Loss: 0.353 | Train Acc: 100.000
87 Train Loss: 0.349 | Train Acc: 100.000
88 Train Loss: 0.346 | Train Acc: 100.000
89 Train Loss: 0.342 | Train Acc: 100.000
90 Train Loss: 0.339 | Train Acc: 100.000
91 Train Loss: 0.334 | Train Acc: 100.000
92 Train Loss: 0.330 | Train Acc: 100.000
93 Train Loss: 0.326 | Train Acc: 100.000
94 Train Loss: 0.322 | Train Acc: 100.000
95 Train Loss: 0.320 | Train Acc: 100.000
96 Train Loss: 0.315 | Train Acc: 100.000
97 Train Loss: 0.310 | Train Acc: 100.000
98 Train Loss: 0.305 | Train Acc: 100.000
99 Train Loss: 0.303 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  97
trainInputDict[data].shape :  torch.Size([597, 16, 8, 8])
copy.shape :  torch.Size([597, 1024])
copyLabel.shape :  torch.Size([597])
Class 0 has 129 instances after oversampling
Class 1 has 130 instances after oversampling
Class 2 has 129 instances after oversampling
Class 3 has 130 instances after oversampling
Class 4 has 130 instances after oversampling
Class 5 has 130 instances after oversampling
Class 6 has 129 instances after oversampling
Class 7 has 130 instances after oversampling
Class 8 has 129 instances after oversampling
Class 9 has 130 instances after oversampling
0 Train Loss: 222.438 | Train Acc: 17.207
1 Train Loss: 170.637 | Train Acc: 42.824
2 Train Loss: 127.108 | Train Acc: 59.645
3 Train Loss: 89.782 | Train Acc: 71.605
4 Train Loss: 66.240 | Train Acc: 78.627
5 Train Loss: 51.937 | Train Acc: 84.414
6 Train Loss: 36.214 | Train Acc: 90.741
7 Train Loss: 27.714 | Train Acc: 92.130
8 Train Loss: 19.346 | Train Acc: 95.448
9 Train Loss: 14.339 | Train Acc: 97.377
10 Train Loss: 10.881 | Train Acc: 98.534
11 Train Loss: 8.712 | Train Acc: 98.997
12 Train Loss: 6.457 | Train Acc: 99.306
13 Train Loss: 4.846 | Train Acc: 99.846
14 Train Loss: 4.067 | Train Acc: 99.691
15 Train Loss: 3.135 | Train Acc: 99.923
16 Train Loss: 2.647 | Train Acc: 100.000
17 Train Loss: 2.136 | Train Acc: 100.000
18 Train Loss: 1.649 | Train Acc: 100.000
19 Train Loss: 1.409 | Train Acc: 100.000
20 Train Loss: 1.150 | Train Acc: 100.000
21 Train Loss: 1.056 | Train Acc: 100.000
22 Train Loss: 1.009 | Train Acc: 100.000
23 Train Loss: 0.955 | Train Acc: 100.000
24 Train Loss: 0.907 | Train Acc: 100.000
25 Train Loss: 0.861 | Train Acc: 100.000
26 Train Loss: 0.818 | Train Acc: 100.000
27 Train Loss: 0.780 | Train Acc: 100.000
28 Train Loss: 0.729 | Train Acc: 100.000
29 Train Loss: 0.695 | Train Acc: 100.000
30 Train Loss: 0.651 | Train Acc: 100.000
31 Train Loss: 0.613 | Train Acc: 100.000
32 Train Loss: 0.586 | Train Acc: 100.000
33 Train Loss: 0.552 | Train Acc: 100.000
34 Train Loss: 0.522 | Train Acc: 100.000
35 Train Loss: 0.495 | Train Acc: 100.000
36 Train Loss: 0.464 | Train Acc: 100.000
37 Train Loss: 0.438 | Train Acc: 100.000
38 Train Loss: 0.416 | Train Acc: 100.000
39 Train Loss: 0.394 | Train Acc: 100.000
40 Train Loss: 0.366 | Train Acc: 100.000
41 Train Loss: 0.349 | Train Acc: 100.000
42 Train Loss: 0.344 | Train Acc: 100.000
43 Train Loss: 0.336 | Train Acc: 100.000
44 Train Loss: 0.328 | Train Acc: 100.000
45 Train Loss: 0.319 | Train Acc: 100.000
46 Train Loss: 0.310 | Train Acc: 100.000
47 Train Loss: 0.304 | Train Acc: 100.000
48 Train Loss: 0.296 | Train Acc: 100.000
49 Train Loss: 0.286 | Train Acc: 100.000
50 Train Loss: 0.281 | Train Acc: 100.000
51 Train Loss: 0.273 | Train Acc: 100.000
52 Train Loss: 0.265 | Train Acc: 100.000
53 Train Loss: 0.256 | Train Acc: 100.000
54 Train Loss: 0.247 | Train Acc: 100.000
55 Train Loss: 0.241 | Train Acc: 100.000
56 Train Loss: 0.232 | Train Acc: 100.000
57 Train Loss: 0.224 | Train Acc: 100.000
58 Train Loss: 0.219 | Train Acc: 100.000
59 Train Loss: 0.208 | Train Acc: 100.000
60 Train Loss: 0.199 | Train Acc: 100.000
61 Train Loss: 0.195 | Train Acc: 100.000
62 Train Loss: 0.193 | Train Acc: 100.000
63 Train Loss: 0.190 | Train Acc: 100.000
64 Train Loss: 0.187 | Train Acc: 100.000
65 Train Loss: 0.184 | Train Acc: 100.000
66 Train Loss: 0.181 | Train Acc: 100.000
67 Train Loss: 0.179 | Train Acc: 100.000
68 Train Loss: 0.174 | Train Acc: 100.000
69 Train Loss: 0.172 | Train Acc: 100.000
70 Train Loss: 0.169 | Train Acc: 100.000
71 Train Loss: 0.165 | Train Acc: 100.000
72 Train Loss: 0.162 | Train Acc: 100.000
73 Train Loss: 0.159 | Train Acc: 100.000
74 Train Loss: 0.155 | Train Acc: 100.000
75 Train Loss: 0.152 | Train Acc: 100.000
76 Train Loss: 0.150 | Train Acc: 100.000
77 Train Loss: 0.146 | Train Acc: 100.000
78 Train Loss: 0.143 | Train Acc: 100.000
79 Train Loss: 0.139 | Train Acc: 100.000
80 Train Loss: 0.133 | Train Acc: 100.000
81 Train Loss: 0.132 | Train Acc: 100.000
82 Train Loss: 0.130 | Train Acc: 100.000
83 Train Loss: 0.129 | Train Acc: 100.000
84 Train Loss: 0.128 | Train Acc: 100.000
85 Train Loss: 0.126 | Train Acc: 100.000
86 Train Loss: 0.125 | Train Acc: 100.000
87 Train Loss: 0.123 | Train Acc: 100.000
88 Train Loss: 0.122 | Train Acc: 100.000
89 Train Loss: 0.120 | Train Acc: 100.000
90 Train Loss: 0.119 | Train Acc: 100.000
91 Train Loss: 0.117 | Train Acc: 100.000
92 Train Loss: 0.115 | Train Acc: 100.000
93 Train Loss: 0.114 | Train Acc: 100.000
94 Train Loss: 0.112 | Train Acc: 100.000
95 Train Loss: 0.110 | Train Acc: 100.000
96 Train Loss: 0.109 | Train Acc: 100.000
97 Train Loss: 0.107 | Train Acc: 100.000
98 Train Loss: 0.106 | Train Acc: 100.000
99 Train Loss: 0.104 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  98
trainInputDict[data].shape :  torch.Size([502, 16, 8, 8])
copy.shape :  torch.Size([502, 1024])
copyLabel.shape :  torch.Size([502])
Class 0 has 150 instances after oversampling
Class 1 has 150 instances after oversampling
Class 2 has 150 instances after oversampling
Class 3 has 150 instances after oversampling
Class 4 has 150 instances after oversampling
Class 5 has 151 instances after oversampling
Class 6 has 150 instances after oversampling
Class 7 has 151 instances after oversampling
Class 8 has 150 instances after oversampling
Class 9 has 151 instances after oversampling
0 Train Loss: 213.429 | Train Acc: 26.667
1 Train Loss: 146.667 | Train Acc: 50.667
2 Train Loss: 107.667 | Train Acc: 65.733
3 Train Loss: 76.129 | Train Acc: 78.467
4 Train Loss: 58.553 | Train Acc: 82.667
5 Train Loss: 41.142 | Train Acc: 88.467
6 Train Loss: 35.676 | Train Acc: 89.467
7 Train Loss: 25.251 | Train Acc: 92.867
8 Train Loss: 22.516 | Train Acc: 93.867
9 Train Loss: 17.414 | Train Acc: 95.200
10 Train Loss: 15.534 | Train Acc: 95.667
11 Train Loss: 10.143 | Train Acc: 97.800
12 Train Loss: 9.836 | Train Acc: 97.467
13 Train Loss: 8.250 | Train Acc: 98.200
14 Train Loss: 6.455 | Train Acc: 98.933
15 Train Loss: 4.950 | Train Acc: 99.333
16 Train Loss: 4.910 | Train Acc: 99.400
17 Train Loss: 3.232 | Train Acc: 99.867
18 Train Loss: 2.670 | Train Acc: 99.933
19 Train Loss: 2.484 | Train Acc: 99.800
20 Train Loss: 1.708 | Train Acc: 99.933
21 Train Loss: 1.425 | Train Acc: 100.000
22 Train Loss: 1.354 | Train Acc: 100.000
23 Train Loss: 1.265 | Train Acc: 100.000
24 Train Loss: 1.210 | Train Acc: 100.000
25 Train Loss: 1.145 | Train Acc: 100.000
26 Train Loss: 1.095 | Train Acc: 100.000
27 Train Loss: 1.017 | Train Acc: 100.000
28 Train Loss: 0.951 | Train Acc: 100.000
29 Train Loss: 0.901 | Train Acc: 100.000
30 Train Loss: 0.854 | Train Acc: 100.000
31 Train Loss: 0.814 | Train Acc: 100.000
32 Train Loss: 0.770 | Train Acc: 100.000
33 Train Loss: 0.730 | Train Acc: 100.000
34 Train Loss: 0.698 | Train Acc: 100.000
35 Train Loss: 0.646 | Train Acc: 100.000
36 Train Loss: 0.620 | Train Acc: 100.000
37 Train Loss: 0.577 | Train Acc: 100.000
38 Train Loss: 0.553 | Train Acc: 100.000
39 Train Loss: 0.518 | Train Acc: 100.000
40 Train Loss: 0.466 | Train Acc: 100.000
41 Train Loss: 0.450 | Train Acc: 100.000
42 Train Loss: 0.442 | Train Acc: 100.000
43 Train Loss: 0.429 | Train Acc: 100.000
44 Train Loss: 0.424 | Train Acc: 100.000
45 Train Loss: 0.411 | Train Acc: 100.000
46 Train Loss: 0.398 | Train Acc: 100.000
47 Train Loss: 0.391 | Train Acc: 100.000
48 Train Loss: 0.379 | Train Acc: 100.000
49 Train Loss: 0.371 | Train Acc: 100.000
50 Train Loss: 0.359 | Train Acc: 100.000
51 Train Loss: 0.350 | Train Acc: 100.000
52 Train Loss: 0.339 | Train Acc: 100.000
53 Train Loss: 0.331 | Train Acc: 100.000
54 Train Loss: 0.316 | Train Acc: 100.000
55 Train Loss: 0.308 | Train Acc: 100.000
56 Train Loss: 0.300 | Train Acc: 100.000
57 Train Loss: 0.290 | Train Acc: 100.000
58 Train Loss: 0.280 | Train Acc: 100.000
59 Train Loss: 0.269 | Train Acc: 100.000
60 Train Loss: 0.253 | Train Acc: 100.000
61 Train Loss: 0.250 | Train Acc: 100.000
62 Train Loss: 0.246 | Train Acc: 100.000
63 Train Loss: 0.243 | Train Acc: 100.000
64 Train Loss: 0.238 | Train Acc: 100.000
65 Train Loss: 0.235 | Train Acc: 100.000
66 Train Loss: 0.234 | Train Acc: 100.000
67 Train Loss: 0.228 | Train Acc: 100.000
68 Train Loss: 0.224 | Train Acc: 100.000
69 Train Loss: 0.220 | Train Acc: 100.000
70 Train Loss: 0.217 | Train Acc: 100.000
71 Train Loss: 0.211 | Train Acc: 100.000
72 Train Loss: 0.207 | Train Acc: 100.000
73 Train Loss: 0.203 | Train Acc: 100.000
74 Train Loss: 0.199 | Train Acc: 100.000
75 Train Loss: 0.195 | Train Acc: 100.000
76 Train Loss: 0.190 | Train Acc: 100.000
77 Train Loss: 0.187 | Train Acc: 100.000
78 Train Loss: 0.183 | Train Acc: 100.000
79 Train Loss: 0.178 | Train Acc: 100.000
80 Train Loss: 0.170 | Train Acc: 100.000
81 Train Loss: 0.169 | Train Acc: 100.000
82 Train Loss: 0.167 | Train Acc: 100.000
83 Train Loss: 0.165 | Train Acc: 100.000
84 Train Loss: 0.164 | Train Acc: 100.000
85 Train Loss: 0.162 | Train Acc: 100.000
86 Train Loss: 0.160 | Train Acc: 100.000
87 Train Loss: 0.158 | Train Acc: 100.000
88 Train Loss: 0.156 | Train Acc: 100.000
89 Train Loss: 0.154 | Train Acc: 100.000
90 Train Loss: 0.153 | Train Acc: 100.000
91 Train Loss: 0.151 | Train Acc: 100.000
92 Train Loss: 0.150 | Train Acc: 100.000
93 Train Loss: 0.146 | Train Acc: 100.000
94 Train Loss: 0.145 | Train Acc: 100.000
95 Train Loss: 0.143 | Train Acc: 100.000
96 Train Loss: 0.140 | Train Acc: 100.000
97 Train Loss: 0.139 | Train Acc: 100.000
98 Train Loss: 0.137 | Train Acc: 100.000
99 Train Loss: 0.134 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  99
trainInputDict[data].shape :  torch.Size([472, 16, 8, 8])
copy.shape :  torch.Size([472, 1024])
copyLabel.shape :  torch.Size([472])
Class 0 has 182 instances after oversampling
Class 1 has 182 instances after oversampling
Class 2 has 182 instances after oversampling
Class 3 has 182 instances after oversampling
Class 4 has 182 instances after oversampling
Class 5 has 182 instances after oversampling
Class 6 has 182 instances after oversampling
Class 7 has 182 instances after oversampling
Class 8 has 182 instances after oversampling
Class 9 has 182 instances after oversampling
0 Train Loss: 216.924 | Train Acc: 28.000
1 Train Loss: 138.376 | Train Acc: 54.167
2 Train Loss: 87.128 | Train Acc: 75.778
3 Train Loss: 54.899 | Train Acc: 85.778
4 Train Loss: 37.905 | Train Acc: 90.056
5 Train Loss: 28.811 | Train Acc: 92.111
6 Train Loss: 19.135 | Train Acc: 95.278
7 Train Loss: 11.952 | Train Acc: 97.111
8 Train Loss: 10.323 | Train Acc: 97.944
9 Train Loss: 6.709 | Train Acc: 99.000
10 Train Loss: 5.056 | Train Acc: 99.333
11 Train Loss: 3.886 | Train Acc: 99.722
12 Train Loss: 2.864 | Train Acc: 99.889
13 Train Loss: 2.107 | Train Acc: 99.889
14 Train Loss: 1.684 | Train Acc: 99.944
15 Train Loss: 1.415 | Train Acc: 100.000
16 Train Loss: 1.151 | Train Acc: 100.000
17 Train Loss: 0.959 | Train Acc: 100.000
18 Train Loss: 0.824 | Train Acc: 100.000
19 Train Loss: 0.717 | Train Acc: 100.000
20 Train Loss: 0.591 | Train Acc: 100.000
21 Train Loss: 0.547 | Train Acc: 100.000
22 Train Loss: 0.523 | Train Acc: 100.000
23 Train Loss: 0.499 | Train Acc: 100.000
24 Train Loss: 0.473 | Train Acc: 100.000
25 Train Loss: 0.447 | Train Acc: 100.000
26 Train Loss: 0.435 | Train Acc: 100.000
27 Train Loss: 0.413 | Train Acc: 100.000
28 Train Loss: 0.385 | Train Acc: 100.000
29 Train Loss: 0.369 | Train Acc: 100.000
30 Train Loss: 0.348 | Train Acc: 100.000
31 Train Loss: 0.330 | Train Acc: 100.000
32 Train Loss: 0.313 | Train Acc: 100.000
33 Train Loss: 0.295 | Train Acc: 100.000
34 Train Loss: 0.281 | Train Acc: 100.000
35 Train Loss: 0.269 | Train Acc: 100.000
36 Train Loss: 0.250 | Train Acc: 100.000
37 Train Loss: 0.238 | Train Acc: 100.000
38 Train Loss: 0.225 | Train Acc: 100.000
39 Train Loss: 0.213 | Train Acc: 100.000
40 Train Loss: 0.199 | Train Acc: 100.000
41 Train Loss: 0.194 | Train Acc: 100.000
42 Train Loss: 0.189 | Train Acc: 100.000
43 Train Loss: 0.185 | Train Acc: 100.000
44 Train Loss: 0.180 | Train Acc: 100.000
45 Train Loss: 0.176 | Train Acc: 100.000
46 Train Loss: 0.171 | Train Acc: 100.000
47 Train Loss: 0.169 | Train Acc: 100.000
48 Train Loss: 0.162 | Train Acc: 100.000
49 Train Loss: 0.159 | Train Acc: 100.000
50 Train Loss: 0.154 | Train Acc: 100.000
51 Train Loss: 0.150 | Train Acc: 100.000
52 Train Loss: 0.145 | Train Acc: 100.000
53 Train Loss: 0.141 | Train Acc: 100.000
54 Train Loss: 0.136 | Train Acc: 100.000
55 Train Loss: 0.132 | Train Acc: 100.000
56 Train Loss: 0.129 | Train Acc: 100.000
57 Train Loss: 0.124 | Train Acc: 100.000
58 Train Loss: 0.120 | Train Acc: 100.000
59 Train Loss: 0.115 | Train Acc: 100.000
60 Train Loss: 0.110 | Train Acc: 100.000
61 Train Loss: 0.108 | Train Acc: 100.000
62 Train Loss: 0.107 | Train Acc: 100.000
63 Train Loss: 0.106 | Train Acc: 100.000
64 Train Loss: 0.104 | Train Acc: 100.000
65 Train Loss: 0.102 | Train Acc: 100.000
66 Train Loss: 0.100 | Train Acc: 100.000
67 Train Loss: 0.099 | Train Acc: 100.000
68 Train Loss: 0.097 | Train Acc: 100.000
69 Train Loss: 0.095 | Train Acc: 100.000
70 Train Loss: 0.093 | Train Acc: 100.000
71 Train Loss: 0.092 | Train Acc: 100.000
72 Train Loss: 0.090 | Train Acc: 100.000
73 Train Loss: 0.088 | Train Acc: 100.000
74 Train Loss: 0.086 | Train Acc: 100.000
75 Train Loss: 0.084 | Train Acc: 100.000
76 Train Loss: 0.082 | Train Acc: 100.000
77 Train Loss: 0.080 | Train Acc: 100.000
78 Train Loss: 0.078 | Train Acc: 100.000
79 Train Loss: 0.076 | Train Acc: 100.000
80 Train Loss: 0.074 | Train Acc: 100.000
81 Train Loss: 0.073 | Train Acc: 100.000
82 Train Loss: 0.072 | Train Acc: 100.000
83 Train Loss: 0.071 | Train Acc: 100.000
84 Train Loss: 0.071 | Train Acc: 100.000
85 Train Loss: 0.070 | Train Acc: 100.000
86 Train Loss: 0.069 | Train Acc: 100.000
87 Train Loss: 0.068 | Train Acc: 100.000
88 Train Loss: 0.067 | Train Acc: 100.000
89 Train Loss: 0.066 | Train Acc: 100.000
90 Train Loss: 0.066 | Train Acc: 100.000
91 Train Loss: 0.065 | Train Acc: 100.000
92 Train Loss: 0.063 | Train Acc: 100.000
93 Train Loss: 0.063 | Train Acc: 100.000
94 Train Loss: 0.062 | Train Acc: 100.000
95 Train Loss: 0.061 | Train Acc: 100.000
96 Train Loss: 0.060 | Train Acc: 100.000
97 Train Loss: 0.059 | Train Acc: 100.000
98 Train Loss: 0.058 | Train Acc: 100.000
99 Train Loss: 0.057 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  100
trainInputDict[data].shape :  torch.Size([528, 16, 8, 8])
copy.shape :  torch.Size([528, 1024])
copyLabel.shape :  torch.Size([528])
Class 0 has 284 instances after oversampling
Class 1 has 284 instances after oversampling
Class 2 has 284 instances after oversampling
Class 3 has 1 instances after oversampling
Class 4 has 284 instances after oversampling
Class 5 has 284 instances after oversampling
Class 6 has 284 instances after oversampling
Class 7 has 284 instances after oversampling
Class 8 has 284 instances after oversampling
0 Train Loss: 160.205 | Train Acc: 47.318
1 Train Loss: 64.855 | Train Acc: 79.000
2 Train Loss: 32.466 | Train Acc: 89.591
3 Train Loss: 22.156 | Train Acc: 93.045
4 Train Loss: 17.280 | Train Acc: 94.318
5 Train Loss: 13.670 | Train Acc: 95.136
6 Train Loss: 10.314 | Train Acc: 96.682
7 Train Loss: 9.834 | Train Acc: 96.409
8 Train Loss: 6.981 | Train Acc: 97.955
9 Train Loss: 5.993 | Train Acc: 98.364
10 Train Loss: 5.107 | Train Acc: 98.318
11 Train Loss: 3.649 | Train Acc: 99.136
12 Train Loss: 2.923 | Train Acc: 99.409
13 Train Loss: 3.064 | Train Acc: 99.182
14 Train Loss: 2.496 | Train Acc: 99.455
15 Train Loss: 1.819 | Train Acc: 99.682
16 Train Loss: 1.481 | Train Acc: 99.955
17 Train Loss: 1.544 | Train Acc: 99.773
18 Train Loss: 1.153 | Train Acc: 99.864
19 Train Loss: 0.897 | Train Acc: 100.000
20 Train Loss: 0.678 | Train Acc: 100.000
21 Train Loss: 0.632 | Train Acc: 100.000
22 Train Loss: 0.595 | Train Acc: 100.000
23 Train Loss: 0.547 | Train Acc: 100.000
24 Train Loss: 0.504 | Train Acc: 100.000
25 Train Loss: 0.498 | Train Acc: 100.000
26 Train Loss: 0.464 | Train Acc: 100.000
27 Train Loss: 0.428 | Train Acc: 100.000
28 Train Loss: 0.418 | Train Acc: 100.000
29 Train Loss: 0.395 | Train Acc: 100.000
30 Train Loss: 0.384 | Train Acc: 100.000
31 Train Loss: 0.349 | Train Acc: 100.000
32 Train Loss: 0.326 | Train Acc: 100.000
33 Train Loss: 0.312 | Train Acc: 100.000
34 Train Loss: 0.292 | Train Acc: 100.000
35 Train Loss: 0.282 | Train Acc: 100.000
36 Train Loss: 0.256 | Train Acc: 100.000
37 Train Loss: 0.240 | Train Acc: 100.000
38 Train Loss: 0.234 | Train Acc: 100.000
39 Train Loss: 0.214 | Train Acc: 100.000
40 Train Loss: 0.199 | Train Acc: 100.000
41 Train Loss: 0.194 | Train Acc: 100.000
42 Train Loss: 0.189 | Train Acc: 100.000
43 Train Loss: 0.187 | Train Acc: 100.000
44 Train Loss: 0.179 | Train Acc: 100.000
45 Train Loss: 0.174 | Train Acc: 100.000
46 Train Loss: 0.174 | Train Acc: 100.000
47 Train Loss: 0.167 | Train Acc: 100.000
48 Train Loss: 0.161 | Train Acc: 100.000
49 Train Loss: 0.154 | Train Acc: 100.000
50 Train Loss: 0.155 | Train Acc: 100.000
51 Train Loss: 0.150 | Train Acc: 100.000
52 Train Loss: 0.144 | Train Acc: 100.000
53 Train Loss: 0.145 | Train Acc: 100.000
54 Train Loss: 0.136 | Train Acc: 100.000
55 Train Loss: 0.133 | Train Acc: 100.000
56 Train Loss: 0.129 | Train Acc: 100.000
57 Train Loss: 0.122 | Train Acc: 100.000
58 Train Loss: 0.121 | Train Acc: 100.000
59 Train Loss: 0.114 | Train Acc: 100.000
60 Train Loss: 0.110 | Train Acc: 100.000
61 Train Loss: 0.106 | Train Acc: 100.000
62 Train Loss: 0.106 | Train Acc: 100.000
63 Train Loss: 0.103 | Train Acc: 100.000
64 Train Loss: 0.102 | Train Acc: 100.000
65 Train Loss: 0.100 | Train Acc: 100.000
66 Train Loss: 0.099 | Train Acc: 100.000
67 Train Loss: 0.097 | Train Acc: 100.000
68 Train Loss: 0.095 | Train Acc: 100.000
69 Train Loss: 0.093 | Train Acc: 100.000
70 Train Loss: 0.092 | Train Acc: 100.000
71 Train Loss: 0.090 | Train Acc: 100.000
72 Train Loss: 0.088 | Train Acc: 100.000
73 Train Loss: 0.087 | Train Acc: 100.000
74 Train Loss: 0.085 | Train Acc: 100.000
75 Train Loss: 0.083 | Train Acc: 100.000
76 Train Loss: 0.081 | Train Acc: 100.000
77 Train Loss: 0.079 | Train Acc: 100.000
78 Train Loss: 0.077 | Train Acc: 100.000
79 Train Loss: 0.074 | Train Acc: 100.000
80 Train Loss: 0.073 | Train Acc: 100.000
81 Train Loss: 0.071 | Train Acc: 100.000
82 Train Loss: 0.071 | Train Acc: 100.000
83 Train Loss: 0.071 | Train Acc: 100.000
84 Train Loss: 0.070 | Train Acc: 100.000
85 Train Loss: 0.069 | Train Acc: 100.000
86 Train Loss: 0.068 | Train Acc: 100.000
87 Train Loss: 0.067 | Train Acc: 100.000
88 Train Loss: 0.066 | Train Acc: 100.000
89 Train Loss: 0.066 | Train Acc: 100.000
90 Train Loss: 0.065 | Train Acc: 100.000
91 Train Loss: 0.063 | Train Acc: 100.000
92 Train Loss: 0.063 | Train Acc: 100.000
93 Train Loss: 0.063 | Train Acc: 100.000
94 Train Loss: 0.061 | Train Acc: 100.000
95 Train Loss: 0.060 | Train Acc: 100.000
96 Train Loss: 0.059 | Train Acc: 100.000
97 Train Loss: 0.058 | Train Acc: 100.000
98 Train Loss: 0.058 | Train Acc: 100.000
99 Train Loss: 0.057 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  101
trainInputDict[data].shape :  torch.Size([162, 16, 8, 8])
copy.shape :  torch.Size([162, 1024])
copyLabel.shape :  torch.Size([162])
Class 0 has 92 instances after oversampling
Class 1 has 92 instances after oversampling
Class 2 has 1 instances after oversampling
Class 3 has 92 instances after oversampling
Class 4 has 92 instances after oversampling
Class 5 has 92 instances after oversampling
Class 6 has 92 instances after oversampling
Class 7 has 92 instances after oversampling
0 Train Loss: 160.088 | Train Acc: 43.000
1 Train Loss: 45.012 | Train Acc: 88.667
2 Train Loss: 25.195 | Train Acc: 94.000
3 Train Loss: 14.098 | Train Acc: 96.500
4 Train Loss: 7.175 | Train Acc: 98.667
5 Train Loss: 4.862 | Train Acc: 99.000
6 Train Loss: 3.663 | Train Acc: 99.167
7 Train Loss: 2.821 | Train Acc: 99.667
8 Train Loss: 2.599 | Train Acc: 99.333
9 Train Loss: 3.980 | Train Acc: 98.833
10 Train Loss: 1.253 | Train Acc: 99.667
11 Train Loss: 0.927 | Train Acc: 99.833
12 Train Loss: 0.580 | Train Acc: 100.000
13 Train Loss: 0.476 | Train Acc: 100.000
14 Train Loss: 0.339 | Train Acc: 100.000
15 Train Loss: 0.263 | Train Acc: 100.000
16 Train Loss: 0.229 | Train Acc: 100.000
17 Train Loss: 0.198 | Train Acc: 100.000
18 Train Loss: 0.179 | Train Acc: 100.000
19 Train Loss: 0.152 | Train Acc: 100.000
20 Train Loss: 0.147 | Train Acc: 100.000
21 Train Loss: 0.134 | Train Acc: 100.000
22 Train Loss: 0.127 | Train Acc: 100.000
23 Train Loss: 0.121 | Train Acc: 100.000
24 Train Loss: 0.116 | Train Acc: 100.000
25 Train Loss: 0.111 | Train Acc: 100.000
26 Train Loss: 0.106 | Train Acc: 100.000
27 Train Loss: 0.102 | Train Acc: 100.000
28 Train Loss: 0.097 | Train Acc: 100.000
29 Train Loss: 0.092 | Train Acc: 100.000
30 Train Loss: 0.086 | Train Acc: 100.000
31 Train Loss: 0.083 | Train Acc: 100.000
32 Train Loss: 0.079 | Train Acc: 100.000
33 Train Loss: 0.076 | Train Acc: 100.000
34 Train Loss: 0.072 | Train Acc: 100.000
35 Train Loss: 0.068 | Train Acc: 100.000
36 Train Loss: 0.065 | Train Acc: 100.000
37 Train Loss: 0.061 | Train Acc: 100.000
38 Train Loss: 0.058 | Train Acc: 100.000
39 Train Loss: 0.055 | Train Acc: 100.000
40 Train Loss: 0.052 | Train Acc: 100.000
41 Train Loss: 0.050 | Train Acc: 100.000
42 Train Loss: 0.049 | Train Acc: 100.000
43 Train Loss: 0.048 | Train Acc: 100.000
44 Train Loss: 0.047 | Train Acc: 100.000
45 Train Loss: 0.046 | Train Acc: 100.000
46 Train Loss: 0.045 | Train Acc: 100.000
47 Train Loss: 0.043 | Train Acc: 100.000
48 Train Loss: 0.042 | Train Acc: 100.000
49 Train Loss: 0.041 | Train Acc: 100.000
50 Train Loss: 0.040 | Train Acc: 100.000
51 Train Loss: 0.039 | Train Acc: 100.000
52 Train Loss: 0.038 | Train Acc: 100.000
53 Train Loss: 0.037 | Train Acc: 100.000
54 Train Loss: 0.036 | Train Acc: 100.000
55 Train Loss: 0.035 | Train Acc: 100.000
56 Train Loss: 0.033 | Train Acc: 100.000
57 Train Loss: 0.032 | Train Acc: 100.000
58 Train Loss: 0.032 | Train Acc: 100.000
59 Train Loss: 0.030 | Train Acc: 100.000
60 Train Loss: 0.029 | Train Acc: 100.000
61 Train Loss: 0.029 | Train Acc: 100.000
62 Train Loss: 0.028 | Train Acc: 100.000
63 Train Loss: 0.028 | Train Acc: 100.000
64 Train Loss: 0.027 | Train Acc: 100.000
65 Train Loss: 0.027 | Train Acc: 100.000
66 Train Loss: 0.026 | Train Acc: 100.000
67 Train Loss: 0.026 | Train Acc: 100.000
68 Train Loss: 0.026 | Train Acc: 100.000
69 Train Loss: 0.025 | Train Acc: 100.000
70 Train Loss: 0.025 | Train Acc: 100.000
71 Train Loss: 0.024 | Train Acc: 100.000
72 Train Loss: 0.024 | Train Acc: 100.000
73 Train Loss: 0.023 | Train Acc: 100.000
74 Train Loss: 0.023 | Train Acc: 100.000
75 Train Loss: 0.022 | Train Acc: 100.000
76 Train Loss: 0.022 | Train Acc: 100.000
77 Train Loss: 0.021 | Train Acc: 100.000
78 Train Loss: 0.021 | Train Acc: 100.000
79 Train Loss: 0.020 | Train Acc: 100.000
80 Train Loss: 0.019 | Train Acc: 100.000
81 Train Loss: 0.019 | Train Acc: 100.000
82 Train Loss: 0.019 | Train Acc: 100.000
83 Train Loss: 0.019 | Train Acc: 100.000
84 Train Loss: 0.019 | Train Acc: 100.000
85 Train Loss: 0.018 | Train Acc: 100.000
86 Train Loss: 0.018 | Train Acc: 100.000
87 Train Loss: 0.018 | Train Acc: 100.000
88 Train Loss: 0.018 | Train Acc: 100.000
89 Train Loss: 0.017 | Train Acc: 100.000
90 Train Loss: 0.017 | Train Acc: 100.000
91 Train Loss: 0.017 | Train Acc: 100.000
92 Train Loss: 0.017 | Train Acc: 100.000
93 Train Loss: 0.016 | Train Acc: 100.000
94 Train Loss: 0.016 | Train Acc: 100.000
95 Train Loss: 0.016 | Train Acc: 100.000
96 Train Loss: 0.016 | Train Acc: 100.000
97 Train Loss: 0.015 | Train Acc: 100.000
98 Train Loss: 0.015 | Train Acc: 100.000
99 Train Loss: 0.015 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  102
trainInputDict[data].shape :  torch.Size([375, 16, 8, 8])
copy.shape :  torch.Size([375, 1024])
copyLabel.shape :  torch.Size([375])
Class 0 has 224 instances after oversampling
Class 1 has 224 instances after oversampling
Class 2 has 1 instances after oversampling
Class 3 has 224 instances after oversampling
Class 4 has 224 instances after oversampling
Class 5 has 224 instances after oversampling
Class 6 has 224 instances after oversampling
Class 7 has 224 instances after oversampling
Class 8 has 224 instances after oversampling
Class 9 has 224 instances after oversampling
0 Train Loss: 197.521 | Train Acc: 27.750
1 Train Loss: 83.025 | Train Acc: 76.300
2 Train Loss: 37.079 | Train Acc: 91.100
3 Train Loss: 21.579 | Train Acc: 94.100
4 Train Loss: 14.326 | Train Acc: 96.250
5 Train Loss: 10.309 | Train Acc: 97.050
6 Train Loss: 7.952 | Train Acc: 98.000
7 Train Loss: 5.777 | Train Acc: 98.350
8 Train Loss: 6.382 | Train Acc: 98.150
9 Train Loss: 3.996 | Train Acc: 98.800
10 Train Loss: 3.241 | Train Acc: 99.450
11 Train Loss: 2.488 | Train Acc: 99.500
12 Train Loss: 2.571 | Train Acc: 99.350
13 Train Loss: 1.870 | Train Acc: 99.750
14 Train Loss: 1.248 | Train Acc: 99.900
15 Train Loss: 1.561 | Train Acc: 99.750
16 Train Loss: 0.899 | Train Acc: 99.950
17 Train Loss: 0.652 | Train Acc: 100.000
18 Train Loss: 0.573 | Train Acc: 100.000
19 Train Loss: 0.507 | Train Acc: 100.000
20 Train Loss: 0.401 | Train Acc: 100.000
21 Train Loss: 0.367 | Train Acc: 100.000
22 Train Loss: 0.347 | Train Acc: 100.000
23 Train Loss: 0.329 | Train Acc: 100.000
24 Train Loss: 0.314 | Train Acc: 100.000
25 Train Loss: 0.300 | Train Acc: 100.000
26 Train Loss: 0.290 | Train Acc: 100.000
27 Train Loss: 0.272 | Train Acc: 100.000
28 Train Loss: 0.257 | Train Acc: 100.000
29 Train Loss: 0.245 | Train Acc: 100.000
30 Train Loss: 0.230 | Train Acc: 100.000
31 Train Loss: 0.220 | Train Acc: 100.000
32 Train Loss: 0.207 | Train Acc: 100.000
33 Train Loss: 0.195 | Train Acc: 100.000
34 Train Loss: 0.187 | Train Acc: 100.000
35 Train Loss: 0.176 | Train Acc: 100.000
36 Train Loss: 0.168 | Train Acc: 100.000
37 Train Loss: 0.159 | Train Acc: 100.000
38 Train Loss: 0.151 | Train Acc: 100.000
39 Train Loss: 0.142 | Train Acc: 100.000
40 Train Loss: 0.128 | Train Acc: 100.000
41 Train Loss: 0.127 | Train Acc: 100.000
42 Train Loss: 0.123 | Train Acc: 100.000
43 Train Loss: 0.120 | Train Acc: 100.000
44 Train Loss: 0.117 | Train Acc: 100.000
45 Train Loss: 0.112 | Train Acc: 100.000
46 Train Loss: 0.114 | Train Acc: 100.000
47 Train Loss: 0.110 | Train Acc: 100.000
48 Train Loss: 0.106 | Train Acc: 100.000
49 Train Loss: 0.104 | Train Acc: 100.000
50 Train Loss: 0.101 | Train Acc: 100.000
51 Train Loss: 0.097 | Train Acc: 100.000
52 Train Loss: 0.095 | Train Acc: 100.000
53 Train Loss: 0.092 | Train Acc: 100.000
54 Train Loss: 0.090 | Train Acc: 100.000
55 Train Loss: 0.086 | Train Acc: 100.000
56 Train Loss: 0.084 | Train Acc: 100.000
57 Train Loss: 0.081 | Train Acc: 100.000
58 Train Loss: 0.078 | Train Acc: 100.000
59 Train Loss: 0.075 | Train Acc: 100.000
60 Train Loss: 0.072 | Train Acc: 100.000
61 Train Loss: 0.071 | Train Acc: 100.000
62 Train Loss: 0.070 | Train Acc: 100.000
63 Train Loss: 0.070 | Train Acc: 100.000
64 Train Loss: 0.067 | Train Acc: 100.000
65 Train Loss: 0.066 | Train Acc: 100.000
66 Train Loss: 0.065 | Train Acc: 100.000
67 Train Loss: 0.065 | Train Acc: 100.000
68 Train Loss: 0.063 | Train Acc: 100.000
69 Train Loss: 0.062 | Train Acc: 100.000
70 Train Loss: 0.061 | Train Acc: 100.000
71 Train Loss: 0.060 | Train Acc: 100.000
72 Train Loss: 0.059 | Train Acc: 100.000
73 Train Loss: 0.058 | Train Acc: 100.000
74 Train Loss: 0.056 | Train Acc: 100.000
75 Train Loss: 0.055 | Train Acc: 100.000
76 Train Loss: 0.053 | Train Acc: 100.000
77 Train Loss: 0.052 | Train Acc: 100.000
78 Train Loss: 0.051 | Train Acc: 100.000
79 Train Loss: 0.050 | Train Acc: 100.000
80 Train Loss: 0.048 | Train Acc: 100.000
81 Train Loss: 0.047 | Train Acc: 100.000
82 Train Loss: 0.047 | Train Acc: 100.000
83 Train Loss: 0.046 | Train Acc: 100.000
84 Train Loss: 0.046 | Train Acc: 100.000
85 Train Loss: 0.045 | Train Acc: 100.000
86 Train Loss: 0.045 | Train Acc: 100.000
87 Train Loss: 0.044 | Train Acc: 100.000
88 Train Loss: 0.044 | Train Acc: 100.000
89 Train Loss: 0.043 | Train Acc: 100.000
90 Train Loss: 0.042 | Train Acc: 100.000
91 Train Loss: 0.042 | Train Acc: 100.000
92 Train Loss: 0.041 | Train Acc: 100.000
93 Train Loss: 0.040 | Train Acc: 100.000
94 Train Loss: 0.040 | Train Acc: 100.000
95 Train Loss: 0.039 | Train Acc: 100.000
96 Train Loss: 0.038 | Train Acc: 100.000
97 Train Loss: 0.038 | Train Acc: 100.000
98 Train Loss: 0.037 | Train Acc: 100.000
99 Train Loss: 0.037 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  103
trainInputDict[data].shape :  torch.Size([184, 16, 8, 8])
copy.shape :  torch.Size([184, 1024])
copyLabel.shape :  torch.Size([184])
Class 0 has 146 instances after oversampling
Class 1 has 146 instances after oversampling
Class 2 has 1 instances after oversampling
Class 3 has 146 instances after oversampling
Class 4 has 146 instances after oversampling
Class 5 has 146 instances after oversampling
0 Train Loss: 104.725 | Train Acc: 63.571
1 Train Loss: 20.710 | Train Acc: 95.143
2 Train Loss: 11.877 | Train Acc: 96.571
3 Train Loss: 6.408 | Train Acc: 98.571
4 Train Loss: 4.170 | Train Acc: 99.000
5 Train Loss: 2.909 | Train Acc: 99.571
6 Train Loss: 1.304 | Train Acc: 99.857
7 Train Loss: 0.955 | Train Acc: 100.000
8 Train Loss: 0.765 | Train Acc: 100.000
9 Train Loss: 0.558 | Train Acc: 100.000
10 Train Loss: 0.451 | Train Acc: 100.000
11 Train Loss: 0.353 | Train Acc: 100.000
12 Train Loss: 0.308 | Train Acc: 100.000
13 Train Loss: 0.249 | Train Acc: 100.000
14 Train Loss: 0.213 | Train Acc: 100.000
15 Train Loss: 0.191 | Train Acc: 100.000
16 Train Loss: 0.154 | Train Acc: 100.000
17 Train Loss: 0.136 | Train Acc: 100.000
18 Train Loss: 0.118 | Train Acc: 100.000
19 Train Loss: 0.112 | Train Acc: 100.000
20 Train Loss: 0.092 | Train Acc: 100.000
21 Train Loss: 0.088 | Train Acc: 100.000
22 Train Loss: 0.086 | Train Acc: 100.000
23 Train Loss: 0.083 | Train Acc: 100.000
24 Train Loss: 0.076 | Train Acc: 100.000
25 Train Loss: 0.073 | Train Acc: 100.000
26 Train Loss: 0.071 | Train Acc: 100.000
27 Train Loss: 0.068 | Train Acc: 100.000
28 Train Loss: 0.064 | Train Acc: 100.000
29 Train Loss: 0.063 | Train Acc: 100.000
30 Train Loss: 0.059 | Train Acc: 100.000
31 Train Loss: 0.055 | Train Acc: 100.000
32 Train Loss: 0.053 | Train Acc: 100.000
33 Train Loss: 0.050 | Train Acc: 100.000
34 Train Loss: 0.047 | Train Acc: 100.000
35 Train Loss: 0.045 | Train Acc: 100.000
36 Train Loss: 0.043 | Train Acc: 100.000
37 Train Loss: 0.041 | Train Acc: 100.000
38 Train Loss: 0.039 | Train Acc: 100.000
39 Train Loss: 0.036 | Train Acc: 100.000
40 Train Loss: 0.034 | Train Acc: 100.000
41 Train Loss: 0.033 | Train Acc: 100.000
42 Train Loss: 0.033 | Train Acc: 100.000
43 Train Loss: 0.032 | Train Acc: 100.000
44 Train Loss: 0.032 | Train Acc: 100.000
45 Train Loss: 0.031 | Train Acc: 100.000
46 Train Loss: 0.030 | Train Acc: 100.000
47 Train Loss: 0.029 | Train Acc: 100.000
48 Train Loss: 0.029 | Train Acc: 100.000
49 Train Loss: 0.028 | Train Acc: 100.000
50 Train Loss: 0.027 | Train Acc: 100.000
51 Train Loss: 0.026 | Train Acc: 100.000
52 Train Loss: 0.025 | Train Acc: 100.000
53 Train Loss: 0.025 | Train Acc: 100.000
54 Train Loss: 0.024 | Train Acc: 100.000
55 Train Loss: 0.023 | Train Acc: 100.000
56 Train Loss: 0.022 | Train Acc: 100.000
57 Train Loss: 0.022 | Train Acc: 100.000
58 Train Loss: 0.021 | Train Acc: 100.000
59 Train Loss: 0.020 | Train Acc: 100.000
60 Train Loss: 0.019 | Train Acc: 100.000
61 Train Loss: 0.019 | Train Acc: 100.000
62 Train Loss: 0.019 | Train Acc: 100.000
63 Train Loss: 0.019 | Train Acc: 100.000
64 Train Loss: 0.018 | Train Acc: 100.000
65 Train Loss: 0.018 | Train Acc: 100.000
66 Train Loss: 0.018 | Train Acc: 100.000
67 Train Loss: 0.017 | Train Acc: 100.000
68 Train Loss: 0.017 | Train Acc: 100.000
69 Train Loss: 0.017 | Train Acc: 100.000
70 Train Loss: 0.016 | Train Acc: 100.000
71 Train Loss: 0.016 | Train Acc: 100.000
72 Train Loss: 0.016 | Train Acc: 100.000
73 Train Loss: 0.015 | Train Acc: 100.000
74 Train Loss: 0.015 | Train Acc: 100.000
75 Train Loss: 0.015 | Train Acc: 100.000
76 Train Loss: 0.015 | Train Acc: 100.000
77 Train Loss: 0.014 | Train Acc: 100.000
78 Train Loss: 0.014 | Train Acc: 100.000
79 Train Loss: 0.013 | Train Acc: 100.000
80 Train Loss: 0.013 | Train Acc: 100.000
81 Train Loss: 0.013 | Train Acc: 100.000
82 Train Loss: 0.013 | Train Acc: 100.000
83 Train Loss: 0.013 | Train Acc: 100.000
84 Train Loss: 0.012 | Train Acc: 100.000
85 Train Loss: 0.012 | Train Acc: 100.000
86 Train Loss: 0.012 | Train Acc: 100.000
87 Train Loss: 0.012 | Train Acc: 100.000
88 Train Loss: 0.012 | Train Acc: 100.000
89 Train Loss: 0.012 | Train Acc: 100.000
90 Train Loss: 0.011 | Train Acc: 100.000
91 Train Loss: 0.011 | Train Acc: 100.000
92 Train Loss: 0.011 | Train Acc: 100.000
93 Train Loss: 0.011 | Train Acc: 100.000
94 Train Loss: 0.011 | Train Acc: 100.000
95 Train Loss: 0.011 | Train Acc: 100.000
96 Train Loss: 0.010 | Train Acc: 100.000
97 Train Loss: 0.010 | Train Acc: 100.000
98 Train Loss: 0.010 | Train Acc: 100.000
99 Train Loss: 0.010 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  104
trainInputDict[data].shape :  torch.Size([774, 16, 8, 8])
copy.shape :  torch.Size([774, 1024])
copyLabel.shape :  torch.Size([774])
Class 0 has 308 instances after oversampling
Class 1 has 308 instances after oversampling
Class 2 has 308 instances after oversampling
Class 3 has 308 instances after oversampling
Class 4 has 308 instances after oversampling
Class 5 has 308 instances after oversampling
Class 6 has 308 instances after oversampling
Class 7 has 308 instances after oversampling
Class 8 has 308 instances after oversampling
0 Train Loss: 184.494 | Train Acc: 33.514
1 Train Loss: 118.996 | Train Acc: 60.354
2 Train Loss: 79.733 | Train Acc: 73.593
3 Train Loss: 62.768 | Train Acc: 79.113
4 Train Loss: 46.088 | Train Acc: 85.786
5 Train Loss: 37.258 | Train Acc: 89.033
6 Train Loss: 32.837 | Train Acc: 90.043
7 Train Loss: 28.822 | Train Acc: 91.595
8 Train Loss: 20.365 | Train Acc: 94.517
9 Train Loss: 16.013 | Train Acc: 96.068
10 Train Loss: 16.195 | Train Acc: 94.986
11 Train Loss: 12.576 | Train Acc: 97.150
12 Train Loss: 12.227 | Train Acc: 96.356
13 Train Loss: 9.195 | Train Acc: 97.763
14 Train Loss: 6.927 | Train Acc: 98.521
15 Train Loss: 11.613 | Train Acc: 96.501
16 Train Loss: 6.435 | Train Acc: 98.449
17 Train Loss: 5.131 | Train Acc: 98.737
18 Train Loss: 3.290 | Train Acc: 99.639
19 Train Loss: 2.835 | Train Acc: 99.711
20 Train Loss: 2.138 | Train Acc: 99.820
21 Train Loss: 1.983 | Train Acc: 99.928
22 Train Loss: 1.855 | Train Acc: 99.820
23 Train Loss: 1.800 | Train Acc: 99.964
24 Train Loss: 1.689 | Train Acc: 99.964
25 Train Loss: 1.570 | Train Acc: 99.964
26 Train Loss: 1.475 | Train Acc: 100.000
27 Train Loss: 1.378 | Train Acc: 100.000
28 Train Loss: 1.299 | Train Acc: 100.000
29 Train Loss: 1.208 | Train Acc: 100.000
30 Train Loss: 1.172 | Train Acc: 100.000
31 Train Loss: 1.122 | Train Acc: 100.000
32 Train Loss: 1.047 | Train Acc: 100.000
33 Train Loss: 0.964 | Train Acc: 100.000
34 Train Loss: 0.930 | Train Acc: 100.000
35 Train Loss: 0.851 | Train Acc: 100.000
36 Train Loss: 0.806 | Train Acc: 100.000
37 Train Loss: 0.762 | Train Acc: 100.000
38 Train Loss: 0.738 | Train Acc: 100.000
39 Train Loss: 0.694 | Train Acc: 100.000
40 Train Loss: 0.602 | Train Acc: 100.000
41 Train Loss: 0.595 | Train Acc: 100.000
42 Train Loss: 0.571 | Train Acc: 100.000
43 Train Loss: 0.558 | Train Acc: 100.000
44 Train Loss: 0.545 | Train Acc: 100.000
45 Train Loss: 0.533 | Train Acc: 100.000
46 Train Loss: 0.523 | Train Acc: 100.000
47 Train Loss: 0.509 | Train Acc: 100.000
48 Train Loss: 0.495 | Train Acc: 100.000
49 Train Loss: 0.489 | Train Acc: 100.000
50 Train Loss: 0.468 | Train Acc: 100.000
51 Train Loss: 0.451 | Train Acc: 100.000
52 Train Loss: 0.441 | Train Acc: 100.000
53 Train Loss: 0.429 | Train Acc: 100.000
54 Train Loss: 0.411 | Train Acc: 100.000
55 Train Loss: 0.421 | Train Acc: 100.000
56 Train Loss: 0.386 | Train Acc: 100.000
57 Train Loss: 0.390 | Train Acc: 100.000
58 Train Loss: 0.366 | Train Acc: 100.000
59 Train Loss: 0.354 | Train Acc: 100.000
60 Train Loss: 0.328 | Train Acc: 100.000
61 Train Loss: 0.320 | Train Acc: 100.000
62 Train Loss: 0.315 | Train Acc: 100.000
63 Train Loss: 0.312 | Train Acc: 100.000
64 Train Loss: 0.308 | Train Acc: 100.000
65 Train Loss: 0.304 | Train Acc: 100.000
66 Train Loss: 0.300 | Train Acc: 100.000
67 Train Loss: 0.294 | Train Acc: 100.000
68 Train Loss: 0.289 | Train Acc: 100.000
69 Train Loss: 0.286 | Train Acc: 100.000
70 Train Loss: 0.281 | Train Acc: 100.000
71 Train Loss: 0.277 | Train Acc: 100.000
72 Train Loss: 0.268 | Train Acc: 100.000
73 Train Loss: 0.264 | Train Acc: 100.000
74 Train Loss: 0.259 | Train Acc: 100.000
75 Train Loss: 0.255 | Train Acc: 100.000
76 Train Loss: 0.247 | Train Acc: 100.000
77 Train Loss: 0.240 | Train Acc: 100.000
78 Train Loss: 0.241 | Train Acc: 100.000
79 Train Loss: 0.231 | Train Acc: 100.000
80 Train Loss: 0.222 | Train Acc: 100.000
81 Train Loss: 0.222 | Train Acc: 100.000
82 Train Loss: 0.218 | Train Acc: 100.000
83 Train Loss: 0.217 | Train Acc: 100.000
84 Train Loss: 0.214 | Train Acc: 100.000
85 Train Loss: 0.212 | Train Acc: 100.000
86 Train Loss: 0.209 | Train Acc: 100.000
87 Train Loss: 0.207 | Train Acc: 100.000
88 Train Loss: 0.205 | Train Acc: 100.000
89 Train Loss: 0.204 | Train Acc: 100.000
90 Train Loss: 0.201 | Train Acc: 100.000
91 Train Loss: 0.198 | Train Acc: 100.000
92 Train Loss: 0.195 | Train Acc: 100.000
93 Train Loss: 0.194 | Train Acc: 100.000
94 Train Loss: 0.191 | Train Acc: 100.000
95 Train Loss: 0.188 | Train Acc: 100.000
96 Train Loss: 0.187 | Train Acc: 100.000
97 Train Loss: 0.185 | Train Acc: 100.000
98 Train Loss: 0.180 | Train Acc: 100.000
99 Train Loss: 0.179 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  105
trainInputDict[data].shape :  torch.Size([231, 16, 8, 8])
copy.shape :  torch.Size([231, 1024])
copyLabel.shape :  torch.Size([231])
Class 0 has 95 instances after oversampling
Class 1 has 95 instances after oversampling
Class 2 has 95 instances after oversampling
Class 3 has 1 instances after oversampling
Class 4 has 95 instances after oversampling
Class 5 has 95 instances after oversampling
Class 6 has 95 instances after oversampling
Class 7 has 95 instances after oversampling
Class 8 has 95 instances after oversampling
Class 9 has 95 instances after oversampling
0 Train Loss: 163.681 | Train Acc: 48.125
1 Train Loss: 64.750 | Train Acc: 80.750
2 Train Loss: 35.405 | Train Acc: 89.750
3 Train Loss: 25.215 | Train Acc: 93.125
4 Train Loss: 18.532 | Train Acc: 93.875
5 Train Loss: 11.714 | Train Acc: 97.000
6 Train Loss: 7.288 | Train Acc: 98.750
7 Train Loss: 7.043 | Train Acc: 98.250
8 Train Loss: 3.999 | Train Acc: 99.500
9 Train Loss: 3.419 | Train Acc: 99.750
10 Train Loss: 2.651 | Train Acc: 99.750
11 Train Loss: 1.739 | Train Acc: 99.750
12 Train Loss: 1.359 | Train Acc: 100.000
13 Train Loss: 1.064 | Train Acc: 100.000
14 Train Loss: 0.887 | Train Acc: 100.000
15 Train Loss: 0.683 | Train Acc: 100.000
16 Train Loss: 0.581 | Train Acc: 100.000
17 Train Loss: 0.460 | Train Acc: 100.000
18 Train Loss: 0.354 | Train Acc: 100.000
19 Train Loss: 0.336 | Train Acc: 100.000
20 Train Loss: 0.281 | Train Acc: 100.000
21 Train Loss: 0.256 | Train Acc: 100.000
22 Train Loss: 0.246 | Train Acc: 100.000
23 Train Loss: 0.232 | Train Acc: 100.000
24 Train Loss: 0.219 | Train Acc: 100.000
25 Train Loss: 0.209 | Train Acc: 100.000
26 Train Loss: 0.199 | Train Acc: 100.000
27 Train Loss: 0.190 | Train Acc: 100.000
28 Train Loss: 0.179 | Train Acc: 100.000
29 Train Loss: 0.170 | Train Acc: 100.000
30 Train Loss: 0.163 | Train Acc: 100.000
31 Train Loss: 0.154 | Train Acc: 100.000
32 Train Loss: 0.143 | Train Acc: 100.000
33 Train Loss: 0.137 | Train Acc: 100.000
34 Train Loss: 0.130 | Train Acc: 100.000
35 Train Loss: 0.121 | Train Acc: 100.000
36 Train Loss: 0.121 | Train Acc: 100.000
37 Train Loss: 0.111 | Train Acc: 100.000
38 Train Loss: 0.104 | Train Acc: 100.000
39 Train Loss: 0.097 | Train Acc: 100.000
40 Train Loss: 0.091 | Train Acc: 100.000
41 Train Loss: 0.088 | Train Acc: 100.000
42 Train Loss: 0.086 | Train Acc: 100.000
43 Train Loss: 0.085 | Train Acc: 100.000
44 Train Loss: 0.083 | Train Acc: 100.000
45 Train Loss: 0.080 | Train Acc: 100.000
46 Train Loss: 0.078 | Train Acc: 100.000
47 Train Loss: 0.077 | Train Acc: 100.000
48 Train Loss: 0.074 | Train Acc: 100.000
49 Train Loss: 0.073 | Train Acc: 100.000
50 Train Loss: 0.071 | Train Acc: 100.000
51 Train Loss: 0.068 | Train Acc: 100.000
52 Train Loss: 0.067 | Train Acc: 100.000
53 Train Loss: 0.064 | Train Acc: 100.000
54 Train Loss: 0.062 | Train Acc: 100.000
55 Train Loss: 0.062 | Train Acc: 100.000
56 Train Loss: 0.058 | Train Acc: 100.000
57 Train Loss: 0.057 | Train Acc: 100.000
58 Train Loss: 0.055 | Train Acc: 100.000
59 Train Loss: 0.053 | Train Acc: 100.000
60 Train Loss: 0.050 | Train Acc: 100.000
61 Train Loss: 0.049 | Train Acc: 100.000
62 Train Loss: 0.049 | Train Acc: 100.000
63 Train Loss: 0.048 | Train Acc: 100.000
64 Train Loss: 0.047 | Train Acc: 100.000
65 Train Loss: 0.046 | Train Acc: 100.000
66 Train Loss: 0.046 | Train Acc: 100.000
67 Train Loss: 0.045 | Train Acc: 100.000
68 Train Loss: 0.044 | Train Acc: 100.000
69 Train Loss: 0.043 | Train Acc: 100.000
70 Train Loss: 0.042 | Train Acc: 100.000
71 Train Loss: 0.042 | Train Acc: 100.000
72 Train Loss: 0.041 | Train Acc: 100.000
73 Train Loss: 0.040 | Train Acc: 100.000
74 Train Loss: 0.039 | Train Acc: 100.000
75 Train Loss: 0.038 | Train Acc: 100.000
76 Train Loss: 0.037 | Train Acc: 100.000
77 Train Loss: 0.037 | Train Acc: 100.000
78 Train Loss: 0.036 | Train Acc: 100.000
79 Train Loss: 0.035 | Train Acc: 100.000
80 Train Loss: 0.034 | Train Acc: 100.000
81 Train Loss: 0.033 | Train Acc: 100.000
82 Train Loss: 0.033 | Train Acc: 100.000
83 Train Loss: 0.033 | Train Acc: 100.000
84 Train Loss: 0.032 | Train Acc: 100.000
85 Train Loss: 0.032 | Train Acc: 100.000
86 Train Loss: 0.031 | Train Acc: 100.000
87 Train Loss: 0.031 | Train Acc: 100.000
88 Train Loss: 0.031 | Train Acc: 100.000
89 Train Loss: 0.030 | Train Acc: 100.000
90 Train Loss: 0.030 | Train Acc: 100.000
91 Train Loss: 0.029 | Train Acc: 100.000
92 Train Loss: 0.029 | Train Acc: 100.000
93 Train Loss: 0.029 | Train Acc: 100.000
94 Train Loss: 0.028 | Train Acc: 100.000
95 Train Loss: 0.028 | Train Acc: 100.000
96 Train Loss: 0.027 | Train Acc: 100.000
97 Train Loss: 0.027 | Train Acc: 100.000
98 Train Loss: 0.026 | Train Acc: 100.000
99 Train Loss: 0.026 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  106
trainInputDict[data].shape :  torch.Size([133, 16, 8, 8])
copy.shape :  torch.Size([133, 1024])
copyLabel.shape :  torch.Size([133])
Class 0 has 52 instances after oversampling
Class 1 has 52 instances after oversampling
Class 2 has 52 instances after oversampling
Class 3 has 1 instances after oversampling
Class 4 has 52 instances after oversampling
Class 5 has 52 instances after oversampling
Class 6 has 52 instances after oversampling
0 Train Loss: 1.953 | Train Acc: 19.489
1 Train Loss: 1.801 | Train Acc: 30.671
2 Train Loss: 1.681 | Train Acc: 41.853
3 Train Loss: 1.566 | Train Acc: 45.687
4 Train Loss: 1.461 | Train Acc: 52.716
5 Train Loss: 1.365 | Train Acc: 60.703
6 Train Loss: 1.277 | Train Acc: 65.176
7 Train Loss: 1.193 | Train Acc: 67.412
8 Train Loss: 1.115 | Train Acc: 65.495
9 Train Loss: 1.044 | Train Acc: 69.010
10 Train Loss: 0.980 | Train Acc: 71.565
11 Train Loss: 0.923 | Train Acc: 76.038
12 Train Loss: 0.871 | Train Acc: 76.358
13 Train Loss: 0.819 | Train Acc: 79.233
14 Train Loss: 0.774 | Train Acc: 81.150
15 Train Loss: 0.735 | Train Acc: 82.109
16 Train Loss: 0.695 | Train Acc: 84.345
17 Train Loss: 0.658 | Train Acc: 86.262
18 Train Loss: 0.623 | Train Acc: 87.220
19 Train Loss: 0.590 | Train Acc: 87.540
20 Train Loss: 0.560 | Train Acc: 86.901
21 Train Loss: 0.548 | Train Acc: 88.498
22 Train Loss: 0.536 | Train Acc: 88.818
23 Train Loss: 0.524 | Train Acc: 89.137
24 Train Loss: 0.512 | Train Acc: 89.137
25 Train Loss: 0.501 | Train Acc: 89.457
26 Train Loss: 0.490 | Train Acc: 89.137
27 Train Loss: 0.479 | Train Acc: 89.457
28 Train Loss: 0.468 | Train Acc: 89.457
29 Train Loss: 0.457 | Train Acc: 90.096
30 Train Loss: 0.446 | Train Acc: 90.096
31 Train Loss: 0.436 | Train Acc: 91.054
32 Train Loss: 0.427 | Train Acc: 90.735
33 Train Loss: 0.417 | Train Acc: 91.054
34 Train Loss: 0.408 | Train Acc: 91.693
35 Train Loss: 0.399 | Train Acc: 92.013
36 Train Loss: 0.390 | Train Acc: 92.971
37 Train Loss: 0.381 | Train Acc: 92.971
38 Train Loss: 0.373 | Train Acc: 92.652
39 Train Loss: 0.365 | Train Acc: 93.610
40 Train Loss: 0.356 | Train Acc: 93.610
41 Train Loss: 0.353 | Train Acc: 93.610
42 Train Loss: 0.350 | Train Acc: 93.610
43 Train Loss: 0.347 | Train Acc: 93.610
44 Train Loss: 0.344 | Train Acc: 93.610
45 Train Loss: 0.341 | Train Acc: 93.610
46 Train Loss: 0.338 | Train Acc: 93.610
47 Train Loss: 0.335 | Train Acc: 93.930
48 Train Loss: 0.332 | Train Acc: 93.930
49 Train Loss: 0.329 | Train Acc: 93.930
50 Train Loss: 0.325 | Train Acc: 93.930
51 Train Loss: 0.322 | Train Acc: 93.930
52 Train Loss: 0.319 | Train Acc: 93.930
53 Train Loss: 0.317 | Train Acc: 93.930
54 Train Loss: 0.314 | Train Acc: 93.930
55 Train Loss: 0.311 | Train Acc: 93.930
56 Train Loss: 0.308 | Train Acc: 93.930
57 Train Loss: 0.305 | Train Acc: 93.930
58 Train Loss: 0.302 | Train Acc: 93.930
59 Train Loss: 0.299 | Train Acc: 93.930
60 Train Loss: 0.297 | Train Acc: 93.930
61 Train Loss: 0.295 | Train Acc: 93.930
62 Train Loss: 0.294 | Train Acc: 93.930
63 Train Loss: 0.293 | Train Acc: 93.930
64 Train Loss: 0.292 | Train Acc: 93.930
65 Train Loss: 0.291 | Train Acc: 93.930
66 Train Loss: 0.290 | Train Acc: 93.930
67 Train Loss: 0.289 | Train Acc: 93.930
68 Train Loss: 0.288 | Train Acc: 94.249
69 Train Loss: 0.287 | Train Acc: 94.249
70 Train Loss: 0.286 | Train Acc: 94.249
71 Train Loss: 0.285 | Train Acc: 94.249
72 Train Loss: 0.284 | Train Acc: 94.249
73 Train Loss: 0.282 | Train Acc: 94.249
74 Train Loss: 0.281 | Train Acc: 94.249
75 Train Loss: 0.280 | Train Acc: 94.249
76 Train Loss: 0.279 | Train Acc: 94.249
77 Train Loss: 0.278 | Train Acc: 94.249
78 Train Loss: 0.277 | Train Acc: 94.249
79 Train Loss: 0.276 | Train Acc: 94.249
80 Train Loss: 0.275 | Train Acc: 94.249
81 Train Loss: 0.275 | Train Acc: 94.249
82 Train Loss: 0.274 | Train Acc: 94.249
83 Train Loss: 0.274 | Train Acc: 94.249
84 Train Loss: 0.273 | Train Acc: 94.249
85 Train Loss: 0.273 | Train Acc: 94.249
86 Train Loss: 0.273 | Train Acc: 94.249
87 Train Loss: 0.272 | Train Acc: 94.249
88 Train Loss: 0.272 | Train Acc: 94.249
89 Train Loss: 0.271 | Train Acc: 94.249
90 Train Loss: 0.271 | Train Acc: 94.249
91 Train Loss: 0.271 | Train Acc: 94.249
92 Train Loss: 0.270 | Train Acc: 94.249
93 Train Loss: 0.270 | Train Acc: 94.249
94 Train Loss: 0.269 | Train Acc: 94.249
95 Train Loss: 0.269 | Train Acc: 94.569
96 Train Loss: 0.268 | Train Acc: 94.569
97 Train Loss: 0.268 | Train Acc: 94.569
98 Train Loss: 0.268 | Train Acc: 94.569
99 Train Loss: 0.267 | Train Acc: 94.569
CNN trained successfully...
Running nodeId:  107
trainInputDict[data].shape :  torch.Size([10, 16, 8, 8])
copy.shape :  torch.Size([10, 1024])
copyLabel.shape :  torch.Size([10])
Class 0 has 1 instances after oversampling
Class 1 has 7 instances after oversampling
Class 2 has 1 instances after oversampling
Class 3 has 1 instances after oversampling
0 Train Loss: 1.770 | Train Acc: 10.000
1 Train Loss: 1.114 | Train Acc: 70.000
2 Train Loss: 0.989 | Train Acc: 70.000
3 Train Loss: 0.896 | Train Acc: 70.000
4 Train Loss: 0.823 | Train Acc: 70.000
5 Train Loss: 0.734 | Train Acc: 80.000
6 Train Loss: 0.630 | Train Acc: 80.000
7 Train Loss: 0.534 | Train Acc: 80.000
8 Train Loss: 0.460 | Train Acc: 90.000
9 Train Loss: 0.405 | Train Acc: 90.000
10 Train Loss: 0.356 | Train Acc: 100.000
11 Train Loss: 0.315 | Train Acc: 100.000
12 Train Loss: 0.277 | Train Acc: 100.000
13 Train Loss: 0.240 | Train Acc: 100.000
14 Train Loss: 0.202 | Train Acc: 100.000
15 Train Loss: 0.172 | Train Acc: 100.000
16 Train Loss: 0.148 | Train Acc: 100.000
17 Train Loss: 0.128 | Train Acc: 100.000
18 Train Loss: 0.112 | Train Acc: 100.000
19 Train Loss: 0.098 | Train Acc: 100.000
20 Train Loss: 0.086 | Train Acc: 100.000
21 Train Loss: 0.082 | Train Acc: 100.000
22 Train Loss: 0.078 | Train Acc: 100.000
23 Train Loss: 0.074 | Train Acc: 100.000
24 Train Loss: 0.070 | Train Acc: 100.000
25 Train Loss: 0.067 | Train Acc: 100.000
26 Train Loss: 0.063 | Train Acc: 100.000
27 Train Loss: 0.060 | Train Acc: 100.000
28 Train Loss: 0.057 | Train Acc: 100.000
29 Train Loss: 0.054 | Train Acc: 100.000
30 Train Loss: 0.051 | Train Acc: 100.000
31 Train Loss: 0.049 | Train Acc: 100.000
32 Train Loss: 0.047 | Train Acc: 100.000
33 Train Loss: 0.045 | Train Acc: 100.000
34 Train Loss: 0.043 | Train Acc: 100.000
35 Train Loss: 0.041 | Train Acc: 100.000
36 Train Loss: 0.039 | Train Acc: 100.000
37 Train Loss: 0.038 | Train Acc: 100.000
38 Train Loss: 0.036 | Train Acc: 100.000
39 Train Loss: 0.035 | Train Acc: 100.000
40 Train Loss: 0.034 | Train Acc: 100.000
41 Train Loss: 0.033 | Train Acc: 100.000
42 Train Loss: 0.033 | Train Acc: 100.000
43 Train Loss: 0.032 | Train Acc: 100.000
44 Train Loss: 0.032 | Train Acc: 100.000
45 Train Loss: 0.031 | Train Acc: 100.000
46 Train Loss: 0.031 | Train Acc: 100.000
47 Train Loss: 0.030 | Train Acc: 100.000
48 Train Loss: 0.030 | Train Acc: 100.000
49 Train Loss: 0.029 | Train Acc: 100.000
50 Train Loss: 0.029 | Train Acc: 100.000
51 Train Loss: 0.028 | Train Acc: 100.000
52 Train Loss: 0.028 | Train Acc: 100.000
53 Train Loss: 0.028 | Train Acc: 100.000
54 Train Loss: 0.027 | Train Acc: 100.000
55 Train Loss: 0.027 | Train Acc: 100.000
56 Train Loss: 0.026 | Train Acc: 100.000
57 Train Loss: 0.026 | Train Acc: 100.000
58 Train Loss: 0.026 | Train Acc: 100.000
59 Train Loss: 0.025 | Train Acc: 100.000
60 Train Loss: 0.025 | Train Acc: 100.000
61 Train Loss: 0.025 | Train Acc: 100.000
62 Train Loss: 0.025 | Train Acc: 100.000
63 Train Loss: 0.025 | Train Acc: 100.000
64 Train Loss: 0.025 | Train Acc: 100.000
65 Train Loss: 0.024 | Train Acc: 100.000
66 Train Loss: 0.024 | Train Acc: 100.000
67 Train Loss: 0.024 | Train Acc: 100.000
68 Train Loss: 0.024 | Train Acc: 100.000
69 Train Loss: 0.024 | Train Acc: 100.000
70 Train Loss: 0.024 | Train Acc: 100.000
71 Train Loss: 0.024 | Train Acc: 100.000
72 Train Loss: 0.024 | Train Acc: 100.000
73 Train Loss: 0.024 | Train Acc: 100.000
74 Train Loss: 0.023 | Train Acc: 100.000
75 Train Loss: 0.023 | Train Acc: 100.000
76 Train Loss: 0.023 | Train Acc: 100.000
77 Train Loss: 0.023 | Train Acc: 100.000
78 Train Loss: 0.023 | Train Acc: 100.000
79 Train Loss: 0.023 | Train Acc: 100.000
80 Train Loss: 0.023 | Train Acc: 100.000
81 Train Loss: 0.023 | Train Acc: 100.000
82 Train Loss: 0.023 | Train Acc: 100.000
83 Train Loss: 0.023 | Train Acc: 100.000
84 Train Loss: 0.023 | Train Acc: 100.000
85 Train Loss: 0.023 | Train Acc: 100.000
86 Train Loss: 0.022 | Train Acc: 100.000
87 Train Loss: 0.022 | Train Acc: 100.000
88 Train Loss: 0.022 | Train Acc: 100.000
89 Train Loss: 0.022 | Train Acc: 100.000
90 Train Loss: 0.022 | Train Acc: 100.000
91 Train Loss: 0.022 | Train Acc: 100.000
92 Train Loss: 0.022 | Train Acc: 100.000
93 Train Loss: 0.022 | Train Acc: 100.000
94 Train Loss: 0.022 | Train Acc: 100.000
95 Train Loss: 0.022 | Train Acc: 100.000
96 Train Loss: 0.022 | Train Acc: 100.000
97 Train Loss: 0.022 | Train Acc: 100.000
98 Train Loss: 0.022 | Train Acc: 100.000
99 Train Loss: 0.022 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  108
trainInputDict[data].shape :  torch.Size([618, 16, 8, 8])
copy.shape :  torch.Size([618, 1024])
copyLabel.shape :  torch.Size([618])
Class 0 has 122 instances after oversampling
Class 1 has 122 instances after oversampling
Class 2 has 122 instances after oversampling
Class 3 has 122 instances after oversampling
Class 4 has 122 instances after oversampling
Class 5 has 122 instances after oversampling
Class 6 has 122 instances after oversampling
Class 7 has 122 instances after oversampling
Class 8 has 122 instances after oversampling
Class 9 has 122 instances after oversampling
0 Train Loss: 229.366 | Train Acc: 17.417
1 Train Loss: 189.683 | Train Acc: 33.167
2 Train Loss: 144.239 | Train Acc: 52.750
3 Train Loss: 114.924 | Train Acc: 63.333
4 Train Loss: 85.818 | Train Acc: 74.500
5 Train Loss: 64.828 | Train Acc: 81.250
6 Train Loss: 50.446 | Train Acc: 86.000
7 Train Loss: 39.394 | Train Acc: 90.167
8 Train Loss: 32.382 | Train Acc: 90.833
9 Train Loss: 25.491 | Train Acc: 94.583
10 Train Loss: 19.974 | Train Acc: 96.083
11 Train Loss: 14.636 | Train Acc: 97.167
12 Train Loss: 13.690 | Train Acc: 97.417
13 Train Loss: 9.474 | Train Acc: 98.750
14 Train Loss: 7.152 | Train Acc: 99.583
15 Train Loss: 5.670 | Train Acc: 99.667
16 Train Loss: 4.108 | Train Acc: 99.833
17 Train Loss: 3.445 | Train Acc: 99.917
18 Train Loss: 2.890 | Train Acc: 99.917
19 Train Loss: 2.513 | Train Acc: 100.000
20 Train Loss: 1.801 | Train Acc: 100.000
21 Train Loss: 1.621 | Train Acc: 100.000
22 Train Loss: 1.524 | Train Acc: 100.000
23 Train Loss: 1.442 | Train Acc: 100.000
24 Train Loss: 1.368 | Train Acc: 100.000
25 Train Loss: 1.315 | Train Acc: 100.000
26 Train Loss: 1.229 | Train Acc: 100.000
27 Train Loss: 1.176 | Train Acc: 100.000
28 Train Loss: 1.118 | Train Acc: 100.000
29 Train Loss: 1.070 | Train Acc: 100.000
30 Train Loss: 0.987 | Train Acc: 100.000
31 Train Loss: 0.960 | Train Acc: 100.000
32 Train Loss: 0.907 | Train Acc: 100.000
33 Train Loss: 0.869 | Train Acc: 100.000
34 Train Loss: 0.806 | Train Acc: 100.000
35 Train Loss: 0.760 | Train Acc: 100.000
36 Train Loss: 0.732 | Train Acc: 100.000
37 Train Loss: 0.688 | Train Acc: 100.000
38 Train Loss: 0.652 | Train Acc: 100.000
39 Train Loss: 0.617 | Train Acc: 100.000
40 Train Loss: 0.555 | Train Acc: 100.000
41 Train Loss: 0.549 | Train Acc: 100.000
42 Train Loss: 0.531 | Train Acc: 100.000
43 Train Loss: 0.518 | Train Acc: 100.000
44 Train Loss: 0.511 | Train Acc: 100.000
45 Train Loss: 0.499 | Train Acc: 100.000
46 Train Loss: 0.488 | Train Acc: 100.000
47 Train Loss: 0.472 | Train Acc: 100.000
48 Train Loss: 0.458 | Train Acc: 100.000
49 Train Loss: 0.447 | Train Acc: 100.000
50 Train Loss: 0.436 | Train Acc: 100.000
51 Train Loss: 0.425 | Train Acc: 100.000
52 Train Loss: 0.415 | Train Acc: 100.000
53 Train Loss: 0.402 | Train Acc: 100.000
54 Train Loss: 0.391 | Train Acc: 100.000
55 Train Loss: 0.376 | Train Acc: 100.000
56 Train Loss: 0.365 | Train Acc: 100.000
57 Train Loss: 0.356 | Train Acc: 100.000
58 Train Loss: 0.342 | Train Acc: 100.000
59 Train Loss: 0.332 | Train Acc: 100.000
60 Train Loss: 0.315 | Train Acc: 100.000
61 Train Loss: 0.308 | Train Acc: 100.000
62 Train Loss: 0.304 | Train Acc: 100.000
63 Train Loss: 0.298 | Train Acc: 100.000
64 Train Loss: 0.296 | Train Acc: 100.000
65 Train Loss: 0.290 | Train Acc: 100.000
66 Train Loss: 0.287 | Train Acc: 100.000
67 Train Loss: 0.281 | Train Acc: 100.000
68 Train Loss: 0.277 | Train Acc: 100.000
69 Train Loss: 0.271 | Train Acc: 100.000
70 Train Loss: 0.268 | Train Acc: 100.000
71 Train Loss: 0.262 | Train Acc: 100.000
72 Train Loss: 0.259 | Train Acc: 100.000
73 Train Loss: 0.253 | Train Acc: 100.000
74 Train Loss: 0.249 | Train Acc: 100.000
75 Train Loss: 0.244 | Train Acc: 100.000
76 Train Loss: 0.238 | Train Acc: 100.000
77 Train Loss: 0.232 | Train Acc: 100.000
78 Train Loss: 0.227 | Train Acc: 100.000
79 Train Loss: 0.221 | Train Acc: 100.000
80 Train Loss: 0.213 | Train Acc: 100.000
81 Train Loss: 0.211 | Train Acc: 100.000
82 Train Loss: 0.209 | Train Acc: 100.000
83 Train Loss: 0.207 | Train Acc: 100.000
84 Train Loss: 0.205 | Train Acc: 100.000
85 Train Loss: 0.203 | Train Acc: 100.000
86 Train Loss: 0.200 | Train Acc: 100.000
87 Train Loss: 0.199 | Train Acc: 100.000
88 Train Loss: 0.196 | Train Acc: 100.000
89 Train Loss: 0.194 | Train Acc: 100.000
90 Train Loss: 0.191 | Train Acc: 100.000
91 Train Loss: 0.189 | Train Acc: 100.000
92 Train Loss: 0.186 | Train Acc: 100.000
93 Train Loss: 0.185 | Train Acc: 100.000
94 Train Loss: 0.182 | Train Acc: 100.000
95 Train Loss: 0.180 | Train Acc: 100.000
96 Train Loss: 0.177 | Train Acc: 100.000
97 Train Loss: 0.175 | Train Acc: 100.000
98 Train Loss: 0.172 | Train Acc: 100.000
99 Train Loss: 0.170 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  109
trainInputDict[data].shape :  torch.Size([286, 16, 8, 8])
copy.shape :  torch.Size([286, 1024])
copyLabel.shape :  torch.Size([286])
Class 0 has 48 instances after oversampling
Class 1 has 48 instances after oversampling
Class 2 has 48 instances after oversampling
Class 3 has 48 instances after oversampling
Class 4 has 48 instances after oversampling
Class 5 has 48 instances after oversampling
Class 6 has 48 instances after oversampling
Class 7 has 48 instances after oversampling
Class 8 has 48 instances after oversampling
Class 9 has 48 instances after oversampling
0 Train Loss: 2.590 | Train Acc: 12.708
1 Train Loss: 2.378 | Train Acc: 12.917
2 Train Loss: 2.264 | Train Acc: 18.333
3 Train Loss: 2.181 | Train Acc: 22.292
4 Train Loss: 2.105 | Train Acc: 28.958
5 Train Loss: 2.036 | Train Acc: 36.042
6 Train Loss: 1.969 | Train Acc: 41.042
7 Train Loss: 1.904 | Train Acc: 44.583
8 Train Loss: 1.841 | Train Acc: 46.667
9 Train Loss: 1.778 | Train Acc: 49.583
10 Train Loss: 1.716 | Train Acc: 50.833
11 Train Loss: 1.653 | Train Acc: 52.917
12 Train Loss: 1.590 | Train Acc: 54.167
13 Train Loss: 1.526 | Train Acc: 56.875
14 Train Loss: 1.464 | Train Acc: 58.542
15 Train Loss: 1.403 | Train Acc: 60.625
16 Train Loss: 1.346 | Train Acc: 62.292
17 Train Loss: 1.290 | Train Acc: 63.750
18 Train Loss: 1.236 | Train Acc: 65.000
19 Train Loss: 1.181 | Train Acc: 65.833
20 Train Loss: 1.127 | Train Acc: 67.083
21 Train Loss: 1.106 | Train Acc: 67.708
22 Train Loss: 1.085 | Train Acc: 68.333
23 Train Loss: 1.064 | Train Acc: 69.167
24 Train Loss: 1.043 | Train Acc: 69.583
25 Train Loss: 1.022 | Train Acc: 69.792
26 Train Loss: 1.001 | Train Acc: 70.625
27 Train Loss: 0.980 | Train Acc: 71.458
28 Train Loss: 0.959 | Train Acc: 72.292
29 Train Loss: 0.939 | Train Acc: 72.917
30 Train Loss: 0.918 | Train Acc: 73.542
31 Train Loss: 0.898 | Train Acc: 73.750
32 Train Loss: 0.879 | Train Acc: 75.000
33 Train Loss: 0.859 | Train Acc: 76.042
34 Train Loss: 0.840 | Train Acc: 76.875
35 Train Loss: 0.822 | Train Acc: 77.917
36 Train Loss: 0.804 | Train Acc: 79.167
37 Train Loss: 0.786 | Train Acc: 79.583
38 Train Loss: 0.768 | Train Acc: 80.208
39 Train Loss: 0.751 | Train Acc: 80.833
40 Train Loss: 0.733 | Train Acc: 81.458
41 Train Loss: 0.727 | Train Acc: 81.458
42 Train Loss: 0.720 | Train Acc: 81.875
43 Train Loss: 0.713 | Train Acc: 82.917
44 Train Loss: 0.706 | Train Acc: 83.125
45 Train Loss: 0.700 | Train Acc: 83.333
46 Train Loss: 0.693 | Train Acc: 83.333
47 Train Loss: 0.686 | Train Acc: 83.750
48 Train Loss: 0.680 | Train Acc: 83.750
49 Train Loss: 0.673 | Train Acc: 83.750
50 Train Loss: 0.667 | Train Acc: 83.958
51 Train Loss: 0.660 | Train Acc: 84.375
52 Train Loss: 0.654 | Train Acc: 84.375
53 Train Loss: 0.648 | Train Acc: 84.375
54 Train Loss: 0.641 | Train Acc: 84.375
55 Train Loss: 0.635 | Train Acc: 84.375
56 Train Loss: 0.629 | Train Acc: 84.792
57 Train Loss: 0.623 | Train Acc: 85.417
58 Train Loss: 0.617 | Train Acc: 85.417
59 Train Loss: 0.611 | Train Acc: 85.417
60 Train Loss: 0.605 | Train Acc: 85.417
61 Train Loss: 0.602 | Train Acc: 85.417
62 Train Loss: 0.600 | Train Acc: 85.417
63 Train Loss: 0.597 | Train Acc: 85.417
64 Train Loss: 0.595 | Train Acc: 85.417
65 Train Loss: 0.593 | Train Acc: 85.417
66 Train Loss: 0.590 | Train Acc: 85.417
67 Train Loss: 0.588 | Train Acc: 85.625
68 Train Loss: 0.586 | Train Acc: 85.625
69 Train Loss: 0.583 | Train Acc: 85.833
70 Train Loss: 0.581 | Train Acc: 85.833
71 Train Loss: 0.579 | Train Acc: 85.833
72 Train Loss: 0.576 | Train Acc: 85.833
73 Train Loss: 0.574 | Train Acc: 86.458
74 Train Loss: 0.572 | Train Acc: 86.458
75 Train Loss: 0.569 | Train Acc: 86.667
76 Train Loss: 0.567 | Train Acc: 86.875
77 Train Loss: 0.565 | Train Acc: 87.083
78 Train Loss: 0.562 | Train Acc: 87.083
79 Train Loss: 0.560 | Train Acc: 87.292
80 Train Loss: 0.558 | Train Acc: 87.292
81 Train Loss: 0.557 | Train Acc: 87.292
82 Train Loss: 0.556 | Train Acc: 87.500
83 Train Loss: 0.555 | Train Acc: 87.500
84 Train Loss: 0.554 | Train Acc: 87.500
85 Train Loss: 0.553 | Train Acc: 87.500
86 Train Loss: 0.552 | Train Acc: 87.500
87 Train Loss: 0.551 | Train Acc: 87.500
88 Train Loss: 0.551 | Train Acc: 87.500
89 Train Loss: 0.550 | Train Acc: 87.500
90 Train Loss: 0.549 | Train Acc: 87.500
91 Train Loss: 0.548 | Train Acc: 87.500
92 Train Loss: 0.547 | Train Acc: 87.500
93 Train Loss: 0.546 | Train Acc: 87.500
94 Train Loss: 0.545 | Train Acc: 87.500
95 Train Loss: 0.544 | Train Acc: 87.917
96 Train Loss: 0.543 | Train Acc: 87.917
97 Train Loss: 0.542 | Train Acc: 88.125
98 Train Loss: 0.541 | Train Acc: 88.125
99 Train Loss: 0.541 | Train Acc: 88.333
CNN trained successfully...
Running nodeId:  110
trainInputDict[data].shape :  torch.Size([97, 16, 8, 8])
copy.shape :  torch.Size([97, 1024])
copyLabel.shape :  torch.Size([97])
Class 0 has 17 instances after oversampling
Class 1 has 17 instances after oversampling
Class 2 has 17 instances after oversampling
Class 3 has 17 instances after oversampling
Class 4 has 17 instances after oversampling
Class 5 has 16 instances after oversampling
Class 6 has 17 instances after oversampling
Class 7 has 17 instances after oversampling
Class 8 has 17 instances after oversampling
Class 9 has 17 instances after oversampling
0 Train Loss: 2.720 | Train Acc: 5.325
1 Train Loss: 2.382 | Train Acc: 15.385
2 Train Loss: 2.204 | Train Acc: 28.994
3 Train Loss: 2.069 | Train Acc: 30.178
4 Train Loss: 1.924 | Train Acc: 33.136
5 Train Loss: 1.778 | Train Acc: 42.604
6 Train Loss: 1.651 | Train Acc: 47.929
7 Train Loss: 1.535 | Train Acc: 52.071
8 Train Loss: 1.421 | Train Acc: 58.580
9 Train Loss: 1.306 | Train Acc: 66.864
10 Train Loss: 1.194 | Train Acc: 69.822
11 Train Loss: 1.091 | Train Acc: 73.964
12 Train Loss: 0.996 | Train Acc: 75.148
13 Train Loss: 0.908 | Train Acc: 78.698
14 Train Loss: 0.825 | Train Acc: 82.840
15 Train Loss: 0.750 | Train Acc: 86.982
16 Train Loss: 0.681 | Train Acc: 88.166
17 Train Loss: 0.615 | Train Acc: 89.349
18 Train Loss: 0.552 | Train Acc: 92.308
19 Train Loss: 0.497 | Train Acc: 94.083
20 Train Loss: 0.449 | Train Acc: 94.675
21 Train Loss: 0.430 | Train Acc: 94.675
22 Train Loss: 0.412 | Train Acc: 94.675
23 Train Loss: 0.393 | Train Acc: 94.675
24 Train Loss: 0.375 | Train Acc: 95.266
25 Train Loss: 0.359 | Train Acc: 95.858
26 Train Loss: 0.343 | Train Acc: 97.041
27 Train Loss: 0.327 | Train Acc: 97.041
28 Train Loss: 0.312 | Train Acc: 97.041
29 Train Loss: 0.298 | Train Acc: 97.041
30 Train Loss: 0.285 | Train Acc: 97.633
31 Train Loss: 0.272 | Train Acc: 98.225
32 Train Loss: 0.260 | Train Acc: 98.225
33 Train Loss: 0.249 | Train Acc: 98.817
34 Train Loss: 0.238 | Train Acc: 98.817
35 Train Loss: 0.228 | Train Acc: 99.408
36 Train Loss: 0.218 | Train Acc: 99.408
37 Train Loss: 0.209 | Train Acc: 100.000
38 Train Loss: 0.200 | Train Acc: 100.000
39 Train Loss: 0.192 | Train Acc: 100.000
40 Train Loss: 0.184 | Train Acc: 100.000
41 Train Loss: 0.181 | Train Acc: 100.000
42 Train Loss: 0.178 | Train Acc: 100.000
43 Train Loss: 0.175 | Train Acc: 100.000
44 Train Loss: 0.173 | Train Acc: 100.000
45 Train Loss: 0.170 | Train Acc: 100.000
46 Train Loss: 0.167 | Train Acc: 100.000
47 Train Loss: 0.164 | Train Acc: 100.000
48 Train Loss: 0.162 | Train Acc: 100.000
49 Train Loss: 0.159 | Train Acc: 100.000
50 Train Loss: 0.157 | Train Acc: 100.000
51 Train Loss: 0.154 | Train Acc: 100.000
52 Train Loss: 0.152 | Train Acc: 100.000
53 Train Loss: 0.150 | Train Acc: 100.000
54 Train Loss: 0.147 | Train Acc: 100.000
55 Train Loss: 0.145 | Train Acc: 100.000
56 Train Loss: 0.143 | Train Acc: 100.000
57 Train Loss: 0.141 | Train Acc: 100.000
58 Train Loss: 0.139 | Train Acc: 100.000
59 Train Loss: 0.137 | Train Acc: 100.000
60 Train Loss: 0.135 | Train Acc: 100.000
61 Train Loss: 0.134 | Train Acc: 100.000
62 Train Loss: 0.133 | Train Acc: 100.000
63 Train Loss: 0.132 | Train Acc: 100.000
64 Train Loss: 0.131 | Train Acc: 100.000
65 Train Loss: 0.131 | Train Acc: 100.000
66 Train Loss: 0.130 | Train Acc: 100.000
67 Train Loss: 0.129 | Train Acc: 100.000
68 Train Loss: 0.128 | Train Acc: 100.000
69 Train Loss: 0.128 | Train Acc: 100.000
70 Train Loss: 0.127 | Train Acc: 100.000
71 Train Loss: 0.126 | Train Acc: 100.000
72 Train Loss: 0.125 | Train Acc: 100.000
73 Train Loss: 0.125 | Train Acc: 100.000
74 Train Loss: 0.124 | Train Acc: 100.000
75 Train Loss: 0.123 | Train Acc: 100.000
76 Train Loss: 0.122 | Train Acc: 100.000
77 Train Loss: 0.122 | Train Acc: 100.000
78 Train Loss: 0.121 | Train Acc: 100.000
79 Train Loss: 0.120 | Train Acc: 100.000
80 Train Loss: 0.119 | Train Acc: 100.000
81 Train Loss: 0.119 | Train Acc: 100.000
82 Train Loss: 0.119 | Train Acc: 100.000
83 Train Loss: 0.119 | Train Acc: 100.000
84 Train Loss: 0.118 | Train Acc: 100.000
85 Train Loss: 0.118 | Train Acc: 100.000
86 Train Loss: 0.118 | Train Acc: 100.000
87 Train Loss: 0.117 | Train Acc: 100.000
88 Train Loss: 0.117 | Train Acc: 100.000
89 Train Loss: 0.117 | Train Acc: 100.000
90 Train Loss: 0.117 | Train Acc: 100.000
91 Train Loss: 0.116 | Train Acc: 100.000
92 Train Loss: 0.116 | Train Acc: 100.000
93 Train Loss: 0.116 | Train Acc: 100.000
94 Train Loss: 0.116 | Train Acc: 100.000
95 Train Loss: 0.115 | Train Acc: 100.000
96 Train Loss: 0.115 | Train Acc: 100.000
97 Train Loss: 0.115 | Train Acc: 100.000
98 Train Loss: 0.114 | Train Acc: 100.000
99 Train Loss: 0.114 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  111
trainInputDict[data].shape :  torch.Size([282, 16, 8, 8])
copy.shape :  torch.Size([282, 1024])
copyLabel.shape :  torch.Size([282])
Class 0 has 69 instances after oversampling
Class 1 has 69 instances after oversampling
Class 2 has 69 instances after oversampling
Class 3 has 69 instances after oversampling
Class 4 has 69 instances after oversampling
Class 5 has 69 instances after oversampling
Class 6 has 69 instances after oversampling
Class 7 has 69 instances after oversampling
Class 8 has 69 instances after oversampling
Class 9 has 69 instances after oversampling
0 Train Loss: 220.837 | Train Acc: 16.333
1 Train Loss: 179.441 | Train Acc: 39.667
2 Train Loss: 136.931 | Train Acc: 58.500
3 Train Loss: 95.295 | Train Acc: 73.333
4 Train Loss: 72.577 | Train Acc: 79.667
5 Train Loss: 53.044 | Train Acc: 85.833
6 Train Loss: 38.988 | Train Acc: 89.500
7 Train Loss: 29.068 | Train Acc: 93.500
8 Train Loss: 23.128 | Train Acc: 94.667
9 Train Loss: 15.934 | Train Acc: 97.333
10 Train Loss: 11.178 | Train Acc: 98.167
11 Train Loss: 8.510 | Train Acc: 99.167
12 Train Loss: 5.784 | Train Acc: 99.667
13 Train Loss: 4.471 | Train Acc: 99.833
14 Train Loss: 3.245 | Train Acc: 100.000
15 Train Loss: 2.557 | Train Acc: 100.000
16 Train Loss: 1.893 | Train Acc: 100.000
17 Train Loss: 1.623 | Train Acc: 100.000
18 Train Loss: 1.330 | Train Acc: 100.000
19 Train Loss: 1.129 | Train Acc: 100.000
20 Train Loss: 0.953 | Train Acc: 100.000
21 Train Loss: 0.866 | Train Acc: 100.000
22 Train Loss: 0.833 | Train Acc: 100.000
23 Train Loss: 0.788 | Train Acc: 100.000
24 Train Loss: 0.752 | Train Acc: 100.000
25 Train Loss: 0.716 | Train Acc: 100.000
26 Train Loss: 0.678 | Train Acc: 100.000
27 Train Loss: 0.641 | Train Acc: 100.000
28 Train Loss: 0.617 | Train Acc: 100.000
29 Train Loss: 0.575 | Train Acc: 100.000
30 Train Loss: 0.546 | Train Acc: 100.000
31 Train Loss: 0.508 | Train Acc: 100.000
32 Train Loss: 0.493 | Train Acc: 100.000
33 Train Loss: 0.465 | Train Acc: 100.000
34 Train Loss: 0.438 | Train Acc: 100.000
35 Train Loss: 0.411 | Train Acc: 100.000
36 Train Loss: 0.388 | Train Acc: 100.000
37 Train Loss: 0.372 | Train Acc: 100.000
38 Train Loss: 0.351 | Train Acc: 100.000
39 Train Loss: 0.333 | Train Acc: 100.000
40 Train Loss: 0.305 | Train Acc: 100.000
41 Train Loss: 0.299 | Train Acc: 100.000
42 Train Loss: 0.291 | Train Acc: 100.000
43 Train Loss: 0.285 | Train Acc: 100.000
44 Train Loss: 0.277 | Train Acc: 100.000
45 Train Loss: 0.272 | Train Acc: 100.000
46 Train Loss: 0.265 | Train Acc: 100.000
47 Train Loss: 0.258 | Train Acc: 100.000
48 Train Loss: 0.253 | Train Acc: 100.000
49 Train Loss: 0.245 | Train Acc: 100.000
50 Train Loss: 0.239 | Train Acc: 100.000
51 Train Loss: 0.232 | Train Acc: 100.000
52 Train Loss: 0.225 | Train Acc: 100.000
53 Train Loss: 0.219 | Train Acc: 100.000
54 Train Loss: 0.211 | Train Acc: 100.000
55 Train Loss: 0.206 | Train Acc: 100.000
56 Train Loss: 0.199 | Train Acc: 100.000
57 Train Loss: 0.193 | Train Acc: 100.000
58 Train Loss: 0.186 | Train Acc: 100.000
59 Train Loss: 0.180 | Train Acc: 100.000
60 Train Loss: 0.170 | Train Acc: 100.000
61 Train Loss: 0.167 | Train Acc: 100.000
62 Train Loss: 0.166 | Train Acc: 100.000
63 Train Loss: 0.163 | Train Acc: 100.000
64 Train Loss: 0.161 | Train Acc: 100.000
65 Train Loss: 0.158 | Train Acc: 100.000
66 Train Loss: 0.156 | Train Acc: 100.000
67 Train Loss: 0.154 | Train Acc: 100.000
68 Train Loss: 0.150 | Train Acc: 100.000
69 Train Loss: 0.148 | Train Acc: 100.000
70 Train Loss: 0.145 | Train Acc: 100.000
71 Train Loss: 0.142 | Train Acc: 100.000
72 Train Loss: 0.139 | Train Acc: 100.000
73 Train Loss: 0.137 | Train Acc: 100.000
74 Train Loss: 0.134 | Train Acc: 100.000
75 Train Loss: 0.131 | Train Acc: 100.000
76 Train Loss: 0.128 | Train Acc: 100.000
77 Train Loss: 0.126 | Train Acc: 100.000
78 Train Loss: 0.122 | Train Acc: 100.000
79 Train Loss: 0.119 | Train Acc: 100.000
80 Train Loss: 0.116 | Train Acc: 100.000
81 Train Loss: 0.114 | Train Acc: 100.000
82 Train Loss: 0.113 | Train Acc: 100.000
83 Train Loss: 0.112 | Train Acc: 100.000
84 Train Loss: 0.110 | Train Acc: 100.000
85 Train Loss: 0.109 | Train Acc: 100.000
86 Train Loss: 0.108 | Train Acc: 100.000
87 Train Loss: 0.107 | Train Acc: 100.000
88 Train Loss: 0.105 | Train Acc: 100.000
89 Train Loss: 0.104 | Train Acc: 100.000
90 Train Loss: 0.103 | Train Acc: 100.000
91 Train Loss: 0.101 | Train Acc: 100.000
92 Train Loss: 0.100 | Train Acc: 100.000
93 Train Loss: 0.098 | Train Acc: 100.000
94 Train Loss: 0.097 | Train Acc: 100.000
95 Train Loss: 0.095 | Train Acc: 100.000
96 Train Loss: 0.094 | Train Acc: 100.000
97 Train Loss: 0.093 | Train Acc: 100.000
98 Train Loss: 0.091 | Train Acc: 100.000
99 Train Loss: 0.090 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  112
trainInputDict[data].shape :  torch.Size([2918, 16, 8, 8])
copy.shape :  torch.Size([2918, 1024])
copyLabel.shape :  torch.Size([2918])
Class 0 has 664 instances after oversampling
Class 1 has 664 instances after oversampling
Class 2 has 664 instances after oversampling
Class 3 has 664 instances after oversampling
Class 4 has 664 instances after oversampling
Class 5 has 664 instances after oversampling
Class 6 has 664 instances after oversampling
Class 7 has 664 instances after oversampling
Class 8 has 664 instances after oversampling
Class 9 has 664 instances after oversampling
0 Train Loss: 206.816 | Train Acc: 28.389
1 Train Loss: 152.228 | Train Acc: 46.551
2 Train Loss: 117.292 | Train Acc: 58.178
3 Train Loss: 104.766 | Train Acc: 61.596
4 Train Loss: 95.546 | Train Acc: 63.931
5 Train Loss: 94.255 | Train Acc: 64.247
6 Train Loss: 84.851 | Train Acc: 68.630
7 Train Loss: 81.202 | Train Acc: 70.316
8 Train Loss: 81.960 | Train Acc: 69.142
9 Train Loss: 77.523 | Train Acc: 71.175
10 Train Loss: 73.411 | Train Acc: 73.117
11 Train Loss: 72.775 | Train Acc: 72.801
12 Train Loss: 69.864 | Train Acc: 74.232
13 Train Loss: 67.491 | Train Acc: 75.392
14 Train Loss: 65.845 | Train Acc: 76.205
15 Train Loss: 64.180 | Train Acc: 76.852
16 Train Loss: 61.183 | Train Acc: 78.012
17 Train Loss: 60.074 | Train Acc: 78.554
18 Train Loss: 60.447 | Train Acc: 77.861
19 Train Loss: 55.016 | Train Acc: 80.602
20 Train Loss: 51.939 | Train Acc: 82.048
21 Train Loss: 51.563 | Train Acc: 82.018
22 Train Loss: 49.300 | Train Acc: 83.268
23 Train Loss: 49.745 | Train Acc: 82.846
24 Train Loss: 48.221 | Train Acc: 83.599
25 Train Loss: 48.583 | Train Acc: 83.645
26 Train Loss: 47.930 | Train Acc: 83.358
27 Train Loss: 47.465 | Train Acc: 83.509
28 Train Loss: 46.171 | Train Acc: 84.172
29 Train Loss: 46.542 | Train Acc: 84.172
30 Train Loss: 45.870 | Train Acc: 84.383
31 Train Loss: 44.714 | Train Acc: 84.623
32 Train Loss: 45.615 | Train Acc: 84.443
33 Train Loss: 44.151 | Train Acc: 84.925
34 Train Loss: 43.184 | Train Acc: 85.602
35 Train Loss: 43.276 | Train Acc: 85.693
36 Train Loss: 42.186 | Train Acc: 85.723
37 Train Loss: 42.797 | Train Acc: 85.587
38 Train Loss: 42.007 | Train Acc: 85.889
39 Train Loss: 40.595 | Train Acc: 86.687
40 Train Loss: 39.319 | Train Acc: 87.500
41 Train Loss: 38.911 | Train Acc: 87.756
42 Train Loss: 38.802 | Train Acc: 87.771
43 Train Loss: 38.621 | Train Acc: 87.651
44 Train Loss: 38.479 | Train Acc: 87.380
45 Train Loss: 37.862 | Train Acc: 87.861
46 Train Loss: 37.815 | Train Acc: 88.102
47 Train Loss: 37.912 | Train Acc: 88.042
48 Train Loss: 37.396 | Train Acc: 88.358
49 Train Loss: 37.534 | Train Acc: 88.163
50 Train Loss: 37.213 | Train Acc: 88.479
51 Train Loss: 36.947 | Train Acc: 88.464
52 Train Loss: 36.958 | Train Acc: 88.358
53 Train Loss: 36.795 | Train Acc: 88.509
54 Train Loss: 36.321 | Train Acc: 88.584
55 Train Loss: 36.150 | Train Acc: 88.554
56 Train Loss: 36.311 | Train Acc: 88.840
57 Train Loss: 35.943 | Train Acc: 88.840
58 Train Loss: 35.487 | Train Acc: 88.931
59 Train Loss: 35.563 | Train Acc: 88.931
60 Train Loss: 34.885 | Train Acc: 89.533
61 Train Loss: 34.841 | Train Acc: 89.187
62 Train Loss: 34.632 | Train Acc: 89.503
63 Train Loss: 34.597 | Train Acc: 89.428
64 Train Loss: 34.540 | Train Acc: 89.428
65 Train Loss: 34.412 | Train Acc: 89.383
66 Train Loss: 34.389 | Train Acc: 89.578
67 Train Loss: 34.420 | Train Acc: 89.413
68 Train Loss: 34.326 | Train Acc: 89.714
69 Train Loss: 34.301 | Train Acc: 89.623
70 Train Loss: 34.133 | Train Acc: 89.669
71 Train Loss: 34.105 | Train Acc: 89.337
72 Train Loss: 34.037 | Train Acc: 89.669
73 Train Loss: 33.849 | Train Acc: 89.759
74 Train Loss: 33.899 | Train Acc: 89.714
75 Train Loss: 33.874 | Train Acc: 89.834
76 Train Loss: 33.694 | Train Acc: 89.654
77 Train Loss: 33.685 | Train Acc: 89.849
78 Train Loss: 33.595 | Train Acc: 89.895
79 Train Loss: 33.545 | Train Acc: 90.045
80 Train Loss: 33.172 | Train Acc: 90.075
81 Train Loss: 33.099 | Train Acc: 90.120
82 Train Loss: 33.110 | Train Acc: 90.181
83 Train Loss: 33.077 | Train Acc: 90.181
84 Train Loss: 33.053 | Train Acc: 90.151
85 Train Loss: 32.995 | Train Acc: 90.241
86 Train Loss: 32.994 | Train Acc: 90.181
87 Train Loss: 32.966 | Train Acc: 90.166
88 Train Loss: 32.988 | Train Acc: 90.015
89 Train Loss: 32.943 | Train Acc: 90.090
90 Train Loss: 32.878 | Train Acc: 90.151
91 Train Loss: 32.843 | Train Acc: 90.196
92 Train Loss: 32.833 | Train Acc: 90.211
93 Train Loss: 32.794 | Train Acc: 90.120
94 Train Loss: 32.751 | Train Acc: 90.392
95 Train Loss: 32.771 | Train Acc: 90.196
96 Train Loss: 32.740 | Train Acc: 90.211
97 Train Loss: 32.653 | Train Acc: 90.316
98 Train Loss: 32.637 | Train Acc: 90.271
99 Train Loss: 32.620 | Train Acc: 90.151
CNN trained successfully...
Running nodeId:  113
trainInputDict[data].shape :  torch.Size([2608, 16, 8, 8])
copy.shape :  torch.Size([2608, 1024])
copyLabel.shape :  torch.Size([2608])
Class 0 has 1130 instances after oversampling
Class 1 has 1130 instances after oversampling
Class 2 has 1130 instances after oversampling
Class 3 has 1130 instances after oversampling
Class 4 has 1130 instances after oversampling
Class 5 has 1130 instances after oversampling
Class 6 has 1130 instances after oversampling
Class 7 has 1130 instances after oversampling
Class 8 has 1130 instances after oversampling
Class 9 has 1130 instances after oversampling
0 Train Loss: 222.337 | Train Acc: 22.513
1 Train Loss: 165.962 | Train Acc: 47.832
2 Train Loss: 117.824 | Train Acc: 59.752
3 Train Loss: 99.058 | Train Acc: 62.549
4 Train Loss: 90.126 | Train Acc: 67.575
5 Train Loss: 85.064 | Train Acc: 68.018
6 Train Loss: 79.895 | Train Acc: 70.372
7 Train Loss: 76.735 | Train Acc: 71.363
8 Train Loss: 72.538 | Train Acc: 73.522
9 Train Loss: 65.859 | Train Acc: 76.407
10 Train Loss: 63.668 | Train Acc: 77.124
11 Train Loss: 59.026 | Train Acc: 79.027
12 Train Loss: 56.323 | Train Acc: 79.867
13 Train Loss: 55.240 | Train Acc: 80.221
14 Train Loss: 51.243 | Train Acc: 81.726
15 Train Loss: 47.120 | Train Acc: 83.097
16 Train Loss: 45.232 | Train Acc: 83.735
17 Train Loss: 46.408 | Train Acc: 83.319
18 Train Loss: 45.704 | Train Acc: 83.593
19 Train Loss: 42.268 | Train Acc: 85.000
20 Train Loss: 35.641 | Train Acc: 87.894
21 Train Loss: 34.767 | Train Acc: 88.230
22 Train Loss: 33.876 | Train Acc: 88.522
23 Train Loss: 33.657 | Train Acc: 88.593
24 Train Loss: 33.797 | Train Acc: 88.602
25 Train Loss: 32.671 | Train Acc: 88.805
26 Train Loss: 31.771 | Train Acc: 89.779
27 Train Loss: 31.259 | Train Acc: 89.478
28 Train Loss: 30.452 | Train Acc: 89.876
29 Train Loss: 29.599 | Train Acc: 90.212
30 Train Loss: 31.003 | Train Acc: 89.549
31 Train Loss: 30.299 | Train Acc: 89.938
32 Train Loss: 29.244 | Train Acc: 90.336
33 Train Loss: 28.823 | Train Acc: 90.522
34 Train Loss: 27.484 | Train Acc: 90.823
35 Train Loss: 27.147 | Train Acc: 91.150
36 Train Loss: 26.751 | Train Acc: 91.265
37 Train Loss: 26.679 | Train Acc: 91.292
38 Train Loss: 26.244 | Train Acc: 91.796
39 Train Loss: 26.589 | Train Acc: 91.425
40 Train Loss: 24.195 | Train Acc: 92.434
41 Train Loss: 23.681 | Train Acc: 92.522
42 Train Loss: 23.563 | Train Acc: 92.779
43 Train Loss: 23.355 | Train Acc: 92.761
44 Train Loss: 23.048 | Train Acc: 92.850
45 Train Loss: 22.915 | Train Acc: 92.850
46 Train Loss: 22.950 | Train Acc: 92.947
47 Train Loss: 22.847 | Train Acc: 92.938
48 Train Loss: 22.077 | Train Acc: 93.274
49 Train Loss: 22.356 | Train Acc: 93.071
50 Train Loss: 21.899 | Train Acc: 93.301
51 Train Loss: 21.921 | Train Acc: 93.248
52 Train Loss: 22.417 | Train Acc: 92.938
53 Train Loss: 22.060 | Train Acc: 93.221
54 Train Loss: 21.898 | Train Acc: 93.540
55 Train Loss: 21.035 | Train Acc: 93.735
56 Train Loss: 21.077 | Train Acc: 93.558
57 Train Loss: 21.373 | Train Acc: 93.531
58 Train Loss: 20.790 | Train Acc: 93.628
59 Train Loss: 20.795 | Train Acc: 93.655
60 Train Loss: 20.063 | Train Acc: 94.115
61 Train Loss: 20.068 | Train Acc: 94.000
62 Train Loss: 19.922 | Train Acc: 94.133
63 Train Loss: 19.904 | Train Acc: 94.062
64 Train Loss: 19.854 | Train Acc: 94.088
65 Train Loss: 19.832 | Train Acc: 94.195
66 Train Loss: 19.754 | Train Acc: 94.133
67 Train Loss: 19.626 | Train Acc: 94.239
68 Train Loss: 19.567 | Train Acc: 94.124
69 Train Loss: 19.547 | Train Acc: 94.327
70 Train Loss: 19.451 | Train Acc: 94.186
71 Train Loss: 19.371 | Train Acc: 94.319
72 Train Loss: 19.141 | Train Acc: 94.425
73 Train Loss: 19.460 | Train Acc: 94.257
74 Train Loss: 19.159 | Train Acc: 94.398
75 Train Loss: 19.191 | Train Acc: 94.372
76 Train Loss: 19.047 | Train Acc: 94.434
77 Train Loss: 19.082 | Train Acc: 94.522
78 Train Loss: 19.007 | Train Acc: 94.398
79 Train Loss: 18.834 | Train Acc: 94.496
80 Train Loss: 18.737 | Train Acc: 94.540
81 Train Loss: 18.593 | Train Acc: 94.584
82 Train Loss: 18.619 | Train Acc: 94.681
83 Train Loss: 18.582 | Train Acc: 94.637
84 Train Loss: 18.549 | Train Acc: 94.637
85 Train Loss: 18.512 | Train Acc: 94.681
86 Train Loss: 18.463 | Train Acc: 94.681
87 Train Loss: 18.494 | Train Acc: 94.549
88 Train Loss: 18.410 | Train Acc: 94.673
89 Train Loss: 18.403 | Train Acc: 94.690
90 Train Loss: 18.364 | Train Acc: 94.690
91 Train Loss: 18.344 | Train Acc: 94.655
92 Train Loss: 18.307 | Train Acc: 94.664
93 Train Loss: 18.302 | Train Acc: 94.743
94 Train Loss: 18.282 | Train Acc: 94.708
95 Train Loss: 18.227 | Train Acc: 94.761
96 Train Loss: 18.291 | Train Acc: 94.726
97 Train Loss: 18.258 | Train Acc: 94.646
98 Train Loss: 18.160 | Train Acc: 94.823
99 Train Loss: 18.182 | Train Acc: 94.752
CNN trained successfully...
Running nodeId:  114
trainInputDict[data].shape :  torch.Size([746, 16, 8, 8])
copy.shape :  torch.Size([746, 1024])
copyLabel.shape :  torch.Size([746])
Class 0 has 186 instances after oversampling
Class 1 has 186 instances after oversampling
Class 2 has 186 instances after oversampling
Class 3 has 186 instances after oversampling
Class 4 has 186 instances after oversampling
Class 5 has 186 instances after oversampling
Class 6 has 186 instances after oversampling
Class 7 has 186 instances after oversampling
Class 8 has 186 instances after oversampling
Class 9 has 186 instances after oversampling
0 Train Loss: 223.195 | Train Acc: 18.611
1 Train Loss: 180.322 | Train Acc: 38.111
2 Train Loss: 137.434 | Train Acc: 55.722
3 Train Loss: 99.507 | Train Acc: 69.722
4 Train Loss: 79.308 | Train Acc: 75.778
5 Train Loss: 63.225 | Train Acc: 80.889
6 Train Loss: 52.153 | Train Acc: 84.611
7 Train Loss: 42.922 | Train Acc: 87.389
8 Train Loss: 35.699 | Train Acc: 89.611
9 Train Loss: 29.745 | Train Acc: 92.056
10 Train Loss: 25.363 | Train Acc: 92.944
11 Train Loss: 21.660 | Train Acc: 94.389
12 Train Loss: 17.429 | Train Acc: 95.778
13 Train Loss: 14.946 | Train Acc: 96.444
14 Train Loss: 12.631 | Train Acc: 97.333
15 Train Loss: 11.450 | Train Acc: 97.722
16 Train Loss: 9.160 | Train Acc: 98.889
17 Train Loss: 7.266 | Train Acc: 99.222
18 Train Loss: 5.985 | Train Acc: 99.722
19 Train Loss: 5.323 | Train Acc: 99.889
20 Train Loss: 3.866 | Train Acc: 99.889
21 Train Loss: 3.547 | Train Acc: 100.000
22 Train Loss: 3.274 | Train Acc: 99.944
23 Train Loss: 3.106 | Train Acc: 100.000
24 Train Loss: 2.945 | Train Acc: 100.000
25 Train Loss: 2.761 | Train Acc: 100.000
26 Train Loss: 2.586 | Train Acc: 100.000
27 Train Loss: 2.441 | Train Acc: 100.000
28 Train Loss: 2.308 | Train Acc: 100.000
29 Train Loss: 2.165 | Train Acc: 100.000
30 Train Loss: 2.037 | Train Acc: 100.000
31 Train Loss: 1.906 | Train Acc: 100.000
32 Train Loss: 1.829 | Train Acc: 100.000
33 Train Loss: 1.723 | Train Acc: 100.000
34 Train Loss: 1.575 | Train Acc: 100.000
35 Train Loss: 1.487 | Train Acc: 100.000
36 Train Loss: 1.381 | Train Acc: 100.000
37 Train Loss: 1.330 | Train Acc: 100.000
38 Train Loss: 1.210 | Train Acc: 100.000
39 Train Loss: 1.147 | Train Acc: 100.000
40 Train Loss: 1.035 | Train Acc: 100.000
41 Train Loss: 1.004 | Train Acc: 100.000
42 Train Loss: 0.987 | Train Acc: 100.000
43 Train Loss: 0.959 | Train Acc: 100.000
44 Train Loss: 0.939 | Train Acc: 100.000
45 Train Loss: 0.912 | Train Acc: 100.000
46 Train Loss: 0.886 | Train Acc: 100.000
47 Train Loss: 0.863 | Train Acc: 100.000
48 Train Loss: 0.837 | Train Acc: 100.000
49 Train Loss: 0.815 | Train Acc: 100.000
50 Train Loss: 0.788 | Train Acc: 100.000
51 Train Loss: 0.771 | Train Acc: 100.000
52 Train Loss: 0.743 | Train Acc: 100.000
53 Train Loss: 0.725 | Train Acc: 100.000
54 Train Loss: 0.701 | Train Acc: 100.000
55 Train Loss: 0.674 | Train Acc: 100.000
56 Train Loss: 0.657 | Train Acc: 100.000
57 Train Loss: 0.629 | Train Acc: 100.000
58 Train Loss: 0.615 | Train Acc: 100.000
59 Train Loss: 0.589 | Train Acc: 100.000
60 Train Loss: 0.553 | Train Acc: 100.000
61 Train Loss: 0.546 | Train Acc: 100.000
62 Train Loss: 0.535 | Train Acc: 100.000
63 Train Loss: 0.530 | Train Acc: 100.000
64 Train Loss: 0.522 | Train Acc: 100.000
65 Train Loss: 0.513 | Train Acc: 100.000
66 Train Loss: 0.508 | Train Acc: 100.000
67 Train Loss: 0.498 | Train Acc: 100.000
68 Train Loss: 0.492 | Train Acc: 100.000
69 Train Loss: 0.482 | Train Acc: 100.000
70 Train Loss: 0.474 | Train Acc: 100.000
71 Train Loss: 0.464 | Train Acc: 100.000
72 Train Loss: 0.454 | Train Acc: 100.000
73 Train Loss: 0.446 | Train Acc: 100.000
74 Train Loss: 0.438 | Train Acc: 100.000
75 Train Loss: 0.429 | Train Acc: 100.000
76 Train Loss: 0.423 | Train Acc: 100.000
77 Train Loss: 0.412 | Train Acc: 100.000
78 Train Loss: 0.405 | Train Acc: 100.000
79 Train Loss: 0.396 | Train Acc: 100.000
80 Train Loss: 0.381 | Train Acc: 100.000
81 Train Loss: 0.376 | Train Acc: 100.000
82 Train Loss: 0.373 | Train Acc: 100.000
83 Train Loss: 0.370 | Train Acc: 100.000
84 Train Loss: 0.366 | Train Acc: 100.000
85 Train Loss: 0.362 | Train Acc: 100.000
86 Train Loss: 0.359 | Train Acc: 100.000
87 Train Loss: 0.355 | Train Acc: 100.000
88 Train Loss: 0.351 | Train Acc: 100.000
89 Train Loss: 0.348 | Train Acc: 100.000
90 Train Loss: 0.344 | Train Acc: 100.000
91 Train Loss: 0.339 | Train Acc: 100.000
92 Train Loss: 0.337 | Train Acc: 100.000
93 Train Loss: 0.334 | Train Acc: 100.000
94 Train Loss: 0.329 | Train Acc: 100.000
95 Train Loss: 0.323 | Train Acc: 100.000
96 Train Loss: 0.321 | Train Acc: 100.000
97 Train Loss: 0.317 | Train Acc: 100.000
98 Train Loss: 0.314 | Train Acc: 100.000
99 Train Loss: 0.311 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  115
trainInputDict[data].shape :  torch.Size([700, 16, 8, 8])
copy.shape :  torch.Size([700, 1024])
copyLabel.shape :  torch.Size([700])
Class 0 has 350 instances after oversampling
Class 1 has 350 instances after oversampling
Class 2 has 351 instances after oversampling
Class 3 has 350 instances after oversampling
Class 4 has 350 instances after oversampling
Class 5 has 350 instances after oversampling
Class 6 has 351 instances after oversampling
Class 7 has 350 instances after oversampling
Class 8 has 1 instances after oversampling
Class 9 has 350 instances after oversampling
0 Train Loss: 201.660 | Train Acc: 29.452
1 Train Loss: 127.298 | Train Acc: 57.742
2 Train Loss: 83.079 | Train Acc: 72.290
3 Train Loss: 61.326 | Train Acc: 80.419
4 Train Loss: 47.226 | Train Acc: 84.903
5 Train Loss: 36.729 | Train Acc: 88.548
6 Train Loss: 28.140 | Train Acc: 91.677
7 Train Loss: 23.780 | Train Acc: 93.065
8 Train Loss: 19.444 | Train Acc: 94.290
9 Train Loss: 18.099 | Train Acc: 94.581
10 Train Loss: 14.121 | Train Acc: 96.000
11 Train Loss: 11.939 | Train Acc: 96.484
12 Train Loss: 10.397 | Train Acc: 97.516
13 Train Loss: 7.668 | Train Acc: 98.581
14 Train Loss: 7.361 | Train Acc: 98.129
15 Train Loss: 5.856 | Train Acc: 98.839
16 Train Loss: 5.788 | Train Acc: 98.742
17 Train Loss: 7.617 | Train Acc: 97.677
18 Train Loss: 4.079 | Train Acc: 99.548
19 Train Loss: 3.715 | Train Acc: 99.516
20 Train Loss: 2.647 | Train Acc: 99.645
21 Train Loss: 2.139 | Train Acc: 99.903
22 Train Loss: 2.030 | Train Acc: 99.968
23 Train Loss: 1.843 | Train Acc: 100.000
24 Train Loss: 1.747 | Train Acc: 100.000
25 Train Loss: 1.683 | Train Acc: 99.935
26 Train Loss: 1.535 | Train Acc: 99.968
27 Train Loss: 1.461 | Train Acc: 100.000
28 Train Loss: 1.365 | Train Acc: 100.000
29 Train Loss: 1.342 | Train Acc: 100.000
30 Train Loss: 1.253 | Train Acc: 100.000
31 Train Loss: 1.142 | Train Acc: 100.000
32 Train Loss: 1.089 | Train Acc: 100.000
33 Train Loss: 1.011 | Train Acc: 100.000
34 Train Loss: 0.956 | Train Acc: 100.000
35 Train Loss: 0.965 | Train Acc: 100.000
36 Train Loss: 0.851 | Train Acc: 100.000
37 Train Loss: 0.782 | Train Acc: 100.000
38 Train Loss: 0.768 | Train Acc: 100.000
39 Train Loss: 0.817 | Train Acc: 100.000
40 Train Loss: 0.634 | Train Acc: 100.000
41 Train Loss: 0.612 | Train Acc: 100.000
42 Train Loss: 0.584 | Train Acc: 100.000
43 Train Loss: 0.570 | Train Acc: 100.000
44 Train Loss: 0.561 | Train Acc: 100.000
45 Train Loss: 0.546 | Train Acc: 100.000
46 Train Loss: 0.515 | Train Acc: 100.000
47 Train Loss: 0.513 | Train Acc: 100.000
48 Train Loss: 0.498 | Train Acc: 100.000
49 Train Loss: 0.495 | Train Acc: 100.000
50 Train Loss: 0.470 | Train Acc: 100.000
51 Train Loss: 0.459 | Train Acc: 100.000
52 Train Loss: 0.438 | Train Acc: 100.000
53 Train Loss: 0.428 | Train Acc: 100.000
54 Train Loss: 0.405 | Train Acc: 100.000
55 Train Loss: 0.403 | Train Acc: 100.000
56 Train Loss: 0.393 | Train Acc: 100.000
57 Train Loss: 0.389 | Train Acc: 100.000
58 Train Loss: 0.357 | Train Acc: 100.000
59 Train Loss: 0.356 | Train Acc: 100.000
60 Train Loss: 0.325 | Train Acc: 100.000
61 Train Loss: 0.318 | Train Acc: 100.000
62 Train Loss: 0.309 | Train Acc: 100.000
63 Train Loss: 0.316 | Train Acc: 100.000
64 Train Loss: 0.302 | Train Acc: 100.000
65 Train Loss: 0.308 | Train Acc: 100.000
66 Train Loss: 0.294 | Train Acc: 100.000
67 Train Loss: 0.289 | Train Acc: 100.000
68 Train Loss: 0.285 | Train Acc: 100.000
69 Train Loss: 0.280 | Train Acc: 100.000
70 Train Loss: 0.277 | Train Acc: 100.000
71 Train Loss: 0.271 | Train Acc: 100.000
72 Train Loss: 0.265 | Train Acc: 100.000
73 Train Loss: 0.265 | Train Acc: 100.000
74 Train Loss: 0.256 | Train Acc: 100.000
75 Train Loss: 0.249 | Train Acc: 100.000
76 Train Loss: 0.245 | Train Acc: 100.000
77 Train Loss: 0.239 | Train Acc: 100.000
78 Train Loss: 0.235 | Train Acc: 100.000
79 Train Loss: 0.234 | Train Acc: 100.000
80 Train Loss: 0.220 | Train Acc: 100.000
81 Train Loss: 0.217 | Train Acc: 100.000
82 Train Loss: 0.215 | Train Acc: 100.000
83 Train Loss: 0.212 | Train Acc: 100.000
84 Train Loss: 0.211 | Train Acc: 100.000
85 Train Loss: 0.209 | Train Acc: 100.000
86 Train Loss: 0.206 | Train Acc: 100.000
87 Train Loss: 0.205 | Train Acc: 100.000
88 Train Loss: 0.202 | Train Acc: 100.000
89 Train Loss: 0.200 | Train Acc: 100.000
90 Train Loss: 0.198 | Train Acc: 100.000
91 Train Loss: 0.196 | Train Acc: 100.000
92 Train Loss: 0.192 | Train Acc: 100.000
93 Train Loss: 0.192 | Train Acc: 100.000
94 Train Loss: 0.191 | Train Acc: 100.000
95 Train Loss: 0.188 | Train Acc: 100.000
96 Train Loss: 0.184 | Train Acc: 100.000
97 Train Loss: 0.182 | Train Acc: 100.000
98 Train Loss: 0.179 | Train Acc: 100.000
99 Train Loss: 0.176 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  116
trainInputDict[data].shape :  torch.Size([1538, 16, 8, 8])
copy.shape :  torch.Size([1538, 1024])
copyLabel.shape :  torch.Size([1538])
Class 0 has 527 instances after oversampling
Class 1 has 528 instances after oversampling
Class 2 has 527 instances after oversampling
Class 3 has 528 instances after oversampling
Class 4 has 527 instances after oversampling
Class 5 has 528 instances after oversampling
Class 6 has 527 instances after oversampling
Class 7 has 527 instances after oversampling
Class 8 has 527 instances after oversampling
0 Train Loss: 194.636 | Train Acc: 26.681
1 Train Loss: 141.228 | Train Acc: 51.787
2 Train Loss: 111.011 | Train Acc: 62.021
3 Train Loss: 97.002 | Train Acc: 65.596
4 Train Loss: 81.593 | Train Acc: 71.979
5 Train Loss: 69.323 | Train Acc: 76.702
6 Train Loss: 61.834 | Train Acc: 79.766
7 Train Loss: 56.246 | Train Acc: 81.128
8 Train Loss: 51.275 | Train Acc: 82.511
9 Train Loss: 46.383 | Train Acc: 84.426
10 Train Loss: 42.109 | Train Acc: 84.936
11 Train Loss: 41.616 | Train Acc: 85.170
12 Train Loss: 35.636 | Train Acc: 88.000
13 Train Loss: 34.652 | Train Acc: 88.404
14 Train Loss: 34.045 | Train Acc: 88.383
15 Train Loss: 29.006 | Train Acc: 90.298
16 Train Loss: 27.478 | Train Acc: 90.319
17 Train Loss: 26.084 | Train Acc: 91.106
18 Train Loss: 23.057 | Train Acc: 92.043
19 Train Loss: 23.242 | Train Acc: 92.128
20 Train Loss: 18.931 | Train Acc: 94.277
21 Train Loss: 17.832 | Train Acc: 94.149
22 Train Loss: 17.719 | Train Acc: 94.489
23 Train Loss: 17.477 | Train Acc: 94.532
24 Train Loss: 16.979 | Train Acc: 94.553
25 Train Loss: 16.239 | Train Acc: 95.149
26 Train Loss: 16.002 | Train Acc: 95.128
27 Train Loss: 15.421 | Train Acc: 94.936
28 Train Loss: 15.309 | Train Acc: 95.447
29 Train Loss: 14.425 | Train Acc: 95.766
30 Train Loss: 14.683 | Train Acc: 95.383
31 Train Loss: 13.875 | Train Acc: 95.766
32 Train Loss: 13.425 | Train Acc: 96.191
33 Train Loss: 13.218 | Train Acc: 96.191
34 Train Loss: 12.920 | Train Acc: 96.213
35 Train Loss: 12.507 | Train Acc: 96.489
36 Train Loss: 11.902 | Train Acc: 96.851
37 Train Loss: 11.833 | Train Acc: 96.468
38 Train Loss: 11.503 | Train Acc: 96.809
39 Train Loss: 11.535 | Train Acc: 96.553
40 Train Loss: 10.132 | Train Acc: 97.447
41 Train Loss: 9.865 | Train Acc: 97.553
42 Train Loss: 9.774 | Train Acc: 97.745
43 Train Loss: 9.666 | Train Acc: 97.809
44 Train Loss: 9.612 | Train Acc: 97.702
45 Train Loss: 9.359 | Train Acc: 97.787
46 Train Loss: 9.402 | Train Acc: 97.702
47 Train Loss: 9.186 | Train Acc: 97.851
48 Train Loss: 9.076 | Train Acc: 97.830
49 Train Loss: 8.901 | Train Acc: 97.894
50 Train Loss: 8.832 | Train Acc: 97.872
51 Train Loss: 8.642 | Train Acc: 97.979
52 Train Loss: 8.574 | Train Acc: 98.106
53 Train Loss: 8.518 | Train Acc: 98.064
54 Train Loss: 8.386 | Train Acc: 98.213
55 Train Loss: 8.201 | Train Acc: 98.000
56 Train Loss: 7.999 | Train Acc: 98.234
57 Train Loss: 7.985 | Train Acc: 98.277
58 Train Loss: 7.765 | Train Acc: 98.255
59 Train Loss: 7.661 | Train Acc: 98.170
60 Train Loss: 7.383 | Train Acc: 98.468
61 Train Loss: 7.287 | Train Acc: 98.511
62 Train Loss: 7.224 | Train Acc: 98.574
63 Train Loss: 7.216 | Train Acc: 98.489
64 Train Loss: 7.155 | Train Acc: 98.426
65 Train Loss: 7.113 | Train Acc: 98.489
66 Train Loss: 7.066 | Train Acc: 98.553
67 Train Loss: 7.033 | Train Acc: 98.468
68 Train Loss: 6.934 | Train Acc: 98.532
69 Train Loss: 6.921 | Train Acc: 98.553
70 Train Loss: 6.937 | Train Acc: 98.553
71 Train Loss: 6.881 | Train Acc: 98.638
72 Train Loss: 6.777 | Train Acc: 98.681
73 Train Loss: 6.732 | Train Acc: 98.553
74 Train Loss: 6.659 | Train Acc: 98.617
75 Train Loss: 6.638 | Train Acc: 98.617
76 Train Loss: 6.613 | Train Acc: 98.553
77 Train Loss: 6.524 | Train Acc: 98.681
78 Train Loss: 6.501 | Train Acc: 98.681
79 Train Loss: 6.425 | Train Acc: 98.702
80 Train Loss: 6.311 | Train Acc: 98.787
81 Train Loss: 6.276 | Train Acc: 98.745
82 Train Loss: 6.250 | Train Acc: 98.830
83 Train Loss: 6.230 | Train Acc: 98.702
84 Train Loss: 6.221 | Train Acc: 98.809
85 Train Loss: 6.208 | Train Acc: 98.787
86 Train Loss: 6.169 | Train Acc: 98.766
87 Train Loss: 6.169 | Train Acc: 98.723
88 Train Loss: 6.133 | Train Acc: 98.745
89 Train Loss: 6.160 | Train Acc: 98.787
90 Train Loss: 6.107 | Train Acc: 98.894
91 Train Loss: 6.097 | Train Acc: 98.681
92 Train Loss: 6.085 | Train Acc: 98.851
93 Train Loss: 6.039 | Train Acc: 98.809
94 Train Loss: 6.028 | Train Acc: 98.809
95 Train Loss: 6.010 | Train Acc: 98.787
96 Train Loss: 5.992 | Train Acc: 98.851
97 Train Loss: 5.968 | Train Acc: 98.830
98 Train Loss: 5.961 | Train Acc: 98.830
99 Train Loss: 5.945 | Train Acc: 98.787
CNN trained successfully...
Running nodeId:  117
trainInputDict[data].shape :  torch.Size([244, 16, 8, 8])
copy.shape :  torch.Size([244, 1024])
copyLabel.shape :  torch.Size([244])
Class 0 has 68 instances after oversampling
Class 1 has 68 instances after oversampling
Class 2 has 68 instances after oversampling
Class 3 has 68 instances after oversampling
Class 4 has 68 instances after oversampling
Class 5 has 68 instances after oversampling
Class 6 has 68 instances after oversampling
Class 7 has 68 instances after oversampling
Class 8 has 68 instances after oversampling
0 Train Loss: 215.466 | Train Acc: 18.667
1 Train Loss: 184.882 | Train Acc: 31.000
2 Train Loss: 151.713 | Train Acc: 45.500
3 Train Loss: 114.017 | Train Acc: 60.500
4 Train Loss: 81.668 | Train Acc: 73.667
5 Train Loss: 67.546 | Train Acc: 77.167
6 Train Loss: 52.393 | Train Acc: 85.000
7 Train Loss: 44.687 | Train Acc: 86.333
8 Train Loss: 32.466 | Train Acc: 91.333
9 Train Loss: 29.299 | Train Acc: 91.000
10 Train Loss: 21.241 | Train Acc: 94.333
11 Train Loss: 18.943 | Train Acc: 95.000
12 Train Loss: 16.372 | Train Acc: 96.167
13 Train Loss: 13.045 | Train Acc: 96.833
14 Train Loss: 10.243 | Train Acc: 97.667
15 Train Loss: 9.550 | Train Acc: 98.500
16 Train Loss: 7.351 | Train Acc: 98.667
17 Train Loss: 12.758 | Train Acc: 96.667
18 Train Loss: 13.465 | Train Acc: 97.167
19 Train Loss: 5.417 | Train Acc: 99.167
20 Train Loss: 4.380 | Train Acc: 99.500
21 Train Loss: 3.415 | Train Acc: 99.667
22 Train Loss: 3.029 | Train Acc: 99.667
23 Train Loss: 2.992 | Train Acc: 99.667
24 Train Loss: 3.009 | Train Acc: 99.667
25 Train Loss: 2.618 | Train Acc: 99.833
26 Train Loss: 2.349 | Train Acc: 100.000
27 Train Loss: 2.209 | Train Acc: 100.000
28 Train Loss: 2.034 | Train Acc: 100.000
29 Train Loss: 1.951 | Train Acc: 100.000
30 Train Loss: 1.915 | Train Acc: 100.000
31 Train Loss: 1.726 | Train Acc: 100.000
32 Train Loss: 1.532 | Train Acc: 100.000
33 Train Loss: 1.460 | Train Acc: 100.000
34 Train Loss: 1.368 | Train Acc: 100.000
35 Train Loss: 1.302 | Train Acc: 100.000
36 Train Loss: 1.268 | Train Acc: 100.000
37 Train Loss: 1.196 | Train Acc: 100.000
38 Train Loss: 1.063 | Train Acc: 100.000
39 Train Loss: 1.024 | Train Acc: 100.000
40 Train Loss: 0.889 | Train Acc: 100.000
41 Train Loss: 0.845 | Train Acc: 100.000
42 Train Loss: 0.805 | Train Acc: 100.000
43 Train Loss: 0.784 | Train Acc: 100.000
44 Train Loss: 0.758 | Train Acc: 100.000
45 Train Loss: 0.738 | Train Acc: 100.000
46 Train Loss: 0.724 | Train Acc: 100.000
47 Train Loss: 0.701 | Train Acc: 100.000
48 Train Loss: 0.688 | Train Acc: 100.000
49 Train Loss: 0.662 | Train Acc: 100.000
50 Train Loss: 0.644 | Train Acc: 100.000
51 Train Loss: 0.626 | Train Acc: 100.000
52 Train Loss: 0.605 | Train Acc: 100.000
53 Train Loss: 0.580 | Train Acc: 100.000
54 Train Loss: 0.570 | Train Acc: 100.000
55 Train Loss: 0.554 | Train Acc: 100.000
56 Train Loss: 0.537 | Train Acc: 100.000
57 Train Loss: 0.506 | Train Acc: 100.000
58 Train Loss: 0.501 | Train Acc: 100.000
59 Train Loss: 0.482 | Train Acc: 100.000
60 Train Loss: 0.445 | Train Acc: 100.000
61 Train Loss: 0.433 | Train Acc: 100.000
62 Train Loss: 0.428 | Train Acc: 100.000
63 Train Loss: 0.425 | Train Acc: 100.000
64 Train Loss: 0.416 | Train Acc: 100.000
65 Train Loss: 0.415 | Train Acc: 100.000
66 Train Loss: 0.405 | Train Acc: 100.000
67 Train Loss: 0.397 | Train Acc: 100.000
68 Train Loss: 0.390 | Train Acc: 100.000
69 Train Loss: 0.382 | Train Acc: 100.000
70 Train Loss: 0.375 | Train Acc: 100.000
71 Train Loss: 0.370 | Train Acc: 100.000
72 Train Loss: 0.364 | Train Acc: 100.000
73 Train Loss: 0.356 | Train Acc: 100.000
74 Train Loss: 0.347 | Train Acc: 100.000
75 Train Loss: 0.341 | Train Acc: 100.000
76 Train Loss: 0.334 | Train Acc: 100.000
77 Train Loss: 0.326 | Train Acc: 100.000
78 Train Loss: 0.318 | Train Acc: 100.000
79 Train Loss: 0.316 | Train Acc: 100.000
80 Train Loss: 0.299 | Train Acc: 100.000
81 Train Loss: 0.295 | Train Acc: 100.000
82 Train Loss: 0.293 | Train Acc: 100.000
83 Train Loss: 0.290 | Train Acc: 100.000
84 Train Loss: 0.286 | Train Acc: 100.000
85 Train Loss: 0.284 | Train Acc: 100.000
86 Train Loss: 0.281 | Train Acc: 100.000
87 Train Loss: 0.277 | Train Acc: 100.000
88 Train Loss: 0.276 | Train Acc: 100.000
89 Train Loss: 0.272 | Train Acc: 100.000
90 Train Loss: 0.269 | Train Acc: 100.000
91 Train Loss: 0.265 | Train Acc: 100.000
92 Train Loss: 0.262 | Train Acc: 100.000
93 Train Loss: 0.259 | Train Acc: 100.000
94 Train Loss: 0.256 | Train Acc: 100.000
95 Train Loss: 0.252 | Train Acc: 100.000
96 Train Loss: 0.249 | Train Acc: 100.000
97 Train Loss: 0.247 | Train Acc: 100.000
98 Train Loss: 0.242 | Train Acc: 100.000
99 Train Loss: 0.240 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  118
trainInputDict[data].shape :  torch.Size([460, 16, 8, 8])
copy.shape :  torch.Size([460, 1024])
copyLabel.shape :  torch.Size([460])
Class 0 has 126 instances after oversampling
Class 1 has 126 instances after oversampling
Class 2 has 127 instances after oversampling
Class 3 has 127 instances after oversampling
Class 4 has 127 instances after oversampling
Class 5 has 127 instances after oversampling
Class 6 has 127 instances after oversampling
Class 7 has 127 instances after oversampling
Class 8 has 126 instances after oversampling
0 Train Loss: 196.357 | Train Acc: 26.455
1 Train Loss: 139.005 | Train Acc: 51.182
2 Train Loss: 107.162 | Train Acc: 63.273
3 Train Loss: 80.874 | Train Acc: 74.000
4 Train Loss: 61.925 | Train Acc: 81.182
5 Train Loss: 52.778 | Train Acc: 83.909
6 Train Loss: 40.037 | Train Acc: 87.545
7 Train Loss: 30.880 | Train Acc: 92.000
8 Train Loss: 25.144 | Train Acc: 93.273
9 Train Loss: 20.117 | Train Acc: 95.182
10 Train Loss: 16.115 | Train Acc: 96.909
11 Train Loss: 12.160 | Train Acc: 98.273
12 Train Loss: 9.959 | Train Acc: 97.545
13 Train Loss: 7.368 | Train Acc: 99.000
14 Train Loss: 5.452 | Train Acc: 99.727
15 Train Loss: 4.160 | Train Acc: 99.909
16 Train Loss: 3.802 | Train Acc: 99.909
17 Train Loss: 2.765 | Train Acc: 99.818
18 Train Loss: 2.396 | Train Acc: 100.000
19 Train Loss: 2.058 | Train Acc: 100.000
20 Train Loss: 1.606 | Train Acc: 100.000
21 Train Loss: 1.389 | Train Acc: 100.000
22 Train Loss: 1.325 | Train Acc: 100.000
23 Train Loss: 1.235 | Train Acc: 100.000
24 Train Loss: 1.153 | Train Acc: 100.000
25 Train Loss: 1.126 | Train Acc: 100.000
26 Train Loss: 1.035 | Train Acc: 100.000
27 Train Loss: 0.978 | Train Acc: 100.000
28 Train Loss: 0.922 | Train Acc: 100.000
29 Train Loss: 0.881 | Train Acc: 100.000
30 Train Loss: 0.847 | Train Acc: 100.000
31 Train Loss: 0.792 | Train Acc: 100.000
32 Train Loss: 0.746 | Train Acc: 100.000
33 Train Loss: 0.707 | Train Acc: 100.000
34 Train Loss: 0.676 | Train Acc: 100.000
35 Train Loss: 0.626 | Train Acc: 100.000
36 Train Loss: 0.597 | Train Acc: 100.000
37 Train Loss: 0.571 | Train Acc: 100.000
38 Train Loss: 0.532 | Train Acc: 100.000
39 Train Loss: 0.495 | Train Acc: 100.000
40 Train Loss: 0.465 | Train Acc: 100.000
41 Train Loss: 0.450 | Train Acc: 100.000
42 Train Loss: 0.438 | Train Acc: 100.000
43 Train Loss: 0.430 | Train Acc: 100.000
44 Train Loss: 0.416 | Train Acc: 100.000
45 Train Loss: 0.409 | Train Acc: 100.000
46 Train Loss: 0.398 | Train Acc: 100.000
47 Train Loss: 0.391 | Train Acc: 100.000
48 Train Loss: 0.376 | Train Acc: 100.000
49 Train Loss: 0.370 | Train Acc: 100.000
50 Train Loss: 0.359 | Train Acc: 100.000
51 Train Loss: 0.349 | Train Acc: 100.000
52 Train Loss: 0.341 | Train Acc: 100.000
53 Train Loss: 0.328 | Train Acc: 100.000
54 Train Loss: 0.318 | Train Acc: 100.000
55 Train Loss: 0.308 | Train Acc: 100.000
56 Train Loss: 0.297 | Train Acc: 100.000
57 Train Loss: 0.292 | Train Acc: 100.000
58 Train Loss: 0.282 | Train Acc: 100.000
59 Train Loss: 0.275 | Train Acc: 100.000
60 Train Loss: 0.253 | Train Acc: 100.000
61 Train Loss: 0.250 | Train Acc: 100.000
62 Train Loss: 0.245 | Train Acc: 100.000
63 Train Loss: 0.242 | Train Acc: 100.000
64 Train Loss: 0.241 | Train Acc: 100.000
65 Train Loss: 0.235 | Train Acc: 100.000
66 Train Loss: 0.232 | Train Acc: 100.000
67 Train Loss: 0.227 | Train Acc: 100.000
68 Train Loss: 0.224 | Train Acc: 100.000
69 Train Loss: 0.219 | Train Acc: 100.000
70 Train Loss: 0.216 | Train Acc: 100.000
71 Train Loss: 0.211 | Train Acc: 100.000
72 Train Loss: 0.207 | Train Acc: 100.000
73 Train Loss: 0.204 | Train Acc: 100.000
74 Train Loss: 0.199 | Train Acc: 100.000
75 Train Loss: 0.195 | Train Acc: 100.000
76 Train Loss: 0.191 | Train Acc: 100.000
77 Train Loss: 0.186 | Train Acc: 100.000
78 Train Loss: 0.181 | Train Acc: 100.000
79 Train Loss: 0.178 | Train Acc: 100.000
80 Train Loss: 0.171 | Train Acc: 100.000
81 Train Loss: 0.169 | Train Acc: 100.000
82 Train Loss: 0.168 | Train Acc: 100.000
83 Train Loss: 0.166 | Train Acc: 100.000
84 Train Loss: 0.165 | Train Acc: 100.000
85 Train Loss: 0.162 | Train Acc: 100.000
86 Train Loss: 0.161 | Train Acc: 100.000
87 Train Loss: 0.159 | Train Acc: 100.000
88 Train Loss: 0.157 | Train Acc: 100.000
89 Train Loss: 0.156 | Train Acc: 100.000
90 Train Loss: 0.154 | Train Acc: 100.000
91 Train Loss: 0.151 | Train Acc: 100.000
92 Train Loss: 0.150 | Train Acc: 100.000
93 Train Loss: 0.147 | Train Acc: 100.000
94 Train Loss: 0.145 | Train Acc: 100.000
95 Train Loss: 0.144 | Train Acc: 100.000
96 Train Loss: 0.141 | Train Acc: 100.000
97 Train Loss: 0.139 | Train Acc: 100.000
98 Train Loss: 0.138 | Train Acc: 100.000
99 Train Loss: 0.135 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  119
trainInputDict[data].shape :  torch.Size([259, 16, 8, 8])
copy.shape :  torch.Size([259, 1024])
copyLabel.shape :  torch.Size([259])
Class 0 has 90 instances after oversampling
Class 1 has 1 instances after oversampling
Class 2 has 90 instances after oversampling
Class 3 has 90 instances after oversampling
Class 4 has 90 instances after oversampling
Class 5 has 90 instances after oversampling
Class 6 has 90 instances after oversampling
Class 7 has 90 instances after oversampling
Class 8 has 90 instances after oversampling
0 Train Loss: 169.693 | Train Acc: 44.714
1 Train Loss: 71.347 | Train Acc: 77.143
2 Train Loss: 41.902 | Train Acc: 87.429
3 Train Loss: 25.381 | Train Acc: 92.857
4 Train Loss: 18.129 | Train Acc: 95.286
5 Train Loss: 13.720 | Train Acc: 96.429
6 Train Loss: 8.376 | Train Acc: 98.286
7 Train Loss: 4.680 | Train Acc: 99.286
8 Train Loss: 3.708 | Train Acc: 99.429
9 Train Loss: 2.146 | Train Acc: 100.000
10 Train Loss: 1.576 | Train Acc: 100.000
11 Train Loss: 1.127 | Train Acc: 100.000
12 Train Loss: 1.008 | Train Acc: 100.000
13 Train Loss: 0.831 | Train Acc: 100.000
14 Train Loss: 0.647 | Train Acc: 100.000
15 Train Loss: 0.515 | Train Acc: 100.000
16 Train Loss: 0.426 | Train Acc: 100.000
17 Train Loss: 0.398 | Train Acc: 100.000
18 Train Loss: 0.339 | Train Acc: 100.000
19 Train Loss: 0.302 | Train Acc: 100.000
20 Train Loss: 0.256 | Train Acc: 100.000
21 Train Loss: 0.243 | Train Acc: 100.000
22 Train Loss: 0.233 | Train Acc: 100.000
23 Train Loss: 0.222 | Train Acc: 100.000
24 Train Loss: 0.214 | Train Acc: 100.000
25 Train Loss: 0.204 | Train Acc: 100.000
26 Train Loss: 0.195 | Train Acc: 100.000
27 Train Loss: 0.188 | Train Acc: 100.000
28 Train Loss: 0.180 | Train Acc: 100.000
29 Train Loss: 0.167 | Train Acc: 100.000
30 Train Loss: 0.163 | Train Acc: 100.000
31 Train Loss: 0.153 | Train Acc: 100.000
32 Train Loss: 0.145 | Train Acc: 100.000
33 Train Loss: 0.139 | Train Acc: 100.000
34 Train Loss: 0.133 | Train Acc: 100.000
35 Train Loss: 0.125 | Train Acc: 100.000
36 Train Loss: 0.119 | Train Acc: 100.000
37 Train Loss: 0.117 | Train Acc: 100.000
38 Train Loss: 0.107 | Train Acc: 100.000
39 Train Loss: 0.104 | Train Acc: 100.000
40 Train Loss: 0.095 | Train Acc: 100.000
41 Train Loss: 0.093 | Train Acc: 100.000
42 Train Loss: 0.091 | Train Acc: 100.000
43 Train Loss: 0.089 | Train Acc: 100.000
44 Train Loss: 0.087 | Train Acc: 100.000
45 Train Loss: 0.086 | Train Acc: 100.000
46 Train Loss: 0.083 | Train Acc: 100.000
47 Train Loss: 0.081 | Train Acc: 100.000
48 Train Loss: 0.079 | Train Acc: 100.000
49 Train Loss: 0.077 | Train Acc: 100.000
50 Train Loss: 0.075 | Train Acc: 100.000
51 Train Loss: 0.073 | Train Acc: 100.000
52 Train Loss: 0.071 | Train Acc: 100.000
53 Train Loss: 0.069 | Train Acc: 100.000
54 Train Loss: 0.067 | Train Acc: 100.000
55 Train Loss: 0.065 | Train Acc: 100.000
56 Train Loss: 0.063 | Train Acc: 100.000
57 Train Loss: 0.061 | Train Acc: 100.000
58 Train Loss: 0.059 | Train Acc: 100.000
59 Train Loss: 0.057 | Train Acc: 100.000
60 Train Loss: 0.055 | Train Acc: 100.000
61 Train Loss: 0.054 | Train Acc: 100.000
62 Train Loss: 0.053 | Train Acc: 100.000
63 Train Loss: 0.052 | Train Acc: 100.000
64 Train Loss: 0.052 | Train Acc: 100.000
65 Train Loss: 0.051 | Train Acc: 100.000
66 Train Loss: 0.050 | Train Acc: 100.000
67 Train Loss: 0.049 | Train Acc: 100.000
68 Train Loss: 0.048 | Train Acc: 100.000
69 Train Loss: 0.047 | Train Acc: 100.000
70 Train Loss: 0.046 | Train Acc: 100.000
71 Train Loss: 0.046 | Train Acc: 100.000
72 Train Loss: 0.045 | Train Acc: 100.000
73 Train Loss: 0.044 | Train Acc: 100.000
74 Train Loss: 0.043 | Train Acc: 100.000
75 Train Loss: 0.042 | Train Acc: 100.000
76 Train Loss: 0.041 | Train Acc: 100.000
77 Train Loss: 0.040 | Train Acc: 100.000
78 Train Loss: 0.039 | Train Acc: 100.000
79 Train Loss: 0.038 | Train Acc: 100.000
80 Train Loss: 0.037 | Train Acc: 100.000
81 Train Loss: 0.036 | Train Acc: 100.000
82 Train Loss: 0.036 | Train Acc: 100.000
83 Train Loss: 0.036 | Train Acc: 100.000
84 Train Loss: 0.035 | Train Acc: 100.000
85 Train Loss: 0.035 | Train Acc: 100.000
86 Train Loss: 0.034 | Train Acc: 100.000
87 Train Loss: 0.034 | Train Acc: 100.000
88 Train Loss: 0.034 | Train Acc: 100.000
89 Train Loss: 0.033 | Train Acc: 100.000
90 Train Loss: 0.033 | Train Acc: 100.000
91 Train Loss: 0.032 | Train Acc: 100.000
92 Train Loss: 0.032 | Train Acc: 100.000
93 Train Loss: 0.031 | Train Acc: 100.000
94 Train Loss: 0.031 | Train Acc: 100.000
95 Train Loss: 0.030 | Train Acc: 100.000
96 Train Loss: 0.030 | Train Acc: 100.000
97 Train Loss: 0.029 | Train Acc: 100.000
98 Train Loss: 0.029 | Train Acc: 100.000
99 Train Loss: 0.028 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  120
trainInputDict[data].shape :  torch.Size([381, 16, 8, 8])
copy.shape :  torch.Size([381, 1024])
copyLabel.shape :  torch.Size([381])
Class 0 has 171 instances after oversampling
Class 1 has 171 instances after oversampling
Class 2 has 171 instances after oversampling
Class 3 has 171 instances after oversampling
Class 4 has 171 instances after oversampling
Class 5 has 171 instances after oversampling
Class 6 has 171 instances after oversampling
Class 7 has 171 instances after oversampling
Class 8 has 1 instances after oversampling
Class 9 has 171 instances after oversampling
0 Train Loss: 201.256 | Train Acc: 32.733
1 Train Loss: 117.472 | Train Acc: 62.933
2 Train Loss: 66.434 | Train Acc: 80.400
3 Train Loss: 38.848 | Train Acc: 89.533
4 Train Loss: 28.817 | Train Acc: 92.200
5 Train Loss: 19.017 | Train Acc: 95.133
6 Train Loss: 12.700 | Train Acc: 97.200
7 Train Loss: 10.375 | Train Acc: 97.467
8 Train Loss: 5.651 | Train Acc: 99.200
9 Train Loss: 3.824 | Train Acc: 99.667
10 Train Loss: 2.810 | Train Acc: 99.733
11 Train Loss: 1.945 | Train Acc: 100.000
12 Train Loss: 1.622 | Train Acc: 100.000
13 Train Loss: 1.299 | Train Acc: 100.000
14 Train Loss: 0.995 | Train Acc: 100.000
15 Train Loss: 0.907 | Train Acc: 100.000
16 Train Loss: 0.723 | Train Acc: 100.000
17 Train Loss: 0.628 | Train Acc: 100.000
18 Train Loss: 0.550 | Train Acc: 100.000
19 Train Loss: 0.468 | Train Acc: 100.000
20 Train Loss: 0.387 | Train Acc: 100.000
21 Train Loss: 0.373 | Train Acc: 100.000
22 Train Loss: 0.352 | Train Acc: 100.000
23 Train Loss: 0.334 | Train Acc: 100.000
24 Train Loss: 0.319 | Train Acc: 100.000
25 Train Loss: 0.303 | Train Acc: 100.000
26 Train Loss: 0.293 | Train Acc: 100.000
27 Train Loss: 0.273 | Train Acc: 100.000
28 Train Loss: 0.268 | Train Acc: 100.000
29 Train Loss: 0.251 | Train Acc: 100.000
30 Train Loss: 0.241 | Train Acc: 100.000
31 Train Loss: 0.224 | Train Acc: 100.000
32 Train Loss: 0.218 | Train Acc: 100.000
33 Train Loss: 0.206 | Train Acc: 100.000
34 Train Loss: 0.192 | Train Acc: 100.000
35 Train Loss: 0.181 | Train Acc: 100.000
36 Train Loss: 0.172 | Train Acc: 100.000
37 Train Loss: 0.166 | Train Acc: 100.000
38 Train Loss: 0.157 | Train Acc: 100.000
39 Train Loss: 0.145 | Train Acc: 100.000
40 Train Loss: 0.138 | Train Acc: 100.000
41 Train Loss: 0.135 | Train Acc: 100.000
42 Train Loss: 0.131 | Train Acc: 100.000
43 Train Loss: 0.129 | Train Acc: 100.000
44 Train Loss: 0.126 | Train Acc: 100.000
45 Train Loss: 0.123 | Train Acc: 100.000
46 Train Loss: 0.119 | Train Acc: 100.000
47 Train Loss: 0.116 | Train Acc: 100.000
48 Train Loss: 0.114 | Train Acc: 100.000
49 Train Loss: 0.111 | Train Acc: 100.000
50 Train Loss: 0.109 | Train Acc: 100.000
51 Train Loss: 0.105 | Train Acc: 100.000
52 Train Loss: 0.103 | Train Acc: 100.000
53 Train Loss: 0.098 | Train Acc: 100.000
54 Train Loss: 0.095 | Train Acc: 100.000
55 Train Loss: 0.094 | Train Acc: 100.000
56 Train Loss: 0.090 | Train Acc: 100.000
57 Train Loss: 0.087 | Train Acc: 100.000
58 Train Loss: 0.084 | Train Acc: 100.000
59 Train Loss: 0.082 | Train Acc: 100.000
60 Train Loss: 0.077 | Train Acc: 100.000
61 Train Loss: 0.076 | Train Acc: 100.000
62 Train Loss: 0.075 | Train Acc: 100.000
63 Train Loss: 0.074 | Train Acc: 100.000
64 Train Loss: 0.073 | Train Acc: 100.000
65 Train Loss: 0.072 | Train Acc: 100.000
66 Train Loss: 0.071 | Train Acc: 100.000
67 Train Loss: 0.069 | Train Acc: 100.000
68 Train Loss: 0.068 | Train Acc: 100.000
69 Train Loss: 0.067 | Train Acc: 100.000
70 Train Loss: 0.066 | Train Acc: 100.000
71 Train Loss: 0.065 | Train Acc: 100.000
72 Train Loss: 0.063 | Train Acc: 100.000
73 Train Loss: 0.062 | Train Acc: 100.000
74 Train Loss: 0.061 | Train Acc: 100.000
75 Train Loss: 0.060 | Train Acc: 100.000
76 Train Loss: 0.058 | Train Acc: 100.000
77 Train Loss: 0.056 | Train Acc: 100.000
78 Train Loss: 0.055 | Train Acc: 100.000
79 Train Loss: 0.054 | Train Acc: 100.000
80 Train Loss: 0.052 | Train Acc: 100.000
81 Train Loss: 0.051 | Train Acc: 100.000
82 Train Loss: 0.051 | Train Acc: 100.000
83 Train Loss: 0.050 | Train Acc: 100.000
84 Train Loss: 0.050 | Train Acc: 100.000
85 Train Loss: 0.049 | Train Acc: 100.000
86 Train Loss: 0.048 | Train Acc: 100.000
87 Train Loss: 0.048 | Train Acc: 100.000
88 Train Loss: 0.047 | Train Acc: 100.000
89 Train Loss: 0.047 | Train Acc: 100.000
90 Train Loss: 0.046 | Train Acc: 100.000
91 Train Loss: 0.046 | Train Acc: 100.000
92 Train Loss: 0.045 | Train Acc: 100.000
93 Train Loss: 0.044 | Train Acc: 100.000
94 Train Loss: 0.043 | Train Acc: 100.000
95 Train Loss: 0.043 | Train Acc: 100.000
96 Train Loss: 0.042 | Train Acc: 100.000
97 Train Loss: 0.041 | Train Acc: 100.000
98 Train Loss: 0.040 | Train Acc: 100.000
99 Train Loss: 0.040 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  121
trainInputDict[data].shape :  torch.Size([729, 16, 8, 8])
copy.shape :  torch.Size([729, 1024])
copyLabel.shape :  torch.Size([729])
Class 0 has 196 instances after oversampling
Class 1 has 196 instances after oversampling
Class 2 has 197 instances after oversampling
Class 3 has 196 instances after oversampling
Class 4 has 197 instances after oversampling
Class 5 has 196 instances after oversampling
Class 6 has 196 instances after oversampling
Class 7 has 196 instances after oversampling
Class 8 has 196 instances after oversampling
Class 9 has 196 instances after oversampling
0 Train Loss: 223.977 | Train Acc: 16.105
1 Train Loss: 190.818 | Train Acc: 33.789
2 Train Loss: 145.447 | Train Acc: 49.158
3 Train Loss: 116.069 | Train Acc: 61.368
4 Train Loss: 89.366 | Train Acc: 70.158
5 Train Loss: 71.241 | Train Acc: 76.947
6 Train Loss: 54.652 | Train Acc: 83.105
7 Train Loss: 47.162 | Train Acc: 85.263
8 Train Loss: 38.098 | Train Acc: 89.474
9 Train Loss: 30.111 | Train Acc: 91.474
10 Train Loss: 23.649 | Train Acc: 94.895
11 Train Loss: 20.187 | Train Acc: 95.632
12 Train Loss: 17.559 | Train Acc: 96.000
13 Train Loss: 12.687 | Train Acc: 97.789
14 Train Loss: 10.707 | Train Acc: 98.053
15 Train Loss: 9.220 | Train Acc: 98.895
16 Train Loss: 7.674 | Train Acc: 98.947
17 Train Loss: 5.990 | Train Acc: 99.316
18 Train Loss: 4.671 | Train Acc: 99.895
19 Train Loss: 3.906 | Train Acc: 99.895
20 Train Loss: 2.856 | Train Acc: 100.000
21 Train Loss: 2.647 | Train Acc: 100.000
22 Train Loss: 2.473 | Train Acc: 100.000
23 Train Loss: 2.326 | Train Acc: 100.000
24 Train Loss: 2.167 | Train Acc: 100.000
25 Train Loss: 2.078 | Train Acc: 100.000
26 Train Loss: 1.991 | Train Acc: 100.000
27 Train Loss: 1.832 | Train Acc: 100.000
28 Train Loss: 1.745 | Train Acc: 100.000
29 Train Loss: 1.639 | Train Acc: 100.000
30 Train Loss: 1.544 | Train Acc: 100.000
31 Train Loss: 1.438 | Train Acc: 100.000
32 Train Loss: 1.362 | Train Acc: 100.000
33 Train Loss: 1.316 | Train Acc: 100.000
34 Train Loss: 1.214 | Train Acc: 100.000
35 Train Loss: 1.134 | Train Acc: 100.000
36 Train Loss: 1.091 | Train Acc: 100.000
37 Train Loss: 1.011 | Train Acc: 100.000
38 Train Loss: 0.952 | Train Acc: 100.000
39 Train Loss: 0.882 | Train Acc: 100.000
40 Train Loss: 0.813 | Train Acc: 100.000
41 Train Loss: 0.787 | Train Acc: 100.000
42 Train Loss: 0.759 | Train Acc: 100.000
43 Train Loss: 0.745 | Train Acc: 100.000
44 Train Loss: 0.726 | Train Acc: 100.000
45 Train Loss: 0.710 | Train Acc: 100.000
46 Train Loss: 0.690 | Train Acc: 100.000
47 Train Loss: 0.672 | Train Acc: 100.000
48 Train Loss: 0.653 | Train Acc: 100.000
49 Train Loss: 0.637 | Train Acc: 100.000
50 Train Loss: 0.617 | Train Acc: 100.000
51 Train Loss: 0.596 | Train Acc: 100.000
52 Train Loss: 0.580 | Train Acc: 100.000
53 Train Loss: 0.564 | Train Acc: 100.000
54 Train Loss: 0.549 | Train Acc: 100.000
55 Train Loss: 0.528 | Train Acc: 100.000
56 Train Loss: 0.514 | Train Acc: 100.000
57 Train Loss: 0.493 | Train Acc: 100.000
58 Train Loss: 0.477 | Train Acc: 100.000
59 Train Loss: 0.464 | Train Acc: 100.000
60 Train Loss: 0.431 | Train Acc: 100.000
61 Train Loss: 0.427 | Train Acc: 100.000
62 Train Loss: 0.420 | Train Acc: 100.000
63 Train Loss: 0.413 | Train Acc: 100.000
64 Train Loss: 0.406 | Train Acc: 100.000
65 Train Loss: 0.402 | Train Acc: 100.000
66 Train Loss: 0.394 | Train Acc: 100.000
67 Train Loss: 0.389 | Train Acc: 100.000
68 Train Loss: 0.381 | Train Acc: 100.000
69 Train Loss: 0.376 | Train Acc: 100.000
70 Train Loss: 0.367 | Train Acc: 100.000
71 Train Loss: 0.362 | Train Acc: 100.000
72 Train Loss: 0.355 | Train Acc: 100.000
73 Train Loss: 0.347 | Train Acc: 100.000
74 Train Loss: 0.339 | Train Acc: 100.000
75 Train Loss: 0.331 | Train Acc: 100.000
76 Train Loss: 0.327 | Train Acc: 100.000
77 Train Loss: 0.318 | Train Acc: 100.000
78 Train Loss: 0.311 | Train Acc: 100.000
79 Train Loss: 0.304 | Train Acc: 100.000
80 Train Loss: 0.291 | Train Acc: 100.000
81 Train Loss: 0.288 | Train Acc: 100.000
82 Train Loss: 0.286 | Train Acc: 100.000
83 Train Loss: 0.283 | Train Acc: 100.000
84 Train Loss: 0.280 | Train Acc: 100.000
85 Train Loss: 0.278 | Train Acc: 100.000
86 Train Loss: 0.275 | Train Acc: 100.000
87 Train Loss: 0.271 | Train Acc: 100.000
88 Train Loss: 0.268 | Train Acc: 100.000
89 Train Loss: 0.266 | Train Acc: 100.000
90 Train Loss: 0.262 | Train Acc: 100.000
91 Train Loss: 0.258 | Train Acc: 100.000
92 Train Loss: 0.255 | Train Acc: 100.000
93 Train Loss: 0.253 | Train Acc: 100.000
94 Train Loss: 0.249 | Train Acc: 100.000
95 Train Loss: 0.246 | Train Acc: 100.000
96 Train Loss: 0.242 | Train Acc: 100.000
97 Train Loss: 0.240 | Train Acc: 100.000
98 Train Loss: 0.236 | Train Acc: 100.000
99 Train Loss: 0.232 | Train Acc: 100.000
CNN trained successfully...
Running nodeId:  122
trainInputDict[data].shape :  torch.Size([3226, 16, 8, 8])
copy.shape :  torch.Size([3226, 1024])
copyLabel.shape :  torch.Size([3226])
Class 0 has 1189 instances after oversampling
Class 1 has 1 instances after oversampling
Class 2 has 1189 instances after oversampling
Class 3 has 1189 instances after oversampling
Class 4 has 1189 instances after oversampling
Class 5 has 1189 instances after oversampling
Class 6 has 1189 instances after oversampling
Class 7 has 1189 instances after oversampling
Class 8 has 1189 instances after oversampling
Class 9 has 1189 instances after oversampling
0 Train Loss: 206.894 | Train Acc: 26.958
1 Train Loss: 147.611 | Train Acc: 50.411
2 Train Loss: 132.010 | Train Acc: 54.027
3 Train Loss: 113.371 | Train Acc: 59.428
4 Train Loss: 101.380 | Train Acc: 63.278
5 Train Loss: 95.051 | Train Acc: 66.679
6 Train Loss: 91.467 | Train Acc: 66.287
7 Train Loss: 80.376 | Train Acc: 71.304
8 Train Loss: 76.031 | Train Acc: 72.706
9 Train Loss: 76.113 | Train Acc: 72.155
10 Train Loss: 68.391 | Train Acc: 75.537
11 Train Loss: 64.269 | Train Acc: 77.649
12 Train Loss: 60.627 | Train Acc: 78.901
13 Train Loss: 60.269 | Train Acc: 78.817
14 Train Loss: 55.833 | Train Acc: 80.452
15 Train Loss: 52.203 | Train Acc: 81.648
16 Train Loss: 53.238 | Train Acc: 81.536
17 Train Loss: 48.766 | Train Acc: 83.227
18 Train Loss: 47.853 | Train Acc: 83.498
19 Train Loss: 43.451 | Train Acc: 84.975
20 Train Loss: 39.178 | Train Acc: 87.077
21 Train Loss: 36.121 | Train Acc: 88.189
22 Train Loss: 36.030 | Train Acc: 88.395
23 Train Loss: 34.292 | Train Acc: 89.320
24 Train Loss: 34.452 | Train Acc: 88.628
25 Train Loss: 33.193 | Train Acc: 89.479
26 Train Loss: 32.871 | Train Acc: 89.525
27 Train Loss: 31.378 | Train Acc: 90.142
28 Train Loss: 29.641 | Train Acc: 90.600
29 Train Loss: 29.457 | Train Acc: 91.039
30 Train Loss: 29.587 | Train Acc: 90.591
31 Train Loss: 28.495 | Train Acc: 90.964
32 Train Loss: 28.113 | Train Acc: 91.525
33 Train Loss: 27.146 | Train Acc: 91.721
34 Train Loss: 25.851 | Train Acc: 92.459
35 Train Loss: 25.851 | Train Acc: 92.478
36 Train Loss: 25.230 | Train Acc: 92.244
37 Train Loss: 23.706 | Train Acc: 92.917
38 Train Loss: 23.785 | Train Acc: 92.899
39 Train Loss: 22.939 | Train Acc: 93.459
40 Train Loss: 21.125 | Train Acc: 94.412
41 Train Loss: 21.021 | Train Acc: 94.356
42 Train Loss: 20.575 | Train Acc: 94.300
43 Train Loss: 20.098 | Train Acc: 94.590
44 Train Loss: 20.608 | Train Acc: 94.468
45 Train Loss: 19.811 | Train Acc: 94.814
46 Train Loss: 19.895 | Train Acc: 94.543
47 Train Loss: 19.637 | Train Acc: 94.758
48 Train Loss: 19.263 | Train Acc: 94.823
49 Train Loss: 19.086 | Train Acc: 94.982
50 Train Loss: 19.168 | Train Acc: 94.534
51 Train Loss: 18.587 | Train Acc: 95.001
52 Train Loss: 18.302 | Train Acc: 95.141
53 Train Loss: 18.272 | Train Acc: 95.356
54 Train Loss: 17.923 | Train Acc: 95.225
55 Train Loss: 17.976 | Train Acc: 95.384
56 Train Loss: 17.688 | Train Acc: 95.534
57 Train Loss: 17.694 | Train Acc: 95.431
58 Train Loss: 17.290 | Train Acc: 95.412
59 Train Loss: 17.085 | Train Acc: 95.711
60 Train Loss: 16.378 | Train Acc: 95.758
61 Train Loss: 16.260 | Train Acc: 95.991
62 Train Loss: 16.172 | Train Acc: 95.917
63 Train Loss: 15.986 | Train Acc: 96.132
64 Train Loss: 16.049 | Train Acc: 96.066
65 Train Loss: 15.858 | Train Acc: 96.104
66 Train Loss: 16.046 | Train Acc: 96.066
67 Train Loss: 15.691 | Train Acc: 96.113
68 Train Loss: 15.515 | Train Acc: 96.169
69 Train Loss: 15.677 | Train Acc: 96.225
70 Train Loss: 15.635 | Train Acc: 96.262
71 Train Loss: 15.408 | Train Acc: 96.244
72 Train Loss: 15.438 | Train Acc: 96.188
73 Train Loss: 15.505 | Train Acc: 96.197
74 Train Loss: 15.166 | Train Acc: 96.272
75 Train Loss: 15.300 | Train Acc: 96.356
76 Train Loss: 15.051 | Train Acc: 96.309
77 Train Loss: 15.000 | Train Acc: 96.281
78 Train Loss: 14.830 | Train Acc: 96.440
79 Train Loss: 14.969 | Train Acc: 96.431
80 Train Loss: 14.601 | Train Acc: 96.571
81 Train Loss: 14.527 | Train Acc: 96.543
82 Train Loss: 14.515 | Train Acc: 96.571
83 Train Loss: 14.492 | Train Acc: 96.496
84 Train Loss: 14.439 | Train Acc: 96.580
85 Train Loss: 14.403 | Train Acc: 96.636
86 Train Loss: 14.369 | Train Acc: 96.617
87 Train Loss: 14.333 | Train Acc: 96.683
88 Train Loss: 14.317 | Train Acc: 96.599
89 Train Loss: 14.269 | Train Acc: 96.561
90 Train Loss: 14.290 | Train Acc: 96.645
91 Train Loss: 14.239 | Train Acc: 96.636
92 Train Loss: 14.184 | Train Acc: 96.720
93 Train Loss: 14.178 | Train Acc: 96.655
94 Train Loss: 14.172 | Train Acc: 96.608
95 Train Loss: 14.117 | Train Acc: 96.702
96 Train Loss: 14.118 | Train Acc: 96.702
97 Train Loss: 14.039 | Train Acc: 96.702
98 Train Loss: 14.036 | Train Acc: 96.711
99 Train Loss: 14.004 | Train Acc: 96.767
CNN trained successfully...
Running nodeId:  123
trainInputDict[data].shape :  torch.Size([111, 16, 8, 8])
copy.shape :  torch.Size([111, 1024])
copyLabel.shape :  torch.Size([111])
Class 0 has 35 instances after oversampling
Class 1 has 35 instances after oversampling
Class 2 has 35 instances after oversampling
Class 3 has 35 instances after oversampling
Class 4 has 35 instances after oversampling
Class 5 has 35 instances after oversampling
Class 6 has 35 instances after oversampling
0 Train Loss: 2.198 | Train Acc: 7.755
1 Train Loss: 2.038 | Train Acc: 10.204
2 Train Loss: 1.923 | Train Acc: 23.265
3 Train Loss: 1.824 | Train Acc: 30.612
4 Train Loss: 1.735 | Train Acc: 40.000
5 Train Loss: 1.650 | Train Acc: 48.571
6 Train Loss: 1.568 | Train Acc: 54.694
7 Train Loss: 1.490 | Train Acc: 62.857
8 Train Loss: 1.412 | Train Acc: 70.204
9 Train Loss: 1.338 | Train Acc: 72.653
10 Train Loss: 1.266 | Train Acc: 74.694
11 Train Loss: 1.196 | Train Acc: 75.510
12 Train Loss: 1.127 | Train Acc: 77.959
13 Train Loss: 1.062 | Train Acc: 78.367
14 Train Loss: 1.000 | Train Acc: 79.592
15 Train Loss: 0.943 | Train Acc: 79.184
16 Train Loss: 0.889 | Train Acc: 81.633
17 Train Loss: 0.836 | Train Acc: 82.449
18 Train Loss: 0.785 | Train Acc: 83.265
19 Train Loss: 0.736 | Train Acc: 84.898
20 Train Loss: 0.689 | Train Acc: 86.939
21 Train Loss: 0.671 | Train Acc: 87.347
22 Train Loss: 0.653 | Train Acc: 87.755
23 Train Loss: 0.635 | Train Acc: 88.163
24 Train Loss: 0.618 | Train Acc: 88.571
25 Train Loss: 0.600 | Train Acc: 89.388
26 Train Loss: 0.583 | Train Acc: 89.796
27 Train Loss: 0.567 | Train Acc: 90.204
28 Train Loss: 0.550 | Train Acc: 90.612
29 Train Loss: 0.535 | Train Acc: 91.429
30 Train Loss: 0.519 | Train Acc: 91.429
31 Train Loss: 0.504 | Train Acc: 91.837
32 Train Loss: 0.490 | Train Acc: 92.245
33 Train Loss: 0.475 | Train Acc: 94.286
34 Train Loss: 0.462 | Train Acc: 94.286
35 Train Loss: 0.448 | Train Acc: 94.694
36 Train Loss: 0.435 | Train Acc: 95.102
37 Train Loss: 0.422 | Train Acc: 95.102
38 Train Loss: 0.409 | Train Acc: 95.510
39 Train Loss: 0.397 | Train Acc: 95.510
40 Train Loss: 0.385 | Train Acc: 95.510
41 Train Loss: 0.381 | Train Acc: 95.918
42 Train Loss: 0.376 | Train Acc: 95.918
43 Train Loss: 0.372 | Train Acc: 95.918
44 Train Loss: 0.367 | Train Acc: 95.918
45 Train Loss: 0.363 | Train Acc: 95.918
46 Train Loss: 0.358 | Train Acc: 96.327
47 Train Loss: 0.354 | Train Acc: 96.327
48 Train Loss: 0.350 | Train Acc: 96.735
49 Train Loss: 0.345 | Train Acc: 96.735
50 Train Loss: 0.341 | Train Acc: 96.735
51 Train Loss: 0.337 | Train Acc: 97.143
52 Train Loss: 0.333 | Train Acc: 97.143
53 Train Loss: 0.329 | Train Acc: 97.143
54 Train Loss: 0.325 | Train Acc: 97.143
55 Train Loss: 0.321 | Train Acc: 97.143
56 Train Loss: 0.317 | Train Acc: 97.143
57 Train Loss: 0.313 | Train Acc: 97.143
58 Train Loss: 0.309 | Train Acc: 97.143
59 Train Loss: 0.306 | Train Acc: 97.143
60 Train Loss: 0.302 | Train Acc: 97.143
61 Train Loss: 0.300 | Train Acc: 97.143
62 Train Loss: 0.299 | Train Acc: 97.143
63 Train Loss: 0.297 | Train Acc: 97.143
64 Train Loss: 0.296 | Train Acc: 97.143
65 Train Loss: 0.295 | Train Acc: 97.143
66 Train Loss: 0.293 | Train Acc: 97.143
67 Train Loss: 0.292 | Train Acc: 97.143
68 Train Loss: 0.290 | Train Acc: 97.143
69 Train Loss: 0.289 | Train Acc: 97.143
70 Train Loss: 0.287 | Train Acc: 97.143
71 Train Loss: 0.286 | Train Acc: 97.143
72 Train Loss: 0.284 | Train Acc: 97.143
73 Train Loss: 0.283 | Train Acc: 97.143
74 Train Loss: 0.282 | Train Acc: 97.143
75 Train Loss: 0.280 | Train Acc: 97.143
76 Train Loss: 0.279 | Train Acc: 97.143
77 Train Loss: 0.278 | Train Acc: 97.143
78 Train Loss: 0.276 | Train Acc: 97.143
79 Train Loss: 0.275 | Train Acc: 97.143
80 Train Loss: 0.273 | Train Acc: 97.143
81 Train Loss: 0.273 | Train Acc: 97.143
82 Train Loss: 0.272 | Train Acc: 97.143
83 Train Loss: 0.272 | Train Acc: 97.143
84 Train Loss: 0.271 | Train Acc: 97.143
85 Train Loss: 0.271 | Train Acc: 97.143
86 Train Loss: 0.270 | Train Acc: 97.143
87 Train Loss: 0.270 | Train Acc: 97.143
88 Train Loss: 0.269 | Train Acc: 97.143
89 Train Loss: 0.268 | Train Acc: 97.143
90 Train Loss: 0.268 | Train Acc: 97.143
91 Train Loss: 0.267 | Train Acc: 97.143
92 Train Loss: 0.267 | Train Acc: 97.143
93 Train Loss: 0.266 | Train Acc: 97.143
94 Train Loss: 0.266 | Train Acc: 97.143
95 Train Loss: 0.265 | Train Acc: 97.143
96 Train Loss: 0.265 | Train Acc: 97.143
97 Train Loss: 0.264 | Train Acc: 97.143
98 Train Loss: 0.264 | Train Acc: 97.143
99 Train Loss: 0.263 | Train Acc: 97.143
CNN trained successfully...
Running nodeId:  124
trainInputDict[data].shape :  torch.Size([3528, 16, 8, 8])
copy.shape :  torch.Size([3528, 1024])
copyLabel.shape :  torch.Size([3528])
Class 0 has 721 instances after oversampling
Class 1 has 721 instances after oversampling
Class 2 has 721 instances after oversampling
Class 3 has 721 instances after oversampling
Class 4 has 721 instances after oversampling
Class 5 has 721 instances after oversampling
Class 6 has 721 instances after oversampling
Class 7 has 721 instances after oversampling
Class 8 has 721 instances after oversampling
Class 9 has 721 instances after oversampling
0 Train Loss: 215.079 | Train Acc: 21.917
1 Train Loss: 167.636 | Train Acc: 42.708
2 Train Loss: 144.647 | Train Acc: 50.069
3 Train Loss: 130.433 | Train Acc: 54.778
4 Train Loss: 116.762 | Train Acc: 59.056
5 Train Loss: 110.077 | Train Acc: 60.556
6 Train Loss: 99.782 | Train Acc: 64.111
7 Train Loss: 93.076 | Train Acc: 67.014
8 Train Loss: 91.351 | Train Acc: 66.764
9 Train Loss: 86.412 | Train Acc: 69.347
10 Train Loss: 82.454 | Train Acc: 70.708
11 Train Loss: 80.028 | Train Acc: 71.597
12 Train Loss: 78.379 | Train Acc: 72.236
13 Train Loss: 74.445 | Train Acc: 73.667
14 Train Loss: 72.881 | Train Acc: 74.222
15 Train Loss: 69.745 | Train Acc: 75.222
16 Train Loss: 66.964 | Train Acc: 76.014
17 Train Loss: 66.443 | Train Acc: 76.486
18 Train Loss: 66.022 | Train Acc: 76.903
19 Train Loss: 63.254 | Train Acc: 78.000
20 Train Loss: 57.946 | Train Acc: 80.056
21 Train Loss: 57.455 | Train Acc: 80.194
22 Train Loss: 55.981 | Train Acc: 80.736
23 Train Loss: 55.402 | Train Acc: 80.889
24 Train Loss: 55.402 | Train Acc: 80.611
25 Train Loss: 54.840 | Train Acc: 81.111
26 Train Loss: 53.723 | Train Acc: 81.736
27 Train Loss: 53.319 | Train Acc: 81.958
28 Train Loss: 53.061 | Train Acc: 82.056
29 Train Loss: 51.775 | Train Acc: 82.222
30 Train Loss: 51.406 | Train Acc: 82.722
31 Train Loss: 51.111 | Train Acc: 82.306
32 Train Loss: 50.490 | Train Acc: 82.736
33 Train Loss: 50.286 | Train Acc: 82.694
34 Train Loss: 49.262 | Train Acc: 83.361
35 Train Loss: 48.447 | Train Acc: 83.500
36 Train Loss: 48.407 | Train Acc: 83.569
37 Train Loss: 48.006 | Train Acc: 83.861
38 Train Loss: 47.270 | Train Acc: 84.056
39 Train Loss: 46.883 | Train Acc: 84.306
40 Train Loss: 45.027 | Train Acc: 85.194
41 Train Loss: 45.088 | Train Acc: 85.222
42 Train Loss: 44.445 | Train Acc: 85.625
43 Train Loss: 44.350 | Train Acc: 85.736
44 Train Loss: 43.961 | Train Acc: 85.778
45 Train Loss: 44.113 | Train Acc: 85.722
46 Train Loss: 43.527 | Train Acc: 85.819
47 Train Loss: 43.508 | Train Acc: 85.861
48 Train Loss: 43.396 | Train Acc: 86.028
49 Train Loss: 43.409 | Train Acc: 86.111
50 Train Loss: 43.276 | Train Acc: 86.014
51 Train Loss: 42.743 | Train Acc: 86.361
52 Train Loss: 42.756 | Train Acc: 86.264
53 Train Loss: 42.317 | Train Acc: 86.500
54 Train Loss: 42.329 | Train Acc: 86.681
55 Train Loss: 42.090 | Train Acc: 86.361
56 Train Loss: 41.850 | Train Acc: 86.736
57 Train Loss: 41.680 | Train Acc: 86.556
58 Train Loss: 41.716 | Train Acc: 86.403
59 Train Loss: 41.610 | Train Acc: 86.597
60 Train Loss: 40.662 | Train Acc: 87.000
61 Train Loss: 40.450 | Train Acc: 87.306
62 Train Loss: 40.393 | Train Acc: 87.153
63 Train Loss: 40.369 | Train Acc: 87.222
64 Train Loss: 40.263 | Train Acc: 87.264
65 Train Loss: 40.227 | Train Acc: 87.278
66 Train Loss: 40.130 | Train Acc: 87.389
67 Train Loss: 40.084 | Train Acc: 87.347
68 Train Loss: 39.955 | Train Acc: 87.444
69 Train Loss: 39.891 | Train Acc: 87.500
70 Train Loss: 39.710 | Train Acc: 87.444
71 Train Loss: 39.790 | Train Acc: 87.389
72 Train Loss: 39.646 | Train Acc: 87.653
73 Train Loss: 39.601 | Train Acc: 87.653
74 Train Loss: 39.529 | Train Acc: 87.347
75 Train Loss: 39.507 | Train Acc: 87.472
76 Train Loss: 39.323 | Train Acc: 87.597
77 Train Loss: 39.234 | Train Acc: 87.569
78 Train Loss: 39.247 | Train Acc: 87.833
79 Train Loss: 39.116 | Train Acc: 87.833
80 Train Loss: 38.826 | Train Acc: 87.861
81 Train Loss: 38.829 | Train Acc: 88.000
82 Train Loss: 38.742 | Train Acc: 87.861
83 Train Loss: 38.773 | Train Acc: 88.000
84 Train Loss: 38.717 | Train Acc: 87.986
85 Train Loss: 38.669 | Train Acc: 87.986
86 Train Loss: 38.664 | Train Acc: 87.944
87 Train Loss: 38.639 | Train Acc: 87.972
88 Train Loss: 38.603 | Train Acc: 87.958
89 Train Loss: 38.551 | Train Acc: 87.944
90 Train Loss: 38.477 | Train Acc: 87.972
91 Train Loss: 38.516 | Train Acc: 87.986
92 Train Loss: 38.443 | Train Acc: 88.014
93 Train Loss: 38.445 | Train Acc: 88.083
94 Train Loss: 38.368 | Train Acc: 88.167
95 Train Loss: 38.362 | Train Acc: 88.125
96 Train Loss: 38.329 | Train Acc: 88.083
97 Train Loss: 38.284 | Train Acc: 88.014
98 Train Loss: 38.249 | Train Acc: 88.097
99 Train Loss: 38.238 | Train Acc: 88.153
CNN trained successfully...
Running nodeId:  125
trainInputDict[data].shape :  torch.Size([2166, 16, 8, 8])
copy.shape :  torch.Size([2166, 1024])
copyLabel.shape :  torch.Size([2166])
Class 0 has 917 instances after oversampling
Class 1 has 917 instances after oversampling
Class 2 has 917 instances after oversampling
Class 3 has 917 instances after oversampling
Class 4 has 917 instances after oversampling
Class 5 has 917 instances after oversampling
Class 6 has 917 instances after oversampling
Class 7 has 917 instances after oversampling
Class 8 has 917 instances after oversampling
Class 9 has 917 instances after oversampling
0 Train Loss: 220.534 | Train Acc: 20.207
1 Train Loss: 158.304 | Train Acc: 46.674
2 Train Loss: 116.749 | Train Acc: 59.913
3 Train Loss: 104.379 | Train Acc: 61.516
4 Train Loss: 97.183 | Train Acc: 64.155
5 Train Loss: 85.903 | Train Acc: 69.029
6 Train Loss: 79.870 | Train Acc: 71.156
7 Train Loss: 80.876 | Train Acc: 70.676
8 Train Loss: 73.440 | Train Acc: 73.391
9 Train Loss: 67.209 | Train Acc: 77.012
10 Train Loss: 65.324 | Train Acc: 77.339
11 Train Loss: 61.191 | Train Acc: 78.866
12 Train Loss: 57.060 | Train Acc: 80.589
13 Train Loss: 54.369 | Train Acc: 81.767
14 Train Loss: 52.553 | Train Acc: 82.912
15 Train Loss: 47.827 | Train Acc: 84.547
16 Train Loss: 45.983 | Train Acc: 84.569
17 Train Loss: 42.737 | Train Acc: 86.183
18 Train Loss: 40.327 | Train Acc: 87.350
19 Train Loss: 39.368 | Train Acc: 87.252
20 Train Loss: 37.158 | Train Acc: 88.670
21 Train Loss: 32.389 | Train Acc: 90.087
22 Train Loss: 31.683 | Train Acc: 90.523
23 Train Loss: 30.733 | Train Acc: 90.829
24 Train Loss: 30.333 | Train Acc: 90.818
25 Train Loss: 30.231 | Train Acc: 90.916
26 Train Loss: 29.051 | Train Acc: 91.341
27 Train Loss: 29.056 | Train Acc: 91.243
28 Train Loss: 28.143 | Train Acc: 91.799
29 Train Loss: 26.873 | Train Acc: 92.148
30 Train Loss: 26.414 | Train Acc: 92.050
31 Train Loss: 25.639 | Train Acc: 92.225
32 Train Loss: 26.533 | Train Acc: 91.778
33 Train Loss: 24.297 | Train Acc: 92.857
34 Train Loss: 24.203 | Train Acc: 92.726
35 Train Loss: 24.049 | Train Acc: 92.879
36 Train Loss: 22.999 | Train Acc: 93.206
37 Train Loss: 23.040 | Train Acc: 93.239
38 Train Loss: 22.093 | Train Acc: 93.370
39 Train Loss: 21.159 | Train Acc: 93.631
40 Train Loss: 20.348 | Train Acc: 94.177
41 Train Loss: 19.904 | Train Acc: 94.340
42 Train Loss: 19.639 | Train Acc: 94.569
43 Train Loss: 19.473 | Train Acc: 94.558
44 Train Loss: 19.404 | Train Acc: 94.591
45 Train Loss: 19.153 | Train Acc: 94.646
46 Train Loss: 18.861 | Train Acc: 94.842
47 Train Loss: 18.934 | Train Acc: 94.667
48 Train Loss: 18.682 | Train Acc: 94.918
49 Train Loss: 18.345 | Train Acc: 94.951
50 Train Loss: 18.498 | Train Acc: 94.995
51 Train Loss: 18.088 | Train Acc: 94.787
52 Train Loss: 17.859 | Train Acc: 95.005
53 Train Loss: 17.829 | Train Acc: 95.224
54 Train Loss: 17.444 | Train Acc: 95.191
55 Train Loss: 17.201 | Train Acc: 95.245
56 Train Loss: 17.259 | Train Acc: 95.071
57 Train Loss: 16.929 | Train Acc: 95.387
58 Train Loss: 16.724 | Train Acc: 95.540
59 Train Loss: 16.577 | Train Acc: 95.398
60 Train Loss: 16.049 | Train Acc: 95.703
61 Train Loss: 16.056 | Train Acc: 95.714
62 Train Loss: 15.902 | Train Acc: 95.692
63 Train Loss: 15.796 | Train Acc: 95.867
64 Train Loss: 15.797 | Train Acc: 95.878
65 Train Loss: 15.657 | Train Acc: 95.878
66 Train Loss: 15.702 | Train Acc: 95.889
67 Train Loss: 15.689 | Train Acc: 95.660
68 Train Loss: 15.481 | Train Acc: 95.834
69 Train Loss: 15.435 | Train Acc: 95.889
70 Train Loss: 15.295 | Train Acc: 96.020
71 Train Loss: 15.319 | Train Acc: 95.932
72 Train Loss: 15.233 | Train Acc: 95.900
73 Train Loss: 15.188 | Train Acc: 96.041
74 Train Loss: 15.053 | Train Acc: 95.987
75 Train Loss: 14.992 | Train Acc: 95.987
76 Train Loss: 14.800 | Train Acc: 95.998
77 Train Loss: 14.937 | Train Acc: 96.031
78 Train Loss: 14.822 | Train Acc: 96.107
79 Train Loss: 14.711 | Train Acc: 96.129
80 Train Loss: 14.600 | Train Acc: 96.129
81 Train Loss: 14.487 | Train Acc: 96.216
82 Train Loss: 14.442 | Train Acc: 96.205
83 Train Loss: 14.418 | Train Acc: 96.249
84 Train Loss: 14.385 | Train Acc: 96.227
85 Train Loss: 14.341 | Train Acc: 96.260
86 Train Loss: 14.340 | Train Acc: 96.238
87 Train Loss: 14.334 | Train Acc: 96.369
88 Train Loss: 14.288 | Train Acc: 96.336
89 Train Loss: 14.297 | Train Acc: 96.161
90 Train Loss: 14.252 | Train Acc: 96.292
91 Train Loss: 14.188 | Train Acc: 96.325
92 Train Loss: 14.222 | Train Acc: 96.314
93 Train Loss: 14.158 | Train Acc: 96.336
94 Train Loss: 14.106 | Train Acc: 96.314
95 Train Loss: 14.084 | Train Acc: 96.358
96 Train Loss: 14.071 | Train Acc: 96.379
97 Train Loss: 14.057 | Train Acc: 96.358
98 Train Loss: 14.013 | Train Acc: 96.390
99 Train Loss: 13.960 | Train Acc: 96.412
CNN trained successfully...
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 58.960
Split Acc: 73.620
# of Left images:  4890.0
# of Right images:  5110.0
giniRightRatio:  0.8753750177120951
giniLeftRatio:  0.8731094299538726
impurityDrop:  0.8732069699356357
giniGain:  0.026793030064364287
lclasses:  [866, 686, 373, 341, 250, 345, 139, 316, 884, 690]
rclasses:  [134, 314, 627, 659, 750, 655, 861, 684, 116, 310]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([4890, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([4890])
rTrainDict[data].shape:  torch.Size([5110, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([5110])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([4890, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 4890
nodeId:  3 , imgTensorShape :  torch.Size([5110, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 5110
Nodes sizes =  10 10
Node 2 Acc: 57.996
Split Acc: 81.104
# of Left images:  2770.0
# of Right images:  2120.0
giniRightRatio:  0.8849804200783197
giniLeftRatio:  0.7895176530386164
impurityDrop:  0.7602484084273866
giniGain:  0.11286102152648603
lclasses:  [647, 594, 100, 29, 76, 19, 21, 39, 780, 465]
rclasses:  [219, 92, 273, 312, 174, 326, 118, 277, 104, 225]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2770, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([2770])
rTrainDict[data].shape:  torch.Size([2120, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([2120])
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([2770, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2770
nodeId:  5 , imgTensorShape :  torch.Size([2120, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2120
Nodes sizes =  10 10
Node 3 Acc: 49.530
Split Acc: 88.474
# of Left images:  1149.0
# of Right images:  3961.0
giniRightRatio:  0.8440448883047481
giniLeftRatio:  0.842977698092942
impurityDrop:  0.8437353196217475
giniGain:  0.03163969809034761
lclasses:  [65, 297, 52, 91, 54, 42, 101, 94, 82, 271]
rclasses:  [69, 17, 575, 568, 696, 613, 760, 590, 34, 39]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1149, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([1149])
rTrainDict[data].shape:  torch.Size([3961, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([3961])
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([1149, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1149
nodeId:  7 , imgTensorShape :  torch.Size([3961, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 3961
Nodes sizes =  10 10
Node 4 Acc: 64.729
Split Acc: 74.332
# of Left images:  766.0
# of Right images:  2004.0
giniRightRatio:  0.7660666690570954
giniLeftRatio:  0.7237386579770808
impurityDrop:  0.7498873993528583
giniGain:  0.03963025368575812
lclasses:  [315, 22, 74, 11, 59, 12, 11, 11, 229, 22]
rclasses:  [332, 572, 26, 18, 17, 7, 10, 28, 551, 443]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([766, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([766])
rTrainDict[data].shape:  torch.Size([2004, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([2004])
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([766, 16, 20, 20])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 766
nodeId:  9 , imgTensorShape :  torch.Size([2004, 16, 20, 20])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2004
Nodes sizes =  10 10
Node 5 Acc: 45.000
Split Acc: 66.981
# of Left images:  800.0
# of Right images:  1320.0
giniRightRatio:  0.8707977502295685
giniLeftRatio:  0.87800625
impurityDrop:  0.875166537969224
giniGain:  0.009813882109095728
lclasses:  [137, 44, 72, 84, 56, 62, 39, 129, 42, 135]
rclasses:  [82, 48, 201, 228, 118, 264, 79, 148, 62, 90]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([800, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([800])
rTrainDict[data].shape:  torch.Size([1320, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([1320])
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([800, 16, 20, 20])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: 20 ,  rchildId: 21 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 800
nodeId:  11 , imgTensorShape :  torch.Size([1320, 16, 20, 20])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 22 ,  rchildId: 23 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1320
Nodes sizes =  10 10
Node 6 Acc: 48.303
Split Acc: 62.489
# of Left images:  681.0
# of Right images:  468.0
giniRightRatio:  0.8636313828621521
giniLeftRatio:  0.810400184577832
impurityDrop:  0.7861731648458659
giniGain:  0.05680453324707613
lclasses:  [21, 188, 26, 58, 28, 32, 44, 70, 16, 198]
rclasses:  [44, 109, 26, 33, 26, 10, 57, 24, 66, 73]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([681, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([681])
rTrainDict[data].shape:  torch.Size([468, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([468])
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([681, 16, 20, 20])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: 24 ,  rchildId: 25 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 681
nodeId:  13 , imgTensorShape :  torch.Size([468, 16, 20, 20])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: 26 ,  rchildId: 27 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 468
Nodes sizes =  10 10
Node 7 Acc: 49.482
Split Acc: 62.661
# of Left images:  1799.0
# of Right images:  2162.0
giniRightRatio:  0.8333249184253111
giniLeftRatio:  0.8113957448412603
impurityDrop:  0.8150776551146232
giniGain:  0.028967233190124952
lclasses:  [35, 7, 344, 234, 387, 179, 497, 81, 22, 13]
rclasses:  [34, 10, 231, 334, 309, 434, 263, 509, 12, 26]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1799, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1799])
rTrainDict[data].shape:  torch.Size([2162, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([2162])
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([1799, 16, 20, 20])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: 28 ,  rchildId: 29 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1799
nodeId:  15 , imgTensorShape :  torch.Size([2162, 16, 20, 20])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 30 ,  rchildId: 31 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 2162
Nodes sizes =  10 10
Node 8 Acc: 57.963
Split Acc: 63.055
# of Left images:  382.0
# of Right images:  384.0
giniRightRatio:  0.6025119357638888
giniLeftRatio:  0.8009785915956251
impurityDrop:  0.7999449110965015
giniGain:  -0.07620625311942064
lclasses:  [107, 11, 57, 9, 44, 12, 11, 9, 108, 14]
rclasses:  [208, 11, 17, 2, 15, 0, 0, 2, 121, 8]
noOfLeftClasses:  10
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([382, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([382])
rTrainDict[data].shape:  torch.Size([384, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([384])
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([382, 16, 16, 16])
nodeId: 16 ,  parentId: 8 ,  level: 4 ,  lchildId: 32 ,  rchildId: 33 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 382
nodeId:  17 , imgTensorShape :  torch.Size([384, 16, 16, 16])
nodeId: 17 ,  parentId: 8 ,  level: 4 ,  lchildId: 34 ,  rchildId: 35 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 384
Nodes sizes =  10 10
Node 9 Acc: 62.874
Split Acc: 62.725
# of Left images:  974.0
# of Right images:  1030.0
giniRightRatio:  0.7441662739183713
giniLeftRatio:  0.7546896938470036
impurityDrop:  0.7541175467440876
giniGain:  0.01194912231300782
lclasses:  [90, 294, 16, 15, 10, 6, 9, 19, 210, 305]
rclasses:  [242, 278, 10, 3, 7, 1, 1, 9, 341, 138]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([974, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([974])
rTrainDict[data].shape:  torch.Size([1030, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1030])
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([974, 16, 16, 16])
nodeId: 18 ,  parentId: 9 ,  level: 4 ,  lchildId: 36 ,  rchildId: 37 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 974
nodeId:  19 , imgTensorShape :  torch.Size([1030, 16, 16, 16])
nodeId: 19 ,  parentId: 9 ,  level: 4 ,  lchildId: 38 ,  rchildId: 39 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1030
Nodes sizes =  10 10
Node 10 Acc: 42.375
Split Acc: 77.750
# of Left images:  605.0
# of Right images:  195.0
giniRightRatio:  0.7808547008547008
giniLeftRatio:  0.8749183798920839
impurityDrop:  1.072693294791197
giniGain:  -0.19468704479119692
lclasses:  [60, 37, 42, 73, 42, 49, 37, 99, 35, 131]
rclasses:  [77, 7, 30, 11, 14, 13, 2, 30, 7, 4]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([605, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([605])
rTrainDict[data].shape:  torch.Size([195, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([195])
RETURNING FROM WORK...
nodeId:  20 , imgTensorShape :  torch.Size([605, 16, 16, 16])
nodeId: 20 ,  parentId: 10 ,  level: 4 ,  lchildId: 40 ,  rchildId: 41 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 605
nodeId:  21 , imgTensorShape :  torch.Size([195, 16, 16, 16])
nodeId: 21 ,  parentId: 10 ,  level: 4 ,  lchildId: 42 ,  rchildId: 43 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 195
Nodes sizes =  10 10
Node 11 Acc: 33.788
Split Acc: 73.409
# of Left images:  449.0
# of Right images:  871.0
giniRightRatio:  0.8385916395238326
giniLeftRatio:  0.8869102831831192
impurityDrop:  0.8634998725927415
giniGain:  0.007297877636826988
lclasses:  [24, 44, 38, 57, 21, 54, 37, 64, 36, 74]
rclasses:  [58, 4, 163, 171, 97, 210, 42, 84, 26, 16]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([449, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([449])
rTrainDict[data].shape:  torch.Size([871, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([871])
RETURNING FROM WORK...
nodeId:  22 , imgTensorShape :  torch.Size([449, 16, 16, 16])
nodeId: 22 ,  parentId: 11 ,  level: 4 ,  lchildId: 44 ,  rchildId: 45 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 449
nodeId:  23 , imgTensorShape :  torch.Size([871, 16, 16, 16])
nodeId: 23 ,  parentId: 11 ,  level: 4 ,  lchildId: 46 ,  rchildId: 47 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 871
Nodes sizes =  10 10
Node 12 Acc: 49.927
Split Acc: 73.421
# of Left images:  452.0
# of Right images:  229.0
giniRightRatio:  0.5907210007436929
giniLeftRatio:  0.8583189756441382
impurityDrop:  1.11890564989217
giniGain:  -0.30850546531433787
lclasses:  [16, 70, 24, 58, 26, 32, 42, 61, 11, 112]
rclasses:  [5, 118, 2, 0, 2, 0, 2, 9, 5, 86]
noOfLeftClasses:  10
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([452, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([452])
rTrainDict[data].shape:  torch.Size([229, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([229])
RETURNING FROM WORK...
nodeId:  24 , imgTensorShape :  torch.Size([452, 16, 16, 16])
nodeId: 24 ,  parentId: 12 ,  level: 4 ,  lchildId: 48 ,  rchildId: 49 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 452
nodeId:  25 , imgTensorShape :  torch.Size([229, 16, 16, 16])
nodeId: 25 ,  parentId: 12 ,  level: 4 ,  lchildId: 50 ,  rchildId: 51 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 229
Nodes sizes =  10 10
Node 13 Acc: 37.393
Split Acc: 67.949
# of Left images:  203.0
# of Right images:  265.0
giniRightRatio:  0.8850694197223211
giniLeftRatio:  0.7813827076609478
impurityDrop:  0.8056414855771936
giniGain:  0.057989897284958514
lclasses:  [24, 78, 7, 6, 3, 1, 17, 5, 34, 28]
rclasses:  [20, 31, 19, 27, 23, 9, 40, 19, 32, 45]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([203, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([203])
rTrainDict[data].shape:  torch.Size([265, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([265])
RETURNING FROM WORK...
nodeId:  26 , imgTensorShape :  torch.Size([203, 16, 16, 16])
nodeId: 26 ,  parentId: 13 ,  level: 4 ,  lchildId: 52 ,  rchildId: 53 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 203
nodeId:  27 , imgTensorShape :  torch.Size([265, 16, 16, 16])
nodeId: 27 ,  parentId: 13 ,  level: 4 ,  lchildId: 54 ,  rchildId: 55 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 265
Nodes sizes =  10 10
Node 14 Acc: 49.416
Split Acc: 77.877
# of Left images:  1414.0
# of Right images:  385.0
giniRightRatio:  0.7681295328048574
giniLeftRatio:  0.8101496651988901
impurityDrop:  0.9224580190520317
giniGain:  -0.11106227421077142
lclasses:  [20, 4, 230, 207, 265, 164, 425, 73, 15, 11]
rclasses:  [15, 3, 114, 27, 122, 15, 72, 8, 7, 2]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1414, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([1414])
rTrainDict[data].shape:  torch.Size([385, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([385])
RETURNING FROM WORK...
nodeId:  28 , imgTensorShape :  torch.Size([1414, 16, 16, 16])
nodeId: 28 ,  parentId: 14 ,  level: 4 ,  lchildId: 56 ,  rchildId: 57 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1414
nodeId:  29 , imgTensorShape :  torch.Size([385, 16, 16, 16])
nodeId: 29 ,  parentId: 14 ,  level: 4 ,  lchildId: 58 ,  rchildId: 59 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 385
Nodes sizes =  10 10
Node 15 Acc: 42.784
Split Acc: 82.886
# of Left images:  376.0
# of Right images:  1786.0
giniRightRatio:  0.8244771765968734
giniLeftRatio:  0.8484749886826618
impurityDrop:  0.8295293475623026
giniGain:  0.003795570863008524
lclasses:  [20, 5, 81, 43, 56, 55, 26, 75, 5, 10]
rclasses:  [14, 5, 150, 291, 253, 379, 237, 434, 7, 16]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([376, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([376])
rTrainDict[data].shape:  torch.Size([1786, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1786])
RETURNING FROM WORK...
nodeId:  30 , imgTensorShape :  torch.Size([376, 16, 16, 16])
nodeId: 30 ,  parentId: 15 ,  level: 4 ,  lchildId: 60 ,  rchildId: 61 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 376
nodeId:  31 , imgTensorShape :  torch.Size([1786, 16, 16, 16])
nodeId: 31 ,  parentId: 15 ,  level: 4 ,  lchildId: 62 ,  rchildId: 63 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1786
Nodes sizes =  10 10
Node 16 Acc: 42.670
Split Acc: 68.063
# of Left images:  296.0
# of Right images:  86.0
giniRightRatio:  0.8439697133585722
giniLeftRatio:  0.7675766983199416
impurityDrop:  0.5810356150860758
giniGain:  0.2199429765095493
lclasses:  [99, 8, 46, 4, 24, 10, 4, 5, 87, 9]
rclasses:  [8, 3, 11, 5, 20, 2, 7, 4, 21, 5]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([296, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([296])
rTrainDict[data].shape:  torch.Size([86, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([86])
RETURNING FROM WORK...
nodeId:  32 , imgTensorShape :  torch.Size([296, 16, 12, 12])
nodeId: 32 ,  parentId: 16 ,  level: 5 ,  lchildId: 64 ,  rchildId: 65 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 296
nodeId:  33 , imgTensorShape :  torch.Size([86, 16, 12, 12])
nodeId: 33 ,  parentId: 16 ,  level: 5 ,  lchildId: 66 ,  rchildId: 67 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 86
Nodes sizes =  10 10
Node 17 Acc: 61.198
Split Acc: 52.344
# of Left images:  183.0
# of Right images:  201.0
giniRightRatio:  0.6353803123685058
giniLeftRatio:  0.5630505539132252
impurityDrop:  0.5695278457151907
giniGain:  0.03298409004869818
lclasses:  [105, 1, 9, 0, 6, 0, 0, 0, 59, 3]
rclasses:  [103, 10, 8, 2, 9, 0, 0, 2, 62, 5]
noOfLeftClasses:  6
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([183, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([183])
rTrainDict[data].shape:  torch.Size([201, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([201])
RETURNING FROM WORK...
nodeId:  34 , imgTensorShape :  torch.Size([183, 16, 12, 12])
nodeId: 34 ,  parentId: 17 ,  level: 5 ,  lchildId: 68 ,  rchildId: 69 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 9 ,  numData: 183
nodeId:  35 , imgTensorShape :  torch.Size([201, 16, 12, 12])
nodeId: 35 ,  parentId: 17 ,  level: 5 ,  lchildId: 70 ,  rchildId: 71 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 201
Nodes sizes =  9 10
Node 18 Acc: 58.316
Split Acc: 66.735
# of Left images:  540.0
# of Right images:  434.0
giniRightRatio:  0.6954278069188133
giniLeftRatio:  0.7405075445816187
impurityDrop:  0.7515178030891241
giniGain:  0.003171890757879492
lclasses:  [47, 92, 12, 9, 8, 4, 8, 16, 121, 223]
rclasses:  [43, 202, 4, 6, 2, 2, 1, 3, 89, 82]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([540, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([540])
rTrainDict[data].shape:  torch.Size([434, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([434])
RETURNING FROM WORK...
nodeId:  36 , imgTensorShape :  torch.Size([540, 16, 12, 12])
nodeId: 36 ,  parentId: 18 ,  level: 5 ,  lchildId: 72 ,  rchildId: 73 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 540
nodeId:  37 , imgTensorShape :  torch.Size([434, 16, 12, 12])
nodeId: 37 ,  parentId: 18 ,  level: 5 ,  lchildId: 74 ,  rchildId: 75 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 434
Nodes sizes =  10 10
Node 19 Acc: 60.874
Split Acc: 63.689
# of Left images:  526.0
# of Right images:  504.0
giniRightRatio:  0.7571097883597884
giniLeftRatio:  0.6924489294337058
impurityDrop:  0.6896264316234404
giniGain:  0.05453984229493092
lclasses:  [140, 110, 5, 2, 1, 0, 0, 3, 228, 37]
rclasses:  [102, 168, 5, 1, 6, 1, 1, 6, 113, 101]
noOfLeftClasses:  8
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([526, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([526])
rTrainDict[data].shape:  torch.Size([504, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([504])
RETURNING FROM WORK...
nodeId:  38 , imgTensorShape :  torch.Size([526, 16, 12, 12])
nodeId: 38 ,  parentId: 19 ,  level: 5 ,  lchildId: 76 ,  rchildId: 77 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 526
nodeId:  39 , imgTensorShape :  torch.Size([504, 16, 12, 12])
nodeId: 39 ,  parentId: 19 ,  level: 5 ,  lchildId: 78 ,  rchildId: 79 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 504
Nodes sizes =  10 10
Node 20 Acc: 33.554
Split Acc: 68.595
# of Left images:  291.0
# of Right images:  314.0
giniRightRatio:  0.8699135867580834
giniLeftRatio:  0.8294658778238331
impurityDrop:  0.8324286080960871
giniGain:  0.04248977179599678
lclasses:  [31, 32, 18, 15, 19, 13, 8, 35, 22, 98]
rclasses:  [29, 5, 24, 58, 23, 36, 29, 64, 13, 33]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([291, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([291])
rTrainDict[data].shape:  torch.Size([314, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([314])
RETURNING FROM WORK...
nodeId:  40 , imgTensorShape :  torch.Size([291, 16, 12, 12])
nodeId: 40 ,  parentId: 20 ,  level: 5 ,  lchildId: 80 ,  rchildId: 81 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 291
nodeId:  41 , imgTensorShape :  torch.Size([314, 16, 12, 12])
nodeId: 41 ,  parentId: 20 ,  level: 5 ,  lchildId: 82 ,  rchildId: 83 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 314
Nodes sizes =  10 10
Node 21 Acc: 52.821
Split Acc: 65.641
# of Left images:  99.0
# of Right images:  96.0
giniRightRatio:  0.7239583333333333
giniLeftRatio:  0.801550862156923
impurityDrop:  0.8039756286826601
giniGain:  -0.02312092782795938
lclasses:  [30, 2, 19, 7, 9, 8, 1, 22, 0, 1]
rclasses:  [47, 5, 11, 4, 5, 5, 1, 8, 7, 3]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([99, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([99])
rTrainDict[data].shape:  torch.Size([96, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([96])
RETURNING FROM WORK...
nodeId:  42 , imgTensorShape :  torch.Size([99, 16, 12, 12])
nodeId: 42 ,  parentId: 21 ,  level: 5 ,  lchildId: 84 ,  rchildId: 85 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 99
nodeId:  43 , imgTensorShape :  torch.Size([96, 16, 12, 12])
nodeId: 43 ,  parentId: 21 ,  level: 5 ,  lchildId: 86 ,  rchildId: 87 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 96
Nodes sizes =  10 10
Node 22 Acc: 35.857
Split Acc: 57.461
# of Left images:  250.0
# of Right images:  199.0
giniRightRatio:  0.8887149314411251
giniLeftRatio:  0.87456
impurityDrop:  0.870932354253782
giniGain:  0.015977928929337137
lclasses:  [12, 21, 16, 44, 4, 37, 20, 34, 21, 41]
rclasses:  [12, 23, 22, 13, 17, 17, 17, 30, 15, 33]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([250, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([250])
rTrainDict[data].shape:  torch.Size([199, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([199])
RETURNING FROM WORK...
nodeId:  44 , imgTensorShape :  torch.Size([250, 16, 12, 12])
nodeId: 44 ,  parentId: 22 ,  level: 5 ,  lchildId: 88 ,  rchildId: 89 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 250
nodeId:  45 , imgTensorShape :  torch.Size([199, 16, 12, 12])
nodeId: 45 ,  parentId: 22 ,  level: 5 ,  lchildId: 90 ,  rchildId: 91 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 199
Nodes sizes =  10 10
Node 23 Acc: 31.917
Split Acc: 83.008
# of Left images:  162.0
# of Right images:  709.0
giniRightRatio:  0.8296474304777782
giniLeftRatio:  0.8155768937661942
impurityDrop:  0.8264324418356391
giniGain:  0.012159197688193513
lclasses:  [6, 1, 45, 36, 20, 16, 28, 5, 1, 4]
rclasses:  [52, 3, 118, 135, 77, 194, 14, 79, 25, 12]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([162, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([162])
rTrainDict[data].shape:  torch.Size([709, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([709])
RETURNING FROM WORK...
nodeId:  46 , imgTensorShape :  torch.Size([162, 16, 12, 12])
nodeId: 46 ,  parentId: 23 ,  level: 5 ,  lchildId: 92 ,  rchildId: 93 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 162
nodeId:  47 , imgTensorShape :  torch.Size([709, 16, 12, 12])
nodeId: 47 ,  parentId: 23 ,  level: 5 ,  lchildId: 94 ,  rchildId: 95 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 709
Nodes sizes =  10 10
Node 24 Acc: 36.283
Split Acc: 63.938
# of Left images:  266.0
# of Right images:  186.0
giniRightRatio:  0.7911897329171003
giniLeftRatio:  0.8818757419865453
impurityDrop:  0.9208804770701775
giniGain:  -0.06256150142603933
lclasses:  [12, 36, 22, 37, 19, 26, 30, 34, 6, 44]
rclasses:  [4, 34, 2, 21, 7, 6, 12, 27, 5, 68]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([266, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([266])
rTrainDict[data].shape:  torch.Size([186, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([186])
RETURNING FROM WORK...
nodeId:  48 , imgTensorShape :  torch.Size([266, 16, 12, 12])
nodeId: 48 ,  parentId: 24 ,  level: 5 ,  lchildId: 96 ,  rchildId: 97 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 266
nodeId:  49 , imgTensorShape :  torch.Size([186, 16, 12, 12])
nodeId: 49 ,  parentId: 24 ,  level: 5 ,  lchildId: 98 ,  rchildId: 99 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 186
Nodes sizes =  10 10
Node 25 Acc: 66.812
Split Acc: 59.389
# of Left images:  111.0
# of Right images:  118.0
giniRightRatio:  0.5927894283251939
giniLeftRatio:  0.5481697914130348
impurityDrop:  0.5508167190264679
giniGain:  0.03990428171722504
lclasses:  [2, 68, 0, 0, 2, 0, 1, 5, 3, 30]
rclasses:  [3, 50, 2, 0, 0, 0, 1, 4, 2, 56]
noOfLeftClasses:  7
noOfRightClasses:  7
lTrainDict[data].shape:  torch.Size([111, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([111])
rTrainDict[data].shape:  torch.Size([118, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([118])
RETURNING FROM WORK...
nodeId:  50 , imgTensorShape :  torch.Size([111, 16, 12, 12])
nodeId: 50 ,  parentId: 25 ,  level: 5 ,  lchildId: 100 ,  rchildId: 101 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 9 ,  numData: 111
nodeId:  51 , imgTensorShape :  torch.Size([118, 16, 12, 12])
nodeId: 51 ,  parentId: 25 ,  level: 5 ,  lchildId: 102 ,  rchildId: 103 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 118
Nodes sizes =  9 10
Node 26 Acc: 50.246
Split Acc: 92.118
# of Left images:  190.0
# of Right images:  13.0
giniRightRatio:  0.7218934911242604
giniLeftRatio:  0.7837119113573408
impurityDrop:  1.6253934791462044
giniGain:  -0.8440107714852566
lclasses:  [23, 72, 7, 6, 2, 1, 17, 4, 32, 26]
rclasses:  [1, 6, 0, 0, 1, 0, 0, 1, 2, 2]
noOfLeftClasses:  10
noOfRightClasses:  6
lTrainDict[data].shape:  torch.Size([190, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([190])
rTrainDict[data].shape:  torch.Size([13, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([13])
RETURNING FROM WORK...
nodeId:  52 , imgTensorShape :  torch.Size([190, 16, 12, 12])
nodeId: 52 ,  parentId: 26 ,  level: 5 ,  lchildId: 104 ,  rchildId: 105 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 190
nodeId:  53 , imgTensorShape :  torch.Size([13, 16, 12, 12])
nodeId: 53 ,  parentId: 26 ,  level: 5 ,  lchildId: 106 ,  rchildId: 107 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 7 ,  numData: 13
Nodes sizes =  10 7
Node 27 Acc: 23.019
Split Acc: 72.453
# of Left images:  200.0
# of Right images:  65.0
giniRightRatio:  0.8582248520710059
giniLeftRatio:  0.8835500000000001
impurityDrop:  0.936148384160219
giniGain:  -0.051078964437897834
lclasses:  [14, 25, 16, 24, 16, 8, 35, 10, 24, 28]
rclasses:  [6, 6, 3, 3, 7, 1, 5, 9, 8, 17]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([200, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([200])
rTrainDict[data].shape:  torch.Size([65, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([65])
RETURNING FROM WORK...
nodeId:  54 , imgTensorShape :  torch.Size([200, 16, 12, 12])
nodeId: 54 ,  parentId: 27 ,  level: 5 ,  lchildId: 108 ,  rchildId: 109 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 200
nodeId:  55 , imgTensorShape :  torch.Size([65, 16, 12, 12])
nodeId: 55 ,  parentId: 27 ,  level: 5 ,  lchildId: 110 ,  rchildId: 111 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 65
Nodes sizes =  10 10
Node 28 Acc: 42.150
Split Acc: 79.279
# of Left images:  1110.0
# of Right images:  304.0
giniRightRatio:  0.7801246537396122
giniLeftRatio:  0.8128106484863241
impurityDrop:  0.8994715424529351
giniGain:  -0.08932187725404506
lclasses:  [6, 4, 171, 186, 205, 146, 315, 64, 6, 7]
rclasses:  [14, 0, 59, 21, 60, 18, 110, 9, 9, 4]
noOfLeftClasses:  10
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([1110, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([1110])
rTrainDict[data].shape:  torch.Size([304, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([304])
RETURNING FROM WORK...
nodeId:  56 , imgTensorShape :  torch.Size([1110, 16, 12, 12])
nodeId: 56 ,  parentId: 28 ,  level: 5 ,  lchildId: 112 ,  rchildId: 113 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1110
nodeId:  57 , imgTensorShape :  torch.Size([304, 16, 12, 12])
nodeId: 57 ,  parentId: 28 ,  level: 5 ,  lchildId: 114 ,  rchildId: 115 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 304
Nodes sizes =  10 10
Node 29 Acc: 45.195
Split Acc: 95.065
# of Left images:  369.0
# of Right images:  16.0
giniRightRatio:  0.4921875
giniLeftRatio:  0.7655936721968846
impurityDrop:  6.79761734629065
giniGain:  -6.029487813485793
lclasses:  [15, 3, 112, 26, 120, 15, 61, 8, 7, 2]
rclasses:  [0, 0, 2, 1, 2, 0, 11, 0, 0, 0]
noOfLeftClasses:  10
noOfRightClasses:  4
lTrainDict[data].shape:  torch.Size([369, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([369])
rTrainDict[data].shape:  torch.Size([16, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([16])
RETURNING FROM WORK...
nodeId:  58 , imgTensorShape :  torch.Size([369, 16, 12, 12])
nodeId: 58 ,  parentId: 29 ,  level: 5 ,  lchildId: 116 ,  rchildId: 117 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 9 ,  numData: 369
nodeId:  59 , imgTensorShape :  torch.Size([16, 16, 12, 12])
nodeId: 59 ,  parentId: 29 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 6 ,  numData: 16
Nodes sizes =  9 6
Node 30 Acc: 30.851
Split Acc: 68.617
# of Left images:  121.0
# of Right images:  255.0
giniRightRatio:  0.8447520184544406
giniLeftRatio:  0.8196161464380848
impurityDrop:  0.832824800752562
giniGain:  0.015650187930099757
lclasses:  [4, 2, 31, 21, 9, 29, 6, 16, 1, 2]
rclasses:  [16, 3, 50, 22, 47, 26, 20, 59, 4, 8]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([121, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([121])
rTrainDict[data].shape:  torch.Size([255, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([255])
RETURNING FROM WORK...
nodeId:  60 , imgTensorShape :  torch.Size([121, 16, 12, 12])
nodeId: 60 ,  parentId: 30 ,  level: 5 ,  lchildId: 118 ,  rchildId: 119 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 121
nodeId:  61 , imgTensorShape :  torch.Size([255, 16, 12, 12])
nodeId: 61 ,  parentId: 30 ,  level: 5 ,  lchildId: 120 ,  rchildId: 121 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 255
Nodes sizes =  10 10
Node 31 Acc: 42.665
Split Acc: 66.013
# of Left images:  648.0
# of Right images:  1138.0
giniRightRatio:  0.8186378223442602
giniLeftRatio:  0.7794162475232435
impurityDrop:  0.7963042718310627
giniGain:  0.02817290476581069
lclasses:  [4, 0, 55, 55, 133, 74, 82, 238, 3, 4]
rclasses:  [10, 5, 95, 236, 120, 305, 155, 196, 4, 12]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([648, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([648])
rTrainDict[data].shape:  torch.Size([1138, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([1138])
RETURNING FROM WORK...
nodeId:  62 , imgTensorShape :  torch.Size([648, 16, 12, 12])
nodeId: 62 ,  parentId: 31 ,  level: 5 ,  lchildId: 122 ,  rchildId: 123 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 648
nodeId:  63 , imgTensorShape :  torch.Size([1138, 16, 12, 12])
nodeId: 63 ,  parentId: 31 ,  level: 5 ,  lchildId: 124 ,  rchildId: 125 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 1138
Nodes sizes =  10 10
Node 32 Acc: 45.270
Split Acc: 61.824
# of Left images:  134.0
# of Right images:  162.0
giniRightRatio:  0.7138393537570492
giniLeftRatio:  0.7780129204722654
impurityDrop:  0.7669211928918577
giniGain:  0.0006555054280839023
lclasses:  [50, 7, 28, 3, 15, 7, 2, 1, 19, 2]
rclasses:  [49, 1, 18, 1, 9, 3, 2, 4, 68, 7]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([134, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([134])
rTrainDict[data].shape:  torch.Size([162, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([162])
RETURNING FROM WORK...
nodeId:  64 , imgTensorShape :  torch.Size([134, 16, 8, 8])
nodeId: 64 ,  parentId: 32 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 134
nodeId:  65 , imgTensorShape :  torch.Size([162, 16, 8, 8])
nodeId: 65 ,  parentId: 32 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 162
Nodes sizes =  10 10
Node 33 Acc: 38.372
Split Acc: 67.442
# of Left images:  50.0
# of Right images:  36.0
giniRightRatio:  0.7916666666666666
giniLeftRatio:  0.8352
impurityDrop:  0.8521296296296299
giniGain:  -0.008159916271057721
lclasses:  [0, 2, 7, 3, 14, 2, 7, 2, 9, 4]
rclasses:  [8, 1, 4, 2, 6, 0, 0, 2, 12, 1]
noOfLeftClasses:  9
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([50, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([50])
rTrainDict[data].shape:  torch.Size([36, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([36])
RETURNING FROM WORK...
nodeId:  66 , imgTensorShape :  torch.Size([50, 16, 8, 8])
nodeId: 66 ,  parentId: 33 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 50
nodeId:  67 , imgTensorShape :  torch.Size([36, 16, 8, 8])
nodeId: 67 ,  parentId: 33 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 36
Nodes sizes =  10 10
Node 34 Acc: 67.760
Split Acc: 66.120
# of Left images:  109.0
# of Right images:  74.0
giniRightRatio:  0.5131482834185537
giniLeftRatio:  0.5560138035518897
impurityDrop:  0.5762880360473864
giniGain:  -0.013237482134161205
lclasses:  [68, 1, 9, 0, 6, 0, 0, 0, 23, 2]
rclasses:  [37, 0, 0, 0, 0, 0, 0, 0, 36, 1]
noOfLeftClasses:  6
noOfRightClasses:  3
lTrainDict[data].shape:  torch.Size([109, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([109])
rTrainDict[data].shape:  torch.Size([74, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([74])
RETURNING FROM WORK...
nodeId:  68 , imgTensorShape :  torch.Size([109, 16, 8, 8])
nodeId: 68 ,  parentId: 34 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 109
nodeId:  69 , imgTensorShape :  torch.Size([74, 16, 8, 8])
nodeId: 69 ,  parentId: 34 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 7 ,  numData: 74
Nodes sizes =  9 7
Node 35 Acc: 55.721
Split Acc: 67.164
# of Left images:  52.0
# of Right images:  149.0
giniRightRatio:  0.6096121796315481
giniLeftRatio:  0.647189349112426
impurityDrop:  0.6227263595846062
giniGain:  0.01265395278389958
lclasses:  [19, 2, 1, 1, 3, 0, 0, 1, 24, 1]
rclasses:  [84, 8, 7, 1, 6, 0, 0, 1, 38, 4]
noOfLeftClasses:  8
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([52, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([52])
rTrainDict[data].shape:  torch.Size([149, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([149])
RETURNING FROM WORK...
nodeId:  70 , imgTensorShape :  torch.Size([52, 16, 8, 8])
nodeId: 70 ,  parentId: 35 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 52
nodeId:  71 , imgTensorShape :  torch.Size([149, 16, 8, 8])
nodeId: 71 ,  parentId: 35 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 149
Nodes sizes =  8 10
Node 36 Acc: 52.593
Split Acc: 63.333
# of Left images:  261.0
# of Right images:  279.0
giniRightRatio:  0.7873228761192688
giniLeftRatio:  0.6457920465054829
impurityDrop:  0.6549230677708885
giniGain:  0.08558447681073023
lclasses:  [14, 34, 4, 3, 5, 2, 1, 8, 47, 143]
rclasses:  [33, 58, 8, 6, 3, 2, 7, 8, 74, 80]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([261, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([261])
rTrainDict[data].shape:  torch.Size([279, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([279])
RETURNING FROM WORK...
nodeId:  72 , imgTensorShape :  torch.Size([261, 16, 8, 8])
nodeId: 72 ,  parentId: 36 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 261
nodeId:  73 , imgTensorShape :  torch.Size([279, 16, 8, 8])
nodeId: 73 ,  parentId: 36 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 279
Nodes sizes =  10 10
Node 37 Acc: 58.986
Split Acc: 67.281
# of Left images:  139.0
# of Right images:  295.0
giniRightRatio:  0.7341798333812122
giniLeftRatio:  0.5406552455877025
impurityDrop:  0.6429936716751178
giniGain:  0.05243413524369556
lclasses:  [7, 87, 0, 0, 0, 1, 0, 0, 10, 34]
rclasses:  [36, 115, 4, 6, 2, 1, 1, 3, 79, 48]
noOfLeftClasses:  5
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([139, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([139])
rTrainDict[data].shape:  torch.Size([295, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([295])
RETURNING FROM WORK...
nodeId:  74 , imgTensorShape :  torch.Size([139, 16, 8, 8])
nodeId: 74 ,  parentId: 37 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 139
nodeId:  75 , imgTensorShape :  torch.Size([295, 16, 8, 8])
nodeId: 75 ,  parentId: 37 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 295
Nodes sizes =  10 10
Node 38 Acc: 60.266
Split Acc: 89.544
# of Left images:  54.0
# of Right images:  472.0
giniRightRatio:  0.6885593220338984
giniLeftRatio:  0.720164609053498
impurityDrop:  0.6921751811420729
giniGain:  0.0002737482916329581
lclasses:  [13, 13, 0, 1, 0, 0, 0, 0, 21, 6]
rclasses:  [127, 97, 5, 1, 1, 0, 0, 3, 207, 31]
noOfLeftClasses:  5
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([54, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([54])
rTrainDict[data].shape:  torch.Size([472, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([472])
RETURNING FROM WORK...
nodeId:  76 , imgTensorShape :  torch.Size([54, 16, 8, 8])
nodeId: 76 ,  parentId: 38 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 54
nodeId:  77 , imgTensorShape :  torch.Size([472, 16, 8, 8])
nodeId: 77 ,  parentId: 38 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 472
Nodes sizes =  8 10
Node 39 Acc: 57.143
Split Acc: 82.937
# of Left images:  89.0
# of Right images:  415.0
giniRightRatio:  0.754663957032951
giniLeftRatio:  0.7372806463830324
impurityDrop:  0.7509359699297155
giniGain:  0.006173818430072919
lclasses:  [18, 38, 3, 0, 1, 1, 0, 5, 14, 9]
rclasses:  [84, 130, 2, 1, 5, 0, 1, 1, 99, 92]
noOfLeftClasses:  8
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([89, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([89])
rTrainDict[data].shape:  torch.Size([415, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([415])
RETURNING FROM WORK...
nodeId:  78 , imgTensorShape :  torch.Size([89, 16, 8, 8])
nodeId: 78 ,  parentId: 39 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 89
nodeId:  79 , imgTensorShape :  torch.Size([415, 16, 8, 8])
nodeId: 79 ,  parentId: 39 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 415
Nodes sizes =  9 10
Node 40 Acc: 39.863
Split Acc: 72.852
# of Left images:  81.0
# of Right images:  210.0
giniRightRatio:  0.7922902494331066
giniLeftRatio:  0.8526139308032311
impurityDrop:  0.8155579551044403
giniGain:  0.013907922719392785
lclasses:  [18, 13, 10, 4, 5, 1, 0, 6, 10, 14]
rclasses:  [13, 19, 8, 11, 14, 12, 8, 29, 12, 84]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([81, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([81])
rTrainDict[data].shape:  torch.Size([210, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([210])
RETURNING FROM WORK...
nodeId:  80 , imgTensorShape :  torch.Size([81, 16, 8, 8])
nodeId: 80 ,  parentId: 40 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 81
nodeId:  81 , imgTensorShape :  torch.Size([210, 16, 8, 8])
nodeId: 81 ,  parentId: 40 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 210
Nodes sizes =  10 10
Node 41 Acc: 30.255
Split Acc: 64.650
# of Left images:  137.0
# of Right images:  177.0
giniRightRatio:  0.8719716556545055
giniLeftRatio:  0.824018328094198
impurityDrop:  0.8348552382773182
giniGain:  0.03505834848076517
lclasses:  [18, 2, 11, 20, 4, 20, 2, 43, 4, 13]
rclasses:  [11, 3, 13, 38, 19, 16, 27, 21, 9, 20]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([137, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([137])
rTrainDict[data].shape:  torch.Size([177, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([177])
RETURNING FROM WORK...
nodeId:  82 , imgTensorShape :  torch.Size([137, 16, 8, 8])
nodeId: 82 ,  parentId: 41 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 137
nodeId:  83 , imgTensorShape :  torch.Size([177, 16, 8, 8])
nodeId: 83 ,  parentId: 41 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 177
Nodes sizes =  10 10
Node 42 Acc: 50.505
Split Acc: 87.879
# of Left images:  12.0
# of Right images:  87.0
giniRightRatio:  0.8038049940546969
giniLeftRatio:  0.5138888888888888
impurityDrop:  0.7638165657559646
giniGain:  0.03773429640095838
lclasses:  [8, 1, 0, 1, 0, 2, 0, 0, 0, 0]
rclasses:  [22, 1, 19, 6, 9, 6, 1, 22, 0, 1]
noOfLeftClasses:  4
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([12, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([12])
rTrainDict[data].shape:  torch.Size([87, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([87])
RETURNING FROM WORK...
nodeId:  84 , imgTensorShape :  torch.Size([12, 16, 8, 8])
nodeId: 84 ,  parentId: 42 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 12
nodeId:  85 , imgTensorShape :  torch.Size([87, 16, 8, 8])
nodeId: 85 ,  parentId: 42 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 87
Nodes sizes =  8 9
Node 43 Acc: 57.292
Split Acc: 57.292
# of Left images:  46.0
# of Right images:  50.0
giniRightRatio:  0.652
giniLeftRatio:  0.7826086956521738
impurityDrop:  0.77216
giniGain:  -0.0482016666666667
lclasses:  [19, 3, 4, 3, 3, 3, 1, 6, 3, 1]
rclasses:  [28, 2, 7, 1, 2, 2, 0, 2, 4, 2]
noOfLeftClasses:  10
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([46, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([46])
rTrainDict[data].shape:  torch.Size([50, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([50])
RETURNING FROM WORK...
nodeId:  86 , imgTensorShape :  torch.Size([46, 16, 8, 8])
nodeId: 86 ,  parentId: 43 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 46
nodeId:  87 , imgTensorShape :  torch.Size([50, 16, 8, 8])
nodeId: 87 ,  parentId: 43 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 50
Nodes sizes =  10 10
Node 44 Acc: 31.600
Split Acc: 82.000
# of Left images:  201.0
# of Right images:  49.0
giniRightRatio:  0.8396501457725948
giniLeftRatio:  0.8677012945224127
impurityDrop:  0.954717102889195
giniGain:  -0.08015710288919498
lclasses:  [10, 18, 10, 33, 3, 31, 8, 31, 21, 36]
rclasses:  [2, 3, 6, 11, 1, 6, 12, 3, 0, 5]
noOfLeftClasses:  10
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([201, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([201])
rTrainDict[data].shape:  torch.Size([49, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([49])
RETURNING FROM WORK...
nodeId:  88 , imgTensorShape :  torch.Size([201, 16, 8, 8])
nodeId: 88 ,  parentId: 44 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 201
nodeId:  89 , imgTensorShape :  torch.Size([49, 16, 8, 8])
nodeId: 89 ,  parentId: 44 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49
Nodes sizes =  10 10
Node 45 Acc: 28.141
Split Acc: 65.829
# of Left images:  80.0
# of Right images:  119.0
giniRightRatio:  0.8704187557375892
giniLeftRatio:  0.8884374999999999
impurityDrop:  0.8825321972585376
giniGain:  0.006182734182587524
lclasses:  [7, 14, 11, 5, 6, 7, 5, 7, 10, 8]
rclasses:  [5, 9, 11, 8, 11, 10, 12, 23, 5, 25]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([80, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([80])
rTrainDict[data].shape:  torch.Size([119, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([119])
RETURNING FROM WORK...
nodeId:  90 , imgTensorShape :  torch.Size([80, 16, 8, 8])
nodeId: 90 ,  parentId: 45 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 80
nodeId:  91 , imgTensorShape :  torch.Size([119, 16, 8, 8])
nodeId: 91 ,  parentId: 45 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 119
Nodes sizes =  10 10
Node 46 Acc: 30.864
Split Acc: 80.864
# of Left images:  31.0
# of Right images:  131.0
giniRightRatio:  0.8179010547170912
giniLeftRatio:  0.7721123829344433
impurityDrop:  0.8070655675013501
giniGain:  0.008511326264844188
lclasses:  [3, 0, 12, 6, 2, 4, 3, 1, 0, 0]
rclasses:  [3, 1, 33, 30, 18, 12, 25, 4, 1, 4]
noOfLeftClasses:  7
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([31, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([31])
rTrainDict[data].shape:  torch.Size([131, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([131])
RETURNING FROM WORK...
nodeId:  92 , imgTensorShape :  torch.Size([31, 16, 8, 8])
nodeId: 92 ,  parentId: 46 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 31
nodeId:  93 , imgTensorShape :  torch.Size([131, 16, 8, 8])
nodeId: 93 ,  parentId: 46 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 131
Nodes sizes =  9 10
Node 47 Acc: 31.312
Split Acc: 77.010
# of Left images:  544.0
# of Right images:  165.0
giniRightRatio:  0.8256382001836547
giniLeftRatio:  0.8237524329584774
impurityDrop:  0.8194208827867062
giniGain:  0.010226547691072008
lclasses:  [25, 2, 85, 112, 65, 149, 12, 70, 13, 11]
rclasses:  [27, 1, 33, 23, 12, 45, 2, 9, 12, 1]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([544, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([544])
rTrainDict[data].shape:  torch.Size([165, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([165])
RETURNING FROM WORK...
nodeId:  94 , imgTensorShape :  torch.Size([544, 16, 8, 8])
nodeId: 94 ,  parentId: 47 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 544
nodeId:  95 , imgTensorShape :  torch.Size([165, 16, 8, 8])
nodeId: 95 ,  parentId: 47 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 165
Nodes sizes =  10 10
Node 48 Acc: 27.820
Split Acc: 69.925
# of Left images:  167.0
# of Right images:  99.0
giniRightRatio:  0.853178247117641
giniLeftRatio:  0.8605543404209545
impurityDrop:  0.8656207479424223
giniGain:  0.016254994044123006
lclasses:  [7, 28, 7, 12, 16, 9, 21, 25, 4, 38]
rclasses:  [5, 8, 15, 25, 3, 17, 9, 9, 2, 6]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([167, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([167])
rTrainDict[data].shape:  torch.Size([99, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([99])
RETURNING FROM WORK...
nodeId:  96 , imgTensorShape :  torch.Size([167, 16, 8, 8])
nodeId: 96 ,  parentId: 48 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 167
nodeId:  97 , imgTensorShape :  torch.Size([99, 16, 8, 8])
nodeId: 97 ,  parentId: 48 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 99
Nodes sizes =  10 10
Node 49 Acc: 40.860
Split Acc: 62.366
# of Left images:  84.0
# of Right images:  102.0
giniRightRatio:  0.7773933102652826
giniLeftRatio:  0.7372448979591836
impurityDrop:  0.744329911895554
giniGain:  0.04685982102154629
lclasses:  [2, 2, 1, 10, 4, 4, 4, 20, 1, 36]
rclasses:  [2, 32, 1, 11, 3, 2, 8, 7, 4, 32]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([84, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([84])
rTrainDict[data].shape:  torch.Size([102, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([102])
RETURNING FROM WORK...
nodeId:  98 , imgTensorShape :  torch.Size([84, 16, 8, 8])
nodeId: 98 ,  parentId: 49 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 84
nodeId:  99 , imgTensorShape :  torch.Size([102, 16, 8, 8])
nodeId: 99 ,  parentId: 49 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 102
Nodes sizes =  10 10
Node 50 Acc: 62.162
Split Acc: 83.784
# of Left images:  88.0
# of Right images:  23.0
giniRightRatio:  0.6918714555765596
giniLeftRatio:  0.4896694214876033
impurityDrop:  -0.0817711096333602
giniGain:  0.629940901046395
lclasses:  [1, 58, 0, 0, 1, 0, 1, 0, 3, 24]
rclasses:  [1, 10, 0, 0, 1, 0, 0, 5, 0, 6]
noOfLeftClasses:  6
noOfRightClasses:  5
lTrainDict[data].shape:  torch.Size([88, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([88])
rTrainDict[data].shape:  torch.Size([23, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([23])
RETURNING FROM WORK...
nodeId:  100 , imgTensorShape :  torch.Size([88, 16, 8, 8])
nodeId: 100 ,  parentId: 50 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 88
nodeId:  101 , imgTensorShape :  torch.Size([23, 16, 8, 8])
nodeId: 101 ,  parentId: 50 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 8 ,  numData: 23
Nodes sizes =  9 8
Node 51 Acc: 70.339
Split Acc: 71.186
# of Left images:  83.0
# of Right images:  35.0
giniRightRatio:  0.41632653061224484
giniLeftRatio:  0.5504427347946
impurityDrop:  0.7343735291018301
giniGain:  -0.1415841007766362
lclasses:  [2, 24, 2, 0, 0, 0, 0, 3, 2, 50]
rclasses:  [1, 26, 0, 0, 0, 0, 1, 1, 0, 6]
noOfLeftClasses:  6
noOfRightClasses:  5
lTrainDict[data].shape:  torch.Size([83, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([83])
rTrainDict[data].shape:  torch.Size([35, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([35])
RETURNING FROM WORK...
nodeId:  102 , imgTensorShape :  torch.Size([83, 16, 8, 8])
nodeId: 102 ,  parentId: 51 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 83
nodeId:  103 , imgTensorShape :  torch.Size([35, 16, 8, 8])
nodeId: 103 ,  parentId: 51 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 6 ,  numData: 35
Nodes sizes =  10 6
Node 52 Acc: 44.737
Split Acc: 80.000
# of Left images:  153.0
# of Right images:  37.0
giniRightRatio:  0.7202337472607744
giniLeftRatio:  0.7955914391900551
impurityDrop:  1.031847986860233
giniGain:  -0.2481360755028923
lclasses:  [18, 56, 6, 6, 2, 1, 16, 4, 24, 20]
rclasses:  [5, 16, 1, 0, 0, 0, 1, 0, 8, 6]
noOfLeftClasses:  10
noOfRightClasses:  6
lTrainDict[data].shape:  torch.Size([153, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([153])
rTrainDict[data].shape:  torch.Size([37, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([37])
RETURNING FROM WORK...
nodeId:  104 , imgTensorShape :  torch.Size([153, 16, 8, 8])
nodeId: 104 ,  parentId: 52 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 153
nodeId:  105 , imgTensorShape :  torch.Size([37, 16, 8, 8])
nodeId: 105 ,  parentId: 52 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 37
Nodes sizes =  9 10
Node 53 Acc: 30.769
Split Acc: 84.615
# of Left images:  12.0
# of Right images:  1.0
giniRightRatio:  0.0
giniLeftRatio:  0.75
impurityDrop:  9.0
giniGain:  -8.278106508875739
lclasses:  [1, 5, 0, 0, 1, 0, 0, 1, 2, 2]
rclasses:  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  6
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([12, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([12])
rTrainDict[data].shape:  torch.Size([1, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([1])
RETURNING FROM WORK...
nodeId:  106 , imgTensorShape :  torch.Size([12, 16, 8, 8])
nodeId: 106 ,  parentId: 53 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 7 ,  numData: 12
nodeId:  107 , imgTensorShape :  torch.Size([1, 16, 8, 8])
nodeId: 107 ,  parentId: 53 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 4 ,  numData: 1
Nodes sizes =  7 4
Node 54 Acc: 23.000
Split Acc: 66.000
# of Left images:  145.0
# of Right images:  55.0
giniRightRatio:  0.8899173553719006
giniLeftRatio:  0.8723900118906065
impurityDrop:  0.8437089043757615
giniGain:  0.03984109562423854
lclasses:  [8, 19, 9, 15, 11, 6, 29, 5, 20, 23]
rclasses:  [6, 6, 7, 9, 5, 2, 6, 5, 4, 5]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([145, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([145])
rTrainDict[data].shape:  torch.Size([55, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([55])
RETURNING FROM WORK...
nodeId:  108 , imgTensorShape :  torch.Size([145, 16, 8, 8])
nodeId: 108 ,  parentId: 54 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 145
nodeId:  109 , imgTensorShape :  torch.Size([55, 16, 8, 8])
nodeId: 109 ,  parentId: 54 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 55
Nodes sizes =  10 10
Node 55 Acc: 16.923
Split Acc: 75.385
# of Left images:  15.0
# of Right images:  50.0
giniRightRatio:  0.8248
giniLeftRatio:  0.808888888888889
impurityDrop:  0.8200266666666667
giniGain:  0.03819818540433917
lclasses:  [1, 4, 0, 1, 2, 0, 1, 2, 4, 0]
rclasses:  [5, 2, 3, 2, 5, 1, 4, 7, 4, 17]
noOfLeftClasses:  7
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([15, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([15])
rTrainDict[data].shape:  torch.Size([50, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([50])
RETURNING FROM WORK...
nodeId:  110 , imgTensorShape :  torch.Size([15, 16, 8, 8])
nodeId: 110 ,  parentId: 55 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 15
nodeId:  111 , imgTensorShape :  torch.Size([50, 16, 8, 8])
nodeId: 111 ,  parentId: 55 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 50
Nodes sizes =  10 10
Node 56 Acc: 41.892
Split Acc: 66.306
# of Left images:  605.0
# of Right images:  505.0
giniRightRatio:  0.7188942260562691
giniLeftRatio:  0.8285663547571887
impurityDrop:  0.8502836079652916
giniGain:  -0.03747295947896745
lclasses:  [4, 3, 102, 136, 87, 125, 92, 46, 5, 5]
rclasses:  [2, 1, 69, 50, 118, 21, 223, 18, 1, 2]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([605, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([605])
rTrainDict[data].shape:  torch.Size([505, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([505])
RETURNING FROM WORK...
nodeId:  112 , imgTensorShape :  torch.Size([605, 16, 8, 8])
nodeId: 112 ,  parentId: 56 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 605
nodeId:  113 , imgTensorShape :  torch.Size([505, 16, 8, 8])
nodeId: 113 ,  parentId: 56 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 505
Nodes sizes =  10 10
Node 57 Acc: 45.724
Split Acc: 57.566
# of Left images:  153.0
# of Right images:  151.0
giniRightRatio:  0.7324240164905049
giniLeftRatio:  0.8118245119398522
impurityDrop:  0.8128761741312343
giniGain:  -0.0327515203916221
lclasses:  [10, 0, 29, 9, 35, 12, 44, 7, 5, 2]
rclasses:  [4, 0, 30, 12, 25, 6, 66, 2, 4, 2]
noOfLeftClasses:  9
noOfRightClasses:  9
lTrainDict[data].shape:  torch.Size([153, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([153])
rTrainDict[data].shape:  torch.Size([151, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([151])
RETURNING FROM WORK...
nodeId:  114 , imgTensorShape :  torch.Size([153, 16, 8, 8])
nodeId: 114 ,  parentId: 57 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 153
nodeId:  115 , imgTensorShape :  torch.Size([151, 16, 8, 8])
nodeId: 115 ,  parentId: 57 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 151
Nodes sizes =  10 10
Node 58 Acc: 40.650
Split Acc: 88.618
# of Left images:  329.0
# of Right images:  40.0
giniRightRatio:  0.82125
giniLeftRatio:  0.7518962315573582
impurityDrop:  0.2508152545592708
giniGain:  0.5147784176376138
lclasses:  [9, 2, 100, 25, 112, 14, 58, 6, 2, 1]
rclasses:  [6, 1, 12, 1, 8, 1, 3, 2, 5, 1]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([329, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([329])
rTrainDict[data].shape:  torch.Size([40, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([40])
RETURNING FROM WORK...
nodeId:  116 , imgTensorShape :  torch.Size([329, 16, 8, 8])
nodeId: 116 ,  parentId: 58 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 329
nodeId:  117 , imgTensorShape :  torch.Size([40, 16, 8, 8])
nodeId: 117 ,  parentId: 58 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 40
Nodes sizes =  9 9
Node 59 Acc: 62.500
Node 60 Acc: 29.752
Split Acc: 76.860
# of Left images:  87.0
# of Right images:  34.0
giniRightRatio:  0.7439446366782008
giniLeftRatio:  0.8040692297529397
impurityDrop:  0.8977928601341505
giniGain:  -0.07817671369606571
lclasses:  [4, 2, 28, 17, 7, 17, 5, 5, 1, 1]
rclasses:  [0, 0, 3, 4, 2, 12, 1, 11, 0, 1]
noOfLeftClasses:  10
noOfRightClasses:  7
lTrainDict[data].shape:  torch.Size([87, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([87])
rTrainDict[data].shape:  torch.Size([34, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([34])
RETURNING FROM WORK...
nodeId:  118 , imgTensorShape :  torch.Size([87, 16, 8, 8])
nodeId: 118 ,  parentId: 60 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 87
nodeId:  119 , imgTensorShape :  torch.Size([34, 16, 8, 8])
nodeId: 119 ,  parentId: 60 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 9 ,  numData: 34
Nodes sizes =  9 9
Node 61 Acc: 30.980
Split Acc: 70.980
# of Left images:  73.0
# of Right images:  182.0
giniRightRatio:  0.8600410578432557
giniLeftRatio:  0.7404766372677801
impurityDrop:  0.8120839001399056
giniGain:  0.03266811831453498
lclasses:  [2, 0, 9, 4, 20, 6, 2, 29, 1, 0]
rclasses:  [14, 3, 41, 18, 27, 20, 18, 30, 3, 8]
noOfLeftClasses:  8
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([73, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([73])
rTrainDict[data].shape:  torch.Size([182, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([182])
RETURNING FROM WORK...
nodeId:  120 , imgTensorShape :  torch.Size([73, 16, 8, 8])
nodeId: 120 ,  parentId: 61 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 73
nodeId:  121 , imgTensorShape :  torch.Size([182, 16, 8, 8])
nodeId: 121 ,  parentId: 61 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 182
Nodes sizes =  10 10
Node 62 Acc: 45.988
Split Acc: 98.148
# of Left images:  636.0
# of Right images:  12.0
giniRightRatio:  0.7222222222222222
giniLeftRatio:  0.7802203235631502
impurityDrop:  3.796121593291403
giniGain:  -3.0167053457681594
lclasses:  [4, 0, 55, 54, 130, 73, 80, 233, 3, 4]
rclasses:  [0, 0, 0, 1, 3, 1, 2, 5, 0, 0]
noOfLeftClasses:  9
noOfRightClasses:  5
lTrainDict[data].shape:  torch.Size([636, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([636])
rTrainDict[data].shape:  torch.Size([12, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([12])
RETURNING FROM WORK...
nodeId:  122 , imgTensorShape :  torch.Size([636, 16, 8, 8])
nodeId: 122 ,  parentId: 62 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 636
nodeId:  123 , imgTensorShape :  torch.Size([12, 16, 8, 8])
nodeId: 123 ,  parentId: 62 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 7 ,  numData: 12
Nodes sizes =  10 7
Node 63 Acc: 37.346
Split Acc: 67.047
# of Left images:  730.0
# of Right images:  408.0
giniRightRatio:  0.7143045943867742
giniLeftRatio:  0.8380296490898854
impurityDrop:  0.9356754030467527
giniGain:  -0.11703758070249248
lclasses:  [8, 5, 67, 119, 104, 133, 137, 142, 4, 11]
rclasses:  [2, 0, 28, 117, 16, 172, 18, 54, 0, 1]
noOfLeftClasses:  10
noOfRightClasses:  8
lTrainDict[data].shape:  torch.Size([730, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([730])
rTrainDict[data].shape:  torch.Size([408, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([408])
RETURNING FROM WORK...
nodeId:  124 , imgTensorShape :  torch.Size([730, 16, 8, 8])
nodeId: 124 ,  parentId: 63 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 730
nodeId:  125 , imgTensorShape :  torch.Size([408, 16, 8, 8])
nodeId: 125 ,  parentId: 63 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: -1 ,  numClasses: 10 ,  numData: 408
Nodes sizes =  10 10
Node 64 Acc: 30.597
Node 65 Acc: 52.469
Node 66 Acc: 34.000
Node 67 Acc: 44.444
Node 68 Acc: 58.716
Node 69 Acc: 78.378
Node 70 Acc: 65.385
Node 71 Acc: 55.034
Node 72 Acc: 57.088
Node 73 Acc: 43.728
Node 74 Acc: 66.187
Node 75 Acc: 53.898
Node 76 Acc: 51.852
Node 77 Acc: 59.746
Node 78 Acc: 50.562
Node 79 Acc: 56.145
Node 80 Acc: 20.988
Node 81 Acc: 40.952
Node 82 Acc: 35.036
Node 83 Acc: 27.119
Node 84 Acc: 75.000
Node 85 Acc: 41.379
Node 86 Acc: 39.130
Node 87 Acc: 64.000
Node 88 Acc: 28.856
Node 89 Acc: 20.408
Node 90 Acc: 21.250
Node 91 Acc: 26.891
Node 92 Acc: 48.387
Node 93 Acc: 30.534
Node 94 Acc: 28.860
Node 95 Acc: 30.303
Node 96 Acc: 23.952
Node 97 Acc: 19.192
Node 98 Acc: 44.048
Node 99 Acc: 35.294
Node 100 Acc: 63.636
Node 101 Acc: 69.565
Node 102 Acc: 62.651
Node 103 Acc: 71.429
Node 104 Acc: 41.830
Node 105 Acc: 59.459
Node 106 Acc: 25.000
Node 107 Acc: 100.000
Node 108 Acc: 26.207
Node 109 Acc: 16.364
Node 110 Acc: 0.000
Node 111 Acc: 26.000
Node 112 Acc: 31.736
Node 113 Acc: 51.485
Node 114 Acc: 34.641
Node 115 Acc: 49.669
Node 116 Acc: 46.201
Node 117 Acc: 25.000
Node 118 Acc: 26.437
Node 119 Acc: 41.176
Node 120 Acc: 43.836
Node 121 Acc: 26.374
Node 122 Acc: 45.440
Node 123 Acc: 50.000
Node 124 Acc: 35.068
Node 125 Acc: 37.010
[[467  78  90  29  36  30  22  22 157  69]
 [ 80 543  28  25  12  18  14  21  78 181]
 [ 85  21 307 117 121 113 103  74  33  26]
 [ 29  14 122 292 101 207 111  75  20  29]
 [ 35  20 140 103 291  98 143 107  26  37]
 [ 26   8  97 214  86 329  72 120  19  29]
 [ 12  18 104 127  95  67 491  32  14  40]
 [ 36  23  70  90  89 127  39 450  23  53]
 [149  92  24  37  25  18  18  11 532  94]
 [ 68 161  21  31  33  15  33  56 102 480]]

Acc: 41.820

                                                                                                                                                                                                                                                                                                                                                                                                                                             1                                                                                                                                                                                                                                                                                                                                                                                                                                                           
                                                                                                                                                                                                             ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                           
                                                                                                                                                                                                             3                                                                                                                                                                                                                                                                                                                                                                                                                                                               2                                                                                                                                                                                                                           
                                                                                             ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                               ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                           
                                                                                             7                                                                                                                                                                                                                               6                                                                                                                                                                                                                               4                                                                                                                                                                                                                               5                                                                                                           
                                     ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                   
                                     14                                                                                                              15                                                                                                              12                                                                                                              13                                                                                                              8                                                                                                               9                                                                                                               10                                                                                                              11                                                  
         ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                       
         29                                                      28                                                      30                                                      31                                                      24                                                      25                                                      26                                                      27                                                      16                                                      17                                                      18                                                      19                                                      20                                                      21                                                      22                                                      23                      
  ┌──────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐         
  59                   58                          56                          57                          60                          61                          62                          63                          48                          49                          50                          51                          52                          53                          54                          55                          32                          33                          34                          35                          36                          37                          38                          39                          40                          41                          42                          43                          44                          45                          46                          47        
                ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐  
               116           117           112           113           114           115           118           119           120           121           122           123           124           125            96            97            98            99           100           101           102           103           104           105           106           107           108           109           110           111            64            65            66            67            68            69            70            71            72            73            74            75            76            77            78            79            80            81            82            83            84            85            86            87            88            89            90            91            92            93            94            95 

                                                                                                                                                                                                                                                                                                                                                                                                                                             -1                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                             ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                           
                                                                                                                                                                                                             -1                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1                                                                                                                                                                                                                          
                                                                                             ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                               ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                           
                                                                                             -1                                                                                                                                                                                                                              -1                                                                                                                                                                                                                              -1                                                                                                                                                                                                                              -1                                                                                                          
                                     ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                   
                                     -1                                                                                                              -1                                                                                                              -1                                                                                                              -1                                                                                                              -1                                                                                                              -1                                                                                                              -1                                                                                                              -1                                                  
         ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                       
         -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                                                      -1                      
  ┌──────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐         
  -1                   -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1                          -1        
                ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐  
                -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1            -1 

                                                                                                                                                                                                                                                                                                                                                                                                                                                       50000                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                         ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                 
                                                                                                                                                                                                                       25778                                                                                                                                                                                                                                                                                                                                                                                                                                                                     24222                                                                                                                                                                                                                               
                                                                                                   ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                               ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                               
                                                                                                 19705                                                                                                                                                                                                                                  6073                                                                                                                                                                                                                           13837                                                                                                                                                                                                                                       10385                                                                                                             
                                       ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                                     ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────┐                                                                                                                     ┌───────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────┐                                                     
                                      8845                                                                                                               10860                                                                                                                  3642                                                                                                            2431                                                                                                            4052                                                                                                                  9785                                                                                                                  3983                                                                                                              6402                                                   
         ┌─────────────────────────────┴───────────────────────────────┐                                                       ┌───────────────────────────┴─────────────────────────────┐                                                           ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                           ┌─────────────────────────────┴─────────────────────────────┐                                                           ┌───────────────────────────┴───────────────────────────┐                                                         ┌───────────────────────────┴───────────────────────────┐                         
        1873                                                          6972                                                    1829                                                      9031                                                        2393                                                    1249                                                    1148                                                    1283                                                    1979                                                    2073                                                        4636                                                        5149                                                        3013                                                    970                                                       2355                                                    4047                       
  ┌──────┴───────────────┐                             ┌───────────────┴─────────────┐                           ┌─────────────┴─────────────┐                             ┌─────────────┴───────────────┐                             ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                             ┌───────────────┴─────────────┐                             ┌───────────────┴─────────────┐                             ┌───────────────┴─────────────┐                           ┌─────────────┴─────────────┐                             ┌─────────────┴─────────────┐                           ┌─────────────┴───────────────┐         
  91                    1782                          5526                          1446                        719                         1110                          3337                          5694                          1419                        974                         690                         559                         1005                        143                         904                         379                         1458                        521                         956                         1117                          2560                          2076                          2667                          2482                          1583                          1430                        497                         473                           1296                        1059                        795                           3252       
                 ┌───────┴──────┐              ┌───────┴───────┐              ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐              ┌───────┴──────┐              ┌───────┴───────┐              ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐              ┌───────┴───────┐              ┌──────┴───────┐              ┌──────┴───────┐              ┌──────┴───────┐              ┌──────┴───────┐              ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐              ┌───────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐              ┌───────┴──────┐  
                1538           244            2918            2608           746           700           460           259           381           729            3226           111            3528            2166           822           597           502           472           528           162           375           184           774           231           133            10           618           286            97           282           637           821           274           247           542           414           275           842            1245            1315           661            1415           285            2382           493            1989           435            1148           675           755            66           431           225           248            1062           234           419           640           173           622            2460           792 

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      {0: 751, 1: 1638, 2: 3137, 3: 3269, 4: 3721, 5: 3406, 6: 4307, 7: 3486, 8: 457, 9: 1606}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {0: 4249, 1: 3362, 2: 1863, 3: 1731, 4: 1279, 5: 1594, 6: 693, 7: 1514, 8: 4543, 9: 3394}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {0: 354, 1: 100, 2: 2851, 3: 2849, 4: 3471, 5: 3068, 6: 3832, 7: 2899, 8: 106, 9: 175}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        {0: 397, 1: 1538, 2: 286, 3: 420, 4: 250, 5: 338, 6: 475, 7: 587, 8: 351, 9: 1431}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {0: 3255, 1: 2884, 2: 591, 3: 137, 4: 423, 5: 83, 6: 136, 7: 186, 8: 3932, 9: 2210}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    {0: 994, 1: 478, 2: 1272, 3: 1594, 4: 856, 5: 1511, 6: 557, 7: 1328, 8: 611, 9: 1184}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             
                                                                                                                                                                                                   ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                           
                                                                                                                                                           {0: 200, 1: 28, 2: 1680, 3: 1165, 4: 1988, 5: 818, 6: 2437, 7: 406, 8: 69, 9: 54}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {0: 154, 1: 72, 2: 1171, 3: 1684, 4: 1483, 5: 2250, 6: 1395, 7: 2493, 8: 37, 9: 121}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    {0: 121, 1: 902, 2: 120, 3: 275, 4: 132, 5: 257, 6: 221, 7: 489, 8: 67, 9: 1058}                                                                                                                                                                                                                                                                                                                                                                                                                                         {0: 276, 1: 636, 2: 166, 3: 145, 4: 118, 5: 81, 6: 254, 7: 98, 8: 284, 9: 373}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {0: 1584, 1: 101, 2: 437, 3: 67, 4: 288, 5: 44, 6: 82, 7: 36, 8: 1300, 9: 113}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {0: 1671, 1: 2783, 2: 154, 3: 70, 4: 135, 5: 39, 6: 54, 7: 150, 8: 2632, 9: 2097}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          {0: 623, 1: 267, 2: 363, 3: 376, 4: 248, 5: 267, 6: 179, 7: 677, 8: 231, 9: 752}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {0: 371, 1: 211, 2: 909, 3: 1218, 4: 608, 5: 1244, 6: 378, 7: 651, 8: 380, 9: 432}                                                                                                                                                                                                                                                                                  
                                             ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                   ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                               ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                   ┌─────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                             ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                         ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                               ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                                                                                                 ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                   
         {0: 90, 1: 4, 2: 540, 3: 149, 4: 570, 5: 105, 6: 331, 7: 37, 8: 35, 9: 12}                                                                                                                                                                                                                                                  {0: 110, 1: 24, 2: 1140, 3: 1016, 4: 1418, 5: 713, 6: 2106, 7: 369, 8: 34, 9: 42}                                                                                                                                                                                                                                      {0: 97, 1: 38, 2: 418, 3: 189, 4: 246, 5: 232, 6: 163, 7: 403, 8: 14, 9: 29}                                                                                                                                                                                                                                       {0: 57, 1: 34, 2: 753, 3: 1495, 4: 1237, 5: 2018, 6: 1232, 7: 2090, 8: 23, 9: 92}                                                                                                                                                                                                                                                                 {0: 91, 1: 283, 2: 112, 3: 268, 4: 117, 5: 241, 6: 188, 7: 453, 8: 49, 9: 591}                                                                                                                                                                                                                                {0: 30, 1: 619, 2: 8, 3: 7, 4: 15, 5: 16, 6: 33, 7: 36, 8: 18, 9: 467}                                                                                                                                                                                                            {0: 183, 1: 462, 2: 39, 3: 10, 4: 29, 5: 4, 6: 81, 7: 10, 8: 173, 9: 157}                                                                                                                                                                                        {0: 93, 1: 174, 2: 127, 3: 135, 4: 89, 5: 77, 6: 173, 7: 88, 8: 111, 9: 216}                                                                                                                                                                                                                                                   {0: 522, 1: 45, 2: 301, 3: 55, 4: 204, 5: 32, 6: 76, 7: 27, 8: 649, 9: 68}                                                                                                                                                                                                                   {0: 1062, 1: 56, 2: 136, 3: 12, 4: 84, 5: 12, 6: 6, 7: 9, 8: 651, 9: 45}                                                                                                                                                                                                                                               {0: 406, 1: 1400, 2: 98, 3: 57, 4: 86, 5: 31, 6: 38, 7: 109, 8: 974, 9: 1437}                                                                                                                                                                                                                                          {0: 1265, 1: 1383, 2: 56, 3: 13, 4: 49, 5: 8, 6: 16, 7: 41, 8: 1658, 9: 660}                                                                                                                                                                                                                                                  {0: 299, 1: 225, 2: 199, 3: 302, 4: 160, 5: 220, 6: 158, 7: 529, 8: 188, 9: 733}                                                                                                                                                                                                                                 {0: 324, 1: 42, 2: 164, 3: 74, 4: 88, 5: 47, 6: 21, 7: 148, 8: 43, 9: 19}                                                                                                                                                                                                                                                      {0: 113, 1: 189, 2: 207, 3: 333, 4: 155, 5: 305, 6: 158, 7: 292, 8: 225, 9: 378}                                                                                                                                                                                                                                               {0: 258, 1: 22, 2: 702, 3: 885, 4: 453, 5: 939, 6: 220, 7: 359, 8: 155, 9: 54}                                                                                                                            
                    ┌────────────────────────┴─────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                             ┌───────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                         ┌─────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                           ┌─────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                       ┌─────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                         ┌─────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────┐                                                                                                                             ┌───────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────┐                                                                                                                       ┌───────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                 ┌───────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                 ┌─────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────┐                                                                                                                                                                 ┌─────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                     ┌─────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                 ┌───────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                 ┌─────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                   ┌───────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                         ┌─────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────┐                                                                             
 {1: 4, 2: 24, 3: 2, 4: 12, 5: 1, 6: 48}                                                  {0: 90, 2: 516, 3: 147, 4: 558, 5: 104, 6: 283, 7: 37, 8: 35, 9: 12}                                                                                     {0: 31, 1: 11, 2: 858, 3: 921, 4: 1134, 5: 648, 6: 1575, 7: 309, 8: 17, 9: 22}                                                                                            {0: 79, 1: 13, 2: 282, 3: 95, 4: 284, 5: 65, 6: 531, 7: 60, 8: 17, 9: 20}                                                                                  {0: 26, 1: 7, 2: 175, 3: 103, 4: 53, 5: 146, 6: 45, 7: 156, 8: 3, 9: 5}                                                                              {0: 71, 1: 31, 2: 243, 3: 86, 4: 193, 5: 86, 6: 118, 7: 247, 8: 11, 9: 24}                                                                                                 {0: 11, 1: 4, 2: 314, 3: 337, 4: 596, 5: 403, 6: 402, 7: 1224, 8: 16, 9: 30}                                                                   {0: 46, 1: 30, 2: 439, 3: 1158, 4: 641, 5: 1615, 6: 830, 7: 866, 8: 7, 9: 62}                                                                                            {0: 75, 1: 167, 2: 81, 3: 200, 4: 86, 5: 153, 6: 126, 7: 259, 8: 14, 9: 258}                                                                                         {0: 16, 1: 116, 2: 31, 3: 68, 4: 31, 5: 88, 6: 62, 7: 194, 8: 35, 9: 333}                                                                                       {0: 14, 1: 376, 2: 7, 4: 8, 5: 7, 6: 23, 7: 28, 8: 4, 9: 223}                                                                        {0: 16, 1: 243, 2: 1, 3: 7, 4: 7, 5: 9, 6: 10, 7: 8, 8: 14, 9: 244}                                                         {0: 140, 1: 403, 2: 32, 3: 10, 4: 29, 5: 4, 6: 79, 7: 6, 8: 159, 9: 143}                                                                           {0: 43, 1: 59, 2: 7, 6: 2, 7: 4, 8: 14, 9: 14}                                                            {0: 46, 1: 112, 2: 99, 3: 116, 4: 54, 5: 62, 6: 144, 7: 53, 8: 80, 9: 138}                                                                                    {0: 47, 1: 62, 2: 28, 3: 19, 4: 35, 5: 15, 6: 29, 7: 35, 8: 31, 9: 78}                                                                                          {0: 457, 1: 39, 2: 155, 3: 37, 4: 93, 5: 16, 6: 26, 7: 16, 8: 566, 9: 53}                                                                                        {0: 65, 1: 6, 2: 146, 3: 18, 4: 111, 5: 16, 6: 50, 7: 11, 8: 83, 9: 15}                                                                                {0: 548, 1: 8, 2: 63, 3: 3, 4: 28, 5: 1, 7: 6, 8: 288, 9: 11}                                                           {0: 514, 1: 48, 2: 73, 3: 9, 4: 56, 5: 11, 6: 6, 7: 3, 8: 363, 9: 34}                                                                                          {0: 210, 1: 468, 2: 59, 3: 38, 4: 63, 5: 19, 6: 31, 7: 71, 8: 524, 9: 1077}                                                                                          {0: 196, 1: 932, 2: 39, 3: 19, 4: 23, 5: 12, 6: 7, 7: 38, 8: 450, 9: 360}                                                                              {0: 678, 1: 626, 2: 26, 3: 5, 4: 19, 5: 7, 6: 1, 7: 3, 8: 1136, 9: 166}                                                                                     {0: 587, 1: 757, 2: 30, 3: 8, 4: 30, 5: 1, 6: 15, 7: 38, 8: 522, 9: 494}                                                                                        {0: 141, 1: 206, 2: 65, 3: 71, 4: 60, 5: 64, 6: 37, 7: 197, 8: 146, 9: 596}                                                                                          {0: 158, 1: 19, 2: 134, 3: 231, 4: 100, 5: 156, 6: 121, 7: 332, 8: 42, 9: 137}                                                                        {0: 127, 1: 2, 2: 99, 3: 43, 4: 67, 5: 33, 6: 11, 7: 103, 8: 9, 9: 3}                                                                                  {0: 197, 1: 40, 2: 65, 3: 31, 4: 21, 5: 14, 6: 10, 7: 45, 8: 34, 9: 16}                                                                                           {0: 43, 1: 80, 2: 121, 3: 230, 4: 60, 5: 204, 6: 85, 7: 145, 8: 128, 9: 200}                                                                                      {0: 70, 1: 109, 2: 86, 3: 103, 4: 95, 5: 101, 6: 73, 7: 147, 8: 97, 9: 178}                                                                                 {0: 23, 1: 1, 2: 203, 3: 189, 4: 86, 5: 93, 6: 151, 7: 26, 8: 15, 9: 8}                                                                                              {0: 235, 1: 21, 2: 499, 3: 696, 4: 367, 5: 846, 6: 69, 7: 333, 8: 140, 9: 46}                                       
                                                                                    ┌──────────────────────────────────────┴───────────────────────────────────┐                                                                              ┌──────────────────────────────────────────┴─────────────────────────────────────────┐                                                                                   ┌─────────────────────────────────────────┴───────────────────────────────────────┐                                                                            ┌────────────────────────────────────┴──────────────────────────────────┐                                                                          ┌───────────────────────────────────────┴─────────────────────────────────────────┐                                                                                     ┌───────────────────────────────────────────┴────────────────────────────┐                                                                       ┌──────────────────────────────────────────┴─────────────────────────────────────────┐                                                                                   ┌─────────────────────────────────────────┴────────────────────────────────────────┐                                                                                 ┌────────────────────────────────────────┴────────────────────────────────────────┐                                                                            ┌───────────────────────────────────┴──────────────────────────────┐                                                                   ┌────────────────────────────────────┴────────────────────────┐                                                              ┌─────────────────────────────────────┴─────────────────────────────────────┐                                                                  ┌────────────────────────────┴─────────────────┐                                                           ┌─────────────────────────────────────────┴───────────────────────────────────────┐                                                                             ┌─────────────────────────────────────┴───────────────────────────────────────┐                                                                                ┌────────────────────────────────────────┴───────────────────────────────────────┐                                                                               ┌───────────────────────────────────────┴─────────────────────────────────────┐                                                                        ┌──────────────────────────────────┴────────────────────────────┐                                                             ┌────────────────────────────────┴───────────────────────────────────────┐                                                                                ┌────────────────────────────────────────┴──────────────────────────────────────────┐                                                                                 ┌──────────────────────────────────────┴─────────────────────────────────────────┐                                                                          ┌────────────────────────────────┴────────────────────────────────────────┐                                                                             ┌────────────────────────────────────┴────────────────────────────────────────┐                                                                                ┌───────────────────────────────────────┴─────────────────────────────────────────┐                                                                                  ┌────────────────────────────────────────┴─────────────────────────────────────────┐                                                                        ┌──────────────────────────────┴────────────────────────────────────┐                                                                           ┌──────────────────────────────────────┴──────────────────────────────────────┐                                                                                 ┌──────────────────────────────────────────┴───────────────────────────────────────┐                                                                                ┌────────────────────────────────────────┴─────────────────────────────────────────┐                                                                            ┌──────────────────────────────────┴────────────────────────────────────────┐                                                                                   ┌──────────────────────────────────────────┴────────────────────────────────────────┐                                    
                                                    {0: 22, 2: 454, 3: 136, 4: 528, 5: 91, 6: 256, 7: 33, 8: 15, 9: 3}           {0: 68, 2: 62, 3: 11, 4: 30, 5: 13, 6: 27, 7: 4, 8: 20, 9: 9}           {0: 19, 1: 6, 2: 444, 3: 664, 4: 541, 5: 533, 6: 445, 7: 239, 8: 12, 9: 15}           {0: 12, 1: 5, 2: 414, 3: 257, 4: 593, 5: 115, 6: 1130, 7: 70, 8: 5, 9: 7}            {0: 55, 1: 7, 2: 144, 3: 62, 4: 186, 5: 39, 6: 180, 7: 40, 8: 16, 9: 17}           {0: 24, 1: 6, 2: 138, 3: 33, 4: 98, 5: 26, 6: 351, 7: 20, 8: 1, 9: 3}            {0: 21, 1: 6, 2: 127, 3: 81, 4: 42, 5: 72, 6: 42, 7: 66, 8: 3}           {0: 5, 1: 1, 2: 48, 3: 22, 4: 11, 5: 74, 6: 3, 7: 90, 9: 5}            {0: 14, 1: 7, 2: 46, 3: 17, 4: 79, 5: 28, 6: 14, 7: 171, 8: 1, 9: 4}           {0: 57, 1: 24, 2: 197, 3: 69, 4: 114, 5: 58, 6: 104, 7: 76, 8: 10, 9: 20}            {0: 11, 1: 1, 2: 301, 3: 321, 4: 573, 5: 391, 6: 393, 7: 1189, 8: 16, 9: 30}           {1: 3, 2: 13, 3: 16, 4: 23, 5: 12, 6: 9, 7: 35}           {0: 35, 1: 22, 2: 291, 3: 543, 4: 518, 5: 698, 6: 721, 7: 643, 8: 2, 9: 55}           {0: 11, 1: 8, 2: 148, 3: 615, 4: 123, 5: 917, 6: 109, 7: 223, 8: 5, 9: 7}            {0: 48, 1: 130, 2: 44, 3: 70, 4: 44, 5: 55, 6: 91, 7: 152, 8: 5, 9: 183}           {0: 27, 1: 37, 2: 37, 3: 130, 4: 42, 5: 98, 6: 35, 7: 107, 8: 9, 9: 75}           {0: 5, 1: 27, 2: 20, 3: 50, 4: 13, 5: 60, 6: 23, 7: 135, 8: 18, 9: 151}           {0: 11, 1: 89, 2: 11, 3: 18, 4: 18, 5: 28, 6: 39, 7: 59, 8: 17, 9: 182}            {0: 12, 1: 284, 2: 6, 4: 1, 5: 4, 6: 21, 7: 9, 8: 4, 9: 187}           {0: 2, 1: 92, 2: 1, 4: 7, 5: 3, 6: 2, 7: 19, 9: 36}           {0: 8, 1: 97, 2: 1, 3: 7, 4: 6, 5: 9, 6: 7, 7: 8, 8: 8, 9: 224}           {0: 8, 1: 146, 4: 1, 6: 3, 8: 6, 9: 20}           {0: 103, 1: 308, 2: 28, 3: 9, 4: 27, 6: 62, 7: 4, 8: 132, 9: 101}           {0: 37, 1: 95, 2: 4, 3: 1, 4: 2, 5: 4, 6: 17, 7: 2, 8: 27, 9: 42}            {0: 42, 1: 52, 2: 7, 6: 1, 7: 4, 8: 14, 9: 13}            {0: 1, 1: 7, 6: 1, 9: 1}            {0: 23, 1: 64, 2: 56, 3: 85, 4: 34, 5: 37, 6: 122, 7: 44, 8: 52, 9: 101}           {0: 23, 1: 48, 2: 43, 3: 31, 4: 20, 5: 25, 6: 22, 7: 9, 8: 28, 9: 37}           {0: 7, 1: 17, 2: 7, 3: 11, 4: 16, 5: 2, 6: 11, 7: 11, 8: 6, 9: 9}           {0: 40, 1: 45, 2: 21, 3: 8, 4: 19, 5: 13, 6: 18, 7: 24, 8: 25, 9: 69}           {0: 218, 1: 30, 2: 67, 3: 22, 4: 50, 5: 13, 6: 15, 7: 9, 8: 176, 9: 37}           {0: 239, 1: 9, 2: 88, 3: 15, 4: 43, 5: 3, 6: 11, 7: 7, 8: 390, 9: 16}            {0: 14, 1: 4, 2: 60, 3: 11, 4: 85, 5: 12, 6: 46, 7: 5, 8: 26, 9: 11}            {0: 51, 1: 2, 2: 86, 3: 7, 4: 26, 5: 4, 6: 4, 7: 6, 8: 57, 9: 4}           {0: 365, 1: 6, 2: 54, 3: 2, 4: 28, 5: 1, 7: 5, 8: 78, 9: 3}            {0: 183, 1: 2, 2: 9, 3: 1, 7: 1, 8: 210, 9: 8}            {0: 101, 1: 7, 2: 11, 4: 12, 5: 2, 6: 1, 8: 135, 9: 6}            {0: 413, 1: 41, 2: 62, 3: 9, 4: 44, 5: 9, 6: 5, 7: 3, 8: 228, 9: 28}            {0: 83, 1: 157, 2: 23, 3: 7, 4: 29, 5: 4, 6: 3, 7: 39, 8: 257, 9: 643}            {0: 127, 1: 311, 2: 36, 3: 31, 4: 34, 5: 15, 6: 28, 7: 32, 8: 267, 9: 434}           {0: 34, 1: 400, 2: 4, 3: 4, 4: 7, 5: 1, 6: 2, 7: 18, 8: 22, 9: 169}           {0: 162, 1: 532, 2: 35, 3: 15, 4: 16, 5: 11, 6: 5, 7: 20, 8: 428, 9: 191}            {0: 92, 1: 63, 2: 14, 3: 2, 4: 14, 5: 2, 8: 78, 9: 20}            {0: 586, 1: 563, 2: 12, 3: 3, 4: 5, 5: 5, 6: 1, 7: 3, 8: 1058, 9: 146}           {0: 149, 1: 124, 2: 13, 3: 6, 4: 21, 6: 2, 7: 25, 8: 82, 9: 71}           {0: 438, 1: 633, 2: 17, 3: 2, 4: 9, 5: 1, 6: 13, 7: 13, 8: 440, 9: 423}           {0: 68, 1: 64, 2: 43, 3: 17, 4: 13, 5: 19, 6: 7, 7: 46, 8: 80, 9: 78}           {0: 73, 1: 142, 2: 22, 3: 54, 4: 47, 5: 45, 6: 30, 7: 151, 8: 66, 9: 518}           {0: 74, 1: 2, 2: 51, 3: 104, 4: 36, 5: 106, 6: 13, 7: 237, 8: 8, 9: 44}            {0: 84, 1: 17, 2: 83, 3: 127, 4: 64, 5: 50, 6: 108, 7: 95, 8: 34, 9: 93}            {0: 39, 1: 2, 2: 14, 3: 1, 4: 4, 5: 2, 7: 1, 8: 3}            {0: 88, 2: 85, 3: 42, 4: 63, 5: 31, 6: 11, 7: 102, 8: 6, 9: 3}            {0: 84, 1: 7, 2: 39, 3: 26, 4: 11, 5: 9, 6: 6, 7: 25, 8: 8, 9: 10}           {0: 113, 1: 33, 2: 26, 3: 5, 4: 10, 5: 5, 6: 4, 7: 20, 8: 26, 9: 6}           {0: 35, 1: 65, 2: 82, 3: 191, 4: 44, 5: 190, 6: 39, 7: 132, 8: 106, 9: 178}           {0: 8, 1: 15, 2: 39, 3: 39, 4: 16, 5: 14, 6: 46, 7: 13, 8: 22, 9: 22}            {0: 42, 1: 71, 2: 39, 3: 43, 4: 32, 5: 38, 6: 27, 7: 38, 8: 54, 9: 35}            {0: 28, 1: 38, 2: 47, 3: 60, 4: 63, 5: 63, 6: 46, 7: 109, 8: 43, 9: 143}           {0: 13, 2: 79, 3: 33, 4: 14, 5: 15, 6: 6, 7: 4, 8: 5, 9: 4}           {0: 10, 1: 1, 2: 124, 3: 156, 4: 72, 5: 78, 6: 145, 7: 22, 8: 10, 9: 4}           {0: 92, 1: 14, 2: 308, 3: 553, 4: 305, 5: 685, 6: 64, 7: 301, 8: 97, 9: 41}           {0: 143, 1: 7, 2: 191, 3: 143, 4: 62, 5: 161, 6: 5, 7: 32, 8: 43, 9: 5} 

                                                                                                                                                                                                                                                                                                                                                                                                                                             73.62                                                                                                                                                                                                                                                                                                                                                                                                                                                             
                                                                                                                                                                                                             ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                             
                                                                                                                                                                                                     88.47358121330724                                                                                                                                                                                                                                                                                                                                                                                                                                                    81.1042944785276                                                                                                                                                                                                                     
                                                                                             ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                               ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                           
                                                                                     62.66094420600859                                                                                                                                                                                                                 62.48912097476066                                                                                                                                                                                                               74.33212996389892                                                                                                                                                                                                                   66.98113207547169                                                                                                   
                                     ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                                 ┌───────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                                                                               ┌───────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────┐                                                                                                               ┌─────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────┐                                                   
                             77.87659811006114                                                                                               82.88621646623497                                                                                                 73.42143906020559                                                                                               67.94871794871794                                                                                               63.054830287206265                                                                                                62.724550898203596                                                                                                    77.75                                                                                                        73.4090909090909                                           
         ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌─────────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                         ┌───────────────────────────┴───────────────────────────┐                                                       ┌───────────────────────────┴───────────────────────────┐                                                         ┌───────────────────────────┴───────────────────────────┐                       
 95.06493506493507                                       79.27864214992928                                       68.61702127659575                                       66.01343784994401                                       63.93805309734513                                         59.38864628820961                                       92.11822660098522                                       72.45283018867924                                       68.06282722513089                                            52.34375                                             66.73511293634498                                       63.689320388349515                                      68.59504132231405                                       65.64102564102564                                         57.46102449888642                                       83.00803673938002               
  ┌──────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴──────────────┐                            ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                            ┌──────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐                           ┌─────────────┴──────────────┐                            ┌─────────────┴─────────────┐                           ┌─────────────┴─────────────┐         
 0.0            88.6178861788618           66.30630630630631           57.56578947368421           76.85950413223141           70.98039215686275           98.14814814814815           67.04745166959579           69.92481203007519            62.365591397849464           83.78378378378379            71.1864406779661                  80.0                 84.61538461538461                  66.0                 75.38461538461539           61.82432432432432           67.44186046511628           66.12021857923497           67.16417910447761            63.333333333333336           67.28110599078342           89.54372623574145           82.93650793650794           72.85223367697594           64.64968152866243           87.87878787878788            57.291666666666664                  82.0                 65.82914572864321            80.8641975308642            77.0098730606488 
                ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐              ┌──────┴──────┐              ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐              ┌──────┴──────┐              ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐              ┌──────┴──────┐              ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐             ┌──────┴──────┐  
               0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0            0.0           0.0            0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0            0.0           0.0            0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0            0.0           0.0            0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0 

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0.027519671091771447                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
                                                                                                                                                                                                                                  ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                        0.031784941931194854                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0.11197626260136206                                                                                                                                                                                                                                                
                                                                                                      ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                                                                                         ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐                                                                                                                         
                                                                                            0.029596982609356393                                                                                                                                                                                                                                       0.04696488313152358                                                                                                                                                                                                                                       0.039781575944398906                                                                                                                                                                                                                                          0.012867384996324893                                                                                                               
                                      ┌───────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────┐                                                                                                                           ┌─────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────┐                                                                                                                             ┌─────────────────────────────────────────────────────────────┴─────────────────────────────────────────────────────────────┐                                                                                                                               ┌───────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────┐                                                         
                             -0.0660367296896397                                                                                                             0.004863649734798248                                                                                                        -0.2574898838648706                                                                                                         0.07990618879303968                                                                                                          -0.052497273914476006                                                                                                        0.012801870584665864                                                                                                            -0.09490105148034145                                                                                                           0.0031320328558918087                                               
          ┌───────────────────────────┴───────────────────────────────┐                                                               ┌───────────────────────────────┴───────────────────────────┐                                                               ┌───────────────────────────────┴─────────────────────────────┐                                                               ┌─────────────────────────────┴─────────────────────────────┐                                                               ┌───────────────────────────────┴─────────────────────────────┐                                                             ┌───────────────────────────────┴───────────────────────────────┐                                                               ┌───────────────────────────────┴───────────────────────────────┐                                                               ┌───────────────────────────────┴─────────────────────────────┐                           
 -2.7297915822290086                                         -0.08873267603231372                                            0.013839250507790779                                        0.02703540688316486                                             -0.04502430008509428                                          0.022195500835344828                                            -0.3006725720234298                                        -0.009522738408373366                                            0.21403846684832029                                           0.042399271478798406                                          0.014360008418475956                                            0.05762587540195119                                              0.0700076301503626                                            -0.007873191521756473                                            0.013143127837155877                                          0.011464550423814113                 
  ┌──────┴─────────────┐                              ┌───────────────┴───────────────┐                               ┌───────────────┴───────────────┐                             ┌─────────────┴───────────────┐                               ┌───────────────┴───────────────┐                              ┌──────────────┴───────────────┐                               ┌───────────────┴──────────────┐                             ┌──────────────┴───────────────┐                               ┌───────────────┴───────────────┐                              ┌──────────────┴───────────────┐                              ┌──────────────┴───────────────┐                               ┌───────────────┴───────────────┐                               ┌───────────────┴───────────────┐                               ┌───────────────┴───────────────┐                               ┌───────────────┴───────────────┐                              ┌──────────────┴───────────────┐           
 0.0           0.352679724192574            -0.031843592187721925            -0.05537753534742518            -0.06608569427860422            0.057082219442429416           0.556787394867335            -0.09038282647131557            0.013006522942194398           0.0029569702529614883           0.07837148700353092            -0.18177575825963144            -0.04096222986792519           -2.9957336855268384           0.01942958211375334            0.007864295603253968           -0.024918474649227584            0.007599448217192495           0.07263804863131929            0.016588245670968393           0.06422481211012421            0.056702621944145104           0.0027505465836258347           0.0018564765443682685            0.009494409600500076            0.053528084420501276            0.029673811728148758           -0.013501707573376542            0.020676001029120927            0.005935928676145341           0.02457607688358554            0.015239548788277268 
                ┌──────┴──────┐                ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐               ┌──────┴──────┐               ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                ┌──────┴──────┐                ┌──────┴──────┐                 ┌──────┴──────┐                ┌──────┴──────┐               ┌──────┴──────┐                ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                ┌──────┴──────┐                ┌──────┴──────┐                ┌──────┴──────┐                ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                 ┌──────┴──────┐                ┌──────┴──────┐                ┌──────┴──────┐    
               0.0           0.0              0.0           0.0               0.0           0.0               0.0           0.0               0.0           0.0             0.0           0.0             0.0           0.0               0.0           0.0               0.0           0.0              0.0           0.0              0.0           0.0               0.0           0.0              0.0           0.0             0.0           0.0              0.0           0.0               0.0           0.0               0.0           0.0              0.0           0.0              0.0           0.0              0.0           0.0              0.0           0.0               0.0           0.0               0.0           0.0               0.0           0.0               0.0           0.0               0.0           0.0               0.0           0.0               0.0           0.0               0.0           0.0              0.0           0.0              0.0           0.0   

