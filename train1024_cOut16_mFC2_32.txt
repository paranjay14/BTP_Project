['options.ckptDir: valDir1024_cOut16_mFC2_32', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 16', 'options.mlpFC1: 1024', 'options.mlpFC2: 32']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 177.956 | Train Acc: 37.506 | Val Loss: 1.554 | Val Accuracy: 45.300
10 Train Loss: 110.440 | Train Acc: 61.871 | Val Loss: 1.218 | Val Accuracy: 58.300
20 Train Loss: 95.641 | Train Acc: 66.978 | Val Loss: 1.156 | Val Accuracy: 60.100
30 Train Loss: 86.108 | Train Acc: 70.427 | Val Loss: 1.148 | Val Accuracy: 62.400
40 Train Loss: 77.209 | Train Acc: 73.724 | Val Loss: 1.152 | Val Accuracy: 61.300
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 71.861 | Train Acc: 75.508 | Val Loss: 1.186 | Val Accuracy: 62.100
60 Train Loss: 65.164 | Train Acc: 78.429 | Val Loss: 1.173 | Val Accuracy: 61.500
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 63.992 | Train Acc: 78.869 | Val Loss: 1.183 | Val Accuracy: 61.100
80 Train Loss: 62.439 | Train Acc: 79.669 | Val Loss: 1.183 | Val Accuracy: 61.100
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 62.157 | Train Acc: 79.829 | Val Loss: 1.187 | Val Accuracy: 61.100
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 12544])
Kmeans trained successfully...
printing expected split from k means
{8: 0, 5: 1, 9: 0, 2: 1, 4: 1, 0: 0, 1: 0, 7: 1, 6: 1, 3: 1}
Printing final_dict items...
{8: 0, 0: 0, 9: 0, 1: 0, 2: 0, 3: 1, 7: 1, 5: 1, 4: 1, 6: 1}
Image Statistics before MLP : L R :  24500 24500
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 82.048 | Acc: 81.735
1 Loss: 69.612 | Acc: 84.869
2 Loss: 64.812 | Acc: 85.965
3 Loss: 60.849 | Acc: 86.857
4 Loss: 57.140 | Acc: 87.710
5 Loss: 55.135 | Acc: 88.145
6 Loss: 51.324 | Acc: 88.984
7 Loss: 48.788 | Acc: 89.441
8 Loss: 47.026 | Acc: 89.792
9 Loss: 43.885 | Acc: 90.580
10 Loss: 36.561 | Acc: 92.429
11 Loss: 33.385 | Acc: 93.020
12 Loss: 30.855 | Acc: 93.633
13 Loss: 29.571 | Acc: 93.735
14 Loss: 28.143 | Acc: 94.206
15 Loss: 26.882 | Acc: 94.445
16 Loss: 24.132 | Acc: 95.098
17 Loss: 23.187 | Acc: 95.227
18 Loss: 22.053 | Acc: 95.524
19 Loss: 20.926 | Acc: 95.778
20 Loss: 16.391 | Acc: 96.769
21 Loss: 15.898 | Acc: 96.867
22 Loss: 14.395 | Acc: 97.100
23 Loss: 13.670 | Acc: 97.316
24 Loss: 13.618 | Acc: 97.386
25 Loss: 12.678 | Acc: 97.539
26 Loss: 12.091 | Acc: 97.690
27 Loss: 11.666 | Acc: 97.718
28 Loss: 11.687 | Acc: 97.780
29 Loss: 10.858 | Acc: 97.904
30 Loss: 9.969 | Acc: 98.131
31 Loss: 8.931 | Acc: 98.345
32 Loss: 8.471 | Acc: 98.457
33 Loss: 8.389 | Acc: 98.365
34 Loss: 8.142 | Acc: 98.543
35 Loss: 7.751 | Acc: 98.573
36 Loss: 7.797 | Acc: 98.590
37 Loss: 7.799 | Acc: 98.551
38 Loss: 7.563 | Acc: 98.592
39 Loss: 7.259 | Acc: 98.641
40 Loss: 6.951 | Acc: 98.702
41 Loss: 6.881 | Acc: 98.771
42 Loss: 6.792 | Acc: 98.767
43 Loss: 6.753 | Acc: 98.737
44 Loss: 6.533 | Acc: 98.792
45 Loss: 6.400 | Acc: 98.849
46 Loss: 6.418 | Acc: 98.859
47 Loss: 6.594 | Acc: 98.782
48 Loss: 6.353 | Acc: 98.831
49 Loss: 6.089 | Acc: 98.902
50 Loss: 5.941 | Acc: 98.910
51 Loss: 5.926 | Acc: 98.902
52 Loss: 5.867 | Acc: 98.906
53 Loss: 6.021 | Acc: 98.957
54 Loss: 6.163 | Acc: 98.898
55 Loss: 5.699 | Acc: 98.978
56 Loss: 5.754 | Acc: 98.980
57 Loss: 5.548 | Acc: 99.069
58 Loss: 5.868 | Acc: 98.935
59 Loss: 5.549 | Acc: 98.976
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([24500])
rTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([24500])
lValDict[data].shape:  torch.Size([500, 3, 32, 32])   lValDict[label].shape:  torch.Size([500])
rValDict[data].shape:  torch.Size([500, 3, 32, 32])   rValDict[label].shape:  torch.Size([500])
# of Left images:  24500.0
# of Right images:  24500.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [4900, 4900, 4900, 0, 0, 0, 0, 0, 4900, 4900]
rclasses:  [0, 0, 0, 4900, 4900, 4900, 4900, 4900, 0, 0]
noOfLeftClasses:  5
noOfRightClasses:  5
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
nodeId:  3 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
Running nodeId:  2
0 Train Loss: 117.490 | Train Acc: 53.371 | Val Loss: 0.999 | Val Accuracy: 63.400
10 Train Loss: 66.338 | Train Acc: 75.690 | Val Loss: 0.748 | Val Accuracy: 72.200
20 Train Loss: 52.890 | Train Acc: 80.943 | Val Loss: 0.698 | Val Accuracy: 73.800
30 Train Loss: 44.869 | Train Acc: 83.849 | Val Loss: 0.739 | Val Accuracy: 73.600
40 Train Loss: 38.561 | Train Acc: 86.584 | Val Loss: 0.734 | Val Accuracy: 74.800
50 Train Loss: 33.259 | Train Acc: 88.759 | Val Loss: 0.768 | Val Accuracy: 77.200
60 Train Loss: 29.958 | Train Acc: 89.751 | Val Loss: 0.836 | Val Accuracy: 75.000
Epoch     8: reducing learning rate of group 0 to 2.0000e-04.
70 Train Loss: 25.593 | Train Acc: 91.714 | Val Loss: 0.914 | Val Accuracy: 73.200
80 Train Loss: 21.590 | Train Acc: 94.184 | Val Loss: 0.908 | Val Accuracy: 74.600
Epoch    10: reducing learning rate of group 0 to 4.0000e-05.
90 Train Loss: 20.814 | Train Acc: 94.506 | Val Loss: 0.931 | Val Accuracy: 73.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Kmeans trained successfully...
printing expected split from k means
{4: 0, 2: 0, 1: 0, 0: 1, 3: 1}
Printing final_dict items...
{2: 0, 1: 0, 4: 1, 0: 1, 3: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 84.051 | Acc: 74.669
1 Loss: 68.478 | Acc: 80.363
2 Loss: 60.677 | Acc: 83.294
3 Loss: 55.530 | Acc: 84.682
4 Loss: 50.808 | Acc: 86.167
5 Loss: 46.566 | Acc: 87.531
6 Loss: 44.394 | Acc: 88.090
7 Loss: 39.974 | Acc: 89.306
8 Loss: 36.260 | Acc: 90.420
9 Loss: 33.790 | Acc: 91.127
10 Loss: 25.315 | Acc: 93.412
11 Loss: 21.869 | Acc: 94.612
12 Loss: 19.760 | Acc: 95.069
13 Loss: 18.291 | Acc: 95.233
14 Loss: 16.572 | Acc: 95.886
15 Loss: 15.727 | Acc: 96.212
16 Loss: 13.690 | Acc: 96.559
17 Loss: 13.435 | Acc: 96.661
18 Loss: 12.462 | Acc: 97.008
19 Loss: 13.174 | Acc: 96.747
20 Loss: 8.791 | Acc: 98.037
21 Loss: 7.562 | Acc: 98.306
22 Loss: 7.091 | Acc: 98.355
23 Loss: 6.722 | Acc: 98.441
24 Loss: 5.809 | Acc: 98.616
25 Loss: 5.755 | Acc: 98.665
26 Loss: 5.753 | Acc: 98.706
27 Loss: 6.018 | Acc: 98.629
28 Loss: 5.184 | Acc: 98.849
29 Loss: 4.928 | Acc: 98.935
30 Loss: 4.101 | Acc: 99.118
31 Loss: 3.803 | Acc: 99.200
32 Loss: 3.648 | Acc: 99.278
33 Loss: 3.640 | Acc: 99.261
34 Loss: 4.120 | Acc: 99.098
35 Loss: 3.367 | Acc: 99.273
36 Loss: 3.721 | Acc: 99.200
37 Loss: 2.897 | Acc: 99.392
38 Loss: 2.997 | Acc: 99.351
39 Loss: 3.037 | Acc: 99.371
40 Loss: 2.761 | Acc: 99.392
41 Loss: 3.014 | Acc: 99.392
42 Loss: 2.490 | Acc: 99.543
43 Loss: 2.633 | Acc: 99.478
44 Loss: 2.559 | Acc: 99.453
45 Loss: 2.453 | Acc: 99.486
46 Loss: 2.446 | Acc: 99.522
47 Loss: 2.573 | Acc: 99.498
48 Loss: 2.426 | Acc: 99.473
49 Loss: 2.718 | Acc: 99.433
50 Loss: 2.232 | Acc: 99.522
51 Loss: 2.397 | Acc: 99.449
52 Loss: 2.330 | Acc: 99.527
53 Loss: 2.216 | Acc: 99.563
54 Loss: 2.195 | Acc: 99.559
55 Loss: 2.213 | Acc: 99.535
56 Loss: 2.082 | Acc: 99.571
57 Loss: 2.293 | Acc: 99.531
58 Loss: 2.211 | Acc: 99.588
59 Loss: 2.006 | Acc: 99.612
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 4900, 4900, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  5 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  3
0 Train Loss: 138.452 | Train Acc: 41.690 | Val Loss: 1.261 | Val Accuracy: 48.600
10 Train Loss: 90.144 | Train Acc: 65.469 | Val Loss: 1.008 | Val Accuracy: 61.400
20 Train Loss: 76.241 | Train Acc: 71.020 | Val Loss: 0.981 | Val Accuracy: 63.400
30 Train Loss: 69.575 | Train Acc: 73.706 | Val Loss: 1.017 | Val Accuracy: 65.000
40 Train Loss: 63.095 | Train Acc: 76.073 | Val Loss: 1.021 | Val Accuracy: 62.600
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 58.029 | Train Acc: 78.416 | Val Loss: 1.063 | Val Accuracy: 63.400
60 Train Loss: 52.841 | Train Acc: 81.282 | Val Loss: 1.064 | Val Accuracy: 62.400
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 51.544 | Train Acc: 81.947 | Val Loss: 1.056 | Val Accuracy: 62.000
80 Train Loss: 50.227 | Train Acc: 82.596 | Val Loss: 1.060 | Val Accuracy: 63.400
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 49.923 | Train Acc: 82.751 | Val Loss: 1.061 | Val Accuracy: 63.200
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Kmeans trained successfully...
printing expected split from k means
{2: 1, 1: 0, 4: 0, 0: 0, 3: 0}
Printing final_dict items...
{1: 0, 4: 0, 3: 1, 0: 1, 2: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 80.510 | Acc: 75.784
1 Loss: 67.576 | Acc: 80.878
2 Loss: 61.185 | Acc: 83.049
3 Loss: 55.915 | Acc: 84.522
4 Loss: 52.435 | Acc: 85.576
5 Loss: 49.153 | Acc: 86.453
6 Loss: 45.033 | Acc: 87.669
7 Loss: 42.306 | Acc: 88.465
8 Loss: 38.769 | Acc: 89.363
9 Loss: 36.140 | Acc: 90.147
10 Loss: 27.274 | Acc: 92.824
11 Loss: 23.433 | Acc: 93.861
12 Loss: 21.898 | Acc: 94.229
13 Loss: 20.772 | Acc: 94.604
14 Loss: 18.813 | Acc: 94.971
15 Loss: 16.656 | Acc: 95.633
16 Loss: 15.944 | Acc: 95.947
17 Loss: 14.494 | Acc: 96.363
18 Loss: 12.966 | Acc: 96.702
19 Loss: 12.834 | Acc: 96.865
20 Loss: 8.868 | Acc: 97.820
21 Loss: 7.924 | Acc: 98.094
22 Loss: 6.988 | Acc: 98.388
23 Loss: 7.065 | Acc: 98.371
24 Loss: 6.255 | Acc: 98.498
25 Loss: 6.617 | Acc: 98.563
26 Loss: 6.056 | Acc: 98.620
27 Loss: 5.313 | Acc: 98.743
28 Loss: 5.543 | Acc: 98.771
29 Loss: 5.433 | Acc: 98.718
30 Loss: 4.213 | Acc: 99.065
31 Loss: 3.613 | Acc: 99.204
32 Loss: 3.519 | Acc: 99.331
33 Loss: 3.551 | Acc: 99.208
34 Loss: 3.175 | Acc: 99.286
35 Loss: 3.329 | Acc: 99.290
36 Loss: 3.076 | Acc: 99.384
37 Loss: 2.773 | Acc: 99.420
38 Loss: 2.869 | Acc: 99.380
39 Loss: 3.071 | Acc: 99.339
40 Loss: 2.707 | Acc: 99.429
41 Loss: 2.373 | Acc: 99.543
42 Loss: 2.794 | Acc: 99.380
43 Loss: 2.630 | Acc: 99.473
44 Loss: 2.373 | Acc: 99.482
45 Loss: 2.266 | Acc: 99.453
46 Loss: 2.218 | Acc: 99.506
47 Loss: 2.317 | Acc: 99.518
48 Loss: 2.278 | Acc: 99.498
49 Loss: 2.076 | Acc: 99.567
50 Loss: 2.039 | Acc: 99.608
51 Loss: 2.133 | Acc: 99.522
52 Loss: 2.130 | Acc: 99.535
53 Loss: 2.271 | Acc: 99.535
54 Loss: 2.113 | Acc: 99.514
55 Loss: 1.983 | Acc: 99.592
56 Loss: 1.951 | Acc: 99.608
57 Loss: 2.152 | Acc: 99.551
58 Loss: 2.241 | Acc: 99.486
59 Loss: 1.901 | Acc: 99.600
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [0, 4900, 0, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 4900, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  7 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  4
0 Train Loss: 37.590 | Train Acc: 82.745 | Val Loss: 0.252 | Val Accuracy: 90.500
10 Train Loss: 10.783 | Train Acc: 96.020 | Val Loss: 0.164 | Val Accuracy: 95.000
20 Train Loss: 7.429 | Train Acc: 97.286 | Val Loss: 0.177 | Val Accuracy: 94.000
Epoch     4: reducing learning rate of group 0 to 2.0000e-04.
30 Train Loss: 5.291 | Train Acc: 98.337 | Val Loss: 0.217 | Val Accuracy: 94.000
40 Train Loss: 3.206 | Train Acc: 99.367 | Val Loss: 0.216 | Val Accuracy: 94.000
Epoch     6: reducing learning rate of group 0 to 4.0000e-05.
50 Train Loss: 2.997 | Train Acc: 99.398 | Val Loss: 0.211 | Val Accuracy: 94.000
60 Train Loss: 2.517 | Train Acc: 99.633 | Val Loss: 0.220 | Val Accuracy: 93.500
Epoch     8: reducing learning rate of group 0 to 8.0000e-06.
70 Train Loss: 2.443 | Train Acc: 99.582 | Val Loss: 0.224 | Val Accuracy: 93.500
80 Train Loss: 2.365 | Train Acc: 99.643 | Val Loss: 0.228 | Val Accuracy: 93.500
Epoch    10: reducing learning rate of group 0 to 1.6000e-06.
90 Train Loss: 2.344 | Train Acc: 99.663 | Val Loss: 0.227 | Val Accuracy: 93.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 43.070 | Acc: 91.133
1 Loss: 30.430 | Acc: 93.969
2 Loss: 25.391 | Acc: 95.082
3 Loss: 21.576 | Acc: 95.867
4 Loss: 20.818 | Acc: 95.704
5 Loss: 15.956 | Acc: 96.898
6 Loss: 14.884 | Acc: 96.990
7 Loss: 11.107 | Acc: 97.898
8 Loss: 12.105 | Acc: 97.735
9 Loss: 10.142 | Acc: 98.214
10 Loss: 5.873 | Acc: 98.867
11 Loss: 2.926 | Acc: 99.408
12 Loss: 2.289 | Acc: 99.551
13 Loss: 2.488 | Acc: 99.551
14 Loss: 2.427 | Acc: 99.612
15 Loss: 1.715 | Acc: 99.673
16 Loss: 2.023 | Acc: 99.704
17 Loss: 1.670 | Acc: 99.684
18 Loss: 2.962 | Acc: 99.500
19 Loss: 1.476 | Acc: 99.724
20 Loss: 0.686 | Acc: 99.867
21 Loss: 0.268 | Acc: 99.990
22 Loss: 0.251 | Acc: 99.959
23 Loss: 0.186 | Acc: 99.980
24 Loss: 0.308 | Acc: 99.959
25 Loss: 0.249 | Acc: 99.969
26 Loss: 0.202 | Acc: 99.980
27 Loss: 0.204 | Acc: 99.969
28 Loss: 0.108 | Acc: 99.990
29 Loss: 0.132 | Acc: 99.990
30 Loss: 0.218 | Acc: 99.929
31 Loss: 0.058 | Acc: 100.000
32 Loss: 0.070 | Acc: 100.000
33 Loss: 0.062 | Acc: 100.000
34 Loss: 0.110 | Acc: 99.990
35 Loss: 0.027 | Acc: 100.000
36 Loss: 0.042 | Acc: 100.000
37 Loss: 0.231 | Acc: 99.969
38 Loss: 0.107 | Acc: 99.980
39 Loss: 0.050 | Acc: 100.000
40 Loss: 0.098 | Acc: 99.980
41 Loss: 0.072 | Acc: 99.990
42 Loss: 0.030 | Acc: 100.000
43 Loss: 0.037 | Acc: 100.000
44 Loss: 0.018 | Acc: 100.000
45 Loss: 0.065 | Acc: 99.990
46 Loss: 0.044 | Acc: 99.990
47 Loss: 0.102 | Acc: 99.969
48 Loss: 0.039 | Acc: 100.000
49 Loss: 0.029 | Acc: 100.000
50 Loss: 0.024 | Acc: 100.000
51 Loss: 0.025 | Acc: 100.000
52 Loss: 0.040 | Acc: 100.000
53 Loss: 0.050 | Acc: 99.990
54 Loss: 0.046 | Acc: 99.990
55 Loss: 0.043 | Acc: 99.990
56 Loss: 0.154 | Acc: 99.980
57 Loss: 0.039 | Acc: 100.000
58 Loss: 0.036 | Acc: 100.000
59 Loss: 0.050 | Acc: 99.990
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 2
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 1
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 2
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 1
nodeId:  8 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
nodeId:  9 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  5
0 Train Loss: 85.145 | Train Acc: 61.735 | Val Loss: 0.750 | Val Accuracy: 65.333
10 Train Loss: 43.323 | Train Acc: 83.082 | Val Loss: 0.509 | Val Accuracy: 80.000
20 Train Loss: 34.454 | Train Acc: 86.918 | Val Loss: 0.489 | Val Accuracy: 78.667
30 Train Loss: 28.655 | Train Acc: 89.293 | Val Loss: 0.517 | Val Accuracy: 81.000
40 Train Loss: 24.119 | Train Acc: 91.231 | Val Loss: 0.558 | Val Accuracy: 80.000
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 20.616 | Train Acc: 92.401 | Val Loss: 0.634 | Val Accuracy: 78.667
60 Train Loss: 16.662 | Train Acc: 94.973 | Val Loss: 0.610 | Val Accuracy: 82.333
70 Train Loss: 15.945 | Train Acc: 95.163 | Val Loss: 0.638 | Val Accuracy: 82.000
Epoch     9: reducing learning rate of group 0 to 4.0000e-05.
80 Train Loss: 15.107 | Train Acc: 95.510 | Val Loss: 0.620 | Val Accuracy: 80.000
90 Train Loss: 14.443 | Train Acc: 95.939 | Val Loss: 0.638 | Val Accuracy: 81.667
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 12544])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0, 2: 1}
Printing final_dict items...
{0: 0, 1: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 63.684 | Acc: 77.795
1 Loss: 51.800 | Acc: 82.774
2 Loss: 47.021 | Acc: 84.808
3 Loss: 40.897 | Acc: 86.623
4 Loss: 37.769 | Acc: 87.466
5 Loss: 33.689 | Acc: 89.055
6 Loss: 30.328 | Acc: 90.390
7 Loss: 26.882 | Acc: 91.308
8 Loss: 24.752 | Acc: 92.068
9 Loss: 24.049 | Acc: 92.445
10 Loss: 16.048 | Acc: 94.911
11 Loss: 13.083 | Acc: 95.952
12 Loss: 11.939 | Acc: 96.356
13 Loss: 11.206 | Acc: 96.582
14 Loss: 10.939 | Acc: 96.582
15 Loss: 10.376 | Acc: 96.788
16 Loss: 9.188 | Acc: 97.301
17 Loss: 8.094 | Acc: 97.678
18 Loss: 7.045 | Acc: 97.870
19 Loss: 7.079 | Acc: 97.781
20 Loss: 5.315 | Acc: 98.534
21 Loss: 4.052 | Acc: 98.795
22 Loss: 3.635 | Acc: 98.979
23 Loss: 3.525 | Acc: 99.000
24 Loss: 3.066 | Acc: 99.185
25 Loss: 2.774 | Acc: 99.260
26 Loss: 3.086 | Acc: 99.247
27 Loss: 2.652 | Acc: 99.260
28 Loss: 3.047 | Acc: 99.103
29 Loss: 2.946 | Acc: 99.205
30 Loss: 2.122 | Acc: 99.438
31 Loss: 1.840 | Acc: 99.466
32 Loss: 1.930 | Acc: 99.500
33 Loss: 1.735 | Acc: 99.589
34 Loss: 1.700 | Acc: 99.521
35 Loss: 1.634 | Acc: 99.575
36 Loss: 1.364 | Acc: 99.610
37 Loss: 1.626 | Acc: 99.623
38 Loss: 1.287 | Acc: 99.658
39 Loss: 1.190 | Acc: 99.719
40 Loss: 1.595 | Acc: 99.596
41 Loss: 1.248 | Acc: 99.658
42 Loss: 1.051 | Acc: 99.767
43 Loss: 1.059 | Acc: 99.705
44 Loss: 1.060 | Acc: 99.788
45 Loss: 1.041 | Acc: 99.712
46 Loss: 1.042 | Acc: 99.726
47 Loss: 1.024 | Acc: 99.705
48 Loss: 0.929 | Acc: 99.760
49 Loss: 0.759 | Acc: 99.795
50 Loss: 0.866 | Acc: 99.767
51 Loss: 0.918 | Acc: 99.753
52 Loss: 0.952 | Acc: 99.767
53 Loss: 0.971 | Acc: 99.767
54 Loss: 0.905 | Acc: 99.801
55 Loss: 0.888 | Acc: 99.801
56 Loss: 0.711 | Acc: 99.836
57 Loss: 0.959 | Acc: 99.774
58 Loss: 0.967 | Acc: 99.760
59 Loss: 0.990 | Acc: 99.719
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
nodeId:  10 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 4900
nodeId:  11 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  6
0 Train Loss: 53.892 | Train Acc: 71.908 | Val Loss: 0.409 | Val Accuracy: 82.000
10 Train Loss: 31.769 | Train Acc: 86.296 | Val Loss: 0.339 | Val Accuracy: 84.000
20 Train Loss: 24.710 | Train Acc: 90.000 | Val Loss: 0.363 | Val Accuracy: 84.000
30 Train Loss: 19.377 | Train Acc: 92.459 | Val Loss: 0.336 | Val Accuracy: 87.000
40 Train Loss: 15.244 | Train Acc: 94.592 | Val Loss: 0.312 | Val Accuracy: 87.500
50 Train Loss: 12.483 | Train Acc: 95.765 | Val Loss: 0.376 | Val Accuracy: 89.000
60 Train Loss: 10.286 | Train Acc: 96.827 | Val Loss: 0.390 | Val Accuracy: 89.000
Epoch     8: reducing learning rate of group 0 to 2.0000e-04.
70 Train Loss: 8.026 | Train Acc: 97.704 | Val Loss: 0.421 | Val Accuracy: 88.000
80 Train Loss: 5.717 | Train Acc: 98.888 | Val Loss: 0.431 | Val Accuracy: 89.500
90 Train Loss: 5.200 | Train Acc: 99.235 | Val Loss: 0.435 | Val Accuracy: 89.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 92.887 | Acc: 77.622
1 Loss: 71.332 | Acc: 84.092
2 Loss: 60.700 | Acc: 86.908
3 Loss: 53.562 | Acc: 88.418
4 Loss: 48.426 | Acc: 89.612
5 Loss: 43.104 | Acc: 90.806
6 Loss: 38.556 | Acc: 91.622
7 Loss: 34.161 | Acc: 92.735
8 Loss: 30.995 | Acc: 93.490
9 Loss: 27.103 | Acc: 94.520
10 Loss: 15.475 | Acc: 96.908
11 Loss: 12.682 | Acc: 97.408
12 Loss: 10.035 | Acc: 98.102
13 Loss: 8.879 | Acc: 98.296
14 Loss: 7.782 | Acc: 98.398
15 Loss: 7.713 | Acc: 98.541
16 Loss: 5.829 | Acc: 98.857
17 Loss: 6.589 | Acc: 98.551
18 Loss: 6.315 | Acc: 98.959
19 Loss: 5.461 | Acc: 98.980
20 Loss: 2.594 | Acc: 99.541
21 Loss: 1.727 | Acc: 99.684
22 Loss: 1.353 | Acc: 99.806
23 Loss: 2.242 | Acc: 99.684
24 Loss: 1.204 | Acc: 99.827
25 Loss: 1.323 | Acc: 99.847
26 Loss: 1.264 | Acc: 99.786
27 Loss: 1.171 | Acc: 99.837
28 Loss: 1.449 | Acc: 99.735
29 Loss: 1.359 | Acc: 99.776
30 Loss: 0.799 | Acc: 99.867
31 Loss: 0.440 | Acc: 99.980
32 Loss: 0.771 | Acc: 99.878
33 Loss: 0.707 | Acc: 99.898
34 Loss: 0.418 | Acc: 99.949
35 Loss: 0.327 | Acc: 99.959
36 Loss: 0.578 | Acc: 99.939
37 Loss: 0.759 | Acc: 99.898
38 Loss: 0.334 | Acc: 99.959
39 Loss: 0.514 | Acc: 99.888
40 Loss: 0.701 | Acc: 99.888
41 Loss: 0.487 | Acc: 99.959
42 Loss: 0.464 | Acc: 99.918
43 Loss: 0.533 | Acc: 99.929
44 Loss: 0.459 | Acc: 99.888
45 Loss: 0.360 | Acc: 99.949
46 Loss: 0.298 | Acc: 99.980
47 Loss: 0.305 | Acc: 99.969
48 Loss: 0.291 | Acc: 99.980
49 Loss: 0.338 | Acc: 99.959
50 Loss: 0.520 | Acc: 99.939
51 Loss: 0.403 | Acc: 99.918
52 Loss: 0.163 | Acc: 99.980
53 Loss: 0.249 | Acc: 99.949
54 Loss: 0.240 | Acc: 99.969
55 Loss: 0.398 | Acc: 99.939
56 Loss: 0.293 | Acc: 99.959
57 Loss: 0.381 | Acc: 99.949
58 Loss: 0.341 | Acc: 99.929
59 Loss: 0.155 | Acc: 99.990
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 4
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 4
nodeId:  12 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 4900
nodeId:  13 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  7
0 Train Loss: 100.734 | Train Acc: 49.571 | Val Loss: 0.936 | Val Accuracy: 55.333
10 Train Loss: 64.379 | Train Acc: 71.735 | Val Loss: 0.737 | Val Accuracy: 65.667
20 Train Loss: 53.819 | Train Acc: 77.218 | Val Loss: 0.684 | Val Accuracy: 68.667
30 Train Loss: 45.656 | Train Acc: 81.272 | Val Loss: 0.744 | Val Accuracy: 68.333
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 39.587 | Train Acc: 84.313 | Val Loss: 0.769 | Val Accuracy: 67.333
50 Train Loss: 34.590 | Train Acc: 87.571 | Val Loss: 0.771 | Val Accuracy: 67.667
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 33.325 | Train Acc: 88.190 | Val Loss: 0.770 | Val Accuracy: 68.667
70 Train Loss: 32.294 | Train Acc: 88.769 | Val Loss: 0.775 | Val Accuracy: 68.667
80 Train Loss: 31.982 | Train Acc: 88.952 | Val Loss: 0.772 | Val Accuracy: 69.333
90 Train Loss: 31.770 | Train Acc: 89.102 | Val Loss: 0.776 | Val Accuracy: 69.333
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 12544])
Kmeans trained successfully...
printing expected split from k means
{0: 0, 1: 1, 2: 1}
Printing final_dict items...
{0: 0, 1: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 84.340 | Acc: 65.315
1 Loss: 74.744 | Acc: 70.240
2 Loss: 69.305 | Acc: 72.281
3 Loss: 64.181 | Acc: 75.240
4 Loss: 59.068 | Acc: 76.849
5 Loss: 53.755 | Acc: 79.548
6 Loss: 49.066 | Acc: 81.712
7 Loss: 44.309 | Acc: 83.945
8 Loss: 39.689 | Acc: 85.836
9 Loss: 36.119 | Acc: 87.295
10 Loss: 24.548 | Acc: 91.959
11 Loss: 19.137 | Acc: 93.897
12 Loss: 17.246 | Acc: 94.425
13 Loss: 15.856 | Acc: 95.048
14 Loss: 12.859 | Acc: 95.973
15 Loss: 11.406 | Acc: 96.473
16 Loss: 10.649 | Acc: 96.863
17 Loss: 9.912 | Acc: 96.877
18 Loss: 8.715 | Acc: 97.493
19 Loss: 9.049 | Acc: 97.370
20 Loss: 6.314 | Acc: 98.253
21 Loss: 5.050 | Acc: 98.521
22 Loss: 4.177 | Acc: 98.932
23 Loss: 3.670 | Acc: 99.041
24 Loss: 3.546 | Acc: 99.068
25 Loss: 3.529 | Acc: 99.123
26 Loss: 3.262 | Acc: 99.205
27 Loss: 2.541 | Acc: 99.397
28 Loss: 3.220 | Acc: 99.164
29 Loss: 3.229 | Acc: 99.240
30 Loss: 2.371 | Acc: 99.445
31 Loss: 1.889 | Acc: 99.562
32 Loss: 1.877 | Acc: 99.479
33 Loss: 1.850 | Acc: 99.534
34 Loss: 1.595 | Acc: 99.575
35 Loss: 1.771 | Acc: 99.582
36 Loss: 1.724 | Acc: 99.596
37 Loss: 1.781 | Acc: 99.630
38 Loss: 1.702 | Acc: 99.616
39 Loss: 1.867 | Acc: 99.555
40 Loss: 1.317 | Acc: 99.651
41 Loss: 1.421 | Acc: 99.671
42 Loss: 1.493 | Acc: 99.685
43 Loss: 1.370 | Acc: 99.726
44 Loss: 1.180 | Acc: 99.767
45 Loss: 1.451 | Acc: 99.651
46 Loss: 1.004 | Acc: 99.795
47 Loss: 1.122 | Acc: 99.808
48 Loss: 1.103 | Acc: 99.795
49 Loss: 1.063 | Acc: 99.788
50 Loss: 1.220 | Acc: 99.719
51 Loss: 1.376 | Acc: 99.671
52 Loss: 1.080 | Acc: 99.712
53 Loss: 1.038 | Acc: 99.788
54 Loss: 1.218 | Acc: 99.692
55 Loss: 0.958 | Acc: 99.808
56 Loss: 1.094 | Acc: 99.726
57 Loss: 0.853 | Acc: 99.829
58 Loss: 1.020 | Acc: 99.767
59 Loss: 0.916 | Acc: 99.795
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
nodeId:  14 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
nodeId:  15 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  8
Running nodeId:  9
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 43.651 | Train Acc: 79.531 | Val Loss: 0.339 | Val Accuracy: 86.500
10 Train Loss: 18.487 | Train Acc: 92.878 | Val Loss: 0.199 | Val Accuracy: 92.000
20 Train Loss: 13.304 | Train Acc: 95.235 | Val Loss: 0.208 | Val Accuracy: 93.500
30 Train Loss: 9.989 | Train Acc: 96.622 | Val Loss: 0.199 | Val Accuracy: 93.500
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 7.210 | Train Acc: 97.796 | Val Loss: 0.231 | Val Accuracy: 92.500
50 Train Loss: 5.217 | Train Acc: 98.990 | Val Loss: 0.212 | Val Accuracy: 93.500
60 Train Loss: 4.879 | Train Acc: 99.163 | Val Loss: 0.222 | Val Accuracy: 94.000
70 Train Loss: 4.336 | Train Acc: 99.296 | Val Loss: 0.228 | Val Accuracy: 93.500
Epoch     9: reducing learning rate of group 0 to 4.0000e-05.
80 Train Loss: 4.000 | Train Acc: 99.388 | Val Loss: 0.243 | Val Accuracy: 94.000
90 Train Loss: 3.610 | Train Acc: 99.592 | Val Loss: 0.238 | Val Accuracy: 93.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 62.954 | Acc: 86.357
1 Loss: 46.218 | Acc: 90.776
2 Loss: 38.946 | Acc: 92.061
3 Loss: 35.034 | Acc: 92.949
4 Loss: 30.593 | Acc: 93.735
5 Loss: 28.090 | Acc: 94.541
6 Loss: 25.563 | Acc: 94.878
7 Loss: 22.088 | Acc: 95.592
8 Loss: 18.626 | Acc: 96.622
9 Loss: 17.124 | Acc: 96.888
10 Loss: 9.996 | Acc: 98.122
11 Loss: 7.916 | Acc: 98.480
12 Loss: 6.088 | Acc: 98.949
13 Loss: 5.396 | Acc: 99.061
14 Loss: 4.076 | Acc: 99.163
15 Loss: 4.412 | Acc: 99.255
16 Loss: 3.968 | Acc: 99.337
17 Loss: 2.841 | Acc: 99.429
18 Loss: 3.413 | Acc: 99.378
19 Loss: 3.694 | Acc: 99.367
20 Loss: 1.597 | Acc: 99.724
21 Loss: 1.345 | Acc: 99.786
22 Loss: 0.881 | Acc: 99.867
23 Loss: 0.793 | Acc: 99.867
24 Loss: 0.531 | Acc: 99.929
25 Loss: 0.316 | Acc: 99.959
26 Loss: 0.889 | Acc: 99.898
27 Loss: 0.840 | Acc: 99.867
28 Loss: 1.005 | Acc: 99.847
29 Loss: 1.186 | Acc: 99.816
30 Loss: 0.625 | Acc: 99.908
31 Loss: 0.491 | Acc: 99.939
32 Loss: 0.423 | Acc: 99.959
33 Loss: 0.257 | Acc: 99.969
34 Loss: 0.229 | Acc: 99.990
35 Loss: 0.296 | Acc: 99.969
36 Loss: 0.327 | Acc: 99.959
37 Loss: 0.212 | Acc: 99.980
38 Loss: 0.153 | Acc: 99.980
39 Loss: 0.299 | Acc: 99.949
40 Loss: 0.335 | Acc: 99.959
41 Loss: 0.174 | Acc: 99.969
42 Loss: 0.261 | Acc: 99.949
43 Loss: 0.191 | Acc: 99.980
44 Loss: 0.107 | Acc: 100.000
45 Loss: 0.121 | Acc: 99.990
46 Loss: 0.316 | Acc: 99.969
47 Loss: 0.138 | Acc: 99.990
48 Loss: 0.182 | Acc: 99.969
49 Loss: 0.097 | Acc: 99.990
50 Loss: 0.097 | Acc: 99.990
51 Loss: 0.154 | Acc: 99.959
52 Loss: 0.085 | Acc: 100.000
53 Loss: 0.137 | Acc: 99.969
54 Loss: 0.279 | Acc: 99.959
55 Loss: 0.096 | Acc: 100.000
56 Loss: 0.151 | Acc: 99.990
57 Loss: 0.104 | Acc: 99.980
58 Loss: 0.118 | Acc: 99.990
59 Loss: 0.083 | Acc: 99.990
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 8
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 8
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  16 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
nodeId:  17 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  12
Running nodeId:  13
Running nodeId:  14
Running nodeId:  15
0 Train Loss: 51.945 | Train Acc: 74.112 | Val Loss: 0.512 | Val Accuracy: 73.500
10 Train Loss: 23.206 | Train Acc: 90.837 | Val Loss: 0.322 | Val Accuracy: 85.500
20 Train Loss: 17.596 | Train Acc: 93.112 | Val Loss: 0.324 | Val Accuracy: 86.500
30 Train Loss: 13.361 | Train Acc: 95.204 | Val Loss: 0.358 | Val Accuracy: 87.000
40 Train Loss: 10.018 | Train Acc: 96.837 | Val Loss: 0.374 | Val Accuracy: 84.500
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 8.093 | Train Acc: 97.480 | Val Loss: 0.397 | Val Accuracy: 85.000
60 Train Loss: 5.520 | Train Acc: 98.969 | Val Loss: 0.415 | Val Accuracy: 85.000
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 5.199 | Train Acc: 99.082 | Val Loss: 0.426 | Val Accuracy: 84.500
80 Train Loss: 4.755 | Train Acc: 99.296 | Val Loss: 0.421 | Val Accuracy: 86.000
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 4.640 | Train Acc: 99.265 | Val Loss: 0.424 | Val Accuracy: 85.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 70.276 | Acc: 84.418
1 Loss: 50.234 | Acc: 89.459
2 Loss: 42.643 | Acc: 91.082
3 Loss: 36.259 | Acc: 92.398
4 Loss: 32.628 | Acc: 93.357
5 Loss: 26.764 | Acc: 94.633
6 Loss: 23.304 | Acc: 95.388
7 Loss: 21.195 | Acc: 95.867
8 Loss: 15.945 | Acc: 96.806
9 Loss: 17.472 | Acc: 96.561
10 Loss: 8.704 | Acc: 98.306
11 Loss: 5.448 | Acc: 99.000
12 Loss: 4.113 | Acc: 99.163
13 Loss: 3.725 | Acc: 99.327
14 Loss: 3.947 | Acc: 99.255
15 Loss: 3.997 | Acc: 99.347
16 Loss: 2.437 | Acc: 99.571
17 Loss: 2.684 | Acc: 99.510
18 Loss: 2.589 | Acc: 99.531
19 Loss: 3.646 | Acc: 99.306
20 Loss: 1.426 | Acc: 99.724
21 Loss: 0.789 | Acc: 99.898
22 Loss: 0.889 | Acc: 99.867
23 Loss: 0.645 | Acc: 99.878
24 Loss: 0.687 | Acc: 99.857
25 Loss: 0.492 | Acc: 99.918
26 Loss: 0.732 | Acc: 99.867
27 Loss: 0.449 | Acc: 99.939
28 Loss: 0.410 | Acc: 99.939
29 Loss: 0.741 | Acc: 99.867
30 Loss: 0.298 | Acc: 99.959
31 Loss: 0.205 | Acc: 99.980
32 Loss: 0.187 | Acc: 99.980
33 Loss: 0.137 | Acc: 100.000
34 Loss: 0.164 | Acc: 99.990
35 Loss: 0.245 | Acc: 99.959
36 Loss: 0.162 | Acc: 99.990
37 Loss: 0.230 | Acc: 99.959
38 Loss: 0.229 | Acc: 99.959
39 Loss: 0.238 | Acc: 99.969
40 Loss: 0.156 | Acc: 99.980
41 Loss: 0.203 | Acc: 99.980
42 Loss: 0.194 | Acc: 99.959
43 Loss: 0.088 | Acc: 100.000
44 Loss: 0.128 | Acc: 99.990
45 Loss: 0.231 | Acc: 99.969
46 Loss: 0.227 | Acc: 99.959
47 Loss: 0.122 | Acc: 99.980
48 Loss: 0.098 | Acc: 100.000
49 Loss: 0.083 | Acc: 99.990
50 Loss: 0.124 | Acc: 99.980
51 Loss: 0.059 | Acc: 100.000
52 Loss: 0.086 | Acc: 99.990
53 Loss: 0.081 | Acc: 100.000
54 Loss: 0.113 | Acc: 99.990
55 Loss: 0.066 | Acc: 100.000
56 Loss: 0.176 | Acc: 99.990
57 Loss: 0.056 | Acc: 100.000
58 Loss: 0.068 | Acc: 99.990
59 Loss: 0.073 | Acc: 100.000
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 5
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 5
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  18 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 4900
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 60.490
Split Acc: 87.630
lTrainDict[data].shape:  torch.Size([4873, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4873])
rTrainDict[data].shape:  torch.Size([5127, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([5127])
# of Left images:  4873.0
# of Right images:  5127.0
giniRightRatio:  0.8427064327349227
giniLeftRatio:  0.8365780376245744
impurityDrop:  0.8368816483829182
giniGain:  0.06311835161708179
lclasses:  [906, 951, 600, 132, 137, 92, 98, 96, 942, 919]
rclasses:  [94, 49, 400, 868, 863, 908, 902, 904, 58, 81]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([4873, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4873
nodeId:  3 , imgTensorShape :  torch.Size([5127, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5127
Nodes sizes =  5 5
Node 2 Acc: 64.827
Split Acc: 76.072
lTrainDict[data].shape:  torch.Size([1888, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1888])
rTrainDict[data].shape:  torch.Size([2985, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2985])
# of Left images:  1888.0
# of Right images:  2985.0
giniRightRatio:  0.7675664755940506
giniLeftRatio:  0.754090845841712
impurityDrop:  0.7590431962063069
giniGain:  0.0775348414182675
lclasses:  [91, 762, 490, 73, 81, 65, 62, 43, 85, 136]
rclasses:  [815, 189, 110, 59, 56, 27, 36, 53, 857, 783]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([1888, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1888
nodeId:  5 , imgTensorShape :  torch.Size([2985, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2985
Nodes sizes =  2 3
Node 3 Acc: 55.978
Split Acc: 73.805
lTrainDict[data].shape:  torch.Size([1998, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1998])
rTrainDict[data].shape:  torch.Size([3129, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3129])
# of Left images:  1998.0
# of Right images:  3129.0
giniRightRatio:  0.7971469896608404
giniLeftRatio:  0.7264286308330352
impurityDrop:  0.7519903003230473
giniGain:  0.09071613241187548
lclasses:  [32, 11, 147, 137, 659, 131, 56, 771, 20, 34]
rclasses:  [62, 38, 253, 731, 204, 777, 846, 133, 38, 47]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([1998, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1998
nodeId:  7 , imgTensorShape :  torch.Size([3129, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3129
Nodes sizes =  2 3
Node 4 Acc: 63.824
Split Acc: 63.983
lTrainDict[data].shape:  torch.Size([886, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([886])
rTrainDict[data].shape:  torch.Size([1002, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1002])
# of Left images:  886.0
# of Right images:  1002.0
giniRightRatio:  0.44275720017051723
giniLeftRatio:  0.6863168729522189
impurityDrop:  0.658120343967511
giniGain:  0.09597050187420109
lclasses:  [68, 27, 473, 61, 77, 57, 45, 37, 24, 17]
rclasses:  [23, 735, 17, 12, 4, 8, 17, 6, 61, 119]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([886, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 886
nodeId:  9 , imgTensorShape :  torch.Size([1002, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 1002
Nodes sizes =  1 1
Node 5 Acc: 67.672
Split Acc: 72.965
lTrainDict[data].shape:  torch.Size([980, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([980])
rTrainDict[data].shape:  torch.Size([2005, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2005])
# of Left images:  980.0
# of Right images:  2005.0
giniRightRatio:  0.7028578180483952
giniLeftRatio:  0.5158808829654311
impurityDrop:  0.6114675954143279
giniGain:  0.15609888017972262
lclasses:  [670, 19, 70, 17, 32, 10, 10, 20, 75, 57]
rclasses:  [145, 170, 40, 42, 24, 17, 26, 33, 782, 726]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([980, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 980
nodeId:  11 , imgTensorShape :  torch.Size([2005, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2005
Nodes sizes =  1 2
Node 6 Acc: 60.561
Split Acc: 62.963
lTrainDict[data].shape:  torch.Size([1002, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1002])
rTrainDict[data].shape:  torch.Size([996, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([996])
# of Left images:  1002.0
# of Right images:  996.0
giniRightRatio:  0.6437557458750665
giniLeftRatio:  0.5083266600531472
impurityDrop:  0.50751082218675
giniGain:  0.21891780864628518
lclasses:  [10, 5, 50, 56, 90, 68, 12, 689, 6, 16]
rclasses:  [22, 6, 97, 81, 569, 63, 44, 82, 14, 18]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([1002, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 1002
nodeId:  13 , imgTensorShape :  torch.Size([996, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 996
Nodes sizes =  1 1
Node 7 Acc: 53.531
Split Acc: 58.166
lTrainDict[data].shape:  torch.Size([981, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([981])
rTrainDict[data].shape:  torch.Size([2148, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2148])
# of Left images:  981.0
# of Right images:  2148.0
giniRightRatio:  0.7638667817969337
giniLeftRatio:  0.7266732546310584
impurityDrop:  0.7468803524907308
giniGain:  0.050266637170109596
lclasses:  [28, 16, 79, 454, 72, 196, 61, 42, 14, 19]
rclasses:  [34, 22, 174, 277, 132, 581, 785, 91, 24, 28]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([981, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 981
nodeId:  15 , imgTensorShape :  torch.Size([2148, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2148
Nodes sizes =  1 2
Node 8 Acc: 53.386
Node 9 Acc: 73.353
Node 10 Acc: 68.367
Node 11 Acc: 69.925
Split Acc: 70.773
lTrainDict[data].shape:  torch.Size([1016, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1016])
rTrainDict[data].shape:  torch.Size([989, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([989])
# of Left images:  1016.0
# of Right images:  989.0
giniRightRatio:  0.5111024096200777
giniLeftRatio:  0.45050452600905205
impurityDrop:  0.4488501854049088
giniGain:  0.2540076326434864
lclasses:  [96, 46, 20, 23, 15, 7, 10, 6, 743, 50]
rclasses:  [49, 124, 20, 19, 9, 10, 16, 27, 39, 676]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([1016, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 1016
nodeId:  17 , imgTensorShape :  torch.Size([989, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 989
Nodes sizes =  1 1
Node 12 Acc: 68.762
Node 13 Acc: 57.129
Node 14 Acc: 46.279
Node 15 Acc: 58.706
Split Acc: 59.264
lTrainDict[data].shape:  torch.Size([1052, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1052])
rTrainDict[data].shape:  torch.Size([1096, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1096])
# of Left images:  1052.0
# of Right images:  1096.0
giniRightRatio:  0.5262267568863552
giniLeftRatio:  0.6887550781419421
impurityDrop:  0.6822302185294915
giniGain:  0.08163656326744217
lclasses:  [11, 7, 89, 199, 64, 533, 45, 79, 12, 13]
rclasses:  [23, 15, 85, 78, 68, 48, 740, 12, 12, 15]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1052, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1052
nodeId:  19 , imgTensorShape :  torch.Size([1096, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1096
Nodes sizes =  1 1
Node 16 Acc: 73.130
Node 17 Acc: 68.352
Node 18 Acc: 50.665
Node 19 Acc: 67.518
[[670  23  68  28  22  11  23  10  96  49]
 [ 19 735  27  16   6   7  15   5  46 124]
 [ 70  17 473  79  97  89  85  50  20  20]
 [ 17  12  61 454  81 199  78  56  23  19]
 [ 32   4  77  72 569  64  68  90  15   9]
 [ 10   8  57 196  63 533  48  68   7  10]
 [ 10  17  45  61  44  45 740  12  10  16]
 [ 20   6  37  42  82  79  12 689   6  27]
 [ 75  61  24  14  14  12  12   6 743  39]
 [ 57 119  17  19  18  13  15  16  50 676]]

Acc: 62.820

                                                             1                                                                 
                   ┌─────────────────────────────────────────┴───────────────────────────┐                                     
                   2                                                                     3                                     
       ┌───────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
       4                         5                                         6                           7                       
 ┌─────┴─────┐            ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
 8           9            10                   11                   12            13            14                   15        
                                        ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                        16            17                                                      18            19 

                                                       -1                                                      
                   ┌───────────────────────────────────┴───────────────────────┐                               
                   -1                                                          -1                              
       ┌───────────┴───────────┐                                   ┌───────────┴───────────┐                   
       -1                      -1                                  -1                      -1                  
 ┌─────┴─────┐           ┌─────┴───────────┐                 ┌─────┴─────┐           ┌─────┴───────────┐       
 2           1           0                 -1                7           4           3                 -1      
                                     ┌─────┴─────┐                                               ┌─────┴─────┐ 
                                     8           9                                               5           6 

                                                                         49000                                                                         
                           ┌───────────────────────────────────────────────┴───────────────────────────────┐                                           
                         24500                                                                           24500                                         
           ┌───────────────┴───────────────┐                                               ┌───────────────┴───────────────┐                           
          9800                           14700                                            9800                           14700                         
   ┌───────┴───────┐               ┌───────┴───────────────┐                       ┌───────┴───────┐               ┌───────┴───────────────┐           
  4900            4900            4900                    9800                    4900            4900            4900                    9800         
                                                   ┌───────┴───────┐                                                               ┌───────┴───────┐   
                                                  4900            4900                                                            4900            4900 

                                                   {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                  
                                   ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────┐                                                       
             {0: 4900, 1: 4900, 2: 4900, 8: 4900, 9: 4900}                                                       {3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900}                                 
               ┌───────────────────┴───────────────────┐                                                           ┌───────────────────┴───────────────────┐                                   
       {1: 4900, 2: 4900}                 {0: 4900, 8: 4900, 9: 4900}                                      {4: 4900, 7: 4900}                 {3: 4900, 5: 4900, 6: 4900}                      
     ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐                             ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐               
 {2: 4900}           {1: 4900}           {0: 4900}                 {8: 4900, 9: 4900}                {7: 4900}           {4: 4900}           {3: 4900}                 {5: 4900, 6: 4900}      
                                                                 ┌─────────┴─────────┐                                                                               ┌─────────┴─────────┐     
                                                             {8: 4900}           {9: 4900}                                                                       {5: 4900}           {6: 4900} 

                                                                 87.63                                                               
                         ┌─────────────────────────────────────────┴───────────────────────────┐                                     
                 76.07223476297969                                                     73.80534425590014                             
          ┌──────────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
  63.983050847457626           72.96482412060301                         62.96296296296296            58.165548098434                
   ┌──────┴──────┐              ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
  0.0           0.0            0.0           70.77306733167082           0.0           0.0           0.0           59.26443202979516 
                                              ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                             0.0           0.0                                                     0.0           0.0 

                                                         0.09999999999999987                                                         
                       ┌──────────────────────────────────────────┴───────────────────────────┐                                      
              0.24444444444444458                                                    0.24444444444444458                             
         ┌─────────────┴──────────────┐                                         ┌─────────────┴──────────────┐                       
        0.5                  0.41666666666666674                               0.5                  0.41666666666666674              
  ┌──────┴──────┐             ┌──────┴─────────────┐                     ┌──────┴──────┐             ┌──────┴─────────────┐          
 0.0           0.0           0.0                  0.5                   0.0           0.0           0.0                  0.5         
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐   
                                           0.0           0.0                                                      0.0           0.0  

