['options.ckptDir: valDir_cOut32_mFC2_32', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 32', 'options.mlpFC1: 516', 'options.mlpFC2: 32']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 181.696 | Train Acc: 37.198 | Val Loss: 1.506 | Val Accuracy: 48.600
10 Train Loss: 96.041 | Train Acc: 67.088 | Val Loss: 1.137 | Val Accuracy: 61.200
20 Train Loss: 74.727 | Train Acc: 74.935 | Val Loss: 1.164 | Val Accuracy: 60.700
30 Train Loss: 60.400 | Train Acc: 79.849 | Val Loss: 1.213 | Val Accuracy: 61.400
40 Train Loss: 46.864 | Train Acc: 85.339 | Val Loss: 1.325 | Val Accuracy: 60.400
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 37.310 | Train Acc: 88.976 | Val Loss: 1.447 | Val Accuracy: 60.300
60 Train Loss: 29.855 | Train Acc: 92.927 | Val Loss: 1.475 | Val Accuracy: 60.300
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 28.042 | Train Acc: 93.549 | Val Loss: 1.506 | Val Accuracy: 60.100
80 Train Loss: 26.328 | Train Acc: 94.359 | Val Loss: 1.516 | Val Accuracy: 59.900
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 25.903 | Train Acc: 94.480 | Val Loss: 1.526 | Val Accuracy: 59.800
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 25088])
Kmeans trained successfully...
printing expected split from k means
{8: 0, 5: 0, 2: 0, 4: 0, 9: 0, 7: 0, 0: 0, 3: 0, 1: 1, 6: 0}
Printing final_dict items...
{0: 0, 8: 0, 4: 0, 2: 0, 7: 0, 9: 1, 6: 1, 3: 1, 5: 1, 1: 1}
Image Statistics before MLP : L R :  24500 24500
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 103.348 | Acc: 74.447
1 Loss: 88.434 | Acc: 79.286
2 Loss: 80.098 | Acc: 81.708
3 Loss: 73.520 | Acc: 83.502
4 Loss: 68.593 | Acc: 84.629
5 Loss: 62.530 | Acc: 86.182
6 Loss: 58.922 | Acc: 87.100
7 Loss: 55.054 | Acc: 88.237
8 Loss: 51.389 | Acc: 88.857
9 Loss: 46.906 | Acc: 90.020
10 Loss: 36.337 | Acc: 92.551
11 Loss: 32.708 | Acc: 93.388
12 Loss: 30.332 | Acc: 93.741
13 Loss: 28.449 | Acc: 94.284
14 Loss: 25.870 | Acc: 94.667
15 Loss: 25.033 | Acc: 94.998
16 Loss: 22.608 | Acc: 95.518
17 Loss: 22.229 | Acc: 95.631
18 Loss: 20.387 | Acc: 96.031
19 Loss: 19.682 | Acc: 96.284
20 Loss: 15.289 | Acc: 97.116
21 Loss: 13.320 | Acc: 97.496
22 Loss: 12.538 | Acc: 97.631
23 Loss: 12.068 | Acc: 97.784
24 Loss: 11.913 | Acc: 97.827
25 Loss: 11.031 | Acc: 97.959
26 Loss: 10.897 | Acc: 98.029
27 Loss: 10.027 | Acc: 98.176
28 Loss: 10.215 | Acc: 98.147
29 Loss: 9.550 | Acc: 98.253
30 Loss: 7.971 | Acc: 98.549
31 Loss: 8.237 | Acc: 98.541
32 Loss: 7.685 | Acc: 98.590
33 Loss: 7.478 | Acc: 98.694
34 Loss: 7.271 | Acc: 98.727
35 Loss: 6.938 | Acc: 98.818
36 Loss: 7.108 | Acc: 98.692
37 Loss: 6.935 | Acc: 98.690
38 Loss: 6.756 | Acc: 98.827
39 Loss: 6.466 | Acc: 98.861
40 Loss: 6.185 | Acc: 98.908
41 Loss: 5.990 | Acc: 98.945
42 Loss: 6.316 | Acc: 98.955
43 Loss: 5.862 | Acc: 98.929
44 Loss: 6.144 | Acc: 98.957
45 Loss: 5.903 | Acc: 98.967
46 Loss: 5.783 | Acc: 98.988
47 Loss: 5.625 | Acc: 98.998
48 Loss: 5.595 | Acc: 99.016
49 Loss: 5.709 | Acc: 98.990
50 Loss: 5.234 | Acc: 99.120
51 Loss: 5.309 | Acc: 99.057
52 Loss: 5.392 | Acc: 99.031
53 Loss: 5.351 | Acc: 99.076
54 Loss: 5.414 | Acc: 99.057
55 Loss: 5.569 | Acc: 99.008
56 Loss: 5.266 | Acc: 99.071
57 Loss: 5.042 | Acc: 99.149
58 Loss: 5.100 | Acc: 99.084
59 Loss: 4.973 | Acc: 99.133
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([24500])
rTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([24500])
lValDict[data].shape:  torch.Size([500, 3, 32, 32])   lValDict[label].shape:  torch.Size([500])
rValDict[data].shape:  torch.Size([500, 3, 32, 32])   rValDict[label].shape:  torch.Size([500])
# of Left images:  24500.0
# of Right images:  24500.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [4900, 0, 4900, 0, 4900, 0, 0, 4900, 4900, 0]
rclasses:  [0, 4900, 0, 4900, 0, 4900, 4900, 0, 0, 4900]
noOfLeftClasses:  5
noOfRightClasses:  5
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
nodeId:  3 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
Running nodeId:  2
0 Train Loss: 120.082 | Train Acc: 51.490 | Val Loss: 1.045 | Val Accuracy: 57.400
10 Train Loss: 64.178 | Train Acc: 75.820 | Val Loss: 0.811 | Val Accuracy: 68.600
20 Train Loss: 46.350 | Train Acc: 82.857 | Val Loss: 0.807 | Val Accuracy: 71.000
30 Train Loss: 34.992 | Train Acc: 87.927 | Val Loss: 0.899 | Val Accuracy: 68.000
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 27.086 | Train Acc: 91.294 | Val Loss: 1.002 | Val Accuracy: 68.000
50 Train Loss: 20.690 | Train Acc: 94.649 | Val Loss: 0.953 | Val Accuracy: 70.200
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 19.261 | Train Acc: 95.318 | Val Loss: 0.984 | Val Accuracy: 69.600
70 Train Loss: 17.986 | Train Acc: 95.927 | Val Loss: 0.988 | Val Accuracy: 69.400
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 17.706 | Train Acc: 96.098 | Val Loss: 0.989 | Val Accuracy: 70.000
90 Train Loss: 17.386 | Train Acc: 96.208 | Val Loss: 0.994 | Val Accuracy: 69.400
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 25088])
Kmeans trained successfully...
printing expected split from k means
{4: 0, 2: 1, 0: 0, 1: 1, 3: 1}
Printing final_dict items...
{4: 0, 0: 0, 1: 1, 2: 1, 3: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 47.573 | Acc: 87.788
1 Loss: 36.321 | Acc: 90.588
2 Loss: 30.945 | Acc: 92.106
3 Loss: 28.160 | Acc: 92.918
4 Loss: 25.993 | Acc: 93.216
5 Loss: 22.538 | Acc: 94.249
6 Loss: 20.243 | Acc: 94.931
7 Loss: 17.810 | Acc: 95.420
8 Loss: 15.270 | Acc: 96.135
9 Loss: 14.490 | Acc: 96.180
10 Loss: 9.641 | Acc: 97.604
11 Loss: 8.038 | Acc: 97.971
12 Loss: 6.618 | Acc: 98.306
13 Loss: 6.169 | Acc: 98.510
14 Loss: 6.307 | Acc: 98.527
15 Loss: 5.221 | Acc: 98.739
16 Loss: 4.792 | Acc: 98.841
17 Loss: 4.526 | Acc: 98.906
18 Loss: 4.390 | Acc: 98.890
19 Loss: 4.308 | Acc: 98.914
20 Loss: 2.811 | Acc: 99.314
21 Loss: 2.672 | Acc: 99.376
22 Loss: 2.264 | Acc: 99.473
23 Loss: 2.023 | Acc: 99.502
24 Loss: 1.986 | Acc: 99.551
25 Loss: 2.197 | Acc: 99.486
26 Loss: 1.992 | Acc: 99.563
27 Loss: 1.970 | Acc: 99.522
28 Loss: 1.621 | Acc: 99.624
29 Loss: 1.698 | Acc: 99.604
30 Loss: 1.535 | Acc: 99.665
31 Loss: 1.314 | Acc: 99.706
32 Loss: 1.036 | Acc: 99.763
33 Loss: 1.235 | Acc: 99.771
34 Loss: 1.113 | Acc: 99.763
35 Loss: 1.031 | Acc: 99.771
36 Loss: 1.206 | Acc: 99.735
37 Loss: 1.068 | Acc: 99.755
38 Loss: 1.111 | Acc: 99.759
39 Loss: 0.788 | Acc: 99.800
40 Loss: 0.907 | Acc: 99.800
41 Loss: 0.802 | Acc: 99.837
42 Loss: 1.020 | Acc: 99.780
43 Loss: 0.878 | Acc: 99.792
44 Loss: 0.743 | Acc: 99.857
45 Loss: 0.793 | Acc: 99.800
46 Loss: 0.690 | Acc: 99.857
47 Loss: 0.620 | Acc: 99.886
48 Loss: 0.814 | Acc: 99.820
49 Loss: 0.783 | Acc: 99.853
50 Loss: 0.663 | Acc: 99.853
51 Loss: 0.618 | Acc: 99.845
52 Loss: 0.657 | Acc: 99.853
53 Loss: 0.611 | Acc: 99.906
54 Loss: 0.535 | Acc: 99.886
55 Loss: 0.644 | Acc: 99.878
56 Loss: 0.636 | Acc: 99.841
57 Loss: 0.608 | Acc: 99.865
58 Loss: 0.639 | Acc: 99.865
59 Loss: 0.703 | Acc: 99.845
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [4900, 0, 0, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  5 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  3
0 Train Loss: 112.993 | Train Acc: 52.665 | Val Loss: 0.950 | Val Accuracy: 61.600
10 Train Loss: 58.682 | Train Acc: 77.135 | Val Loss: 0.710 | Val Accuracy: 72.000
20 Train Loss: 44.262 | Train Acc: 83.294 | Val Loss: 0.690 | Val Accuracy: 73.400
30 Train Loss: 33.627 | Train Acc: 87.922 | Val Loss: 0.748 | Val Accuracy: 74.000
40 Train Loss: 25.972 | Train Acc: 91.265 | Val Loss: 0.798 | Val Accuracy: 72.600
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 20.364 | Train Acc: 93.559 | Val Loss: 0.872 | Val Accuracy: 71.400
60 Train Loss: 15.091 | Train Acc: 96.902 | Val Loss: 0.895 | Val Accuracy: 71.800
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 13.995 | Train Acc: 97.237 | Val Loss: 0.906 | Val Accuracy: 72.400
80 Train Loss: 13.044 | Train Acc: 97.824 | Val Loss: 0.914 | Val Accuracy: 71.600
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 12.786 | Train Acc: 97.873 | Val Loss: 0.919 | Val Accuracy: 72.600
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 25088])
Kmeans trained successfully...
printing expected split from k means
{2: 1, 4: 0, 0: 0, 3: 1, 1: 1}
Printing final_dict items...
{4: 0, 0: 0, 1: 1, 2: 1, 3: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 34.631 | Acc: 91.282
1 Loss: 23.338 | Acc: 94.445
2 Loss: 20.202 | Acc: 95.204
3 Loss: 16.530 | Acc: 96.131
4 Loss: 14.259 | Acc: 96.535
5 Loss: 12.091 | Acc: 97.073
6 Loss: 12.028 | Acc: 96.963
7 Loss: 8.622 | Acc: 98.004
8 Loss: 8.560 | Acc: 97.955
9 Loss: 6.744 | Acc: 98.433
10 Loss: 4.207 | Acc: 99.037
11 Loss: 2.588 | Acc: 99.424
12 Loss: 2.483 | Acc: 99.420
13 Loss: 1.819 | Acc: 99.580
14 Loss: 2.042 | Acc: 99.571
15 Loss: 1.983 | Acc: 99.567
16 Loss: 1.685 | Acc: 99.620
17 Loss: 1.871 | Acc: 99.624
18 Loss: 1.549 | Acc: 99.661
19 Loss: 1.355 | Acc: 99.686
20 Loss: 0.960 | Acc: 99.820
21 Loss: 0.571 | Acc: 99.898
22 Loss: 0.531 | Acc: 99.873
23 Loss: 0.676 | Acc: 99.853
24 Loss: 0.374 | Acc: 99.935
25 Loss: 0.301 | Acc: 99.963
26 Loss: 0.350 | Acc: 99.906
27 Loss: 0.536 | Acc: 99.906
28 Loss: 0.578 | Acc: 99.890
29 Loss: 0.351 | Acc: 99.927
30 Loss: 0.245 | Acc: 99.967
31 Loss: 0.199 | Acc: 99.951
32 Loss: 0.281 | Acc: 99.943
33 Loss: 0.180 | Acc: 99.980
34 Loss: 0.245 | Acc: 99.963
35 Loss: 0.201 | Acc: 99.976
36 Loss: 0.162 | Acc: 99.980
37 Loss: 0.224 | Acc: 99.951
38 Loss: 0.238 | Acc: 99.967
39 Loss: 0.182 | Acc: 99.959
40 Loss: 0.091 | Acc: 99.992
41 Loss: 0.167 | Acc: 99.963
42 Loss: 0.168 | Acc: 99.971
43 Loss: 0.105 | Acc: 99.980
44 Loss: 0.197 | Acc: 99.967
45 Loss: 0.115 | Acc: 99.967
46 Loss: 0.115 | Acc: 99.976
47 Loss: 0.113 | Acc: 99.988
48 Loss: 0.103 | Acc: 99.984
49 Loss: 0.127 | Acc: 99.971
50 Loss: 0.085 | Acc: 99.984
51 Loss: 0.066 | Acc: 99.992
52 Loss: 0.088 | Acc: 99.980
53 Loss: 0.103 | Acc: 99.988
54 Loss: 0.089 | Acc: 99.984
55 Loss: 0.101 | Acc: 99.980
56 Loss: 0.093 | Acc: 99.984
57 Loss: 0.067 | Acc: 99.992
58 Loss: 0.085 | Acc: 99.988
59 Loss: 0.065 | Acc: 99.992
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [4900, 0, 0, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  7 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  4
0 Train Loss: 60.329 | Train Acc: 69.327 | Val Loss: 0.529 | Val Accuracy: 73.000
10 Train Loss: 29.046 | Train Acc: 88.122 | Val Loss: 0.379 | Val Accuracy: 84.000
20 Train Loss: 19.755 | Train Acc: 92.643 | Val Loss: 0.422 | Val Accuracy: 83.500
Epoch     4: reducing learning rate of group 0 to 2.0000e-04.
30 Train Loss: 13.288 | Train Acc: 95.347 | Val Loss: 0.422 | Val Accuracy: 81.500
40 Train Loss: 9.298 | Train Acc: 97.663 | Val Loss: 0.393 | Val Accuracy: 84.000
Epoch     6: reducing learning rate of group 0 to 4.0000e-05.
50 Train Loss: 8.384 | Train Acc: 98.071 | Val Loss: 0.419 | Val Accuracy: 84.000
60 Train Loss: 7.587 | Train Acc: 98.398 | Val Loss: 0.388 | Val Accuracy: 84.500
70 Train Loss: 7.393 | Train Acc: 98.429 | Val Loss: 0.394 | Val Accuracy: 84.500
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 7.169 | Train Acc: 98.490 | Val Loss: 0.393 | Val Accuracy: 84.500
90 Train Loss: 6.988 | Train Acc: 98.582 | Val Loss: 0.395 | Val Accuracy: 84.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 90.073 | Acc: 79.000
1 Loss: 66.894 | Acc: 85.602
2 Loss: 57.358 | Acc: 87.786
3 Loss: 49.136 | Acc: 89.735
4 Loss: 40.904 | Acc: 91.776
5 Loss: 37.108 | Acc: 92.469
6 Loss: 29.974 | Acc: 93.816
7 Loss: 28.023 | Acc: 94.398
8 Loss: 25.918 | Acc: 94.888
9 Loss: 17.439 | Acc: 96.643
10 Loss: 10.509 | Acc: 98.041
11 Loss: 7.283 | Acc: 98.714
12 Loss: 7.182 | Acc: 98.582
13 Loss: 6.562 | Acc: 98.745
14 Loss: 5.068 | Acc: 99.071
15 Loss: 5.275 | Acc: 99.031
16 Loss: 4.493 | Acc: 99.122
17 Loss: 4.616 | Acc: 99.296
18 Loss: 4.858 | Acc: 99.153
19 Loss: 5.311 | Acc: 99.061
20 Loss: 2.720 | Acc: 99.551
21 Loss: 1.806 | Acc: 99.745
22 Loss: 1.659 | Acc: 99.745
23 Loss: 1.318 | Acc: 99.796
24 Loss: 1.499 | Acc: 99.755
25 Loss: 1.268 | Acc: 99.837
26 Loss: 1.146 | Acc: 99.796
27 Loss: 1.434 | Acc: 99.745
28 Loss: 1.393 | Acc: 99.745
29 Loss: 0.930 | Acc: 99.857
30 Loss: 0.832 | Acc: 99.847
31 Loss: 0.962 | Acc: 99.867
32 Loss: 0.670 | Acc: 99.898
33 Loss: 0.643 | Acc: 99.929
34 Loss: 0.680 | Acc: 99.939
35 Loss: 0.670 | Acc: 99.867
36 Loss: 0.427 | Acc: 99.959
37 Loss: 0.564 | Acc: 99.908
38 Loss: 0.424 | Acc: 99.959
39 Loss: 0.604 | Acc: 99.898
40 Loss: 0.610 | Acc: 99.898
41 Loss: 0.487 | Acc: 99.929
42 Loss: 0.692 | Acc: 99.929
43 Loss: 0.599 | Acc: 99.908
44 Loss: 0.315 | Acc: 99.969
45 Loss: 0.282 | Acc: 99.980
46 Loss: 0.247 | Acc: 99.969
47 Loss: 0.389 | Acc: 99.949
48 Loss: 0.423 | Acc: 99.959
49 Loss: 0.650 | Acc: 99.918
50 Loss: 0.487 | Acc: 99.929
51 Loss: 0.341 | Acc: 99.969
52 Loss: 0.431 | Acc: 99.939
53 Loss: 0.383 | Acc: 99.939
54 Loss: 0.427 | Acc: 99.949
55 Loss: 0.359 | Acc: 99.959
56 Loss: 0.290 | Acc: 99.969
57 Loss: 0.362 | Acc: 99.959
58 Loss: 0.476 | Acc: 99.949
59 Loss: 0.394 | Acc: 99.918
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  8 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 4900
nodeId:  9 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  5
0 Train Loss: 97.329 | Train Acc: 53.469 | Val Loss: 0.880 | Val Accuracy: 62.000
10 Train Loss: 54.426 | Train Acc: 77.796 | Val Loss: 0.720 | Val Accuracy: 70.333
20 Train Loss: 40.164 | Train Acc: 84.585 | Val Loss: 0.720 | Val Accuracy: 71.333
30 Train Loss: 30.783 | Train Acc: 88.803 | Val Loss: 0.761 | Val Accuracy: 74.333
40 Train Loss: 22.502 | Train Acc: 92.878 | Val Loss: 0.783 | Val Accuracy: 74.667
50 Train Loss: 17.395 | Train Acc: 94.891 | Val Loss: 0.930 | Val Accuracy: 73.667
Epoch     7: reducing learning rate of group 0 to 2.0000e-04.
60 Train Loss: 13.231 | Train Acc: 96.544 | Val Loss: 1.004 | Val Accuracy: 74.333
70 Train Loss: 9.287 | Train Acc: 98.571 | Val Loss: 1.045 | Val Accuracy: 74.000
Epoch     9: reducing learning rate of group 0 to 4.0000e-05.
80 Train Loss: 8.606 | Train Acc: 98.803 | Val Loss: 1.075 | Val Accuracy: 73.000
90 Train Loss: 7.840 | Train Acc: 98.980 | Val Loss: 1.058 | Val Accuracy: 73.667
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 25088])
Kmeans trained successfully...
printing expected split from k means
{0: 1, 1: 0, 2: 1}
Printing final_dict items...
{1: 0, 0: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 78.857 | Acc: 67.664
1 Loss: 67.627 | Acc: 73.979
2 Loss: 59.549 | Acc: 78.199
3 Loss: 53.653 | Acc: 81.116
4 Loss: 47.839 | Acc: 83.548
5 Loss: 42.219 | Acc: 85.603
6 Loss: 37.681 | Acc: 87.110
7 Loss: 35.223 | Acc: 87.986
8 Loss: 31.184 | Acc: 89.637
9 Loss: 28.240 | Acc: 90.897
10 Loss: 19.344 | Acc: 93.993
11 Loss: 16.545 | Acc: 94.747
12 Loss: 14.464 | Acc: 95.644
13 Loss: 13.368 | Acc: 95.904
14 Loss: 12.833 | Acc: 96.158
15 Loss: 12.268 | Acc: 96.233
16 Loss: 10.543 | Acc: 96.808
17 Loss: 9.734 | Acc: 97.123
18 Loss: 9.348 | Acc: 97.247
19 Loss: 8.421 | Acc: 97.589
20 Loss: 5.955 | Acc: 98.260
21 Loss: 5.086 | Acc: 98.596
22 Loss: 4.881 | Acc: 98.726
23 Loss: 4.074 | Acc: 98.904
24 Loss: 3.827 | Acc: 98.993
25 Loss: 3.719 | Acc: 98.993
26 Loss: 3.414 | Acc: 99.055
27 Loss: 3.375 | Acc: 99.021
28 Loss: 3.603 | Acc: 99.116
29 Loss: 3.135 | Acc: 99.096
30 Loss: 2.495 | Acc: 99.288
31 Loss: 2.237 | Acc: 99.397
32 Loss: 2.434 | Acc: 99.308
33 Loss: 2.282 | Acc: 99.479
34 Loss: 1.981 | Acc: 99.589
35 Loss: 1.768 | Acc: 99.534
36 Loss: 1.854 | Acc: 99.568
37 Loss: 1.829 | Acc: 99.527
38 Loss: 2.008 | Acc: 99.548
39 Loss: 1.694 | Acc: 99.644
40 Loss: 1.645 | Acc: 99.596
41 Loss: 1.330 | Acc: 99.658
42 Loss: 1.349 | Acc: 99.651
43 Loss: 1.691 | Acc: 99.616
44 Loss: 1.367 | Acc: 99.623
45 Loss: 1.217 | Acc: 99.699
46 Loss: 1.382 | Acc: 99.678
47 Loss: 1.388 | Acc: 99.685
48 Loss: 1.551 | Acc: 99.582
49 Loss: 1.288 | Acc: 99.719
50 Loss: 1.399 | Acc: 99.671
51 Loss: 1.271 | Acc: 99.685
52 Loss: 1.076 | Acc: 99.712
53 Loss: 1.346 | Acc: 99.671
54 Loss: 1.150 | Acc: 99.719
55 Loss: 1.149 | Acc: 99.664
56 Loss: 1.118 | Acc: 99.726
57 Loss: 1.033 | Acc: 99.795
58 Loss: 1.276 | Acc: 99.671
59 Loss: 1.093 | Acc: 99.719
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 4
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 4
nodeId:  10 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 4900
nodeId:  11 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  6
0 Train Loss: 73.255 | Train Acc: 60.388 | Val Loss: 0.593 | Val Accuracy: 69.500
10 Train Loss: 28.084 | Train Acc: 88.612 | Val Loss: 0.390 | Val Accuracy: 84.000
20 Train Loss: 18.374 | Train Acc: 93.051 | Val Loss: 0.398 | Val Accuracy: 85.000
30 Train Loss: 11.472 | Train Acc: 96.276 | Val Loss: 0.462 | Val Accuracy: 84.500
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 5.643 | Train Acc: 99.092 | Val Loss: 0.528 | Val Accuracy: 83.000
50 Train Loss: 3.620 | Train Acc: 99.827 | Val Loss: 0.528 | Val Accuracy: 83.500
60 Train Loss: 3.058 | Train Acc: 99.898 | Val Loss: 0.541 | Val Accuracy: 85.500
70 Train Loss: 2.499 | Train Acc: 99.949 | Val Loss: 0.565 | Val Accuracy: 85.000
Epoch     9: reducing learning rate of group 0 to 4.0000e-05.
80 Train Loss: 1.996 | Train Acc: 99.959 | Val Loss: 0.580 | Val Accuracy: 85.000
90 Train Loss: 1.761 | Train Acc: 99.959 | Val Loss: 0.600 | Val Accuracy: 84.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 102.372 | Acc: 75.582
1 Loss: 68.957 | Acc: 85.388
2 Loss: 58.063 | Acc: 87.847
3 Loss: 47.965 | Acc: 89.990
4 Loss: 40.195 | Acc: 91.776
5 Loss: 32.666 | Acc: 93.214
6 Loss: 27.461 | Acc: 94.602
7 Loss: 21.747 | Acc: 95.776
8 Loss: 20.185 | Acc: 96.235
9 Loss: 16.995 | Acc: 96.745
10 Loss: 9.149 | Acc: 98.306
11 Loss: 4.818 | Acc: 99.214
12 Loss: 4.211 | Acc: 99.245
13 Loss: 3.716 | Acc: 99.388
14 Loss: 3.945 | Acc: 99.276
15 Loss: 3.072 | Acc: 99.561
16 Loss: 3.533 | Acc: 99.306
17 Loss: 3.966 | Acc: 99.337
18 Loss: 2.562 | Acc: 99.541
19 Loss: 5.232 | Acc: 99.092
20 Loss: 1.999 | Acc: 99.714
21 Loss: 1.257 | Acc: 99.816
22 Loss: 0.657 | Acc: 99.918
23 Loss: 0.727 | Acc: 99.908
24 Loss: 0.389 | Acc: 99.939
25 Loss: 0.991 | Acc: 99.847
26 Loss: 1.100 | Acc: 99.837
27 Loss: 0.855 | Acc: 99.888
28 Loss: 0.703 | Acc: 99.878
29 Loss: 0.570 | Acc: 99.888
30 Loss: 0.437 | Acc: 99.969
31 Loss: 0.397 | Acc: 99.949
32 Loss: 0.497 | Acc: 99.898
33 Loss: 0.502 | Acc: 99.949
34 Loss: 0.579 | Acc: 99.939
35 Loss: 0.260 | Acc: 99.959
36 Loss: 0.158 | Acc: 100.000
37 Loss: 0.295 | Acc: 99.980
38 Loss: 0.261 | Acc: 99.969
39 Loss: 0.209 | Acc: 99.969
40 Loss: 0.359 | Acc: 99.929
41 Loss: 0.197 | Acc: 99.969
42 Loss: 0.334 | Acc: 99.959
43 Loss: 0.280 | Acc: 99.959
44 Loss: 0.255 | Acc: 99.949
45 Loss: 0.215 | Acc: 99.949
46 Loss: 0.179 | Acc: 99.980
47 Loss: 0.219 | Acc: 99.969
48 Loss: 0.163 | Acc: 99.980
49 Loss: 0.308 | Acc: 99.969
50 Loss: 0.217 | Acc: 99.959
51 Loss: 0.274 | Acc: 99.959
52 Loss: 0.354 | Acc: 99.959
53 Loss: 0.131 | Acc: 99.990
54 Loss: 0.105 | Acc: 99.990
55 Loss: 0.161 | Acc: 99.980
56 Loss: 0.111 | Acc: 99.980
57 Loss: 0.156 | Acc: 99.980
58 Loss: 0.137 | Acc: 99.980
59 Loss: 0.094 | Acc: 99.990
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  12 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 4900
nodeId:  13 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  7
0 Train Loss: 98.603 | Train Acc: 51.599 | Val Loss: 0.874 | Val Accuracy: 58.000
10 Train Loss: 54.099 | Train Acc: 77.054 | Val Loss: 0.715 | Val Accuracy: 68.333
20 Train Loss: 39.054 | Train Acc: 84.946 | Val Loss: 0.762 | Val Accuracy: 70.333
30 Train Loss: 28.765 | Train Acc: 89.884 | Val Loss: 0.931 | Val Accuracy: 64.333
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 21.186 | Train Acc: 93.170 | Val Loss: 0.999 | Val Accuracy: 64.667
50 Train Loss: 15.376 | Train Acc: 96.789 | Val Loss: 1.026 | Val Accuracy: 65.333
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 13.976 | Train Acc: 97.354 | Val Loss: 1.074 | Val Accuracy: 64.333
70 Train Loss: 12.924 | Train Acc: 97.844 | Val Loss: 1.093 | Val Accuracy: 64.000
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 12.611 | Train Acc: 97.939 | Val Loss: 1.092 | Val Accuracy: 64.667
90 Train Loss: 12.376 | Train Acc: 98.041 | Val Loss: 1.090 | Val Accuracy: 64.667
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 25088])
Kmeans trained successfully...
printing expected split from k means
{0: 0, 1: 1, 2: 1}
Printing final_dict items...
{0: 0, 1: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 84.842 | Acc: 64.432
1 Loss: 75.001 | Acc: 70.466
2 Loss: 67.242 | Acc: 74.075
3 Loss: 61.866 | Acc: 77.021
4 Loss: 55.496 | Acc: 79.658
5 Loss: 49.364 | Acc: 82.329
6 Loss: 44.274 | Acc: 84.507
7 Loss: 39.346 | Acc: 86.726
8 Loss: 34.073 | Acc: 88.664
9 Loss: 28.548 | Acc: 90.877
10 Loss: 19.616 | Acc: 93.692
11 Loss: 14.936 | Acc: 95.404
12 Loss: 13.978 | Acc: 95.719
13 Loss: 11.330 | Acc: 96.555
14 Loss: 10.626 | Acc: 96.849
15 Loss: 9.368 | Acc: 97.178
16 Loss: 8.186 | Acc: 97.644
17 Loss: 7.748 | Acc: 97.870
18 Loss: 8.015 | Acc: 97.767
19 Loss: 7.697 | Acc: 97.973
20 Loss: 5.018 | Acc: 98.719
21 Loss: 3.931 | Acc: 99.007
22 Loss: 3.445 | Acc: 99.219
23 Loss: 3.318 | Acc: 99.205
24 Loss: 3.397 | Acc: 99.185
25 Loss: 3.232 | Acc: 99.247
26 Loss: 2.909 | Acc: 99.329
27 Loss: 2.362 | Acc: 99.432
28 Loss: 2.342 | Acc: 99.404
29 Loss: 2.364 | Acc: 99.377
30 Loss: 1.973 | Acc: 99.534
31 Loss: 2.267 | Acc: 99.486
32 Loss: 1.727 | Acc: 99.610
33 Loss: 1.703 | Acc: 99.582
34 Loss: 1.835 | Acc: 99.562
35 Loss: 1.561 | Acc: 99.644
36 Loss: 1.554 | Acc: 99.740
37 Loss: 1.641 | Acc: 99.658
38 Loss: 1.561 | Acc: 99.630
39 Loss: 1.474 | Acc: 99.664
40 Loss: 1.440 | Acc: 99.658
41 Loss: 1.241 | Acc: 99.692
42 Loss: 1.299 | Acc: 99.678
43 Loss: 1.208 | Acc: 99.726
44 Loss: 1.293 | Acc: 99.712
45 Loss: 1.150 | Acc: 99.712
46 Loss: 0.977 | Acc: 99.815
47 Loss: 0.944 | Acc: 99.781
48 Loss: 0.965 | Acc: 99.788
49 Loss: 1.013 | Acc: 99.795
50 Loss: 0.993 | Acc: 99.767
51 Loss: 1.054 | Acc: 99.760
52 Loss: 1.277 | Acc: 99.705
53 Loss: 0.855 | Acc: 99.849
54 Loss: 0.909 | Acc: 99.795
55 Loss: 1.060 | Acc: 99.808
56 Loss: 0.853 | Acc: 99.795
57 Loss: 0.917 | Acc: 99.801
58 Loss: 0.942 | Acc: 99.815
59 Loss: 0.913 | Acc: 99.788
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
nodeId:  14 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
nodeId:  15 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  8
Running nodeId:  9
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 57.051 | Train Acc: 70.908 | Val Loss: 0.533 | Val Accuracy: 73.500
10 Train Loss: 22.193 | Train Acc: 90.857 | Val Loss: 0.342 | Val Accuracy: 87.000
20 Train Loss: 14.453 | Train Acc: 94.653 | Val Loss: 0.409 | Val Accuracy: 85.000
Epoch     4: reducing learning rate of group 0 to 2.0000e-04.
30 Train Loss: 8.150 | Train Acc: 97.714 | Val Loss: 0.481 | Val Accuracy: 86.500
40 Train Loss: 5.495 | Train Acc: 99.102 | Val Loss: 0.523 | Val Accuracy: 86.000
Epoch     6: reducing learning rate of group 0 to 4.0000e-05.
50 Train Loss: 4.643 | Train Acc: 99.316 | Val Loss: 0.485 | Val Accuracy: 86.000
60 Train Loss: 4.155 | Train Acc: 99.561 | Val Loss: 0.525 | Val Accuracy: 85.000
Epoch     8: reducing learning rate of group 0 to 8.0000e-06.
70 Train Loss: 4.004 | Train Acc: 99.561 | Val Loss: 0.552 | Val Accuracy: 85.000
80 Train Loss: 3.870 | Train Acc: 99.592 | Val Loss: 0.518 | Val Accuracy: 85.500
Epoch    10: reducing learning rate of group 0 to 1.6000e-06.
90 Train Loss: 3.834 | Train Acc: 99.612 | Val Loss: 0.522 | Val Accuracy: 85.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 82.133 | Acc: 80.908
1 Loss: 58.212 | Acc: 87.490
2 Loss: 45.745 | Acc: 90.367
3 Loss: 38.739 | Acc: 91.816
4 Loss: 33.039 | Acc: 92.949
5 Loss: 28.688 | Acc: 93.786
6 Loss: 24.339 | Acc: 95.020
7 Loss: 19.265 | Acc: 96.133
8 Loss: 18.585 | Acc: 96.367
9 Loss: 17.409 | Acc: 96.561
10 Loss: 8.628 | Acc: 98.429
11 Loss: 4.698 | Acc: 99.153
12 Loss: 5.153 | Acc: 98.990
13 Loss: 4.468 | Acc: 99.173
14 Loss: 4.176 | Acc: 99.245
15 Loss: 3.275 | Acc: 99.439
16 Loss: 3.151 | Acc: 99.480
17 Loss: 4.555 | Acc: 99.163
18 Loss: 2.214 | Acc: 99.612
19 Loss: 3.575 | Acc: 99.378
20 Loss: 2.042 | Acc: 99.622
21 Loss: 1.067 | Acc: 99.837
22 Loss: 1.346 | Acc: 99.755
23 Loss: 0.799 | Acc: 99.908
24 Loss: 0.773 | Acc: 99.898
25 Loss: 0.600 | Acc: 99.929
26 Loss: 0.790 | Acc: 99.857
27 Loss: 0.752 | Acc: 99.878
28 Loss: 0.352 | Acc: 99.969
29 Loss: 0.732 | Acc: 99.898
30 Loss: 1.181 | Acc: 99.878
31 Loss: 0.593 | Acc: 99.918
32 Loss: 0.441 | Acc: 99.939
33 Loss: 0.638 | Acc: 99.918
34 Loss: 0.320 | Acc: 99.969
35 Loss: 0.237 | Acc: 99.990
36 Loss: 0.323 | Acc: 99.939
37 Loss: 0.276 | Acc: 99.969
38 Loss: 0.305 | Acc: 99.949
39 Loss: 0.268 | Acc: 99.969
40 Loss: 0.416 | Acc: 99.939
41 Loss: 0.301 | Acc: 99.959
42 Loss: 0.268 | Acc: 99.949
43 Loss: 0.315 | Acc: 99.939
44 Loss: 0.287 | Acc: 99.959
45 Loss: 0.244 | Acc: 99.969
46 Loss: 0.334 | Acc: 99.969
47 Loss: 0.251 | Acc: 99.959
48 Loss: 0.293 | Acc: 99.980
49 Loss: 0.128 | Acc: 99.990
50 Loss: 0.324 | Acc: 99.969
51 Loss: 0.280 | Acc: 99.969
52 Loss: 0.134 | Acc: 99.990
53 Loss: 0.092 | Acc: 100.000
54 Loss: 0.195 | Acc: 99.990
55 Loss: 0.125 | Acc: 100.000
56 Loss: 0.180 | Acc: 99.980
57 Loss: 0.122 | Acc: 99.980
58 Loss: 0.178 | Acc: 99.980
59 Loss: 0.214 | Acc: 99.959
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 2
nodeId:  16 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 4900
nodeId:  17 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  12
Running nodeId:  13
Running nodeId:  14
Running nodeId:  15
0 Train Loss: 52.531 | Train Acc: 73.082 | Val Loss: 0.498 | Val Accuracy: 74.500
10 Train Loss: 19.498 | Train Acc: 92.510 | Val Loss: 0.319 | Val Accuracy: 88.000
20 Train Loss: 11.128 | Train Acc: 96.449 | Val Loss: 0.339 | Val Accuracy: 86.500
Epoch     4: reducing learning rate of group 0 to 2.0000e-04.
30 Train Loss: 6.941 | Train Acc: 97.857 | Val Loss: 0.409 | Val Accuracy: 86.500
40 Train Loss: 4.136 | Train Acc: 99.398 | Val Loss: 0.416 | Val Accuracy: 87.000
Epoch     6: reducing learning rate of group 0 to 4.0000e-05.
50 Train Loss: 3.442 | Train Acc: 99.561 | Val Loss: 0.432 | Val Accuracy: 87.000
60 Train Loss: 3.008 | Train Acc: 99.745 | Val Loss: 0.431 | Val Accuracy: 86.500
Epoch     8: reducing learning rate of group 0 to 8.0000e-06.
70 Train Loss: 2.878 | Train Acc: 99.765 | Val Loss: 0.431 | Val Accuracy: 86.500
80 Train Loss: 2.780 | Train Acc: 99.796 | Val Loss: 0.433 | Val Accuracy: 86.500
Epoch    10: reducing learning rate of group 0 to 1.6000e-06.
90 Train Loss: 2.743 | Train Acc: 99.827 | Val Loss: 0.435 | Val Accuracy: 86.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 25088])
Kmeans trained successfully...
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 71.085 | Acc: 84.500
1 Loss: 50.033 | Acc: 89.765
2 Loss: 41.442 | Acc: 91.500
3 Loss: 33.216 | Acc: 93.357
4 Loss: 27.355 | Acc: 94.612
5 Loss: 21.646 | Acc: 95.765
6 Loss: 20.207 | Acc: 95.806
7 Loss: 14.869 | Acc: 96.949
8 Loss: 13.603 | Acc: 97.378
9 Loss: 14.231 | Acc: 97.337
10 Loss: 6.337 | Acc: 98.939
11 Loss: 3.929 | Acc: 99.296
12 Loss: 2.577 | Acc: 99.551
13 Loss: 3.054 | Acc: 99.480
14 Loss: 2.308 | Acc: 99.592
15 Loss: 3.653 | Acc: 99.378
16 Loss: 2.912 | Acc: 99.571
17 Loss: 2.236 | Acc: 99.724
18 Loss: 2.794 | Acc: 99.531
19 Loss: 1.917 | Acc: 99.694
20 Loss: 1.525 | Acc: 99.776
21 Loss: 0.703 | Acc: 99.908
22 Loss: 0.753 | Acc: 99.908
23 Loss: 0.373 | Acc: 99.969
24 Loss: 0.524 | Acc: 99.929
25 Loss: 0.577 | Acc: 99.908
26 Loss: 0.496 | Acc: 99.959
27 Loss: 0.413 | Acc: 99.939
28 Loss: 0.249 | Acc: 99.980
29 Loss: 0.454 | Acc: 99.918
30 Loss: 0.271 | Acc: 99.959
31 Loss: 0.276 | Acc: 99.990
32 Loss: 0.291 | Acc: 99.990
33 Loss: 0.172 | Acc: 99.980
34 Loss: 0.153 | Acc: 99.990
35 Loss: 0.153 | Acc: 99.980
36 Loss: 0.236 | Acc: 99.959
37 Loss: 0.192 | Acc: 99.980
38 Loss: 0.135 | Acc: 99.969
39 Loss: 0.102 | Acc: 100.000
40 Loss: 0.240 | Acc: 99.969
41 Loss: 0.192 | Acc: 99.969
42 Loss: 0.186 | Acc: 99.980
43 Loss: 0.105 | Acc: 100.000
44 Loss: 0.193 | Acc: 99.969
45 Loss: 0.099 | Acc: 99.990
46 Loss: 0.100 | Acc: 99.990
47 Loss: 0.154 | Acc: 99.990
48 Loss: 0.149 | Acc: 99.980
49 Loss: 0.085 | Acc: 99.980
50 Loss: 0.129 | Acc: 99.980
51 Loss: 0.081 | Acc: 100.000
52 Loss: 0.057 | Acc: 100.000
53 Loss: 0.067 | Acc: 99.990
54 Loss: 0.069 | Acc: 100.000
55 Loss: 0.085 | Acc: 99.990
56 Loss: 0.053 | Acc: 100.000
57 Loss: 0.137 | Acc: 99.980
58 Loss: 0.058 | Acc: 100.000
59 Loss: 0.140 | Acc: 99.980
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 6
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 5
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 6
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 5
nodeId:  18 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 60.430
Split Acc: 83.200
lTrainDict[data].shape:  torch.Size([5008, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([5008])
rTrainDict[data].shape:  torch.Size([4992, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4992])
# of Left images:  5008.0
# of Right images:  4992.0
giniRightRatio:  0.8549319937541092
giniLeftRatio:  0.8552195082117813
impurityDrop:  0.8552204297324789
giniGain:  0.04477957026752111
lclasses:  [888, 118, 752, 234, 811, 207, 144, 858, 855, 141]
rclasses:  [112, 882, 248, 766, 189, 793, 856, 142, 145, 859]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([5008, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5008
nodeId:  3 , imgTensorShape :  torch.Size([4992, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4992
Nodes sizes =  5 5
Node 2 Acc: 61.302
Split Acc: 77.636
lTrainDict[data].shape:  torch.Size([2028, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2028])
rTrainDict[data].shape:  torch.Size([2980, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2980])
# of Left images:  2028.0
# of Right images:  2980.0
giniRightRatio:  0.7933043556596551
giniLeftRatio:  0.6745041801368611
impurityDrop:  0.7124564509750154
giniGain:  0.14276305723676586
lclasses:  [795, 94, 85, 40, 46, 15, 17, 20, 823, 93]
rclasses:  [93, 24, 667, 194, 765, 192, 127, 838, 32, 48]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([2028, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2028
nodeId:  5 , imgTensorShape :  torch.Size([2980, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2980
Nodes sizes =  2 3
Node 3 Acc: 59.836
Split Acc: 80.028
lTrainDict[data].shape:  torch.Size([1957, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1957])
rTrainDict[data].shape:  torch.Size([3035, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3035])
# of Left images:  1957.0
# of Right images:  3035.0
giniRightRatio:  0.790167214458446
giniLeftRatio:  0.636384880970503
impurityDrop:  0.6910067443971925
giniGain:  0.16392524935691677
lclasses:  [57, 846, 21, 39, 11, 13, 25, 22, 112, 811]
rclasses:  [55, 36, 227, 727, 178, 780, 831, 120, 33, 48]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([1957, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1957
nodeId:  7 , imgTensorShape :  torch.Size([3035, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3035
Nodes sizes =  2 3
Node 4 Acc: 68.935
Split Acc: 70.858
lTrainDict[data].shape:  torch.Size([1040, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1040])
rTrainDict[data].shape:  torch.Size([988, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([988])
# of Left images:  1040.0
# of Right images:  988.0
giniRightRatio:  0.4432296874231671
giniLeftRatio:  0.5180066568047337
impurityDrop:  0.5219422867721846
giniGain:  0.15256189336467652
lclasses:  [709, 41, 63, 19, 27, 10, 11, 16, 95, 49]
rclasses:  [86, 53, 22, 21, 19, 5, 6, 4, 728, 44]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([1040, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 1040
nodeId:  9 , imgTensorShape :  torch.Size([988, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 988
Nodes sizes =  1 1
Node 5 Acc: 56.946
Split Acc: 63.859
lTrainDict[data].shape:  torch.Size([962, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([962])
rTrainDict[data].shape:  torch.Size([2018, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2018])
# of Left images:  962.0
# of Right images:  2018.0
giniRightRatio:  0.7591822261686446
giniLeftRatio:  0.6080065352414625
impurityDrop:  0.6871153209793734
giniGain:  0.10618903468028162
lclasses:  [21, 3, 106, 65, 580, 52, 43, 76, 8, 8]
rclasses:  [72, 21, 561, 129, 185, 140, 84, 762, 24, 40]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([962, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 962
nodeId:  11 , imgTensorShape :  torch.Size([2018, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2018
Nodes sizes =  1 2
Node 6 Acc: 70.976
Split Acc: 73.071
lTrainDict[data].shape:  torch.Size([991, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([991])
rTrainDict[data].shape:  torch.Size([966, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([966])
# of Left images:  991.0
# of Right images:  966.0
giniRightRatio:  0.464216058193914
giniLeftRatio:  0.43070785403647965
impurityDrop:  0.4298406644878918
giniGain:  0.20654421648261123
lclasses:  [22, 735, 11, 14, 4, 5, 14, 4, 66, 116]
rclasses:  [35, 111, 10, 25, 7, 8, 11, 18, 46, 695]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([991, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 991
nodeId:  13 , imgTensorShape :  torch.Size([966, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 966
Nodes sizes =  1 1
Node 7 Acc: 55.651
Split Acc: 59.110
lTrainDict[data].shape:  torch.Size([979, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([979])
rTrainDict[data].shape:  torch.Size([2056, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2056])
# of Left images:  979.0
# of Right images:  2056.0
giniRightRatio:  0.7532603635179943
giniLeftRatio:  0.7260707753528909
impurityDrop:  0.7403135703207004
giniGain:  0.04985364413774551
lclasses:  [24, 17, 76, 450, 67, 207, 60, 43, 16, 19]
rclasses:  [31, 19, 151, 277, 111, 573, 771, 77, 17, 29]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([979, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 979
nodeId:  15 , imgTensorShape :  torch.Size([2056, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2056
Nodes sizes =  1 2
Node 8 Acc: 68.173
Node 9 Acc: 73.684
Node 10 Acc: 60.291
Node 11 Acc: 58.523
Split Acc: 59.415
lTrainDict[data].shape:  torch.Size([1046, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1046])
rTrainDict[data].shape:  torch.Size([972, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([972])
# of Left images:  1046.0
# of Right images:  972.0
giniRightRatio:  0.7039894833104711
giniLeftRatio:  0.5300023032292737
impurityDrop:  0.5167563656510755
giniGain:  0.2424258605175691
lclasses:  [19, 10, 66, 46, 77, 67, 20, 704, 9, 28]
rclasses:  [53, 11, 495, 83, 108, 73, 64, 58, 15, 12]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([1046, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 1046
nodeId:  17 , imgTensorShape :  torch.Size([972, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 972
Nodes sizes =  1 1
Node 12 Acc: 74.168
Node 13 Acc: 71.946
Node 14 Acc: 45.965
Node 15 Acc: 60.068
Split Acc: 60.992
lTrainDict[data].shape:  torch.Size([1083, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1083])
rTrainDict[data].shape:  torch.Size([973, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([973])
# of Left images:  1083.0
# of Right images:  973.0
giniRightRatio:  0.6588136626215104
giniLeftRatio:  0.5263157894736843
impurityDrop:  0.5113365849040431
giniGain:  0.2419237786139512
lclasses:  [22, 13, 83, 89, 67, 49, 730, 11, 6, 13]
rclasses:  [9, 6, 68, 188, 44, 524, 41, 66, 11, 16]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1083, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1083
nodeId:  19 , imgTensorShape :  torch.Size([973, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 973
Nodes sizes =  1 1
Node 16 Acc: 67.304
Node 17 Acc: 50.926
Node 18 Acc: 67.405
Node 19 Acc: 53.854
[[709  22  53  24  21   9  22  19  86  35]
 [ 41 735  11  17   3   6  13  10  53 111]
 [ 63  11 495  76 106  68  83  66  22  10]
 [ 19  14  83 450  65 188  89  46  21  25]
 [ 27   4 108  67 580  44  67  77  19   7]
 [ 10   5  73 207  52 524  49  67   5   8]
 [ 11  14  64  60  43  41 730  20   6  11]
 [ 16   4  58  43  76  66  11 704   4  18]
 [ 95  66  15  16   8  11   6   9 728  46]
 [ 49 116  12  19   8  16  13  28  44 695]]

Acc: 63.500

                                                             1                                                                 
                   ┌─────────────────────────────────────────┴───────────────────────────┐                                     
                   2                                                                     3                                     
       ┌───────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
       4                         5                                         6                           7                       
 ┌─────┴─────┐            ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
 8           9            10                   11                   12            13            14                   15        
                                        ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                        16            17                                                      18            19 

                                                       -1                                                      
                   ┌───────────────────────────────────┴───────────────────────┐                               
                   -1                                                          -1                              
       ┌───────────┴───────────┐                                   ┌───────────┴───────────┐                   
       -1                      -1                                  -1                      -1                  
 ┌─────┴─────┐           ┌─────┴───────────┐                 ┌─────┴─────┐           ┌─────┴───────────┐       
 0           8           4                 -1                1           9           3                 -1      
                                     ┌─────┴─────┐                                               ┌─────┴─────┐ 
                                     7           2                                               6           5 

                                                                         49000                                                                         
                           ┌───────────────────────────────────────────────┴───────────────────────────────┐                                           
                         24500                                                                           24500                                         
           ┌───────────────┴───────────────┐                                               ┌───────────────┴───────────────┐                           
          9800                           14700                                            9800                           14700                         
   ┌───────┴───────┐               ┌───────┴───────────────┐                       ┌───────┴───────┐               ┌───────┴───────────────┐           
  4900            4900            4900                    9800                    4900            4900            4900                    9800         
                                                   ┌───────┴───────┐                                                               ┌───────┴───────┐   
                                                  4900            4900                                                            4900            4900 

                                                   {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                  
                                   ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────┐                                                       
             {0: 4900, 2: 4900, 4: 4900, 7: 4900, 8: 4900}                                                       {1: 4900, 3: 4900, 5: 4900, 6: 4900, 9: 4900}                                 
               ┌───────────────────┴───────────────────┐                                                           ┌───────────────────┴───────────────────┐                                   
       {0: 4900, 8: 4900}                 {2: 4900, 4: 4900, 7: 4900}                                      {1: 4900, 9: 4900}                 {3: 4900, 5: 4900, 6: 4900}                      
     ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐                             ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐               
 {0: 4900}           {8: 4900}           {4: 4900}                 {2: 4900, 7: 4900}                {1: 4900}           {9: 4900}           {3: 4900}                 {5: 4900, 6: 4900}      
                                                                 ┌─────────┴─────────┐                                                                               ┌─────────┴─────────┐     
                                                             {7: 4900}           {2: 4900}                                                                       {6: 4900}           {5: 4900} 

                                                               83.2                                                                   
                       ┌─────────────────────────────────────────┴───────────────────────────┐                                        
               77.63578274760384                                                     80.02804487179488                                
         ┌─────────────┴─────────────┐                                         ┌─────────────┴──────────────┐                         
 70.85798816568047           63.85906040268456                         73.07102708226878           59.110378912685334                 
  ┌──────┴──────┐             ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴──────────────┐           
 0.0           0.0           0.0           59.41526263627354           0.0           0.0           0.0            60.992217898832685  
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐    
                                           0.0           0.0                                                      0.0           0.0   

                                                         0.09999999999999987                                                         
                       ┌──────────────────────────────────────────┴───────────────────────────┐                                      
              0.24444444444444458                                                    0.24444444444444458                             
         ┌─────────────┴──────────────┐                                         ┌─────────────┴──────────────┐                       
        0.5                  0.41666666666666674                               0.5                  0.41666666666666674              
  ┌──────┴──────┐             ┌──────┴─────────────┐                     ┌──────┴──────┐             ┌──────┴─────────────┐          
 0.0           0.0           0.0                  0.5                   0.0           0.0           0.0                  0.5         
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐   
                                           0.0           0.0                                                      0.0           0.0  

