['options.ckptDir: cnn16levelsnewDir_KM', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 16', 'options.mlpFC1: 516', 'options.mlpFC2: 16']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 177.956 | Train Acc: 37.506 
1 Train Loss: 145.234 | Train Acc: 49.384 
2 Train Loss: 136.029 | Train Acc: 52.553 
3 Train Loss: 130.495 | Train Acc: 54.624 
4 Train Loss: 126.714 | Train Acc: 55.814 
5 Train Loss: 123.980 | Train Acc: 56.949 
6 Train Loss: 121.057 | Train Acc: 57.814 
7 Train Loss: 118.400 | Train Acc: 59.047 
8 Train Loss: 115.725 | Train Acc: 59.947 
9 Train Loss: 113.133 | Train Acc: 60.778 
10 Train Loss: 110.440 | Train Acc: 61.871 
11 Train Loss: 108.610 | Train Acc: 62.447 
12 Train Loss: 106.663 | Train Acc: 63.131 
13 Train Loss: 105.405 | Train Acc: 63.439 
14 Train Loss: 103.329 | Train Acc: 64.208 
15 Train Loss: 101.570 | Train Acc: 64.833 
16 Train Loss: 100.632 | Train Acc: 65.310 
17 Train Loss: 99.249 | Train Acc: 65.859 
18 Train Loss: 97.858 | Train Acc: 66.114 
19 Train Loss: 96.561 | Train Acc: 66.716 
20 Train Loss: 93.073 | Train Acc: 68.184 
21 Train Loss: 92.450 | Train Acc: 68.184 
22 Train Loss: 91.767 | Train Acc: 68.563 
23 Train Loss: 91.453 | Train Acc: 68.465 
24 Train Loss: 90.543 | Train Acc: 68.929 
25 Train Loss: 90.315 | Train Acc: 69.082 
26 Train Loss: 90.020 | Train Acc: 69.096 
27 Train Loss: 89.560 | Train Acc: 69.296 
28 Train Loss: 88.968 | Train Acc: 69.524 
29 Train Loss: 88.610 | Train Acc: 69.608 
30 Train Loss: 88.114 | Train Acc: 69.902 
31 Train Loss: 87.722 | Train Acc: 70.104 
32 Train Loss: 87.169 | Train Acc: 70.116 
33 Train Loss: 86.493 | Train Acc: 70.280 
34 Train Loss: 86.249 | Train Acc: 70.476 
35 Train Loss: 85.617 | Train Acc: 70.753 
36 Train Loss: 85.302 | Train Acc: 70.957 
37 Train Loss: 84.776 | Train Acc: 71.186 
38 Train Loss: 84.499 | Train Acc: 71.284 
39 Train Loss: 83.934 | Train Acc: 71.312 
40 Train Loss: 82.320 | Train Acc: 71.996 
41 Train Loss: 81.999 | Train Acc: 72.224 
42 Train Loss: 81.669 | Train Acc: 72.347 
43 Train Loss: 81.580 | Train Acc: 72.437 
44 Train Loss: 81.344 | Train Acc: 72.520 
45 Train Loss: 81.283 | Train Acc: 72.429 
46 Train Loss: 81.186 | Train Acc: 72.631 
47 Train Loss: 81.020 | Train Acc: 72.508 
48 Train Loss: 80.742 | Train Acc: 72.682 
49 Train Loss: 80.627 | Train Acc: 72.751 
50 Train Loss: 80.462 | Train Acc: 72.855 
51 Train Loss: 80.187 | Train Acc: 73.000 
52 Train Loss: 80.194 | Train Acc: 72.910 
53 Train Loss: 80.012 | Train Acc: 72.957 
54 Train Loss: 79.738 | Train Acc: 73.037 
55 Train Loss: 79.447 | Train Acc: 73.200 
56 Train Loss: 79.390 | Train Acc: 73.245 
57 Train Loss: 79.152 | Train Acc: 73.324 
58 Train Loss: 79.075 | Train Acc: 73.161 
59 Train Loss: 78.819 | Train Acc: 73.376 
60 Train Loss: 78.056 | Train Acc: 73.741 
61 Train Loss: 78.025 | Train Acc: 73.908 
62 Train Loss: 77.882 | Train Acc: 73.888 
63 Train Loss: 77.874 | Train Acc: 73.851 
64 Train Loss: 77.801 | Train Acc: 73.849 
65 Train Loss: 77.711 | Train Acc: 73.859 
66 Train Loss: 77.614 | Train Acc: 73.935 
67 Train Loss: 77.616 | Train Acc: 73.888 
68 Train Loss: 77.543 | Train Acc: 73.929 
69 Train Loss: 77.411 | Train Acc: 74.065 
70 Train Loss: 77.398 | Train Acc: 74.059 
71 Train Loss: 77.324 | Train Acc: 74.027 
72 Train Loss: 77.247 | Train Acc: 74.002 
73 Train Loss: 77.214 | Train Acc: 74.114 
74 Train Loss: 77.100 | Train Acc: 74.133 
75 Train Loss: 77.033 | Train Acc: 74.214 
76 Train Loss: 77.028 | Train Acc: 74.176 
77 Train Loss: 76.922 | Train Acc: 74.114 
78 Train Loss: 76.770 | Train Acc: 74.190 
79 Train Loss: 76.740 | Train Acc: 74.276 
80 Train Loss: 76.404 | Train Acc: 74.416 
81 Train Loss: 76.379 | Train Acc: 74.408 
82 Train Loss: 76.358 | Train Acc: 74.402 
83 Train Loss: 76.324 | Train Acc: 74.418 
84 Train Loss: 76.298 | Train Acc: 74.480 
85 Train Loss: 76.261 | Train Acc: 74.506 
86 Train Loss: 76.250 | Train Acc: 74.429 
87 Train Loss: 76.233 | Train Acc: 74.498 
88 Train Loss: 76.177 | Train Acc: 74.527 
89 Train Loss: 76.203 | Train Acc: 74.390 
90 Train Loss: 76.134 | Train Acc: 74.514 
91 Train Loss: 76.109 | Train Acc: 74.484 
92 Train Loss: 76.074 | Train Acc: 74.465 
93 Train Loss: 76.065 | Train Acc: 74.535 
94 Train Loss: 76.007 | Train Acc: 74.518 
95 Train Loss: 75.997 | Train Acc: 74.531 
96 Train Loss: 75.989 | Train Acc: 74.531 
97 Train Loss: 75.932 | Train Acc: 74.518 
98 Train Loss: 75.886 | Train Acc: 74.629 
99 Train Loss: 75.880 | Train Acc: 74.588 
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 12544])
Time Taken by Kmeans is  3.99812912940979
Kmeans completed successfully...
printing expected split from k means
{8: 0, 5: 1, 9: 0, 2: 1, 4: 1, 0: 0, 1: 0, 7: 1, 6: 1, 3: 1}
Printing final_dict items...
{8: 0, 5: 1, 9: 0, 2: 1, 4: 1, 0: 0, 1: 0, 7: 1, 6: 1, 3: 1}
Image Statistics before MLP : L R :  19600 29400
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 47.801 | Acc: 87.710
1 Loss: 38.901 | Acc: 90.171
2 Loss: 36.047 | Acc: 90.988
3 Loss: 33.812 | Acc: 91.696
4 Loss: 31.944 | Acc: 92.004
5 Loss: 29.703 | Acc: 92.492
6 Loss: 28.107 | Acc: 92.992
7 Loss: 27.154 | Acc: 93.288
8 Loss: 25.400 | Acc: 93.512
9 Loss: 24.407 | Acc: 93.873
10 Loss: 19.597 | Acc: 94.971
11 Loss: 18.385 | Acc: 95.318
12 Loss: 17.276 | Acc: 95.433
13 Loss: 16.375 | Acc: 95.712
14 Loss: 16.244 | Acc: 95.935
15 Loss: 14.837 | Acc: 96.163
16 Loss: 14.160 | Acc: 96.306
17 Loss: 13.699 | Acc: 96.571
18 Loss: 13.302 | Acc: 96.476
19 Loss: 12.454 | Acc: 96.778
20 Loss: 10.271 | Acc: 97.410
21 Loss: 9.650 | Acc: 97.555
22 Loss: 9.552 | Acc: 97.537
23 Loss: 9.112 | Acc: 97.680
24 Loss: 8.775 | Acc: 97.814
25 Loss: 8.596 | Acc: 97.835
26 Loss: 8.114 | Acc: 97.922
27 Loss: 8.128 | Acc: 97.947
28 Loss: 7.769 | Acc: 98.080
29 Loss: 7.925 | Acc: 98.014
30 Loss: 6.633 | Acc: 98.398
31 Loss: 6.989 | Acc: 98.265
32 Loss: 6.474 | Acc: 98.441
33 Loss: 6.352 | Acc: 98.439
34 Loss: 6.423 | Acc: 98.465
35 Loss: 6.148 | Acc: 98.478
36 Loss: 6.219 | Acc: 98.490
37 Loss: 5.814 | Acc: 98.557
38 Loss: 5.950 | Acc: 98.490
39 Loss: 5.864 | Acc: 98.578
40 Loss: 5.514 | Acc: 98.702
41 Loss: 5.430 | Acc: 98.667
42 Loss: 5.620 | Acc: 98.606
43 Loss: 5.382 | Acc: 98.655
44 Loss: 5.257 | Acc: 98.700
45 Loss: 5.052 | Acc: 98.771
46 Loss: 5.195 | Acc: 98.643
47 Loss: 5.183 | Acc: 98.661
48 Loss: 5.159 | Acc: 98.710
49 Loss: 5.200 | Acc: 98.765
50 Loss: 4.929 | Acc: 98.806
51 Loss: 4.824 | Acc: 98.869
52 Loss: 4.956 | Acc: 98.818
53 Loss: 4.885 | Acc: 98.843
54 Loss: 4.720 | Acc: 98.859
55 Loss: 4.988 | Acc: 98.771
56 Loss: 5.014 | Acc: 98.765
57 Loss: 4.780 | Acc: 98.816
58 Loss: 4.661 | Acc: 98.855
59 Loss: 5.016 | Acc: 98.780
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([19600, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([19600])
rTrainDict[data].shape:  torch.Size([29400, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([29400])
lValDict[data].shape:  torch.Size([400, 3, 32, 32])   lValDict[label].shape:  torch.Size([400])
rValDict[data].shape:  torch.Size([600, 3, 32, 32])   rValDict[label].shape:  torch.Size([600])
# of Left images:  19600.0
# of Right images:  29400.0
giniRightRatio:  0.8333333333333333
giniLeftRatio:  0.75
impurityDrop:  0.7777777777777778
giniGain:  0.12222222222222223
lclasses:  [4900, 4900, 0, 0, 0, 0, 0, 0, 4900, 4900]
rclasses:  [0, 0, 4900, 4900, 4900, 4900, 4900, 4900, 0, 0]
noOfLeftClasses:  4
noOfRightClasses:  6
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([19600, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 19600
nodeId:  3 , imgTensorShape :  torch.Size([29400, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 6 ,  numData: 29400
Running nodeId:  2
0 Train Loss: 119.412 | Train Acc: 48.964 
1 Train Loss: 89.975 | Train Acc: 62.944 
2 Train Loss: 83.611 | Train Acc: 66.378 
3 Train Loss: 79.686 | Train Acc: 68.214 
4 Train Loss: 74.958 | Train Acc: 70.230 
5 Train Loss: 71.961 | Train Acc: 71.755 
6 Train Loss: 68.973 | Train Acc: 73.097 
7 Train Loss: 65.726 | Train Acc: 74.811 
8 Train Loss: 63.523 | Train Acc: 75.929 
9 Train Loss: 61.652 | Train Acc: 76.500 
10 Train Loss: 60.019 | Train Acc: 77.138 
11 Train Loss: 57.267 | Train Acc: 78.571 
12 Train Loss: 55.992 | Train Acc: 79.061 
13 Train Loss: 53.574 | Train Acc: 80.066 
14 Train Loss: 52.555 | Train Acc: 80.495 
15 Train Loss: 51.096 | Train Acc: 81.153 
16 Train Loss: 49.682 | Train Acc: 81.469 
17 Train Loss: 48.851 | Train Acc: 81.765 
18 Train Loss: 47.360 | Train Acc: 82.628 
19 Train Loss: 46.035 | Train Acc: 83.158 
20 Train Loss: 42.782 | Train Acc: 84.658 
21 Train Loss: 42.421 | Train Acc: 84.837 
22 Train Loss: 41.910 | Train Acc: 84.893 
23 Train Loss: 41.442 | Train Acc: 85.092 
24 Train Loss: 41.123 | Train Acc: 85.219 
25 Train Loss: 40.248 | Train Acc: 85.750 
26 Train Loss: 39.926 | Train Acc: 85.765 
27 Train Loss: 39.821 | Train Acc: 85.806 
28 Train Loss: 39.160 | Train Acc: 86.173 
29 Train Loss: 38.553 | Train Acc: 86.388 
30 Train Loss: 38.057 | Train Acc: 86.474 
31 Train Loss: 37.824 | Train Acc: 86.607 
32 Train Loss: 37.524 | Train Acc: 86.663 
33 Train Loss: 36.834 | Train Acc: 86.949 
34 Train Loss: 36.587 | Train Acc: 87.133 
35 Train Loss: 35.988 | Train Acc: 87.408 
36 Train Loss: 35.556 | Train Acc: 87.735 
37 Train Loss: 35.028 | Train Acc: 87.883 
38 Train Loss: 34.933 | Train Acc: 87.719 
39 Train Loss: 34.520 | Train Acc: 88.107 
40 Train Loss: 32.734 | Train Acc: 88.939 
41 Train Loss: 32.583 | Train Acc: 89.041 
42 Train Loss: 32.316 | Train Acc: 89.184 
43 Train Loss: 32.270 | Train Acc: 89.158 
44 Train Loss: 32.051 | Train Acc: 89.316 
45 Train Loss: 32.000 | Train Acc: 89.408 
46 Train Loss: 31.780 | Train Acc: 89.459 
47 Train Loss: 31.591 | Train Acc: 89.388 
48 Train Loss: 31.373 | Train Acc: 89.622 
49 Train Loss: 31.197 | Train Acc: 89.719 
50 Train Loss: 31.022 | Train Acc: 89.816 
51 Train Loss: 30.899 | Train Acc: 89.903 
52 Train Loss: 30.711 | Train Acc: 90.000 
53 Train Loss: 30.603 | Train Acc: 89.837 
54 Train Loss: 30.366 | Train Acc: 89.934 
55 Train Loss: 30.207 | Train Acc: 90.087 
56 Train Loss: 30.152 | Train Acc: 90.148 
57 Train Loss: 29.823 | Train Acc: 90.321 
58 Train Loss: 29.729 | Train Acc: 90.372 
59 Train Loss: 29.540 | Train Acc: 90.423 
60 Train Loss: 28.893 | Train Acc: 90.898 
61 Train Loss: 28.765 | Train Acc: 91.031 
62 Train Loss: 28.675 | Train Acc: 90.847 
63 Train Loss: 28.653 | Train Acc: 90.980 
64 Train Loss: 28.630 | Train Acc: 90.852 
65 Train Loss: 28.531 | Train Acc: 90.857 
66 Train Loss: 28.434 | Train Acc: 91.138 
67 Train Loss: 28.385 | Train Acc: 91.117 
68 Train Loss: 28.340 | Train Acc: 91.051 
69 Train Loss: 28.253 | Train Acc: 91.173 
70 Train Loss: 28.187 | Train Acc: 91.143 
71 Train Loss: 28.131 | Train Acc: 91.097 
72 Train Loss: 28.051 | Train Acc: 91.189 
73 Train Loss: 28.048 | Train Acc: 91.209 
74 Train Loss: 27.955 | Train Acc: 91.189 
75 Train Loss: 27.907 | Train Acc: 91.265 
76 Train Loss: 27.839 | Train Acc: 91.270 
77 Train Loss: 27.681 | Train Acc: 91.311 
78 Train Loss: 27.672 | Train Acc: 91.367 
79 Train Loss: 27.683 | Train Acc: 91.321 
80 Train Loss: 27.322 | Train Acc: 91.505 
81 Train Loss: 27.284 | Train Acc: 91.526 
82 Train Loss: 27.277 | Train Acc: 91.571 
83 Train Loss: 27.255 | Train Acc: 91.556 
84 Train Loss: 27.235 | Train Acc: 91.541 
85 Train Loss: 27.226 | Train Acc: 91.531 
86 Train Loss: 27.187 | Train Acc: 91.490 
87 Train Loss: 27.148 | Train Acc: 91.602 
88 Train Loss: 27.118 | Train Acc: 91.628 
89 Train Loss: 27.096 | Train Acc: 91.663 
90 Train Loss: 27.073 | Train Acc: 91.561 
91 Train Loss: 27.013 | Train Acc: 91.622 
92 Train Loss: 27.058 | Train Acc: 91.490 
93 Train Loss: 26.973 | Train Acc: 91.699 
94 Train Loss: 26.972 | Train Acc: 91.745 
95 Train Loss: 26.933 | Train Acc: 91.760 
96 Train Loss: 26.880 | Train Acc: 91.694 
97 Train Loss: 26.888 | Train Acc: 91.699 
98 Train Loss: 26.862 | Train Acc: 91.730 
99 Train Loss: 26.867 | Train Acc: 91.694 
CNN trained successfully...
image_next_flat.shape :  torch.Size([19600, 15680])
Time Taken by Kmeans is  2.175666332244873
Kmeans completed successfully...
printing expected split from k means
{3: 0, 2: 0, 1: 0, 0: 1}
Printing final_dict items...
{3: 0, 2: 0, 1: 0, 0: 1}
Image Statistics before MLP : L R :  14700 4900
expectedMlpLabels.shape :  torch.Size([19600])
0 Loss: 46.481 | Acc: 77.714
1 Loss: 36.762 | Acc: 83.796
2 Loss: 31.969 | Acc: 86.357
3 Loss: 28.339 | Acc: 87.699
4 Loss: 25.508 | Acc: 89.020
5 Loss: 23.826 | Acc: 89.709
6 Loss: 20.563 | Acc: 91.092
7 Loss: 19.451 | Acc: 91.633
8 Loss: 17.606 | Acc: 92.383
9 Loss: 15.924 | Acc: 93.296
10 Loss: 11.852 | Acc: 95.158
11 Loss: 10.347 | Acc: 95.587
12 Loss: 9.247 | Acc: 96.235
13 Loss: 8.327 | Acc: 96.577
14 Loss: 7.931 | Acc: 96.668
15 Loss: 7.520 | Acc: 96.898
16 Loss: 7.539 | Acc: 96.903
17 Loss: 6.769 | Acc: 97.342
18 Loss: 6.331 | Acc: 97.301
19 Loss: 5.563 | Acc: 97.750
20 Loss: 4.692 | Acc: 98.260
21 Loss: 4.039 | Acc: 98.388
22 Loss: 3.514 | Acc: 98.673
23 Loss: 3.356 | Acc: 98.724
24 Loss: 3.351 | Acc: 98.648
25 Loss: 3.803 | Acc: 98.546
26 Loss: 3.368 | Acc: 98.709
27 Loss: 3.506 | Acc: 98.699
28 Loss: 2.819 | Acc: 98.847
29 Loss: 2.905 | Acc: 98.903
30 Loss: 2.563 | Acc: 99.046
31 Loss: 2.325 | Acc: 99.148
32 Loss: 2.090 | Acc: 99.270
33 Loss: 2.215 | Acc: 99.230
34 Loss: 1.939 | Acc: 99.306
35 Loss: 2.194 | Acc: 99.255
36 Loss: 2.215 | Acc: 99.168
37 Loss: 1.801 | Acc: 99.342
38 Loss: 1.968 | Acc: 99.286
39 Loss: 1.996 | Acc: 99.311
40 Loss: 1.884 | Acc: 99.383
41 Loss: 1.700 | Acc: 99.418
42 Loss: 1.722 | Acc: 99.378
43 Loss: 1.579 | Acc: 99.480
44 Loss: 1.469 | Acc: 99.459
45 Loss: 1.631 | Acc: 99.429
46 Loss: 1.626 | Acc: 99.418
47 Loss: 1.533 | Acc: 99.464
48 Loss: 1.556 | Acc: 99.459
49 Loss: 1.587 | Acc: 99.480
50 Loss: 1.549 | Acc: 99.429
51 Loss: 1.310 | Acc: 99.546
52 Loss: 1.388 | Acc: 99.500
53 Loss: 1.348 | Acc: 99.582
54 Loss: 1.286 | Acc: 99.531
55 Loss: 1.230 | Acc: 99.571
56 Loss: 1.417 | Acc: 99.577
57 Loss: 1.431 | Acc: 99.505
58 Loss: 1.404 | Acc: 99.515
59 Loss: 1.265 | Acc: 99.566
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([14700])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([300, 3, 32, 32])   lValDict[label].shape:  torch.Size([300])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  14700.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.6666666666666667
impurityDrop:  2.0
giniGain:  -1.25
lclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 0
nodeId:  4 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
nodeId:  5 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  3
0 Train Loss: 152.975 | Train Acc: 39.102 
1 Train Loss: 132.441 | Train Acc: 49.092 
2 Train Loss: 125.019 | Train Acc: 52.446 
3 Train Loss: 121.154 | Train Acc: 54.020 
4 Train Loss: 117.774 | Train Acc: 55.442 
5 Train Loss: 114.884 | Train Acc: 56.650 
6 Train Loss: 111.693 | Train Acc: 58.316 
7 Train Loss: 108.942 | Train Acc: 59.241 
8 Train Loss: 106.805 | Train Acc: 60.126 
9 Train Loss: 104.577 | Train Acc: 61.187 
10 Train Loss: 101.608 | Train Acc: 62.350 
11 Train Loss: 99.061 | Train Acc: 63.517 
12 Train Loss: 97.803 | Train Acc: 63.891 
13 Train Loss: 96.668 | Train Acc: 64.364 
14 Train Loss: 94.168 | Train Acc: 65.204 
15 Train Loss: 92.361 | Train Acc: 66.122 
16 Train Loss: 91.240 | Train Acc: 66.442 
17 Train Loss: 89.626 | Train Acc: 67.371 
18 Train Loss: 88.527 | Train Acc: 67.636 
19 Train Loss: 87.524 | Train Acc: 67.701 
20 Train Loss: 82.626 | Train Acc: 70.340 
21 Train Loss: 81.654 | Train Acc: 70.636 
22 Train Loss: 81.390 | Train Acc: 70.796 
23 Train Loss: 80.908 | Train Acc: 71.034 
24 Train Loss: 80.139 | Train Acc: 71.306 
25 Train Loss: 79.466 | Train Acc: 71.714 
26 Train Loss: 79.102 | Train Acc: 71.707 
27 Train Loss: 78.781 | Train Acc: 71.616 
28 Train Loss: 78.317 | Train Acc: 72.000 
29 Train Loss: 77.977 | Train Acc: 72.078 
30 Train Loss: 77.407 | Train Acc: 72.323 
31 Train Loss: 77.103 | Train Acc: 72.425 
32 Train Loss: 76.435 | Train Acc: 72.837 
33 Train Loss: 76.399 | Train Acc: 72.673 
34 Train Loss: 75.446 | Train Acc: 73.088 
35 Train Loss: 75.288 | Train Acc: 72.986 
36 Train Loss: 74.959 | Train Acc: 73.337 
37 Train Loss: 74.562 | Train Acc: 73.313 
38 Train Loss: 74.033 | Train Acc: 73.602 
39 Train Loss: 73.623 | Train Acc: 73.864 
40 Train Loss: 71.538 | Train Acc: 74.901 
41 Train Loss: 71.373 | Train Acc: 75.017 
42 Train Loss: 71.147 | Train Acc: 75.133 
43 Train Loss: 70.904 | Train Acc: 75.105 
44 Train Loss: 70.923 | Train Acc: 75.163 
45 Train Loss: 70.622 | Train Acc: 75.235 
46 Train Loss: 70.419 | Train Acc: 75.401 
47 Train Loss: 70.209 | Train Acc: 75.442 
48 Train Loss: 70.282 | Train Acc: 75.486 
49 Train Loss: 69.987 | Train Acc: 75.629 
50 Train Loss: 69.787 | Train Acc: 75.636 
51 Train Loss: 69.742 | Train Acc: 75.565 
52 Train Loss: 69.422 | Train Acc: 75.861 
53 Train Loss: 69.409 | Train Acc: 75.684 
54 Train Loss: 69.483 | Train Acc: 75.680 
55 Train Loss: 69.250 | Train Acc: 75.735 
56 Train Loss: 68.933 | Train Acc: 75.789 
57 Train Loss: 68.628 | Train Acc: 75.857 
58 Train Loss: 68.450 | Train Acc: 76.058 
59 Train Loss: 68.535 | Train Acc: 76.204 
60 Train Loss: 67.547 | Train Acc: 76.656 
61 Train Loss: 67.432 | Train Acc: 76.653 
62 Train Loss: 67.278 | Train Acc: 76.745 
63 Train Loss: 67.319 | Train Acc: 76.663 
64 Train Loss: 67.118 | Train Acc: 76.813 
65 Train Loss: 67.119 | Train Acc: 76.830 
66 Train Loss: 67.058 | Train Acc: 76.827 
67 Train Loss: 67.056 | Train Acc: 76.983 
68 Train Loss: 66.961 | Train Acc: 76.857 
69 Train Loss: 66.824 | Train Acc: 77.088 
70 Train Loss: 66.837 | Train Acc: 76.925 
71 Train Loss: 66.765 | Train Acc: 77.082 
72 Train Loss: 66.658 | Train Acc: 77.051 
73 Train Loss: 66.533 | Train Acc: 77.054 
74 Train Loss: 66.610 | Train Acc: 76.915 
75 Train Loss: 66.472 | Train Acc: 77.207 
76 Train Loss: 66.384 | Train Acc: 77.214 
77 Train Loss: 66.381 | Train Acc: 77.167 
78 Train Loss: 66.385 | Train Acc: 77.058 
79 Train Loss: 66.184 | Train Acc: 77.190 
80 Train Loss: 65.852 | Train Acc: 77.371 
81 Train Loss: 65.805 | Train Acc: 77.503 
82 Train Loss: 65.754 | Train Acc: 77.527 
83 Train Loss: 65.757 | Train Acc: 77.486 
84 Train Loss: 65.708 | Train Acc: 77.469 
85 Train Loss: 65.655 | Train Acc: 77.544 
86 Train Loss: 65.634 | Train Acc: 77.524 
87 Train Loss: 65.633 | Train Acc: 77.544 
88 Train Loss: 65.597 | Train Acc: 77.643 
89 Train Loss: 65.586 | Train Acc: 77.578 
90 Train Loss: 65.594 | Train Acc: 77.592 
91 Train Loss: 65.537 | Train Acc: 77.537 
92 Train Loss: 65.496 | Train Acc: 77.697 
93 Train Loss: 65.491 | Train Acc: 77.578 
94 Train Loss: 65.472 | Train Acc: 77.646 
95 Train Loss: 65.398 | Train Acc: 77.609 
96 Train Loss: 65.420 | Train Acc: 77.633 
97 Train Loss: 65.388 | Train Acc: 77.646 
98 Train Loss: 65.312 | Train Acc: 77.656 
99 Train Loss: 65.268 | Train Acc: 77.697 
CNN trained successfully...
image_next_flat.shape :  torch.Size([29400, 15680])
Time Taken by Kmeans is  4.345515012741089
Kmeans completed successfully...
printing expected split from k means
{0: 0, 3: 1, 2: 0, 1: 1, 5: 1, 4: 0}
Printing final_dict items...
{0: 0, 3: 1, 2: 0, 1: 1, 5: 1, 4: 0}
Image Statistics before MLP : L R :  14700 14700
expectedMlpLabels.shape :  torch.Size([29400])
0 Loss: 105.754 | Acc: 73.622
1 Loss: 93.632 | Acc: 77.878
2 Loss: 89.108 | Acc: 79.221
3 Loss: 84.593 | Acc: 80.473
4 Loss: 81.358 | Acc: 81.425
5 Loss: 76.302 | Acc: 82.857
6 Loss: 73.721 | Acc: 83.446
7 Loss: 70.305 | Acc: 84.201
8 Loss: 67.224 | Acc: 84.830
9 Loss: 63.595 | Acc: 85.837
10 Loss: 54.271 | Acc: 88.099
11 Loss: 50.668 | Acc: 89.010
12 Loss: 47.384 | Acc: 89.806
13 Loss: 44.361 | Acc: 90.544
14 Loss: 42.358 | Acc: 90.973
15 Loss: 39.486 | Acc: 91.704
16 Loss: 38.833 | Acc: 91.837
17 Loss: 36.117 | Acc: 92.534
18 Loss: 34.725 | Acc: 92.850
19 Loss: 33.276 | Acc: 93.122
20 Loss: 27.474 | Acc: 94.354
21 Loss: 25.374 | Acc: 94.874
22 Loss: 24.052 | Acc: 95.156
23 Loss: 22.785 | Acc: 95.510
24 Loss: 22.570 | Acc: 95.435
25 Loss: 21.156 | Acc: 95.772
26 Loss: 20.777 | Acc: 95.864
27 Loss: 20.236 | Acc: 95.969
28 Loss: 19.851 | Acc: 96.095
29 Loss: 19.078 | Acc: 96.384
30 Loss: 16.950 | Acc: 96.752
31 Loss: 16.024 | Acc: 96.942
32 Loss: 15.430 | Acc: 96.980
33 Loss: 15.156 | Acc: 97.085
34 Loss: 15.670 | Acc: 97.061
35 Loss: 14.839 | Acc: 97.214
36 Loss: 14.202 | Acc: 97.337
37 Loss: 14.206 | Acc: 97.231
38 Loss: 13.865 | Acc: 97.391
39 Loss: 13.847 | Acc: 97.293
40 Loss: 12.868 | Acc: 97.633
41 Loss: 13.052 | Acc: 97.554
42 Loss: 12.475 | Acc: 97.752
43 Loss: 12.670 | Acc: 97.609
44 Loss: 12.121 | Acc: 97.735
45 Loss: 12.083 | Acc: 97.728
46 Loss: 12.164 | Acc: 97.619
47 Loss: 12.377 | Acc: 97.724
48 Loss: 11.973 | Acc: 97.639
49 Loss: 11.763 | Acc: 97.779
50 Loss: 11.589 | Acc: 97.789
51 Loss: 11.579 | Acc: 97.874
52 Loss: 11.897 | Acc: 97.799
53 Loss: 11.201 | Acc: 97.874
54 Loss: 11.518 | Acc: 97.789
55 Loss: 11.311 | Acc: 97.881
56 Loss: 11.250 | Acc: 97.956
57 Loss: 11.252 | Acc: 98.037
58 Loss: 11.852 | Acc: 97.827
59 Loss: 11.149 | Acc: 98.003
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([14700])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([300, 3, 32, 32])   lValDict[label].shape:  torch.Size([300])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  14700.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.6666666666666667
impurityDrop:  0.6666666666666667
giniGain:  0.16666666666666652
lclasses:  [4900, 0, 4900, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 4900, 0, 4900, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
nodeId:  7 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  4
0 Train Loss: 85.996 | Train Acc: 60.932 
1 Train Loss: 62.938 | Train Acc: 74.048 
2 Train Loss: 56.697 | Train Acc: 76.776 
3 Train Loss: 53.896 | Train Acc: 78.279 
4 Train Loss: 51.520 | Train Acc: 79.361 
5 Train Loss: 48.703 | Train Acc: 80.551 
6 Train Loss: 45.958 | Train Acc: 81.993 
7 Train Loss: 43.618 | Train Acc: 82.816 
8 Train Loss: 41.100 | Train Acc: 84.231 
9 Train Loss: 39.133 | Train Acc: 84.830 
10 Train Loss: 38.153 | Train Acc: 85.320 
11 Train Loss: 36.221 | Train Acc: 86.252 
12 Train Loss: 34.474 | Train Acc: 87.027 
13 Train Loss: 33.210 | Train Acc: 87.408 
14 Train Loss: 31.292 | Train Acc: 88.354 
15 Train Loss: 31.158 | Train Acc: 88.265 
16 Train Loss: 29.396 | Train Acc: 89.306 
17 Train Loss: 28.733 | Train Acc: 89.687 
18 Train Loss: 28.299 | Train Acc: 89.456 
19 Train Loss: 26.812 | Train Acc: 90.531 
20 Train Loss: 23.727 | Train Acc: 91.946 
21 Train Loss: 23.411 | Train Acc: 92.014 
22 Train Loss: 22.828 | Train Acc: 92.265 
23 Train Loss: 22.757 | Train Acc: 92.245 
24 Train Loss: 22.048 | Train Acc: 92.816 
25 Train Loss: 21.728 | Train Acc: 92.850 
26 Train Loss: 21.463 | Train Acc: 92.952 
27 Train Loss: 21.356 | Train Acc: 92.966 
28 Train Loss: 20.910 | Train Acc: 93.116 
29 Train Loss: 20.542 | Train Acc: 93.143 
30 Train Loss: 20.156 | Train Acc: 93.361 
31 Train Loss: 19.634 | Train Acc: 93.857 
32 Train Loss: 19.695 | Train Acc: 93.714 
33 Train Loss: 19.184 | Train Acc: 93.844 
34 Train Loss: 18.910 | Train Acc: 94.245 
35 Train Loss: 18.961 | Train Acc: 93.946 
36 Train Loss: 18.273 | Train Acc: 94.401 
37 Train Loss: 18.509 | Train Acc: 94.184 
38 Train Loss: 17.536 | Train Acc: 94.687 
39 Train Loss: 17.238 | Train Acc: 94.782 
40 Train Loss: 16.291 | Train Acc: 95.483 
41 Train Loss: 16.092 | Train Acc: 95.537 
42 Train Loss: 15.909 | Train Acc: 95.667 
43 Train Loss: 15.779 | Train Acc: 95.639 
44 Train Loss: 15.654 | Train Acc: 95.646 
45 Train Loss: 15.644 | Train Acc: 95.626 
46 Train Loss: 15.451 | Train Acc: 95.803 
47 Train Loss: 15.300 | Train Acc: 95.946 
48 Train Loss: 15.130 | Train Acc: 95.966 
49 Train Loss: 15.273 | Train Acc: 95.803 
50 Train Loss: 15.058 | Train Acc: 95.986 
51 Train Loss: 14.927 | Train Acc: 95.946 
52 Train Loss: 14.851 | Train Acc: 96.034 
53 Train Loss: 14.739 | Train Acc: 96.272 
54 Train Loss: 14.543 | Train Acc: 96.245 
55 Train Loss: 14.475 | Train Acc: 96.218 
56 Train Loss: 14.225 | Train Acc: 96.306 
57 Train Loss: 14.093 | Train Acc: 96.503 
58 Train Loss: 13.949 | Train Acc: 96.558 
59 Train Loss: 13.910 | Train Acc: 96.551 
60 Train Loss: 13.501 | Train Acc: 96.769 
61 Train Loss: 13.369 | Train Acc: 96.816 
62 Train Loss: 13.355 | Train Acc: 96.857 
63 Train Loss: 13.265 | Train Acc: 96.966 
64 Train Loss: 13.229 | Train Acc: 96.905 
65 Train Loss: 13.219 | Train Acc: 97.034 
66 Train Loss: 13.160 | Train Acc: 96.959 
67 Train Loss: 13.067 | Train Acc: 97.020 
68 Train Loss: 13.082 | Train Acc: 97.068 
69 Train Loss: 12.996 | Train Acc: 97.034 
70 Train Loss: 12.978 | Train Acc: 97.034 
71 Train Loss: 12.898 | Train Acc: 97.122 
72 Train Loss: 12.897 | Train Acc: 97.020 
73 Train Loss: 12.785 | Train Acc: 97.068 
74 Train Loss: 12.861 | Train Acc: 96.898 
75 Train Loss: 12.784 | Train Acc: 97.129 
76 Train Loss: 12.690 | Train Acc: 97.150 
77 Train Loss: 12.644 | Train Acc: 97.109 
78 Train Loss: 12.616 | Train Acc: 97.143 
79 Train Loss: 12.562 | Train Acc: 97.259 
80 Train Loss: 12.305 | Train Acc: 97.395 
81 Train Loss: 12.312 | Train Acc: 97.333 
82 Train Loss: 12.275 | Train Acc: 97.374 
83 Train Loss: 12.265 | Train Acc: 97.354 
84 Train Loss: 12.253 | Train Acc: 97.429 
85 Train Loss: 12.248 | Train Acc: 97.374 
86 Train Loss: 12.233 | Train Acc: 97.401 
87 Train Loss: 12.173 | Train Acc: 97.313 
88 Train Loss: 12.167 | Train Acc: 97.381 
89 Train Loss: 12.161 | Train Acc: 97.367 
90 Train Loss: 12.131 | Train Acc: 97.422 
91 Train Loss: 12.113 | Train Acc: 97.408 
92 Train Loss: 12.102 | Train Acc: 97.367 
93 Train Loss: 12.100 | Train Acc: 97.531 
94 Train Loss: 12.051 | Train Acc: 97.476 
95 Train Loss: 12.039 | Train Acc: 97.367 
96 Train Loss: 12.050 | Train Acc: 97.401 
97 Train Loss: 11.994 | Train Acc: 97.476 
98 Train Loss: 11.970 | Train Acc: 97.497 
99 Train Loss: 11.967 | Train Acc: 97.490 
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 18816])
Time Taken by Kmeans is  1.8791444301605225
Kmeans completed successfully...
printing expected split from k means
{2: 0, 1: 1, 0: 0}
Printing final_dict items...
{2: 0, 1: 1, 0: 0}
Image Statistics before MLP : L R :  9800 4900
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 45.277 | Acc: 86.075
1 Loss: 32.621 | Acc: 89.870
2 Loss: 27.256 | Acc: 91.815
3 Loss: 23.856 | Acc: 92.938
4 Loss: 20.957 | Acc: 93.479
5 Loss: 17.893 | Acc: 94.486
6 Loss: 15.704 | Acc: 95.274
7 Loss: 13.929 | Acc: 95.993
8 Loss: 12.496 | Acc: 96.137
9 Loss: 11.668 | Acc: 96.390
10 Loss: 7.372 | Acc: 97.993
11 Loss: 5.347 | Acc: 98.610
12 Loss: 5.118 | Acc: 98.541
13 Loss: 4.672 | Acc: 98.685
14 Loss: 4.074 | Acc: 98.945
15 Loss: 3.218 | Acc: 99.130
16 Loss: 3.366 | Acc: 99.075
17 Loss: 3.211 | Acc: 99.089
18 Loss: 3.098 | Acc: 99.096
19 Loss: 2.966 | Acc: 99.226
20 Loss: 2.409 | Acc: 99.438
21 Loss: 1.688 | Acc: 99.596
22 Loss: 1.615 | Acc: 99.637
23 Loss: 1.439 | Acc: 99.623
24 Loss: 1.491 | Acc: 99.610
25 Loss: 1.289 | Acc: 99.692
26 Loss: 1.235 | Acc: 99.685
27 Loss: 1.106 | Acc: 99.712
28 Loss: 1.241 | Acc: 99.719
29 Loss: 1.183 | Acc: 99.678
30 Loss: 0.683 | Acc: 99.856
31 Loss: 0.577 | Acc: 99.849
32 Loss: 0.708 | Acc: 99.822
33 Loss: 0.678 | Acc: 99.863
34 Loss: 0.423 | Acc: 99.890
35 Loss: 0.733 | Acc: 99.849
36 Loss: 0.516 | Acc: 99.856
37 Loss: 0.453 | Acc: 99.897
38 Loss: 0.421 | Acc: 99.897
39 Loss: 0.495 | Acc: 99.890
40 Loss: 0.548 | Acc: 99.884
41 Loss: 0.537 | Acc: 99.897
42 Loss: 0.402 | Acc: 99.932
43 Loss: 0.379 | Acc: 99.897
44 Loss: 0.430 | Acc: 99.904
45 Loss: 0.367 | Acc: 99.918
46 Loss: 0.311 | Acc: 99.904
47 Loss: 0.458 | Acc: 99.877
48 Loss: 0.457 | Acc: 99.904
49 Loss: 0.367 | Acc: 99.911
50 Loss: 0.289 | Acc: 99.918
51 Loss: 0.377 | Acc: 99.911
52 Loss: 0.285 | Acc: 99.925
53 Loss: 0.255 | Acc: 99.932
54 Loss: 0.318 | Acc: 99.925
55 Loss: 0.270 | Acc: 99.918
56 Loss: 0.264 | Acc: 99.938
57 Loss: 0.306 | Acc: 99.897
58 Loss: 0.286 | Acc: 99.918
59 Loss: 0.300 | Acc: 99.952
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  9800.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.5
impurityDrop:  1.0
giniGain:  -0.33333333333333326
lclasses:  [4900, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  8 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  9 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  5
Running nodeId:  6
0 Train Loss: 95.895 | Train Acc: 54.027 
1 Train Loss: 83.592 | Train Acc: 62.844 
2 Train Loss: 78.288 | Train Acc: 65.755 
3 Train Loss: 73.023 | Train Acc: 68.483 
4 Train Loss: 67.707 | Train Acc: 71.544 
5 Train Loss: 63.679 | Train Acc: 74.088 
6 Train Loss: 59.799 | Train Acc: 75.952 
7 Train Loss: 56.602 | Train Acc: 77.299 
8 Train Loss: 55.123 | Train Acc: 77.537 
9 Train Loss: 53.695 | Train Acc: 78.313 
10 Train Loss: 51.052 | Train Acc: 79.912 
11 Train Loss: 49.626 | Train Acc: 80.218 
12 Train Loss: 47.068 | Train Acc: 81.544 
13 Train Loss: 45.527 | Train Acc: 82.143 
14 Train Loss: 46.450 | Train Acc: 81.605 
15 Train Loss: 43.425 | Train Acc: 83.109 
16 Train Loss: 42.383 | Train Acc: 83.483 
17 Train Loss: 41.570 | Train Acc: 83.925 
18 Train Loss: 40.426 | Train Acc: 84.687 
19 Train Loss: 39.072 | Train Acc: 85.122 
20 Train Loss: 35.142 | Train Acc: 87.476 
21 Train Loss: 34.922 | Train Acc: 87.456 
22 Train Loss: 34.331 | Train Acc: 87.558 
23 Train Loss: 33.748 | Train Acc: 88.082 
24 Train Loss: 33.160 | Train Acc: 88.367 
25 Train Loss: 33.164 | Train Acc: 88.041 
26 Train Loss: 32.494 | Train Acc: 88.626 
27 Train Loss: 31.774 | Train Acc: 89.020 
28 Train Loss: 32.485 | Train Acc: 88.435 
29 Train Loss: 31.452 | Train Acc: 88.946 
30 Train Loss: 30.806 | Train Acc: 89.075 
31 Train Loss: 31.397 | Train Acc: 88.973 
32 Train Loss: 30.551 | Train Acc: 89.571 
33 Train Loss: 30.290 | Train Acc: 89.476 
34 Train Loss: 29.510 | Train Acc: 89.823 
35 Train Loss: 29.763 | Train Acc: 89.483 
36 Train Loss: 28.723 | Train Acc: 90.170 
37 Train Loss: 28.387 | Train Acc: 90.442 
38 Train Loss: 28.534 | Train Acc: 90.333 
39 Train Loss: 27.784 | Train Acc: 90.776 
40 Train Loss: 26.576 | Train Acc: 91.497 
41 Train Loss: 26.495 | Train Acc: 91.347 
42 Train Loss: 26.456 | Train Acc: 91.381 
43 Train Loss: 25.920 | Train Acc: 91.680 
44 Train Loss: 25.798 | Train Acc: 91.694 
45 Train Loss: 25.967 | Train Acc: 91.741 
46 Train Loss: 25.703 | Train Acc: 91.701 
47 Train Loss: 25.457 | Train Acc: 91.973 
48 Train Loss: 25.545 | Train Acc: 91.844 
49 Train Loss: 25.233 | Train Acc: 92.034 
50 Train Loss: 25.281 | Train Acc: 92.027 
51 Train Loss: 25.244 | Train Acc: 92.054 
52 Train Loss: 24.771 | Train Acc: 92.252 
53 Train Loss: 24.842 | Train Acc: 92.143 
54 Train Loss: 24.768 | Train Acc: 92.095 
55 Train Loss: 24.600 | Train Acc: 92.320 
56 Train Loss: 24.324 | Train Acc: 92.347 
57 Train Loss: 24.250 | Train Acc: 92.626 
58 Train Loss: 24.334 | Train Acc: 92.327 
59 Train Loss: 24.162 | Train Acc: 92.483 
60 Train Loss: 23.418 | Train Acc: 93.034 
61 Train Loss: 23.244 | Train Acc: 93.034 
62 Train Loss: 23.257 | Train Acc: 93.014 
63 Train Loss: 23.322 | Train Acc: 92.878 
64 Train Loss: 23.127 | Train Acc: 93.041 
65 Train Loss: 23.133 | Train Acc: 92.939 
66 Train Loss: 22.961 | Train Acc: 93.156 
67 Train Loss: 23.077 | Train Acc: 93.197 
68 Train Loss: 22.847 | Train Acc: 93.197 
69 Train Loss: 23.088 | Train Acc: 93.109 
70 Train Loss: 22.854 | Train Acc: 93.163 
71 Train Loss: 23.039 | Train Acc: 93.211 
72 Train Loss: 22.880 | Train Acc: 93.218 
73 Train Loss: 22.627 | Train Acc: 93.333 
74 Train Loss: 22.623 | Train Acc: 93.415 
75 Train Loss: 22.647 | Train Acc: 93.259 
76 Train Loss: 22.650 | Train Acc: 93.333 
77 Train Loss: 22.455 | Train Acc: 93.537 
78 Train Loss: 22.501 | Train Acc: 93.388 
79 Train Loss: 22.510 | Train Acc: 93.381 
80 Train Loss: 22.138 | Train Acc: 93.551 
81 Train Loss: 22.104 | Train Acc: 93.612 
82 Train Loss: 22.062 | Train Acc: 93.633 
83 Train Loss: 22.055 | Train Acc: 93.667 
84 Train Loss: 22.054 | Train Acc: 93.578 
85 Train Loss: 22.058 | Train Acc: 93.599 
86 Train Loss: 21.957 | Train Acc: 93.755 
87 Train Loss: 21.944 | Train Acc: 93.687 
88 Train Loss: 21.908 | Train Acc: 93.728 
89 Train Loss: 21.937 | Train Acc: 93.667 
90 Train Loss: 21.887 | Train Acc: 93.735 
91 Train Loss: 21.959 | Train Acc: 93.816 
92 Train Loss: 21.866 | Train Acc: 93.673 
93 Train Loss: 21.817 | Train Acc: 93.891 
94 Train Loss: 21.822 | Train Acc: 93.687 
95 Train Loss: 21.811 | Train Acc: 93.673 
96 Train Loss: 21.780 | Train Acc: 93.871 
97 Train Loss: 21.769 | Train Acc: 93.816 
98 Train Loss: 21.695 | Train Acc: 93.871 
99 Train Loss: 21.702 | Train Acc: 93.803 
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 18816])
Time Taken by Kmeans is  1.968637228012085
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1, 2: 1}
Printing final_dict items...
{0: 0, 1: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 74.901 | Acc: 71.014
1 Loss: 62.811 | Acc: 77.616
2 Loss: 55.978 | Acc: 80.404
3 Loss: 50.428 | Acc: 82.842
4 Loss: 46.037 | Acc: 84.308
5 Loss: 42.640 | Acc: 85.534
6 Loss: 37.738 | Acc: 87.322
7 Loss: 34.348 | Acc: 88.603
8 Loss: 31.407 | Acc: 89.788
9 Loss: 28.169 | Acc: 91.021
10 Loss: 20.639 | Acc: 93.760
11 Loss: 16.367 | Acc: 95.041
12 Loss: 14.994 | Acc: 95.342
13 Loss: 14.259 | Acc: 95.582
14 Loss: 12.888 | Acc: 96.199
15 Loss: 11.915 | Acc: 96.541
16 Loss: 10.524 | Acc: 96.952
17 Loss: 9.222 | Acc: 97.377
18 Loss: 8.933 | Acc: 97.329
19 Loss: 8.379 | Acc: 97.486
20 Loss: 6.071 | Acc: 98.212
21 Loss: 4.824 | Acc: 98.712
22 Loss: 4.938 | Acc: 98.651
23 Loss: 4.099 | Acc: 98.966
24 Loss: 4.016 | Acc: 99.014
25 Loss: 3.725 | Acc: 98.979
26 Loss: 3.962 | Acc: 98.932
27 Loss: 3.365 | Acc: 99.110
28 Loss: 3.492 | Acc: 99.178
29 Loss: 3.482 | Acc: 99.034
30 Loss: 2.550 | Acc: 99.329
31 Loss: 2.439 | Acc: 99.452
32 Loss: 2.336 | Acc: 99.445
33 Loss: 2.155 | Acc: 99.438
34 Loss: 1.851 | Acc: 99.507
35 Loss: 1.885 | Acc: 99.527
36 Loss: 2.332 | Acc: 99.432
37 Loss: 1.733 | Acc: 99.555
38 Loss: 1.839 | Acc: 99.534
39 Loss: 1.845 | Acc: 99.548
40 Loss: 1.834 | Acc: 99.603
41 Loss: 2.180 | Acc: 99.425
42 Loss: 1.528 | Acc: 99.651
43 Loss: 1.740 | Acc: 99.603
44 Loss: 1.439 | Acc: 99.623
45 Loss: 1.491 | Acc: 99.699
46 Loss: 1.379 | Acc: 99.651
47 Loss: 1.355 | Acc: 99.664
48 Loss: 1.302 | Acc: 99.685
49 Loss: 1.265 | Acc: 99.664
50 Loss: 1.326 | Acc: 99.678
51 Loss: 1.350 | Acc: 99.630
52 Loss: 1.174 | Acc: 99.733
53 Loss: 1.257 | Acc: 99.664
54 Loss: 1.417 | Acc: 99.685
55 Loss: 1.414 | Acc: 99.651
56 Loss: 1.165 | Acc: 99.685
57 Loss: 1.306 | Acc: 99.705
58 Loss: 1.318 | Acc: 99.740
59 Loss: 1.194 | Acc: 99.753
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 2
nodeId:  10 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 10 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
nodeId:  11 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 11 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  7
0 Train Loss: 96.856 | Train Acc: 51.918 
1 Train Loss: 82.608 | Train Acc: 61.673 
2 Train Loss: 77.540 | Train Acc: 64.735 
3 Train Loss: 73.603 | Train Acc: 67.027 
4 Train Loss: 70.615 | Train Acc: 68.966 
5 Train Loss: 68.067 | Train Acc: 70.102 
6 Train Loss: 66.549 | Train Acc: 71.000 
7 Train Loss: 64.471 | Train Acc: 72.177 
8 Train Loss: 62.319 | Train Acc: 73.102 
9 Train Loss: 61.056 | Train Acc: 73.721 
10 Train Loss: 59.724 | Train Acc: 74.442 
11 Train Loss: 58.937 | Train Acc: 75.048 
12 Train Loss: 57.158 | Train Acc: 75.646 
13 Train Loss: 55.230 | Train Acc: 76.850 
14 Train Loss: 53.856 | Train Acc: 77.075 
15 Train Loss: 53.654 | Train Acc: 77.762 
16 Train Loss: 51.700 | Train Acc: 78.830 
17 Train Loss: 50.554 | Train Acc: 79.102 
18 Train Loss: 49.028 | Train Acc: 80.020 
19 Train Loss: 48.357 | Train Acc: 80.497 
20 Train Loss: 44.590 | Train Acc: 82.490 
21 Train Loss: 43.766 | Train Acc: 83.143 
22 Train Loss: 43.137 | Train Acc: 83.190 
23 Train Loss: 42.859 | Train Acc: 83.408 
24 Train Loss: 42.146 | Train Acc: 83.871 
25 Train Loss: 41.697 | Train Acc: 84.204 
26 Train Loss: 41.100 | Train Acc: 84.184 
27 Train Loss: 40.610 | Train Acc: 84.864 
28 Train Loss: 40.505 | Train Acc: 84.497 
29 Train Loss: 40.292 | Train Acc: 84.701 
30 Train Loss: 39.495 | Train Acc: 85.170 
31 Train Loss: 39.333 | Train Acc: 85.014 
32 Train Loss: 38.759 | Train Acc: 85.537 
33 Train Loss: 38.198 | Train Acc: 85.857 
34 Train Loss: 37.986 | Train Acc: 85.776 
35 Train Loss: 37.786 | Train Acc: 86.088 
36 Train Loss: 37.420 | Train Acc: 86.068 
37 Train Loss: 36.873 | Train Acc: 86.469 
38 Train Loss: 36.630 | Train Acc: 86.673 
39 Train Loss: 36.032 | Train Acc: 86.687 
40 Train Loss: 34.387 | Train Acc: 87.782 
41 Train Loss: 34.117 | Train Acc: 88.041 
42 Train Loss: 33.910 | Train Acc: 88.048 
43 Train Loss: 33.725 | Train Acc: 88.150 
44 Train Loss: 33.530 | Train Acc: 88.224 
45 Train Loss: 33.323 | Train Acc: 88.456 
46 Train Loss: 33.615 | Train Acc: 88.041 
47 Train Loss: 33.025 | Train Acc: 88.544 
48 Train Loss: 32.919 | Train Acc: 88.755 
49 Train Loss: 32.751 | Train Acc: 88.694 
50 Train Loss: 32.586 | Train Acc: 88.612 
51 Train Loss: 32.548 | Train Acc: 88.762 
52 Train Loss: 32.268 | Train Acc: 88.905 
53 Train Loss: 32.130 | Train Acc: 89.054 
54 Train Loss: 31.884 | Train Acc: 89.041 
55 Train Loss: 31.744 | Train Acc: 89.034 
56 Train Loss: 31.789 | Train Acc: 89.170 
57 Train Loss: 31.461 | Train Acc: 89.197 
58 Train Loss: 31.220 | Train Acc: 89.367 
59 Train Loss: 31.116 | Train Acc: 89.367 
60 Train Loss: 30.538 | Train Acc: 89.844 
61 Train Loss: 30.328 | Train Acc: 90.129 
62 Train Loss: 30.339 | Train Acc: 89.898 
63 Train Loss: 30.276 | Train Acc: 89.891 
64 Train Loss: 30.151 | Train Acc: 89.912 
65 Train Loss: 30.058 | Train Acc: 90.150 
66 Train Loss: 30.012 | Train Acc: 90.265 
67 Train Loss: 29.942 | Train Acc: 90.170 
68 Train Loss: 29.881 | Train Acc: 90.034 
69 Train Loss: 29.891 | Train Acc: 90.259 
70 Train Loss: 29.770 | Train Acc: 90.177 
71 Train Loss: 29.753 | Train Acc: 90.265 
72 Train Loss: 29.608 | Train Acc: 90.231 
73 Train Loss: 29.566 | Train Acc: 90.156 
74 Train Loss: 29.481 | Train Acc: 90.381 
75 Train Loss: 29.481 | Train Acc: 90.422 
76 Train Loss: 29.446 | Train Acc: 90.204 
77 Train Loss: 29.272 | Train Acc: 90.612 
78 Train Loss: 29.258 | Train Acc: 90.415 
79 Train Loss: 29.224 | Train Acc: 90.415 
80 Train Loss: 28.921 | Train Acc: 90.660 
81 Train Loss: 28.833 | Train Acc: 90.789 
82 Train Loss: 28.792 | Train Acc: 90.816 
83 Train Loss: 28.804 | Train Acc: 90.646 
84 Train Loss: 28.779 | Train Acc: 90.769 
85 Train Loss: 28.754 | Train Acc: 90.816 
86 Train Loss: 28.706 | Train Acc: 90.803 
87 Train Loss: 28.711 | Train Acc: 90.925 
88 Train Loss: 28.692 | Train Acc: 90.728 
89 Train Loss: 28.660 | Train Acc: 90.816 
90 Train Loss: 28.617 | Train Acc: 90.830 
91 Train Loss: 28.586 | Train Acc: 90.871 
92 Train Loss: 28.564 | Train Acc: 90.837 
93 Train Loss: 28.548 | Train Acc: 90.912 
94 Train Loss: 28.509 | Train Acc: 90.850 
95 Train Loss: 28.490 | Train Acc: 90.952 
96 Train Loss: 28.447 | Train Acc: 91.027 
97 Train Loss: 28.452 | Train Acc: 90.898 
98 Train Loss: 28.427 | Train Acc: 90.932 
99 Train Loss: 28.398 | Train Acc: 90.932 
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 18816])
Time Taken by Kmeans is  1.8770811557769775
Kmeans completed successfully...
printing expected split from k means
{0: 1, 2: 1, 1: 0}
Printing final_dict items...
{0: 1, 2: 1, 1: 0}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 82.331 | Acc: 63.849
1 Loss: 73.871 | Acc: 69.521
2 Loss: 69.374 | Acc: 72.240
3 Loss: 65.417 | Acc: 73.493
4 Loss: 60.772 | Acc: 75.904
5 Loss: 56.981 | Acc: 78.308
6 Loss: 53.304 | Acc: 79.644
7 Loss: 49.075 | Acc: 81.808
8 Loss: 46.738 | Acc: 83.185
9 Loss: 42.749 | Acc: 84.603
10 Loss: 31.420 | Acc: 89.158
11 Loss: 28.108 | Acc: 90.774
12 Loss: 25.415 | Acc: 91.514
13 Loss: 23.107 | Acc: 92.404
14 Loss: 20.581 | Acc: 93.452
15 Loss: 18.396 | Acc: 94.137
16 Loss: 16.832 | Acc: 94.932
17 Loss: 16.649 | Acc: 94.829
18 Loss: 14.863 | Acc: 95.349
19 Loss: 14.447 | Acc: 95.740
20 Loss: 10.361 | Acc: 96.877
21 Loss: 8.638 | Acc: 97.534
22 Loss: 8.620 | Acc: 97.500
23 Loss: 8.012 | Acc: 97.637
24 Loss: 7.820 | Acc: 97.767
25 Loss: 7.498 | Acc: 97.959
26 Loss: 6.511 | Acc: 98.192
27 Loss: 6.121 | Acc: 98.260
28 Loss: 6.276 | Acc: 98.336
29 Loss: 5.681 | Acc: 98.356
30 Loss: 4.919 | Acc: 98.747
31 Loss: 4.289 | Acc: 98.918
32 Loss: 4.526 | Acc: 98.760
33 Loss: 4.097 | Acc: 98.945
34 Loss: 4.453 | Acc: 98.911
35 Loss: 3.605 | Acc: 99.075
36 Loss: 3.768 | Acc: 99.055
37 Loss: 3.994 | Acc: 98.884
38 Loss: 3.647 | Acc: 99.055
39 Loss: 3.677 | Acc: 98.966
40 Loss: 3.375 | Acc: 99.130
41 Loss: 3.388 | Acc: 99.144
42 Loss: 3.130 | Acc: 99.199
43 Loss: 2.886 | Acc: 99.336
44 Loss: 3.132 | Acc: 99.233
45 Loss: 2.957 | Acc: 99.212
46 Loss: 2.573 | Acc: 99.404
47 Loss: 2.960 | Acc: 99.288
48 Loss: 2.616 | Acc: 99.370
49 Loss: 3.050 | Acc: 99.151
50 Loss: 2.570 | Acc: 99.336
51 Loss: 2.690 | Acc: 99.411
52 Loss: 2.541 | Acc: 99.342
53 Loss: 2.303 | Acc: 99.486
54 Loss: 2.592 | Acc: 99.315
55 Loss: 2.448 | Acc: 99.397
56 Loss: 2.596 | Acc: 99.356
57 Loss: 2.349 | Acc: 99.473
58 Loss: 2.837 | Acc: 99.260
59 Loss: 2.269 | Acc: 99.390
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 5
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 5
nodeId:  12 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 12 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 4900
nodeId:  13 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 13 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  8
0 Train Loss: 67.603 | Train Acc: 60.224 
1 Train Loss: 52.077 | Train Acc: 74.327 
2 Train Loss: 46.138 | Train Acc: 78.633 
3 Train Loss: 43.015 | Train Acc: 81.000 
4 Train Loss: 40.165 | Train Acc: 81.939 
5 Train Loss: 37.652 | Train Acc: 83.510 
6 Train Loss: 36.247 | Train Acc: 84.582 
7 Train Loss: 34.687 | Train Acc: 85.122 
8 Train Loss: 31.465 | Train Acc: 86.765 
9 Train Loss: 30.679 | Train Acc: 87.337 
10 Train Loss: 29.207 | Train Acc: 87.959 
11 Train Loss: 27.342 | Train Acc: 88.980 
12 Train Loss: 25.712 | Train Acc: 89.929 
13 Train Loss: 24.621 | Train Acc: 90.367 
14 Train Loss: 23.862 | Train Acc: 90.469 
15 Train Loss: 22.462 | Train Acc: 91.286 
16 Train Loss: 21.006 | Train Acc: 92.265 
17 Train Loss: 20.566 | Train Acc: 92.214 
18 Train Loss: 18.999 | Train Acc: 93.020 
19 Train Loss: 18.389 | Train Acc: 93.316 
20 Train Loss: 15.709 | Train Acc: 94.745 
21 Train Loss: 15.538 | Train Acc: 94.786 
22 Train Loss: 14.928 | Train Acc: 95.204 
23 Train Loss: 14.627 | Train Acc: 95.337 
24 Train Loss: 14.285 | Train Acc: 95.551 
25 Train Loss: 14.081 | Train Acc: 95.653 
26 Train Loss: 13.649 | Train Acc: 95.582 
27 Train Loss: 13.258 | Train Acc: 96.122 
28 Train Loss: 13.178 | Train Acc: 95.939 
29 Train Loss: 12.564 | Train Acc: 96.286 
30 Train Loss: 12.487 | Train Acc: 96.204 
31 Train Loss: 12.128 | Train Acc: 96.500 
32 Train Loss: 11.774 | Train Acc: 96.673 
33 Train Loss: 11.494 | Train Acc: 96.980 
34 Train Loss: 11.163 | Train Acc: 96.908 
35 Train Loss: 10.909 | Train Acc: 97.061 
36 Train Loss: 10.586 | Train Acc: 97.490 
37 Train Loss: 10.537 | Train Acc: 97.327 
38 Train Loss: 10.132 | Train Acc: 97.429 
39 Train Loss: 10.044 | Train Acc: 97.408 
40 Train Loss: 9.077 | Train Acc: 98.071 
41 Train Loss: 8.843 | Train Acc: 98.163 
42 Train Loss: 8.776 | Train Acc: 98.367 
43 Train Loss: 8.695 | Train Acc: 98.173 
44 Train Loss: 8.555 | Train Acc: 98.265 
45 Train Loss: 8.582 | Train Acc: 98.276 
46 Train Loss: 8.383 | Train Acc: 98.367 
47 Train Loss: 8.359 | Train Acc: 98.357 
48 Train Loss: 8.187 | Train Acc: 98.469 
49 Train Loss: 8.224 | Train Acc: 98.551 
50 Train Loss: 8.089 | Train Acc: 98.500 
51 Train Loss: 7.957 | Train Acc: 98.582 
52 Train Loss: 7.808 | Train Acc: 98.541 
53 Train Loss: 7.795 | Train Acc: 98.704 
54 Train Loss: 7.702 | Train Acc: 98.643 
55 Train Loss: 7.549 | Train Acc: 98.735 
56 Train Loss: 7.583 | Train Acc: 98.582 
57 Train Loss: 7.394 | Train Acc: 98.755 
58 Train Loss: 7.231 | Train Acc: 98.847 
59 Train Loss: 7.286 | Train Acc: 98.776 
60 Train Loss: 6.837 | Train Acc: 99.031 
61 Train Loss: 6.806 | Train Acc: 99.061 
62 Train Loss: 6.754 | Train Acc: 98.990 
63 Train Loss: 6.760 | Train Acc: 99.031 
64 Train Loss: 6.706 | Train Acc: 99.061 
65 Train Loss: 6.664 | Train Acc: 99.102 
66 Train Loss: 6.638 | Train Acc: 99.092 
67 Train Loss: 6.595 | Train Acc: 99.122 
68 Train Loss: 6.548 | Train Acc: 99.112 
69 Train Loss: 6.521 | Train Acc: 99.112 
70 Train Loss: 6.478 | Train Acc: 99.071 
71 Train Loss: 6.435 | Train Acc: 99.173 
72 Train Loss: 6.407 | Train Acc: 99.082 
73 Train Loss: 6.364 | Train Acc: 99.102 
74 Train Loss: 6.321 | Train Acc: 99.143 
75 Train Loss: 6.275 | Train Acc: 99.214 
76 Train Loss: 6.261 | Train Acc: 99.235 
77 Train Loss: 6.206 | Train Acc: 99.194 
78 Train Loss: 6.224 | Train Acc: 99.173 
79 Train Loss: 6.134 | Train Acc: 99.224 
80 Train Loss: 6.004 | Train Acc: 99.276 
81 Train Loss: 5.989 | Train Acc: 99.327 
82 Train Loss: 6.009 | Train Acc: 99.265 
83 Train Loss: 5.958 | Train Acc: 99.276 
84 Train Loss: 5.948 | Train Acc: 99.276 
85 Train Loss: 5.925 | Train Acc: 99.296 
86 Train Loss: 5.906 | Train Acc: 99.286 
87 Train Loss: 5.880 | Train Acc: 99.347 
88 Train Loss: 5.886 | Train Acc: 99.296 
89 Train Loss: 5.880 | Train Acc: 99.286 
90 Train Loss: 5.844 | Train Acc: 99.316 
91 Train Loss: 5.850 | Train Acc: 99.316 
92 Train Loss: 5.843 | Train Acc: 99.306 
93 Train Loss: 5.806 | Train Acc: 99.347 
94 Train Loss: 5.807 | Train Acc: 99.306 
95 Train Loss: 5.779 | Train Acc: 99.337 
96 Train Loss: 5.751 | Train Acc: 99.316 
97 Train Loss: 5.735 | Train Acc: 99.347 
98 Train Loss: 5.723 | Train Acc: 99.337 
99 Train Loss: 5.719 | Train Acc: 99.378 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 21952])
Time Taken by Kmeans is  1.6750178337097168
Kmeans completed successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 97.694 | Acc: 76.561
1 Loss: 74.377 | Acc: 83.776
2 Loss: 61.381 | Acc: 87.112
3 Loss: 52.907 | Acc: 88.806
4 Loss: 43.263 | Acc: 90.949
5 Loss: 38.760 | Acc: 92.000
6 Loss: 32.841 | Acc: 93.286
7 Loss: 25.684 | Acc: 94.898
8 Loss: 23.319 | Acc: 95.429
9 Loss: 18.914 | Acc: 96.357
10 Loss: 9.941 | Acc: 98.235
11 Loss: 7.824 | Acc: 98.561
12 Loss: 5.605 | Acc: 99.071
13 Loss: 5.859 | Acc: 99.082
14 Loss: 4.735 | Acc: 99.235
15 Loss: 3.911 | Acc: 99.367
16 Loss: 4.286 | Acc: 99.265
17 Loss: 6.263 | Acc: 98.867
18 Loss: 3.257 | Acc: 99.480
19 Loss: 4.090 | Acc: 99.296
20 Loss: 2.656 | Acc: 99.531
21 Loss: 1.611 | Acc: 99.745
22 Loss: 1.281 | Acc: 99.816
23 Loss: 1.311 | Acc: 99.786
24 Loss: 0.881 | Acc: 99.918
25 Loss: 1.039 | Acc: 99.847
26 Loss: 1.156 | Acc: 99.847
27 Loss: 1.160 | Acc: 99.857
28 Loss: 0.933 | Acc: 99.857
29 Loss: 0.817 | Acc: 99.888
30 Loss: 0.823 | Acc: 99.918
31 Loss: 0.852 | Acc: 99.827
32 Loss: 0.704 | Acc: 99.908
33 Loss: 0.940 | Acc: 99.888
34 Loss: 0.367 | Acc: 99.959
35 Loss: 0.420 | Acc: 99.939
36 Loss: 0.582 | Acc: 99.898
37 Loss: 0.368 | Acc: 99.949
38 Loss: 0.422 | Acc: 99.918
39 Loss: 0.590 | Acc: 99.908
40 Loss: 0.384 | Acc: 99.929
41 Loss: 0.455 | Acc: 99.929
42 Loss: 0.532 | Acc: 99.918
43 Loss: 0.319 | Acc: 99.969
44 Loss: 0.524 | Acc: 99.939
45 Loss: 0.473 | Acc: 99.898
46 Loss: 0.385 | Acc: 99.929
47 Loss: 0.332 | Acc: 99.949
48 Loss: 0.362 | Acc: 99.959
49 Loss: 0.248 | Acc: 99.990
50 Loss: 0.156 | Acc: 100.000
51 Loss: 0.249 | Acc: 99.990
52 Loss: 0.313 | Acc: 99.959
53 Loss: 0.332 | Acc: 99.959
54 Loss: 0.288 | Acc: 99.980
55 Loss: 0.495 | Acc: 99.918
56 Loss: 0.236 | Acc: 99.990
57 Loss: 0.243 | Acc: 99.969
58 Loss: 0.188 | Acc: 99.980
59 Loss: 0.226 | Acc: 99.990
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  14 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 14 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 4900
nodeId:  15 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 15 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  9
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 55.764 | Train Acc: 71.347 
1 Train Loss: 45.761 | Train Acc: 78.449 
2 Train Loss: 41.583 | Train Acc: 81.112 
3 Train Loss: 37.821 | Train Acc: 83.827 
4 Train Loss: 35.882 | Train Acc: 84.602 
5 Train Loss: 31.837 | Train Acc: 86.408 
6 Train Loss: 30.685 | Train Acc: 87.031 
7 Train Loss: 28.943 | Train Acc: 88.000 
8 Train Loss: 26.993 | Train Acc: 88.908 
9 Train Loss: 25.074 | Train Acc: 90.061 
10 Train Loss: 24.095 | Train Acc: 90.204 
11 Train Loss: 24.242 | Train Acc: 90.561 
12 Train Loss: 21.666 | Train Acc: 91.653 
13 Train Loss: 20.898 | Train Acc: 91.776 
14 Train Loss: 20.874 | Train Acc: 91.878 
15 Train Loss: 19.510 | Train Acc: 92.643 
16 Train Loss: 19.333 | Train Acc: 92.480 
17 Train Loss: 17.619 | Train Acc: 93.347 
18 Train Loss: 19.096 | Train Acc: 92.724 
19 Train Loss: 18.056 | Train Acc: 93.224 
20 Train Loss: 14.609 | Train Acc: 94.837 
21 Train Loss: 14.466 | Train Acc: 94.888 
22 Train Loss: 13.351 | Train Acc: 95.643 
23 Train Loss: 13.110 | Train Acc: 95.704 
24 Train Loss: 13.063 | Train Acc: 95.622 
25 Train Loss: 13.602 | Train Acc: 95.316 
26 Train Loss: 12.635 | Train Acc: 96.010 
27 Train Loss: 12.712 | Train Acc: 95.888 
28 Train Loss: 12.484 | Train Acc: 95.969 
29 Train Loss: 11.886 | Train Acc: 96.367 
30 Train Loss: 11.643 | Train Acc: 96.408 
31 Train Loss: 11.544 | Train Acc: 96.337 
32 Train Loss: 11.263 | Train Acc: 96.459 
33 Train Loss: 11.445 | Train Acc: 96.612 
34 Train Loss: 10.731 | Train Acc: 96.827 
35 Train Loss: 10.740 | Train Acc: 96.776 
36 Train Loss: 10.304 | Train Acc: 97.071 
37 Train Loss: 10.564 | Train Acc: 96.694 
38 Train Loss: 9.771 | Train Acc: 97.255 
39 Train Loss: 9.611 | Train Acc: 97.173 
40 Train Loss: 8.840 | Train Acc: 97.796 
41 Train Loss: 8.636 | Train Acc: 97.857 
42 Train Loss: 8.459 | Train Acc: 97.867 
43 Train Loss: 8.539 | Train Acc: 97.980 
44 Train Loss: 8.498 | Train Acc: 97.929 
45 Train Loss: 8.269 | Train Acc: 98.061 
46 Train Loss: 8.413 | Train Acc: 97.918 
47 Train Loss: 8.021 | Train Acc: 98.082 
48 Train Loss: 8.155 | Train Acc: 98.020 
49 Train Loss: 8.131 | Train Acc: 98.041 
50 Train Loss: 7.842 | Train Acc: 98.255 
51 Train Loss: 7.889 | Train Acc: 98.143 
52 Train Loss: 7.749 | Train Acc: 98.286 
53 Train Loss: 7.576 | Train Acc: 98.378 
54 Train Loss: 7.644 | Train Acc: 98.296 
55 Train Loss: 7.371 | Train Acc: 98.439 
56 Train Loss: 7.327 | Train Acc: 98.490 
57 Train Loss: 7.393 | Train Acc: 98.398 
58 Train Loss: 7.610 | Train Acc: 98.214 
59 Train Loss: 7.270 | Train Acc: 98.429 
60 Train Loss: 6.776 | Train Acc: 98.724 
61 Train Loss: 6.738 | Train Acc: 98.806 
62 Train Loss: 6.723 | Train Acc: 98.776 
63 Train Loss: 6.750 | Train Acc: 98.857 
64 Train Loss: 6.628 | Train Acc: 98.867 
65 Train Loss: 6.659 | Train Acc: 98.735 
66 Train Loss: 6.600 | Train Acc: 98.796 
67 Train Loss: 6.620 | Train Acc: 98.806 
68 Train Loss: 6.624 | Train Acc: 98.806 
69 Train Loss: 6.502 | Train Acc: 98.827 
70 Train Loss: 6.484 | Train Acc: 98.867 
71 Train Loss: 6.400 | Train Acc: 98.949 
72 Train Loss: 6.431 | Train Acc: 98.908 
73 Train Loss: 6.414 | Train Acc: 98.867 
74 Train Loss: 6.327 | Train Acc: 98.908 
75 Train Loss: 6.306 | Train Acc: 98.929 
76 Train Loss: 6.293 | Train Acc: 98.949 
77 Train Loss: 6.332 | Train Acc: 98.867 
78 Train Loss: 6.306 | Train Acc: 98.908 
79 Train Loss: 6.174 | Train Acc: 99.041 
80 Train Loss: 6.035 | Train Acc: 99.092 
81 Train Loss: 6.031 | Train Acc: 99.071 
82 Train Loss: 6.023 | Train Acc: 99.082 
83 Train Loss: 6.019 | Train Acc: 99.031 
84 Train Loss: 5.992 | Train Acc: 99.102 
85 Train Loss: 5.985 | Train Acc: 99.092 
86 Train Loss: 6.007 | Train Acc: 99.041 
87 Train Loss: 5.957 | Train Acc: 99.041 
88 Train Loss: 5.943 | Train Acc: 99.102 
89 Train Loss: 5.939 | Train Acc: 99.071 
90 Train Loss: 5.891 | Train Acc: 99.133 
91 Train Loss: 5.899 | Train Acc: 99.061 
92 Train Loss: 5.882 | Train Acc: 99.153 
93 Train Loss: 5.894 | Train Acc: 99.082 
94 Train Loss: 5.893 | Train Acc: 99.133 
95 Train Loss: 5.841 | Train Acc: 99.163 
96 Train Loss: 5.832 | Train Acc: 99.112 
97 Train Loss: 5.818 | Train Acc: 99.112 
98 Train Loss: 5.815 | Train Acc: 99.133 
99 Train Loss: 5.845 | Train Acc: 99.173 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 21952])
Time Taken by Kmeans is  1.9685895442962646
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 86.835 | Acc: 80.204
1 Loss: 59.730 | Acc: 87.602
2 Loss: 48.897 | Acc: 89.857
3 Loss: 42.373 | Acc: 91.551
4 Loss: 37.305 | Acc: 92.286
5 Loss: 31.512 | Acc: 93.837
6 Loss: 28.287 | Acc: 94.582
7 Loss: 23.740 | Acc: 95.439
8 Loss: 20.519 | Acc: 96.051
9 Loss: 18.299 | Acc: 96.439
10 Loss: 9.339 | Acc: 98.296
11 Loss: 7.325 | Acc: 98.592
12 Loss: 5.320 | Acc: 99.010
13 Loss: 6.101 | Acc: 98.908
14 Loss: 4.716 | Acc: 99.153
15 Loss: 4.840 | Acc: 99.122
16 Loss: 3.810 | Acc: 99.347
17 Loss: 4.611 | Acc: 99.255
18 Loss: 4.293 | Acc: 99.184
19 Loss: 3.668 | Acc: 99.357
20 Loss: 2.238 | Acc: 99.633
21 Loss: 1.346 | Acc: 99.806
22 Loss: 1.185 | Acc: 99.816
23 Loss: 1.074 | Acc: 99.837
24 Loss: 1.138 | Acc: 99.776
25 Loss: 1.585 | Acc: 99.796
26 Loss: 1.143 | Acc: 99.857
27 Loss: 0.782 | Acc: 99.918
28 Loss: 1.002 | Acc: 99.867
29 Loss: 0.850 | Acc: 99.837
30 Loss: 0.755 | Acc: 99.908
31 Loss: 0.875 | Acc: 99.878
32 Loss: 0.529 | Acc: 99.949
33 Loss: 0.699 | Acc: 99.908
34 Loss: 0.336 | Acc: 99.969
35 Loss: 0.449 | Acc: 99.939
36 Loss: 0.659 | Acc: 99.908
37 Loss: 0.419 | Acc: 99.969
38 Loss: 0.293 | Acc: 99.990
39 Loss: 0.310 | Acc: 99.969
40 Loss: 0.333 | Acc: 99.969
41 Loss: 0.241 | Acc: 99.990
42 Loss: 0.513 | Acc: 99.929
43 Loss: 0.391 | Acc: 99.949
44 Loss: 0.321 | Acc: 99.969
45 Loss: 0.557 | Acc: 99.949
46 Loss: 0.433 | Acc: 99.929
47 Loss: 0.253 | Acc: 99.969
48 Loss: 0.259 | Acc: 99.959
49 Loss: 0.233 | Acc: 99.969
50 Loss: 0.302 | Acc: 99.939
51 Loss: 0.261 | Acc: 99.959
52 Loss: 0.177 | Acc: 99.990
53 Loss: 0.303 | Acc: 99.949
54 Loss: 0.247 | Acc: 99.980
55 Loss: 0.243 | Acc: 99.980
56 Loss: 0.352 | Acc: 99.949
57 Loss: 0.194 | Acc: 99.990
58 Loss: 0.206 | Acc: 99.980
59 Loss: 0.236 | Acc: 99.980
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 4
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 4
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  16 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 4900
nodeId:  17 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  12
Running nodeId:  13
0 Train Loss: 59.356 | Train Acc: 69.500 
1 Train Loss: 42.863 | Train Acc: 80.592 
2 Train Loss: 38.272 | Train Acc: 83.163 
3 Train Loss: 36.455 | Train Acc: 84.327 
4 Train Loss: 34.250 | Train Acc: 85.388 
5 Train Loss: 31.619 | Train Acc: 86.755 
6 Train Loss: 30.766 | Train Acc: 87.378 
7 Train Loss: 28.502 | Train Acc: 88.439 
8 Train Loss: 27.640 | Train Acc: 88.633 
9 Train Loss: 27.153 | Train Acc: 88.959 
10 Train Loss: 26.305 | Train Acc: 89.122 
11 Train Loss: 24.714 | Train Acc: 89.878 
12 Train Loss: 23.873 | Train Acc: 90.061 
13 Train Loss: 23.675 | Train Acc: 90.378 
14 Train Loss: 21.355 | Train Acc: 91.592 
15 Train Loss: 21.356 | Train Acc: 91.571 
16 Train Loss: 20.834 | Train Acc: 91.653 
17 Train Loss: 19.445 | Train Acc: 92.673 
18 Train Loss: 18.882 | Train Acc: 92.745 
19 Train Loss: 18.025 | Train Acc: 93.071 
20 Train Loss: 15.306 | Train Acc: 94.612 
21 Train Loss: 14.922 | Train Acc: 94.653 
22 Train Loss: 14.414 | Train Acc: 95.071 
23 Train Loss: 14.007 | Train Acc: 95.143 
24 Train Loss: 13.816 | Train Acc: 95.184 
25 Train Loss: 13.550 | Train Acc: 95.500 
26 Train Loss: 13.120 | Train Acc: 95.878 
27 Train Loss: 12.812 | Train Acc: 95.755 
28 Train Loss: 12.910 | Train Acc: 95.765 
29 Train Loss: 12.318 | Train Acc: 95.949 
30 Train Loss: 12.197 | Train Acc: 96.214 
31 Train Loss: 11.863 | Train Acc: 96.122 
32 Train Loss: 11.806 | Train Acc: 96.245 
33 Train Loss: 11.348 | Train Acc: 96.408 
34 Train Loss: 10.988 | Train Acc: 96.745 
35 Train Loss: 10.778 | Train Acc: 96.796 
36 Train Loss: 10.340 | Train Acc: 96.990 
37 Train Loss: 10.159 | Train Acc: 97.071 
38 Train Loss: 10.402 | Train Acc: 96.847 
39 Train Loss: 9.971 | Train Acc: 96.857 
40 Train Loss: 9.032 | Train Acc: 97.612 
41 Train Loss: 8.906 | Train Acc: 97.673 
42 Train Loss: 8.704 | Train Acc: 97.776 
43 Train Loss: 8.631 | Train Acc: 97.714 
44 Train Loss: 8.626 | Train Acc: 97.888 
45 Train Loss: 8.450 | Train Acc: 97.847 
46 Train Loss: 8.383 | Train Acc: 97.969 
47 Train Loss: 8.407 | Train Acc: 97.898 
48 Train Loss: 8.247 | Train Acc: 98.031 
49 Train Loss: 8.059 | Train Acc: 98.143 
50 Train Loss: 7.998 | Train Acc: 98.173 
51 Train Loss: 7.953 | Train Acc: 98.235 
52 Train Loss: 7.835 | Train Acc: 98.102 
53 Train Loss: 7.745 | Train Acc: 98.296 
54 Train Loss: 7.673 | Train Acc: 98.224 
55 Train Loss: 7.578 | Train Acc: 98.347 
56 Train Loss: 7.613 | Train Acc: 98.347 
57 Train Loss: 7.464 | Train Acc: 98.337 
58 Train Loss: 7.256 | Train Acc: 98.500 
59 Train Loss: 7.165 | Train Acc: 98.510 
60 Train Loss: 6.900 | Train Acc: 98.724 
61 Train Loss: 6.812 | Train Acc: 98.776 
62 Train Loss: 6.791 | Train Acc: 98.786 
63 Train Loss: 6.744 | Train Acc: 98.755 
64 Train Loss: 6.776 | Train Acc: 98.765 
65 Train Loss: 6.694 | Train Acc: 98.796 
66 Train Loss: 6.667 | Train Acc: 98.806 
67 Train Loss: 6.597 | Train Acc: 98.867 
68 Train Loss: 6.573 | Train Acc: 98.857 
69 Train Loss: 6.548 | Train Acc: 98.898 
70 Train Loss: 6.524 | Train Acc: 98.816 
71 Train Loss: 6.456 | Train Acc: 98.969 
72 Train Loss: 6.440 | Train Acc: 98.929 
73 Train Loss: 6.436 | Train Acc: 98.918 
74 Train Loss: 6.355 | Train Acc: 98.959 
75 Train Loss: 6.354 | Train Acc: 98.908 
76 Train Loss: 6.267 | Train Acc: 99.010 
77 Train Loss: 6.238 | Train Acc: 99.051 
78 Train Loss: 6.213 | Train Acc: 99.031 
79 Train Loss: 6.227 | Train Acc: 99.031 
80 Train Loss: 6.090 | Train Acc: 99.082 
81 Train Loss: 6.046 | Train Acc: 99.051 
82 Train Loss: 6.040 | Train Acc: 99.112 
83 Train Loss: 6.025 | Train Acc: 99.092 
84 Train Loss: 6.027 | Train Acc: 99.061 
85 Train Loss: 5.995 | Train Acc: 99.122 
86 Train Loss: 5.991 | Train Acc: 99.092 
87 Train Loss: 5.946 | Train Acc: 99.122 
88 Train Loss: 5.951 | Train Acc: 99.102 
89 Train Loss: 5.936 | Train Acc: 99.143 
90 Train Loss: 5.910 | Train Acc: 99.184 
91 Train Loss: 5.920 | Train Acc: 99.163 
92 Train Loss: 5.885 | Train Acc: 99.133 
93 Train Loss: 5.873 | Train Acc: 99.122 
94 Train Loss: 5.868 | Train Acc: 99.173 
95 Train Loss: 5.856 | Train Acc: 99.184 
96 Train Loss: 5.833 | Train Acc: 99.143 
97 Train Loss: 5.847 | Train Acc: 99.153 
98 Train Loss: 5.806 | Train Acc: 99.184 
99 Train Loss: 5.796 | Train Acc: 99.143 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 21952])
Time Taken by Kmeans is  1.6143572330474854
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 89.375 | Acc: 79.041
1 Loss: 64.659 | Acc: 86.367
2 Loss: 54.817 | Acc: 88.337
3 Loss: 47.503 | Acc: 90.133
4 Loss: 43.294 | Acc: 90.694
5 Loss: 36.957 | Acc: 91.949
6 Loss: 33.051 | Acc: 93.184
7 Loss: 27.649 | Acc: 94.592
8 Loss: 25.588 | Acc: 94.653
9 Loss: 23.165 | Acc: 95.459
10 Loss: 12.986 | Acc: 97.561
11 Loss: 10.041 | Acc: 98.153
12 Loss: 9.255 | Acc: 98.337
13 Loss: 7.158 | Acc: 98.714
14 Loss: 7.625 | Acc: 98.520
15 Loss: 6.548 | Acc: 98.786
16 Loss: 6.408 | Acc: 98.704
17 Loss: 4.950 | Acc: 99.082
18 Loss: 6.483 | Acc: 98.816
19 Loss: 5.088 | Acc: 99.122
20 Loss: 2.186 | Acc: 99.663
21 Loss: 2.334 | Acc: 99.653
22 Loss: 2.255 | Acc: 99.602
23 Loss: 1.505 | Acc: 99.755
24 Loss: 1.303 | Acc: 99.765
25 Loss: 1.312 | Acc: 99.806
26 Loss: 0.860 | Acc: 99.898
27 Loss: 1.045 | Acc: 99.857
28 Loss: 1.232 | Acc: 99.816
29 Loss: 1.331 | Acc: 99.786
30 Loss: 0.852 | Acc: 99.867
31 Loss: 0.828 | Acc: 99.857
32 Loss: 0.506 | Acc: 99.939
33 Loss: 0.544 | Acc: 99.929
34 Loss: 0.488 | Acc: 99.969
35 Loss: 0.415 | Acc: 99.949
36 Loss: 0.444 | Acc: 99.918
37 Loss: 0.522 | Acc: 99.939
38 Loss: 0.486 | Acc: 99.959
39 Loss: 0.330 | Acc: 99.990
40 Loss: 0.405 | Acc: 99.939
41 Loss: 0.395 | Acc: 99.918
42 Loss: 0.400 | Acc: 99.939
43 Loss: 0.541 | Acc: 99.939
44 Loss: 0.512 | Acc: 99.939
45 Loss: 0.324 | Acc: 99.949
46 Loss: 0.627 | Acc: 99.908
47 Loss: 0.355 | Acc: 99.959
48 Loss: 0.250 | Acc: 99.990
49 Loss: 0.338 | Acc: 99.939
50 Loss: 0.306 | Acc: 99.959
51 Loss: 0.481 | Acc: 99.929
52 Loss: 0.346 | Acc: 99.959
53 Loss: 0.191 | Acc: 100.000
54 Loss: 0.220 | Acc: 99.980
55 Loss: 0.246 | Acc: 99.969
56 Loss: 0.282 | Acc: 99.969
57 Loss: 0.225 | Acc: 99.969
58 Loss: 0.288 | Acc: 99.980
59 Loss: 0.205 | Acc: 99.980
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 7
nodeId:  18 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 18 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  14
Running nodeId:  15
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 61.210
Split Acc: 92.400
lTrainDict[data].shape:  torch.Size([3990, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([3990])
rTrainDict[data].shape:  torch.Size([6010, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([6010])
# of Left images:  3990.0
# of Right images:  6010.0
giniRightRatio:  0.8527741617548125
giniLeftRatio:  0.7928523062041067
impurityDrop:  0.8129924306986867
giniGain:  0.08700756930131337
lclasses:  [858, 934, 109, 74, 55, 34, 48, 55, 931, 892]
rclasses:  [142, 66, 891, 926, 945, 966, 952, 945, 69, 108]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([3990, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 3990
nodeId:  3 , imgTensorShape :  torch.Size([6010, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 6 ,  numData: 6010
Nodes sizes =  4 6
Node 2 Acc: 70.501
Split Acc: 83.108
lTrainDict[data].shape:  torch.Size([2995, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2995])
rTrainDict[data].shape:  torch.Size([995, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([995])
# of Left images:  2995.0
# of Right images:  995.0
giniRightRatio:  0.48720991894144083
giniLeftRatio:  0.7420768615472085
impurityDrop:  1.2543722235688524
giniGain:  -0.4615199173647456
lclasses:  [156, 913, 41, 52, 27, 24, 41, 40, 851, 850]
rclasses:  [702, 21, 68, 22, 28, 10, 7, 15, 80, 42]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([2995, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2995
nodeId:  5 , imgTensorShape :  torch.Size([995, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 995
Nodes sizes =  3 1
Node 3 Acc: 54.642
Split Acc: 75.707
lTrainDict[data].shape:  torch.Size([2959, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2959])
rTrainDict[data].shape:  torch.Size([3051, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3051])
# of Left images:  2959.0
# of Right images:  3051.0
giniRightRatio:  0.7945135901732171
giniLeftRatio:  0.795418197625062
impurityDrop:  0.7953909200486707
giniGain:  0.05738324170614173
lclasses:  [105, 34, 673, 236, 728, 153, 835, 134, 28, 33]
rclasses:  [37, 32, 218, 690, 217, 813, 117, 811, 41, 75]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([2959, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2959
nodeId:  7 , imgTensorShape :  torch.Size([3051, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3051
Nodes sizes =  3 3
Node 4 Acc: 72.721
Split Acc: 81.970
lTrainDict[data].shape:  torch.Size([2002, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2002])
rTrainDict[data].shape:  torch.Size([993, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([993])
# of Left images:  2002.0
# of Right images:  993.0
giniRightRatio:  0.39485056016486
giniLeftRatio:  0.6391710187913985
impurityDrop:  0.8874281615448499
giniGain:  -0.1453512999976414
lclasses:  [78, 879, 24, 31, 15, 14, 30, 36, 85, 810]
rclasses:  [78, 34, 17, 21, 12, 10, 11, 4, 766, 40]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([2002, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2002
nodeId:  9 , imgTensorShape :  torch.Size([993, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 993
Nodes sizes =  2 1
Node 5 Acc: 70.553
Node 6 Acc: 58.026
Split Acc: 63.569
lTrainDict[data].shape:  torch.Size([926, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([926])
rTrainDict[data].shape:  torch.Size([2033, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2033])
# of Left images:  926.0
# of Right images:  2033.0
giniRightRatio:  0.74371831818768
giniLeftRatio:  0.6888519328820865
impurityDrop:  0.7187275297995936
giniGain:  0.0766906678254684
lclasses:  [56, 9, 487, 79, 93, 61, 76, 42, 11, 12]
rclasses:  [49, 25, 186, 157, 635, 92, 759, 92, 17, 21]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([926, 3, 32, 32])
nodeId: 10 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 926
nodeId:  11 , imgTensorShape :  torch.Size([2033, 3, 32, 32])
nodeId: 11 ,  parentId: 6 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2033
Nodes sizes =  1 2
Node 7 Acc: 53.753
Split Acc: 57.883
lTrainDict[data].shape:  torch.Size([960, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([960])
rTrainDict[data].shape:  torch.Size([2091, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2091])
# of Left images:  960.0
# of Right images:  2091.0
giniRightRatio:  0.7818715219813184
giniLeftRatio:  0.65470703125
impurityDrop:  0.7234889724346585
giniGain:  0.07102461773855862
lclasses:  [9, 5, 77, 183, 39, 520, 38, 72, 7, 10]
rclasses:  [28, 27, 141, 507, 178, 293, 79, 739, 34, 65]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([960, 3, 32, 32])
nodeId: 12 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 960
nodeId:  13 , imgTensorShape :  torch.Size([2091, 3, 32, 32])
nodeId: 13 ,  parentId: 7 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2091
Nodes sizes =  1 2
Node 8 Acc: 71.229
Split Acc: 72.378
lTrainDict[data].shape:  torch.Size([975, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([975])
rTrainDict[data].shape:  torch.Size([1027, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1027])
# of Left images:  975.0
# of Right images:  1027.0
giniRightRatio:  0.5103149719027352
giniLeftRatio:  0.39711978961209726
impurityDrop:  0.40285119124706625
giniGain:  0.23631982754433223
lclasses:  [24, 747, 10, 11, 1, 6, 13, 6, 49, 108]
rclasses:  [54, 132, 14, 20, 14, 8, 17, 30, 36, 702]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([975, 3, 32, 32])
nodeId: 14 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 975
nodeId:  15 , imgTensorShape :  torch.Size([1027, 3, 32, 32])
nodeId: 15 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1027
Nodes sizes =  1 1
Node 9 Acc: 77.140
Node 10 Acc: 52.592
Node 11 Acc: 61.485
Split Acc: 62.273
lTrainDict[data].shape:  torch.Size([975, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([975])
rTrainDict[data].shape:  torch.Size([1058, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1058])
# of Left images:  975.0
# of Right images:  1058.0
giniRightRatio:  0.5272494023391855
giniLeftRatio:  0.6466209072978304
impurityDrop:  0.6372562240165756
giniGain:  0.10646209417110442
lclasses:  [26, 16, 106, 75, 554, 52, 47, 78, 9, 12]
rclasses:  [23, 9, 80, 82, 81, 40, 712, 14, 8, 9]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([975, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 975
nodeId:  17 , imgTensorShape :  torch.Size([1058, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1058
Nodes sizes =  1 1
Node 12 Acc: 54.167
Node 13 Acc: 52.989
Split Acc: 53.898
lTrainDict[data].shape:  torch.Size([1058, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1058])
rTrainDict[data].shape:  torch.Size([1033, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1033])
# of Left images:  1058.0
# of Right images:  1033.0
giniRightRatio:  0.5410345341391393
giniLeftRatio:  0.7584878556037177
impurityDrop:  0.7637505206924055
giniGain:  0.01812100128891292
lclasses:  [18, 20, 92, 443, 84, 221, 64, 55, 27, 34]
rclasses:  [10, 7, 49, 64, 94, 72, 15, 684, 7, 31]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1058, 3, 32, 32])
nodeId: 18 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 1058
nodeId:  19 , imgTensorShape :  torch.Size([1033, 3, 32, 32])
nodeId: 19 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 1033
Nodes sizes =  1 1
Node 14 Acc: 76.615
Node 15 Acc: 68.354
Node 16 Acc: 56.821
Node 17 Acc: 67.297
Node 18 Acc: 41.871
Node 19 Acc: 66.215
[[702  24  56  18  26   9  23  10  78  54]
 [ 21 747   9  20  16   5   9   7  34 132]
 [ 68  10 487  92 106  77  80  49  17  14]
 [ 22  11  79 443  75 183  82  64  21  20]
 [ 28   1  93  84 554  39  81  94  12  14]
 [ 10   6  61 221  52 520  40  72  10   8]
 [  7  13  76  64  47  38 712  15  11  17]
 [ 15   6  42  55  78  72  14 684   4  30]
 [ 80  49  11  27   9   7   8   7 766  36]
 [ 42 108  12  34  12  10   9  31  40 702]]

Final Acc: 63.170

Level 0 Acc: 61.210
Level 1 Acc: 60.970
Level 2 Acc: 62.370
Level 3 Acc: 62.590
Level 4 Acc: 63.170

                                               1                                                                               
       ┌───────────────────────────────────────┴─────────────────────────────────────────┐                                     
       2                                                                                 3                                     
 ┌─────┴───────────┐                                         ┌───────────────────────────┴─────────────┐                       
 5                 4                                         6                                         7                       
             ┌─────┴─────────────┐                    ┌──────┴─────────────┐                    ┌──────┴─────────────┐         
             9                   8                    10                   11                   12                   13        
                          ┌──────┴──────┐                           ┌──────┴──────┐                           ┌──────┴──────┐  
                          14            15                          16            17                          18            19 

                                           -1                                                                  
       ┌───────────────────────────────────┴───────────────────────────────────┐                               
       -1                                                                      -1                              
 ┌─────┴───────────┐                                   ┌───────────────────────┴───────────┐                   
 0                 -1                                  -1                                  -1                  
             ┌─────┴───────────┐                 ┌─────┴───────────┐                 ┌─────┴───────────┐       
             8                 -1                2                 -1                5                 -1      
                         ┌─────┴─────┐                       ┌─────┴─────┐                       ┌─────┴─────┐ 
                         1           9                       4           6                       3           7 

                                                         49000                                                                                         
           ┌───────────────────────────────────────────────┴───────────────────────────────────────────────┐                                           
         19600                                                                                           29400                                         
   ┌───────┴───────────────┐                                               ┌───────────────────────────────┴───────────────┐                           
  4900                   14700                                           14700                                           14700                         
                   ┌───────┴───────────────┐                       ┌───────┴───────────────┐                       ┌───────┴───────────────┐           
                  4900                    9800                    4900                    9800                    4900                    9800         
                                   ┌───────┴───────┐                               ┌───────┴───────┐                               ┌───────┴───────┐   
                                  4900            4900                            4900            4900                            4900            4900 

                                   {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                                      
                   ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────┐                                                       
  {0: 4900, 1: 4900, 8: 4900, 9: 4900}                                                                           {2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900}                            
       ┌─────────┴───────────────────┐                                                             ┌───────────────────────────────────────┴───────────────────┐                                   
   {0: 4900}            {1: 4900, 8: 4900, 9: 4900}                                   {2: 4900, 4: 4900, 6: 4900}                                 {3: 4900, 5: 4900, 7: 4900}                      
                           ┌─────────┴───────────────────┐                               ┌─────────┴───────────────────┐                             ┌─────────┴───────────────────┐               
                       {8: 4900}                 {1: 4900, 9: 4900}                  {2: 4900}                 {4: 4900, 6: 4900}                {5: 4900}                 {3: 4900, 7: 4900}      
                                               ┌─────────┴─────────┐                                         ┌─────────┴─────────┐                                       ┌─────────┴─────────┐     
                                           {1: 4900}           {9: 4900}                                 {4: 4900}           {6: 4900}                               {3: 4900}           {7: 4900} 

                                                  92.4                                                                               
         ┌─────────────────────────────────────────┴───────────────────────────────────────────┐                                     
 83.10776942355889                                                                      75.7071547420965                             
  ┌──────┴─────────────┐                                         ┌─────────────────────────────┴─────────────┐                       
 0.0           81.96994991652754                         63.56877323420074                           57.88266142248443               
                ┌──────┴─────────────┐                    ┌──────┴──────────────┐                     ┌──────┴─────────────┐         
               0.0           72.37762237762237           0.0            62.272503689129366           0.0           53.89765662362506 
                              ┌──────┴──────┐                            ┌──────┴──────┐                            ┌──────┴──────┐  
                             0.0           0.0                          0.0           0.0                          0.0           0.0 

                                          ┌[702, 995, 70.553]
                     ┌[2813, 3990, 70.501]┤
                     │                    │                    ┌[766, 993, 77.14]
                     │                    └[2178, 2995, 72.721]┤
                     │                                         │                    ┌[747, 975, 76.615]
                     │                                         └[1426, 2002, 71.229]┤
                     │                                                              └[702, 1027, 68.354]
 [6121, 10000, 61.21]┤
                     │                                         ┌[487, 926, 52.592]
                     │                    ┌[1717, 2959, 58.026]┤
                     │                    │                    │                    ┌[554, 975, 56.821]
                     │                    │                    └[1250, 2033, 61.485]┤
                     │                    │                                         └[712, 1058, 67.297]
                     └[3284, 6010, 54.642]┤
                                          │                    ┌[520, 960, 54.167]
                                          └[1640, 3051, 53.753]┤
                                                               │                    ┌[443, 1058, 41.871]
                                                               └[1108, 2091, 52.989]┤
                                                                                    └[684, 1033, 66.215]

                                            0.12222222222222223                                                                        
         ┌───────────────────────────────────────────┴──────────────────────────────────────────┐                                      
       -1.25                                                                           0.16666666666666652                             
  ┌──────┴───────────────┐                                          ┌───────────────────────────┴──────────────┐                       
 0.0            -0.33333333333333326                       0.41666666666666674                        0.41666666666666674              
                 ┌──────┴─────────────┐                     ┌──────┴─────────────┐                     ┌──────┴─────────────┐          
                0.0                  0.5                   0.0                  0.5                   0.0                  0.5         
                               ┌──────┴──────┐                            ┌──────┴──────┐                            ┌──────┴──────┐   
                              0.0           0.0                          0.0           0.0                          0.0           0.0  

Time Taken by whole program is  29.174538453420002  minutes.
