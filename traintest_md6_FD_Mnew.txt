==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  50000 ,  len(valInputDict["data"]):  0 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([50000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 50000
Running nodeId:  1
0 Train Loss: 177.246 | Train Acc: 37.916
1 Train Loss: 148.880 | Train Acc: 47.872
2 Train Loss: 136.418 | Train Acc: 52.378
3 Train Loss: 132.068 | Train Acc: 53.810
4 Train Loss: 126.597 | Train Acc: 55.706
5 Train Loss: 123.646 | Train Acc: 56.838
6 Train Loss: 120.314 | Train Acc: 57.976
7 Train Loss: 118.040 | Train Acc: 58.998
8 Train Loss: 115.639 | Train Acc: 59.652
9 Train Loss: 113.236 | Train Acc: 60.650
10 Train Loss: 111.123 | Train Acc: 61.306
11 Train Loss: 109.876 | Train Acc: 61.812
12 Train Loss: 108.882 | Train Acc: 62.118
13 Train Loss: 106.814 | Train Acc: 62.864
14 Train Loss: 105.334 | Train Acc: 63.560
15 Train Loss: 104.289 | Train Acc: 63.930
16 Train Loss: 103.157 | Train Acc: 64.266
17 Train Loss: 102.024 | Train Acc: 64.552
18 Train Loss: 100.916 | Train Acc: 65.052
19 Train Loss: 99.975 | Train Acc: 65.280
20 Train Loss: 96.271 | Train Acc: 66.900
21 Train Loss: 95.517 | Train Acc: 67.176
22 Train Loss: 94.958 | Train Acc: 67.504
23 Train Loss: 94.489 | Train Acc: 67.512
24 Train Loss: 94.384 | Train Acc: 67.656
25 Train Loss: 93.931 | Train Acc: 67.938
26 Train Loss: 93.572 | Train Acc: 67.698
27 Train Loss: 93.384 | Train Acc: 67.972
28 Train Loss: 92.830 | Train Acc: 68.078
29 Train Loss: 92.200 | Train Acc: 68.328
30 Train Loss: 91.952 | Train Acc: 68.398
31 Train Loss: 91.653 | Train Acc: 68.644
32 Train Loss: 91.270 | Train Acc: 68.636
33 Train Loss: 91.247 | Train Acc: 68.716
34 Train Loss: 90.594 | Train Acc: 68.926
35 Train Loss: 90.446 | Train Acc: 68.916
36 Train Loss: 90.030 | Train Acc: 69.240
37 Train Loss: 89.678 | Train Acc: 69.462
38 Train Loss: 89.364 | Train Acc: 69.388
39 Train Loss: 88.892 | Train Acc: 69.596
40 Train Loss: 87.252 | Train Acc: 70.414
41 Train Loss: 87.089 | Train Acc: 70.472
42 Train Loss: 86.986 | Train Acc: 70.558
43 Train Loss: 86.832 | Train Acc: 70.562
44 Train Loss: 86.686 | Train Acc: 70.734
45 Train Loss: 86.618 | Train Acc: 70.568
46 Train Loss: 86.422 | Train Acc: 70.724
47 Train Loss: 86.407 | Train Acc: 70.610
48 Train Loss: 86.162 | Train Acc: 70.752
49 Train Loss: 86.046 | Train Acc: 70.796
50 Train Loss: 85.935 | Train Acc: 70.818
51 Train Loss: 85.715 | Train Acc: 70.922
52 Train Loss: 85.636 | Train Acc: 70.942
53 Train Loss: 85.556 | Train Acc: 70.856
54 Train Loss: 85.409 | Train Acc: 71.078
55 Train Loss: 85.284 | Train Acc: 71.080
56 Train Loss: 85.140 | Train Acc: 71.170
57 Train Loss: 85.090 | Train Acc: 70.994
58 Train Loss: 84.954 | Train Acc: 71.190
59 Train Loss: 84.663 | Train Acc: 71.310
60 Train Loss: 84.049 | Train Acc: 71.566
61 Train Loss: 83.896 | Train Acc: 71.690
62 Train Loss: 83.814 | Train Acc: 71.764
63 Train Loss: 83.831 | Train Acc: 71.650
64 Train Loss: 83.722 | Train Acc: 71.692
65 Train Loss: 83.690 | Train Acc: 71.778
66 Train Loss: 83.706 | Train Acc: 71.724
67 Train Loss: 83.558 | Train Acc: 71.854
68 Train Loss: 83.566 | Train Acc: 71.836
69 Train Loss: 83.485 | Train Acc: 71.772
70 Train Loss: 83.365 | Train Acc: 71.812
71 Train Loss: 83.350 | Train Acc: 71.888
72 Train Loss: 83.261 | Train Acc: 71.984
73 Train Loss: 83.203 | Train Acc: 71.940
74 Train Loss: 83.159 | Train Acc: 71.918
75 Train Loss: 83.126 | Train Acc: 71.914
76 Train Loss: 83.034 | Train Acc: 71.944
77 Train Loss: 83.033 | Train Acc: 71.984
78 Train Loss: 82.997 | Train Acc: 72.108
79 Train Loss: 82.891 | Train Acc: 71.996
80 Train Loss: 82.602 | Train Acc: 72.186
81 Train Loss: 82.579 | Train Acc: 72.216
82 Train Loss: 82.545 | Train Acc: 72.126
83 Train Loss: 82.493 | Train Acc: 72.244
84 Train Loss: 82.471 | Train Acc: 72.254
85 Train Loss: 82.474 | Train Acc: 72.184
86 Train Loss: 82.447 | Train Acc: 72.186
87 Train Loss: 82.419 | Train Acc: 72.286
88 Train Loss: 82.400 | Train Acc: 72.268
89 Train Loss: 82.407 | Train Acc: 72.258
90 Train Loss: 82.362 | Train Acc: 72.258
91 Train Loss: 82.329 | Train Acc: 72.290
92 Train Loss: 82.317 | Train Acc: 72.218
93 Train Loss: 82.306 | Train Acc: 72.322
94 Train Loss: 82.296 | Train Acc: 72.262
95 Train Loss: 82.259 | Train Acc: 72.246
96 Train Loss: 82.217 | Train Acc: 72.186
97 Train Loss: 82.246 | Train Acc: 72.212
98 Train Loss: 82.167 | Train Acc: 72.318
99 Train Loss: 82.176 | Train Acc: 72.328
CNN trained successfully...
image_next_flat.shape :  torch.Size([50000, 12544])
printing expected split from k means
{9: 0, 1: 0, 8: 0, 7: 1, 2: 1, 6: 1, 4: 1, 5: 1, 0: 0, 3: 1}
Printing final_dict items...
{8: 0, 0: 0, 9: 0, 1: 0, 2: 0, 3: 1, 5: 1, 7: 1, 4: 1, 6: 1}
Image Statistics before MLP : L R :  25000 25000
expectedMlpLabels.shape :  torch.Size([50000])
0 Loss: 84.558 | Acc: 81.342
1 Loss: 72.069 | Acc: 84.580
2 Loss: 67.079 | Acc: 85.482
3 Loss: 63.282 | Acc: 86.490
4 Loss: 59.983 | Acc: 87.136
5 Loss: 56.582 | Acc: 88.038
6 Loss: 54.025 | Acc: 88.688
7 Loss: 50.486 | Acc: 89.452
8 Loss: 48.025 | Acc: 89.988
9 Loss: 44.648 | Acc: 90.732
10 Loss: 36.743 | Acc: 92.400
11 Loss: 34.084 | Acc: 93.124
12 Loss: 31.648 | Acc: 93.636
13 Loss: 29.345 | Acc: 94.114
14 Loss: 27.387 | Acc: 94.538
15 Loss: 26.199 | Acc: 94.868
16 Loss: 24.756 | Acc: 95.178
17 Loss: 22.817 | Acc: 95.474
18 Loss: 21.639 | Acc: 95.808
19 Loss: 21.011 | Acc: 95.886
20 Loss: 16.668 | Acc: 96.852
21 Loss: 15.563 | Acc: 97.058
22 Loss: 14.936 | Acc: 97.222
23 Loss: 13.733 | Acc: 97.370
24 Loss: 13.288 | Acc: 97.444
25 Loss: 12.733 | Acc: 97.530
26 Loss: 12.059 | Acc: 97.696
27 Loss: 12.031 | Acc: 97.832
28 Loss: 11.250 | Acc: 97.796
29 Loss: 11.371 | Acc: 97.796
30 Loss: 9.893 | Acc: 98.162
31 Loss: 9.347 | Acc: 98.306
32 Loss: 9.198 | Acc: 98.258
33 Loss: 8.873 | Acc: 98.328
34 Loss: 8.874 | Acc: 98.376
35 Loss: 8.216 | Acc: 98.498
36 Loss: 7.967 | Acc: 98.566
37 Loss: 7.968 | Acc: 98.550
38 Loss: 7.942 | Acc: 98.556
39 Loss: 7.664 | Acc: 98.626
40 Loss: 7.517 | Acc: 98.624
41 Loss: 7.540 | Acc: 98.684
42 Loss: 7.530 | Acc: 98.632
43 Loss: 7.007 | Acc: 98.714
44 Loss: 6.575 | Acc: 98.776
45 Loss: 6.619 | Acc: 98.784
46 Loss: 6.858 | Acc: 98.768
47 Loss: 6.865 | Acc: 98.724
48 Loss: 6.838 | Acc: 98.756
49 Loss: 6.844 | Acc: 98.774
50 Loss: 6.237 | Acc: 98.860
51 Loss: 6.142 | Acc: 98.914
52 Loss: 6.408 | Acc: 98.864
53 Loss: 6.024 | Acc: 98.894
54 Loss: 5.984 | Acc: 98.918
55 Loss: 6.421 | Acc: 98.800
56 Loss: 6.174 | Acc: 98.846
57 Loss: 6.352 | Acc: 98.844
58 Loss: 5.856 | Acc: 98.938
59 Loss: 6.179 | Acc: 98.858
MLP trained successfully...
# of Left images:  25000.0
# of Right images:  25000.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [5000, 5000, 5000, 0, 0, 0, 0, 0, 5000, 5000]
rclasses:  [0, 0, 0, 5000, 5000, 5000, 5000, 5000, 0, 0]
noOfLeftClasses:  5
noOfRightClasses:  5
lTrainDict[data].shape:  torch.Size([25000, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([25000])
rTrainDict[data].shape:  torch.Size([25000, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([25000])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([25000, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 25000
nodeId:  3 , imgTensorShape :  torch.Size([25000, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 25000
Running nodeId:  2
0 Train Loss: 98.172 | Train Acc: 61.572
1 Train Loss: 77.846 | Train Acc: 70.992
2 Train Loss: 70.786 | Train Acc: 73.788
3 Train Loss: 66.872 | Train Acc: 75.380
4 Train Loss: 63.862 | Train Acc: 76.612
5 Train Loss: 61.209 | Train Acc: 77.680
6 Train Loss: 58.834 | Train Acc: 78.544
7 Train Loss: 56.370 | Train Acc: 79.588
8 Train Loss: 54.840 | Train Acc: 79.916
9 Train Loss: 53.814 | Train Acc: 80.528
10 Train Loss: 52.576 | Train Acc: 80.804
11 Train Loss: 51.115 | Train Acc: 81.520
12 Train Loss: 50.100 | Train Acc: 81.992
13 Train Loss: 48.122 | Train Acc: 82.588
14 Train Loss: 47.854 | Train Acc: 82.840
15 Train Loss: 46.724 | Train Acc: 82.936
16 Train Loss: 45.618 | Train Acc: 83.684
17 Train Loss: 44.634 | Train Acc: 83.872
18 Train Loss: 43.924 | Train Acc: 84.292
19 Train Loss: 42.696 | Train Acc: 84.608
20 Train Loss: 39.814 | Train Acc: 85.784
21 Train Loss: 38.968 | Train Acc: 86.208
22 Train Loss: 38.648 | Train Acc: 86.356
23 Train Loss: 38.232 | Train Acc: 86.576
24 Train Loss: 37.879 | Train Acc: 86.572
25 Train Loss: 37.704 | Train Acc: 86.684
26 Train Loss: 37.260 | Train Acc: 86.948
27 Train Loss: 37.261 | Train Acc: 86.848
28 Train Loss: 36.654 | Train Acc: 87.328
29 Train Loss: 36.118 | Train Acc: 87.392
30 Train Loss: 35.941 | Train Acc: 87.508
31 Train Loss: 35.790 | Train Acc: 87.444
32 Train Loss: 35.012 | Train Acc: 88.044
33 Train Loss: 34.700 | Train Acc: 88.016
34 Train Loss: 34.562 | Train Acc: 88.156
35 Train Loss: 34.224 | Train Acc: 88.336
36 Train Loss: 33.895 | Train Acc: 88.252
37 Train Loss: 33.369 | Train Acc: 88.636
38 Train Loss: 33.029 | Train Acc: 88.648
39 Train Loss: 33.206 | Train Acc: 88.564
40 Train Loss: 31.392 | Train Acc: 89.516
41 Train Loss: 31.186 | Train Acc: 89.568
42 Train Loss: 30.925 | Train Acc: 89.836
43 Train Loss: 30.872 | Train Acc: 89.676
44 Train Loss: 30.636 | Train Acc: 89.804
45 Train Loss: 30.572 | Train Acc: 89.688
46 Train Loss: 30.430 | Train Acc: 89.964
47 Train Loss: 30.350 | Train Acc: 89.980
48 Train Loss: 30.163 | Train Acc: 90.124
49 Train Loss: 30.096 | Train Acc: 90.060
50 Train Loss: 29.866 | Train Acc: 90.276
51 Train Loss: 29.721 | Train Acc: 90.128
52 Train Loss: 29.688 | Train Acc: 90.184
53 Train Loss: 29.477 | Train Acc: 90.484
54 Train Loss: 29.462 | Train Acc: 90.176
55 Train Loss: 29.212 | Train Acc: 90.428
56 Train Loss: 29.144 | Train Acc: 90.444
57 Train Loss: 28.966 | Train Acc: 90.564
58 Train Loss: 28.966 | Train Acc: 90.420
59 Train Loss: 28.660 | Train Acc: 90.640
60 Train Loss: 28.062 | Train Acc: 90.944
61 Train Loss: 27.941 | Train Acc: 91.016
62 Train Loss: 27.890 | Train Acc: 91.024
63 Train Loss: 27.814 | Train Acc: 91.124
64 Train Loss: 27.777 | Train Acc: 91.172
65 Train Loss: 27.726 | Train Acc: 91.120
66 Train Loss: 27.725 | Train Acc: 91.216
67 Train Loss: 27.664 | Train Acc: 91.140
68 Train Loss: 27.527 | Train Acc: 91.236
69 Train Loss: 27.463 | Train Acc: 91.208
70 Train Loss: 27.471 | Train Acc: 91.176
71 Train Loss: 27.401 | Train Acc: 91.256
72 Train Loss: 27.335 | Train Acc: 91.304
73 Train Loss: 27.291 | Train Acc: 91.272
74 Train Loss: 27.272 | Train Acc: 91.304
75 Train Loss: 27.228 | Train Acc: 91.288
76 Train Loss: 27.087 | Train Acc: 91.348
77 Train Loss: 27.063 | Train Acc: 91.360
78 Train Loss: 27.030 | Train Acc: 91.432
79 Train Loss: 26.950 | Train Acc: 91.360
80 Train Loss: 26.669 | Train Acc: 91.604
81 Train Loss: 26.627 | Train Acc: 91.588
82 Train Loss: 26.625 | Train Acc: 91.600
83 Train Loss: 26.604 | Train Acc: 91.600
84 Train Loss: 26.562 | Train Acc: 91.700
85 Train Loss: 26.551 | Train Acc: 91.580
86 Train Loss: 26.536 | Train Acc: 91.600
87 Train Loss: 26.499 | Train Acc: 91.560
88 Train Loss: 26.465 | Train Acc: 91.664
89 Train Loss: 26.453 | Train Acc: 91.588
90 Train Loss: 26.466 | Train Acc: 91.676
91 Train Loss: 26.428 | Train Acc: 91.648
92 Train Loss: 26.374 | Train Acc: 91.616
93 Train Loss: 26.367 | Train Acc: 91.704
94 Train Loss: 26.334 | Train Acc: 91.740
95 Train Loss: 26.307 | Train Acc: 91.668
96 Train Loss: 26.291 | Train Acc: 91.740
97 Train Loss: 26.281 | Train Acc: 91.724
98 Train Loss: 26.272 | Train Acc: 91.684
99 Train Loss: 26.218 | Train Acc: 91.748
CNN trained successfully...
image_next_flat.shape :  torch.Size([25000, 9216])
printing expected split from k means
{2: 1, 3: 0, 4: 1, 0: 0, 1: 1}
Printing final_dict items...
{0: 0, 3: 0, 2: 1, 4: 1, 1: 1}
Image Statistics before MLP : L R :  10000 15000
expectedMlpLabels.shape :  torch.Size([25000])
0 Loss: 63.578 | Acc: 82.384
1 Loss: 50.101 | Acc: 87.076
2 Loss: 44.645 | Acc: 88.452
3 Loss: 42.754 | Acc: 89.200
4 Loss: 38.152 | Acc: 90.060
5 Loss: 35.455 | Acc: 91.048
6 Loss: 32.433 | Acc: 91.744
7 Loss: 29.921 | Acc: 92.252
8 Loss: 26.445 | Acc: 93.292
9 Loss: 24.372 | Acc: 93.660
10 Loss: 17.476 | Acc: 95.444
11 Loss: 14.728 | Acc: 96.416
12 Loss: 13.109 | Acc: 96.836
13 Loss: 11.780 | Acc: 97.100
14 Loss: 11.038 | Acc: 97.340
15 Loss: 10.117 | Acc: 97.592
16 Loss: 9.256 | Acc: 97.660
17 Loss: 7.845 | Acc: 98.144
18 Loss: 8.360 | Acc: 98.024
19 Loss: 7.288 | Acc: 98.196
20 Loss: 5.686 | Acc: 98.668
21 Loss: 3.975 | Acc: 99.032
22 Loss: 4.107 | Acc: 99.036
23 Loss: 3.878 | Acc: 99.108
24 Loss: 3.698 | Acc: 99.176
25 Loss: 3.445 | Acc: 99.176
26 Loss: 3.321 | Acc: 99.288
27 Loss: 3.157 | Acc: 99.308
28 Loss: 3.048 | Acc: 99.380
29 Loss: 2.889 | Acc: 99.304
30 Loss: 2.710 | Acc: 99.396
31 Loss: 2.343 | Acc: 99.488
32 Loss: 2.024 | Acc: 99.556
33 Loss: 2.347 | Acc: 99.516
34 Loss: 2.269 | Acc: 99.544
35 Loss: 2.173 | Acc: 99.516
36 Loss: 1.892 | Acc: 99.572
37 Loss: 1.901 | Acc: 99.596
38 Loss: 1.796 | Acc: 99.596
39 Loss: 1.704 | Acc: 99.620
40 Loss: 1.652 | Acc: 99.592
41 Loss: 1.437 | Acc: 99.708
42 Loss: 1.564 | Acc: 99.672
43 Loss: 1.111 | Acc: 99.772
44 Loss: 1.429 | Acc: 99.656
45 Loss: 1.315 | Acc: 99.688
46 Loss: 1.425 | Acc: 99.708
47 Loss: 1.429 | Acc: 99.708
48 Loss: 1.207 | Acc: 99.728
49 Loss: 1.486 | Acc: 99.660
50 Loss: 1.314 | Acc: 99.668
51 Loss: 1.079 | Acc: 99.740
52 Loss: 1.266 | Acc: 99.716
53 Loss: 1.051 | Acc: 99.796
54 Loss: 1.089 | Acc: 99.736
55 Loss: 1.238 | Acc: 99.736
56 Loss: 0.961 | Acc: 99.760
57 Loss: 1.254 | Acc: 99.760
58 Loss: 1.074 | Acc: 99.776
59 Loss: 1.008 | Acc: 99.788
MLP trained successfully...
# of Left images:  10000.0
# of Right images:  15000.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [5000, 0, 0, 5000, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 5000, 0, 5000, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
lTrainDict[data].shape:  torch.Size([10000, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([10000])
rTrainDict[data].shape:  torch.Size([15000, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([15000])
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([10000, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 10000
nodeId:  5 , imgTensorShape :  torch.Size([15000, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 15000
Running nodeId:  3
0 Train Loss: 121.305 | Train Acc: 50.500
1 Train Loss: 102.866 | Train Acc: 59.784
2 Train Loss: 94.254 | Train Acc: 63.324
3 Train Loss: 89.668 | Train Acc: 65.364
4 Train Loss: 86.544 | Train Acc: 66.692
5 Train Loss: 83.991 | Train Acc: 67.920
6 Train Loss: 82.256 | Train Acc: 68.600
7 Train Loss: 80.068 | Train Acc: 69.484
8 Train Loss: 78.255 | Train Acc: 70.136
9 Train Loss: 76.725 | Train Acc: 71.008
10 Train Loss: 75.522 | Train Acc: 71.264
11 Train Loss: 74.292 | Train Acc: 71.732
12 Train Loss: 72.811 | Train Acc: 72.620
13 Train Loss: 71.434 | Train Acc: 73.120
14 Train Loss: 70.127 | Train Acc: 73.688
15 Train Loss: 69.827 | Train Acc: 73.628
16 Train Loss: 68.201 | Train Acc: 74.240
17 Train Loss: 66.966 | Train Acc: 74.900
18 Train Loss: 66.176 | Train Acc: 75.056
19 Train Loss: 64.285 | Train Acc: 75.728
20 Train Loss: 60.955 | Train Acc: 77.708
21 Train Loss: 60.250 | Train Acc: 77.764
22 Train Loss: 59.816 | Train Acc: 77.920
23 Train Loss: 59.298 | Train Acc: 78.224
24 Train Loss: 59.220 | Train Acc: 78.216
25 Train Loss: 58.654 | Train Acc: 78.468
26 Train Loss: 58.001 | Train Acc: 78.720
27 Train Loss: 57.534 | Train Acc: 78.936
28 Train Loss: 57.215 | Train Acc: 79.168
29 Train Loss: 56.797 | Train Acc: 79.324
30 Train Loss: 56.543 | Train Acc: 79.424
31 Train Loss: 56.183 | Train Acc: 79.404
32 Train Loss: 55.665 | Train Acc: 79.808
33 Train Loss: 55.626 | Train Acc: 79.696
34 Train Loss: 54.699 | Train Acc: 80.172
35 Train Loss: 54.416 | Train Acc: 80.244
36 Train Loss: 54.015 | Train Acc: 80.420
37 Train Loss: 53.727 | Train Acc: 80.440
38 Train Loss: 53.328 | Train Acc: 80.788
39 Train Loss: 52.775 | Train Acc: 80.992
40 Train Loss: 50.911 | Train Acc: 82.084
41 Train Loss: 50.602 | Train Acc: 81.992
42 Train Loss: 50.471 | Train Acc: 82.128
43 Train Loss: 50.592 | Train Acc: 81.908
44 Train Loss: 50.215 | Train Acc: 82.340
45 Train Loss: 50.102 | Train Acc: 82.304
46 Train Loss: 49.916 | Train Acc: 82.420
47 Train Loss: 49.664 | Train Acc: 82.484
48 Train Loss: 49.578 | Train Acc: 82.512
49 Train Loss: 49.413 | Train Acc: 82.672
50 Train Loss: 49.184 | Train Acc: 82.672
51 Train Loss: 49.052 | Train Acc: 82.692
52 Train Loss: 48.965 | Train Acc: 82.736
53 Train Loss: 48.754 | Train Acc: 82.920
54 Train Loss: 48.552 | Train Acc: 83.116
55 Train Loss: 48.440 | Train Acc: 83.040
56 Train Loss: 48.189 | Train Acc: 83.132
57 Train Loss: 48.078 | Train Acc: 83.200
58 Train Loss: 47.901 | Train Acc: 83.192
59 Train Loss: 47.790 | Train Acc: 83.392
60 Train Loss: 47.054 | Train Acc: 83.572
61 Train Loss: 46.916 | Train Acc: 83.828
62 Train Loss: 46.852 | Train Acc: 83.748
63 Train Loss: 46.753 | Train Acc: 83.920
64 Train Loss: 46.708 | Train Acc: 83.812
65 Train Loss: 46.624 | Train Acc: 83.864
66 Train Loss: 46.518 | Train Acc: 83.964
67 Train Loss: 46.504 | Train Acc: 84.044
68 Train Loss: 46.412 | Train Acc: 84.028
69 Train Loss: 46.344 | Train Acc: 84.012
70 Train Loss: 46.331 | Train Acc: 84.196
71 Train Loss: 46.392 | Train Acc: 83.900
72 Train Loss: 46.199 | Train Acc: 84.008
73 Train Loss: 46.115 | Train Acc: 84.088
74 Train Loss: 46.086 | Train Acc: 84.100
75 Train Loss: 45.991 | Train Acc: 84.156
76 Train Loss: 45.932 | Train Acc: 84.088
77 Train Loss: 45.819 | Train Acc: 84.276
78 Train Loss: 45.792 | Train Acc: 84.288
79 Train Loss: 45.780 | Train Acc: 84.244
80 Train Loss: 45.354 | Train Acc: 84.444
81 Train Loss: 45.326 | Train Acc: 84.536
82 Train Loss: 45.281 | Train Acc: 84.560
83 Train Loss: 45.266 | Train Acc: 84.472
84 Train Loss: 45.262 | Train Acc: 84.532
85 Train Loss: 45.224 | Train Acc: 84.568
86 Train Loss: 45.194 | Train Acc: 84.564
87 Train Loss: 45.178 | Train Acc: 84.540
88 Train Loss: 45.143 | Train Acc: 84.584
89 Train Loss: 45.102 | Train Acc: 84.448
90 Train Loss: 45.110 | Train Acc: 84.608
91 Train Loss: 45.051 | Train Acc: 84.580
92 Train Loss: 45.029 | Train Acc: 84.584
93 Train Loss: 44.999 | Train Acc: 84.632
94 Train Loss: 44.987 | Train Acc: 84.584
95 Train Loss: 44.937 | Train Acc: 84.652
96 Train Loss: 44.939 | Train Acc: 84.692
97 Train Loss: 44.904 | Train Acc: 84.652
98 Train Loss: 44.888 | Train Acc: 84.628
99 Train Loss: 44.849 | Train Acc: 84.752
CNN trained successfully...
image_next_flat.shape :  torch.Size([25000, 9216])
printing expected split from k means
{3: 0, 1: 0, 0: 0, 4: 1, 2: 1}
Printing final_dict items...
{3: 0, 1: 0, 0: 1, 2: 1, 4: 1}
Image Statistics before MLP : L R :  10000 15000
expectedMlpLabels.shape :  torch.Size([25000])
0 Loss: 73.909 | Acc: 78.704
1 Loss: 62.022 | Acc: 83.132
2 Loss: 58.051 | Acc: 84.500
3 Loss: 52.833 | Acc: 85.396
4 Loss: 48.814 | Acc: 87.144
5 Loss: 44.363 | Acc: 87.992
6 Loss: 39.608 | Acc: 89.668
7 Loss: 36.538 | Acc: 90.480
8 Loss: 31.688 | Acc: 91.612
9 Loss: 28.334 | Acc: 92.728
10 Loss: 19.029 | Acc: 95.288
11 Loss: 15.822 | Acc: 96.152
12 Loss: 13.925 | Acc: 96.536
13 Loss: 12.377 | Acc: 97.160
14 Loss: 11.283 | Acc: 97.340
15 Loss: 10.308 | Acc: 97.608
16 Loss: 8.737 | Acc: 98.092
17 Loss: 8.723 | Acc: 97.896
18 Loss: 8.134 | Acc: 98.164
19 Loss: 7.066 | Acc: 98.444
20 Loss: 5.178 | Acc: 98.820
21 Loss: 4.241 | Acc: 99.132
22 Loss: 4.263 | Acc: 99.124
23 Loss: 3.453 | Acc: 99.232
24 Loss: 3.809 | Acc: 99.188
25 Loss: 3.558 | Acc: 99.220
26 Loss: 3.309 | Acc: 99.296
27 Loss: 2.835 | Acc: 99.460
28 Loss: 2.754 | Acc: 99.408
29 Loss: 2.959 | Acc: 99.324
30 Loss: 2.386 | Acc: 99.500
31 Loss: 2.312 | Acc: 99.524
32 Loss: 1.939 | Acc: 99.544
33 Loss: 1.617 | Acc: 99.680
34 Loss: 1.857 | Acc: 99.628
35 Loss: 1.739 | Acc: 99.608
36 Loss: 1.526 | Acc: 99.720
37 Loss: 1.728 | Acc: 99.672
38 Loss: 1.673 | Acc: 99.636
39 Loss: 1.685 | Acc: 99.668
40 Loss: 1.213 | Acc: 99.724
41 Loss: 1.239 | Acc: 99.744
42 Loss: 1.125 | Acc: 99.748
43 Loss: 1.196 | Acc: 99.728
44 Loss: 1.325 | Acc: 99.760
45 Loss: 1.136 | Acc: 99.760
46 Loss: 1.183 | Acc: 99.728
47 Loss: 1.298 | Acc: 99.724
48 Loss: 1.095 | Acc: 99.772
49 Loss: 1.271 | Acc: 99.768
50 Loss: 0.952 | Acc: 99.792
51 Loss: 0.860 | Acc: 99.804
52 Loss: 0.992 | Acc: 99.828
53 Loss: 1.066 | Acc: 99.796
54 Loss: 1.068 | Acc: 99.788
55 Loss: 0.956 | Acc: 99.784
56 Loss: 1.236 | Acc: 99.772
57 Loss: 1.080 | Acc: 99.804
58 Loss: 1.251 | Acc: 99.732
59 Loss: 0.940 | Acc: 99.856
MLP trained successfully...
# of Left images:  10000.0
# of Right images:  15000.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [0, 5000, 0, 5000, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 0, 5000, 0, 5000, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
lTrainDict[data].shape:  torch.Size([10000, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([10000])
rTrainDict[data].shape:  torch.Size([15000, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([15000])
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([10000, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 10000
nodeId:  7 , imgTensorShape :  torch.Size([15000, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 15000
Running nodeId:  4
0 Train Loss: 50.251 | Train Acc: 74.300
1 Train Loss: 32.855 | Train Acc: 85.910
2 Train Loss: 29.036 | Train Acc: 87.720
3 Train Loss: 27.627 | Train Acc: 88.650
4 Train Loss: 24.931 | Train Acc: 89.680
5 Train Loss: 23.776 | Train Acc: 90.270
6 Train Loss: 22.115 | Train Acc: 91.130
7 Train Loss: 21.339 | Train Acc: 91.410
8 Train Loss: 20.644 | Train Acc: 91.950
9 Train Loss: 19.391 | Train Acc: 92.330
10 Train Loss: 18.928 | Train Acc: 92.720
11 Train Loss: 17.689 | Train Acc: 93.000
12 Train Loss: 18.442 | Train Acc: 92.480
13 Train Loss: 16.047 | Train Acc: 93.810
14 Train Loss: 14.798 | Train Acc: 94.440
15 Train Loss: 14.083 | Train Acc: 94.580
16 Train Loss: 13.794 | Train Acc: 94.640
17 Train Loss: 13.527 | Train Acc: 94.620
18 Train Loss: 12.244 | Train Acc: 95.440
19 Train Loss: 11.384 | Train Acc: 95.680
20 Train Loss: 9.385 | Train Acc: 96.830
21 Train Loss: 9.066 | Train Acc: 97.110
22 Train Loss: 8.785 | Train Acc: 97.200
23 Train Loss: 8.549 | Train Acc: 97.090
24 Train Loss: 8.486 | Train Acc: 97.150
25 Train Loss: 8.059 | Train Acc: 97.350
26 Train Loss: 7.825 | Train Acc: 97.480
27 Train Loss: 7.554 | Train Acc: 97.620
28 Train Loss: 7.529 | Train Acc: 97.640
29 Train Loss: 7.420 | Train Acc: 97.520
30 Train Loss: 6.937 | Train Acc: 98.110
31 Train Loss: 6.751 | Train Acc: 97.980
32 Train Loss: 6.607 | Train Acc: 98.070
33 Train Loss: 6.344 | Train Acc: 98.320
34 Train Loss: 6.407 | Train Acc: 98.200
35 Train Loss: 5.992 | Train Acc: 98.420
36 Train Loss: 5.675 | Train Acc: 98.640
37 Train Loss: 5.429 | Train Acc: 98.710
38 Train Loss: 5.270 | Train Acc: 98.810
39 Train Loss: 5.079 | Train Acc: 98.740
40 Train Loss: 4.570 | Train Acc: 99.080
41 Train Loss: 4.416 | Train Acc: 99.150
42 Train Loss: 4.317 | Train Acc: 99.200
43 Train Loss: 4.242 | Train Acc: 99.190
44 Train Loss: 4.156 | Train Acc: 99.290
45 Train Loss: 4.065 | Train Acc: 99.320
46 Train Loss: 4.054 | Train Acc: 99.270
47 Train Loss: 3.949 | Train Acc: 99.340
48 Train Loss: 3.935 | Train Acc: 99.340
49 Train Loss: 3.843 | Train Acc: 99.390
50 Train Loss: 3.805 | Train Acc: 99.380
51 Train Loss: 3.696 | Train Acc: 99.540
52 Train Loss: 3.764 | Train Acc: 99.380
53 Train Loss: 3.518 | Train Acc: 99.470
54 Train Loss: 3.522 | Train Acc: 99.470
55 Train Loss: 3.440 | Train Acc: 99.540
56 Train Loss: 3.422 | Train Acc: 99.530
57 Train Loss: 3.376 | Train Acc: 99.520
58 Train Loss: 3.228 | Train Acc: 99.700
59 Train Loss: 3.178 | Train Acc: 99.640
60 Train Loss: 2.996 | Train Acc: 99.710
61 Train Loss: 2.963 | Train Acc: 99.740
62 Train Loss: 2.939 | Train Acc: 99.720
63 Train Loss: 2.923 | Train Acc: 99.720
64 Train Loss: 2.926 | Train Acc: 99.690
65 Train Loss: 2.872 | Train Acc: 99.790
66 Train Loss: 2.855 | Train Acc: 99.740
67 Train Loss: 2.816 | Train Acc: 99.770
68 Train Loss: 2.810 | Train Acc: 99.750
69 Train Loss: 2.783 | Train Acc: 99.760
70 Train Loss: 2.747 | Train Acc: 99.830
71 Train Loss: 2.743 | Train Acc: 99.770
72 Train Loss: 2.724 | Train Acc: 99.780
73 Train Loss: 2.693 | Train Acc: 99.830
74 Train Loss: 2.664 | Train Acc: 99.820
75 Train Loss: 2.648 | Train Acc: 99.780
76 Train Loss: 2.621 | Train Acc: 99.800
77 Train Loss: 2.589 | Train Acc: 99.840
78 Train Loss: 2.565 | Train Acc: 99.850
79 Train Loss: 2.584 | Train Acc: 99.830
80 Train Loss: 2.465 | Train Acc: 99.850
81 Train Loss: 2.460 | Train Acc: 99.860
82 Train Loss: 2.446 | Train Acc: 99.850
83 Train Loss: 2.447 | Train Acc: 99.860
84 Train Loss: 2.423 | Train Acc: 99.850
85 Train Loss: 2.427 | Train Acc: 99.850
86 Train Loss: 2.411 | Train Acc: 99.860
87 Train Loss: 2.407 | Train Acc: 99.860
88 Train Loss: 2.394 | Train Acc: 99.880
89 Train Loss: 2.389 | Train Acc: 99.870
90 Train Loss: 2.372 | Train Acc: 99.870
91 Train Loss: 2.363 | Train Acc: 99.860
92 Train Loss: 2.362 | Train Acc: 99.870
93 Train Loss: 2.344 | Train Acc: 99.860
94 Train Loss: 2.336 | Train Acc: 99.870
95 Train Loss: 2.327 | Train Acc: 99.870
96 Train Loss: 2.324 | Train Acc: 99.870
97 Train Loss: 2.304 | Train Acc: 99.870
98 Train Loss: 2.303 | Train Acc: 99.850
99 Train Loss: 2.295 | Train Acc: 99.860
CNN trained successfully...
image_next_flat.shape :  torch.Size([10000, 6400])
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  5000 5000
expectedMlpLabels.shape :  torch.Size([10000])
0 Loss: 62.256 | Acc: 86.570
1 Loss: 39.761 | Acc: 92.040
2 Loss: 32.618 | Acc: 93.550
3 Loss: 26.477 | Acc: 94.840
4 Loss: 22.363 | Acc: 95.660
5 Loss: 19.409 | Acc: 96.150
6 Loss: 15.933 | Acc: 96.810
7 Loss: 15.071 | Acc: 97.130
8 Loss: 11.225 | Acc: 97.740
9 Loss: 9.501 | Acc: 98.150
10 Loss: 4.570 | Acc: 99.230
11 Loss: 2.853 | Acc: 99.530
12 Loss: 2.553 | Acc: 99.580
13 Loss: 2.332 | Acc: 99.520
14 Loss: 1.887 | Acc: 99.650
15 Loss: 2.262 | Acc: 99.690
16 Loss: 1.933 | Acc: 99.660
17 Loss: 1.863 | Acc: 99.620
18 Loss: 2.147 | Acc: 99.620
19 Loss: 1.660 | Acc: 99.670
20 Loss: 0.361 | Acc: 99.930
21 Loss: 0.694 | Acc: 99.880
22 Loss: 0.699 | Acc: 99.880
23 Loss: 0.533 | Acc: 99.920
24 Loss: 0.254 | Acc: 99.950
25 Loss: 0.361 | Acc: 99.940
26 Loss: 0.274 | Acc: 99.940
27 Loss: 0.529 | Acc: 99.920
28 Loss: 0.394 | Acc: 99.950
29 Loss: 0.261 | Acc: 99.960
30 Loss: 0.366 | Acc: 99.940
31 Loss: 0.161 | Acc: 99.970
32 Loss: 0.107 | Acc: 99.980
33 Loss: 0.212 | Acc: 99.980
34 Loss: 0.084 | Acc: 99.990
35 Loss: 0.042 | Acc: 100.000
36 Loss: 0.037 | Acc: 100.000
37 Loss: 0.179 | Acc: 99.960
38 Loss: 0.075 | Acc: 99.980
39 Loss: 0.172 | Acc: 99.980
40 Loss: 0.032 | Acc: 100.000
41 Loss: 0.015 | Acc: 100.000
42 Loss: 0.071 | Acc: 99.980
43 Loss: 0.067 | Acc: 99.990
44 Loss: 0.016 | Acc: 100.000
45 Loss: 0.048 | Acc: 99.990
46 Loss: 0.059 | Acc: 99.990
47 Loss: 0.086 | Acc: 99.970
48 Loss: 0.013 | Acc: 100.000
49 Loss: 0.027 | Acc: 100.000
50 Loss: 0.010 | Acc: 100.000
51 Loss: 0.009 | Acc: 100.000
52 Loss: 0.072 | Acc: 99.980
53 Loss: 0.049 | Acc: 99.990
54 Loss: 0.009 | Acc: 100.000
55 Loss: 0.013 | Acc: 100.000
56 Loss: 0.015 | Acc: 100.000
57 Loss: 0.028 | Acc: 100.000
58 Loss: 0.093 | Acc: 99.970
59 Loss: 0.012 | Acc: 100.000
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 8
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 0
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 8
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 0
nodeId:  8 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 5000
nodeId:  9 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  5
0 Train Loss: 47.833 | Train Acc: 79.753
1 Train Loss: 35.761 | Train Acc: 86.267
2 Train Loss: 31.799 | Train Acc: 87.793
3 Train Loss: 30.414 | Train Acc: 88.493
4 Train Loss: 27.447 | Train Acc: 89.633
5 Train Loss: 26.213 | Train Acc: 89.967
6 Train Loss: 25.769 | Train Acc: 90.200
7 Train Loss: 23.876 | Train Acc: 91.167
8 Train Loss: 22.686 | Train Acc: 91.640
9 Train Loss: 21.114 | Train Acc: 92.267
10 Train Loss: 20.692 | Train Acc: 92.187
11 Train Loss: 20.249 | Train Acc: 92.480
12 Train Loss: 19.622 | Train Acc: 92.827
13 Train Loss: 18.772 | Train Acc: 93.000
14 Train Loss: 17.797 | Train Acc: 93.573
15 Train Loss: 16.491 | Train Acc: 94.127
16 Train Loss: 16.747 | Train Acc: 93.880
17 Train Loss: 15.062 | Train Acc: 94.540
18 Train Loss: 14.901 | Train Acc: 94.533
19 Train Loss: 14.391 | Train Acc: 94.880
20 Train Loss: 11.653 | Train Acc: 96.180
21 Train Loss: 11.426 | Train Acc: 96.227
22 Train Loss: 10.899 | Train Acc: 96.473
23 Train Loss: 10.645 | Train Acc: 96.613
24 Train Loss: 10.407 | Train Acc: 96.700
25 Train Loss: 10.244 | Train Acc: 96.587
26 Train Loss: 9.926 | Train Acc: 96.840
27 Train Loss: 9.760 | Train Acc: 96.953
28 Train Loss: 9.581 | Train Acc: 96.980
29 Train Loss: 9.273 | Train Acc: 97.220
30 Train Loss: 8.910 | Train Acc: 97.293
31 Train Loss: 8.861 | Train Acc: 97.393
32 Train Loss: 8.592 | Train Acc: 97.460
33 Train Loss: 8.456 | Train Acc: 97.533
34 Train Loss: 8.264 | Train Acc: 97.580
35 Train Loss: 7.971 | Train Acc: 97.860
36 Train Loss: 7.752 | Train Acc: 97.907
37 Train Loss: 7.354 | Train Acc: 97.980
38 Train Loss: 7.201 | Train Acc: 98.127
39 Train Loss: 7.368 | Train Acc: 97.920
40 Train Loss: 6.350 | Train Acc: 98.520
41 Train Loss: 6.066 | Train Acc: 98.713
42 Train Loss: 6.077 | Train Acc: 98.693
43 Train Loss: 6.060 | Train Acc: 98.713
44 Train Loss: 5.837 | Train Acc: 98.860
45 Train Loss: 5.806 | Train Acc: 98.813
46 Train Loss: 5.715 | Train Acc: 98.887
47 Train Loss: 5.669 | Train Acc: 98.933
48 Train Loss: 5.578 | Train Acc: 98.920
49 Train Loss: 5.481 | Train Acc: 98.907
50 Train Loss: 5.448 | Train Acc: 98.993
51 Train Loss: 5.336 | Train Acc: 99.027
52 Train Loss: 5.344 | Train Acc: 98.940
53 Train Loss: 5.222 | Train Acc: 99.053
54 Train Loss: 5.155 | Train Acc: 99.047
55 Train Loss: 5.045 | Train Acc: 99.153
56 Train Loss: 5.042 | Train Acc: 99.020
57 Train Loss: 5.135 | Train Acc: 99.060
58 Train Loss: 4.863 | Train Acc: 99.040
59 Train Loss: 4.719 | Train Acc: 99.300
60 Train Loss: 4.478 | Train Acc: 99.353
61 Train Loss: 4.413 | Train Acc: 99.367
62 Train Loss: 4.386 | Train Acc: 99.393
63 Train Loss: 4.375 | Train Acc: 99.420
64 Train Loss: 4.317 | Train Acc: 99.427
65 Train Loss: 4.316 | Train Acc: 99.453
66 Train Loss: 4.313 | Train Acc: 99.380
67 Train Loss: 4.237 | Train Acc: 99.447
68 Train Loss: 4.225 | Train Acc: 99.480
69 Train Loss: 4.168 | Train Acc: 99.447
70 Train Loss: 4.181 | Train Acc: 99.533
71 Train Loss: 4.154 | Train Acc: 99.487
72 Train Loss: 4.095 | Train Acc: 99.507
73 Train Loss: 4.059 | Train Acc: 99.513
74 Train Loss: 4.047 | Train Acc: 99.547
75 Train Loss: 4.023 | Train Acc: 99.540
76 Train Loss: 4.005 | Train Acc: 99.587
77 Train Loss: 3.954 | Train Acc: 99.533
78 Train Loss: 3.946 | Train Acc: 99.547
79 Train Loss: 3.905 | Train Acc: 99.553
80 Train Loss: 3.782 | Train Acc: 99.627
81 Train Loss: 3.765 | Train Acc: 99.647
82 Train Loss: 3.755 | Train Acc: 99.613
83 Train Loss: 3.748 | Train Acc: 99.627
84 Train Loss: 3.741 | Train Acc: 99.593
85 Train Loss: 3.719 | Train Acc: 99.647
86 Train Loss: 3.704 | Train Acc: 99.620
87 Train Loss: 3.690 | Train Acc: 99.647
88 Train Loss: 3.677 | Train Acc: 99.660
89 Train Loss: 3.668 | Train Acc: 99.653
90 Train Loss: 3.669 | Train Acc: 99.673
91 Train Loss: 3.643 | Train Acc: 99.687
92 Train Loss: 3.624 | Train Acc: 99.680
93 Train Loss: 3.626 | Train Acc: 99.653
94 Train Loss: 3.602 | Train Acc: 99.680
95 Train Loss: 3.600 | Train Acc: 99.653
96 Train Loss: 3.599 | Train Acc: 99.667
97 Train Loss: 3.584 | Train Acc: 99.673
98 Train Loss: 3.560 | Train Acc: 99.687
99 Train Loss: 3.542 | Train Acc: 99.700
CNN trained successfully...
image_next_flat.shape :  torch.Size([15000, 6400])
printing expected split from k means
{2: 0, 0: 0, 1: 1}
Printing final_dict items...
{0: 0, 2: 1, 1: 1}
Image Statistics before MLP : L R :  5000 10000
expectedMlpLabels.shape :  torch.Size([15000])
0 Loss: 43.947 | Acc: 85.547
1 Loss: 31.186 | Acc: 91.127
2 Loss: 25.939 | Acc: 92.233
3 Loss: 22.722 | Acc: 93.333
4 Loss: 19.019 | Acc: 94.200
5 Loss: 17.574 | Acc: 94.820
6 Loss: 14.675 | Acc: 95.480
7 Loss: 13.078 | Acc: 96.087
8 Loss: 11.825 | Acc: 96.087
9 Loss: 10.025 | Acc: 96.747
10 Loss: 5.771 | Acc: 98.327
11 Loss: 3.919 | Acc: 98.933
12 Loss: 3.480 | Acc: 98.980
13 Loss: 2.930 | Acc: 99.160
14 Loss: 3.454 | Acc: 98.980
15 Loss: 2.615 | Acc: 99.260
16 Loss: 2.392 | Acc: 99.313
17 Loss: 1.979 | Acc: 99.473
18 Loss: 2.269 | Acc: 99.400
19 Loss: 2.001 | Acc: 99.433
20 Loss: 1.007 | Acc: 99.753
21 Loss: 0.646 | Acc: 99.807
22 Loss: 0.724 | Acc: 99.800
23 Loss: 0.286 | Acc: 99.893
24 Loss: 0.264 | Acc: 99.913
25 Loss: 0.348 | Acc: 99.927
26 Loss: 0.657 | Acc: 99.813
27 Loss: 0.951 | Acc: 99.727
28 Loss: 0.606 | Acc: 99.860
29 Loss: 0.541 | Acc: 99.900
30 Loss: 0.399 | Acc: 99.893
31 Loss: 0.264 | Acc: 99.953
32 Loss: 0.269 | Acc: 99.927
33 Loss: 0.238 | Acc: 99.947
34 Loss: 0.150 | Acc: 99.973
35 Loss: 0.281 | Acc: 99.927
36 Loss: 0.148 | Acc: 99.967
37 Loss: 0.121 | Acc: 99.980
38 Loss: 0.229 | Acc: 99.960
39 Loss: 0.219 | Acc: 99.953
40 Loss: 0.116 | Acc: 99.967
41 Loss: 0.265 | Acc: 99.940
42 Loss: 0.270 | Acc: 99.960
43 Loss: 0.163 | Acc: 99.960
44 Loss: 0.109 | Acc: 99.973
45 Loss: 0.086 | Acc: 99.980
46 Loss: 0.151 | Acc: 99.953
47 Loss: 0.103 | Acc: 99.973
48 Loss: 0.110 | Acc: 99.967
49 Loss: 0.118 | Acc: 99.967
50 Loss: 0.194 | Acc: 99.960
51 Loss: 0.148 | Acc: 99.947
52 Loss: 0.146 | Acc: 99.967
53 Loss: 0.105 | Acc: 99.967
54 Loss: 0.203 | Acc: 99.947
55 Loss: 0.083 | Acc: 99.973
56 Loss: 0.147 | Acc: 99.947
57 Loss: 0.202 | Acc: 99.947
58 Loss: 0.194 | Acc: 99.987
59 Loss: 0.050 | Acc: 99.987
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  10000.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 5000, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([10000, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([10000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
nodeId:  10 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 5000
nodeId:  11 , imgTensorShape :  torch.Size([10000, 16, 20, 20])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 10000
Running nodeId:  6
0 Train Loss: 41.725 | Train Acc: 80.530
1 Train Loss: 28.636 | Train Acc: 87.920
2 Train Loss: 26.374 | Train Acc: 88.630
3 Train Loss: 25.153 | Train Acc: 89.520
4 Train Loss: 25.037 | Train Acc: 89.380
5 Train Loss: 22.022 | Train Acc: 90.810
6 Train Loss: 20.641 | Train Acc: 91.290
7 Train Loss: 19.241 | Train Acc: 92.150
8 Train Loss: 18.078 | Train Acc: 92.820
9 Train Loss: 17.518 | Train Acc: 92.910
10 Train Loss: 15.942 | Train Acc: 93.710
11 Train Loss: 16.147 | Train Acc: 93.390
12 Train Loss: 15.502 | Train Acc: 93.710
13 Train Loss: 13.803 | Train Acc: 94.500
14 Train Loss: 13.167 | Train Acc: 94.830
15 Train Loss: 12.362 | Train Acc: 95.040
16 Train Loss: 11.363 | Train Acc: 95.800
17 Train Loss: 10.589 | Train Acc: 96.050
18 Train Loss: 10.465 | Train Acc: 96.120
19 Train Loss: 9.137 | Train Acc: 96.490
20 Train Loss: 7.906 | Train Acc: 97.420
21 Train Loss: 7.454 | Train Acc: 97.790
22 Train Loss: 7.387 | Train Acc: 97.590
23 Train Loss: 7.197 | Train Acc: 97.900
24 Train Loss: 6.941 | Train Acc: 97.860
25 Train Loss: 6.416 | Train Acc: 98.180
26 Train Loss: 6.236 | Train Acc: 98.290
27 Train Loss: 6.532 | Train Acc: 98.000
28 Train Loss: 5.945 | Train Acc: 98.410
29 Train Loss: 5.714 | Train Acc: 98.580
30 Train Loss: 5.659 | Train Acc: 98.560
31 Train Loss: 5.512 | Train Acc: 98.620
32 Train Loss: 5.174 | Train Acc: 98.820
33 Train Loss: 5.062 | Train Acc: 98.860
34 Train Loss: 5.186 | Train Acc: 98.670
35 Train Loss: 4.559 | Train Acc: 99.020
36 Train Loss: 4.411 | Train Acc: 99.130
37 Train Loss: 4.364 | Train Acc: 99.160
38 Train Loss: 4.309 | Train Acc: 99.070
39 Train Loss: 3.944 | Train Acc: 99.250
40 Train Loss: 3.495 | Train Acc: 99.540
41 Train Loss: 3.381 | Train Acc: 99.560
42 Train Loss: 3.356 | Train Acc: 99.550
43 Train Loss: 3.288 | Train Acc: 99.600
44 Train Loss: 3.314 | Train Acc: 99.510
45 Train Loss: 3.194 | Train Acc: 99.580
46 Train Loss: 3.113 | Train Acc: 99.570
47 Train Loss: 3.033 | Train Acc: 99.670
48 Train Loss: 3.038 | Train Acc: 99.660
49 Train Loss: 2.978 | Train Acc: 99.680
50 Train Loss: 2.908 | Train Acc: 99.700
51 Train Loss: 2.884 | Train Acc: 99.670
52 Train Loss: 2.806 | Train Acc: 99.740
53 Train Loss: 2.726 | Train Acc: 99.790
54 Train Loss: 2.687 | Train Acc: 99.740
55 Train Loss: 2.659 | Train Acc: 99.780
56 Train Loss: 2.607 | Train Acc: 99.810
57 Train Loss: 2.537 | Train Acc: 99.740
58 Train Loss: 2.514 | Train Acc: 99.770
59 Train Loss: 2.446 | Train Acc: 99.770
60 Train Loss: 2.260 | Train Acc: 99.850
61 Train Loss: 2.268 | Train Acc: 99.840
62 Train Loss: 2.207 | Train Acc: 99.830
63 Train Loss: 2.190 | Train Acc: 99.830
64 Train Loss: 2.190 | Train Acc: 99.860
65 Train Loss: 2.166 | Train Acc: 99.830
66 Train Loss: 2.138 | Train Acc: 99.860
67 Train Loss: 2.118 | Train Acc: 99.890
68 Train Loss: 2.098 | Train Acc: 99.870
69 Train Loss: 2.083 | Train Acc: 99.860
70 Train Loss: 2.081 | Train Acc: 99.830
71 Train Loss: 2.056 | Train Acc: 99.850
72 Train Loss: 2.017 | Train Acc: 99.860
73 Train Loss: 2.002 | Train Acc: 99.870
74 Train Loss: 1.989 | Train Acc: 99.890
75 Train Loss: 1.959 | Train Acc: 99.880
76 Train Loss: 1.940 | Train Acc: 99.860
77 Train Loss: 1.937 | Train Acc: 99.890
78 Train Loss: 1.903 | Train Acc: 99.900
79 Train Loss: 1.893 | Train Acc: 99.880
80 Train Loss: 1.822 | Train Acc: 99.920
81 Train Loss: 1.809 | Train Acc: 99.900
82 Train Loss: 1.799 | Train Acc: 99.920
83 Train Loss: 1.793 | Train Acc: 99.920
84 Train Loss: 1.786 | Train Acc: 99.920
85 Train Loss: 1.786 | Train Acc: 99.910
86 Train Loss: 1.767 | Train Acc: 99.910
87 Train Loss: 1.763 | Train Acc: 99.930
88 Train Loss: 1.758 | Train Acc: 99.910
89 Train Loss: 1.759 | Train Acc: 99.940
90 Train Loss: 1.736 | Train Acc: 99.920
91 Train Loss: 1.731 | Train Acc: 99.930
92 Train Loss: 1.732 | Train Acc: 99.920
93 Train Loss: 1.719 | Train Acc: 99.930
94 Train Loss: 1.711 | Train Acc: 99.950
95 Train Loss: 1.718 | Train Acc: 99.930
96 Train Loss: 1.692 | Train Acc: 99.940
97 Train Loss: 1.685 | Train Acc: 99.920
98 Train Loss: 1.679 | Train Acc: 99.940
99 Train Loss: 1.665 | Train Acc: 99.950
CNN trained successfully...
image_next_flat.shape :  torch.Size([10000, 6400])
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  5000 5000
expectedMlpLabels.shape :  torch.Size([10000])
0 Loss: 61.270 | Acc: 86.790
1 Loss: 42.864 | Acc: 91.680
2 Loss: 33.556 | Acc: 93.480
3 Loss: 27.624 | Acc: 94.570
4 Loss: 23.436 | Acc: 95.190
5 Loss: 20.869 | Acc: 95.730
6 Loss: 18.482 | Acc: 96.210
7 Loss: 16.065 | Acc: 96.770
8 Loss: 14.047 | Acc: 97.450
9 Loss: 10.930 | Acc: 97.920
10 Loss: 5.099 | Acc: 99.030
11 Loss: 3.499 | Acc: 99.360
12 Loss: 3.254 | Acc: 99.450
13 Loss: 3.046 | Acc: 99.450
14 Loss: 2.924 | Acc: 99.490
15 Loss: 3.095 | Acc: 99.410
16 Loss: 2.341 | Acc: 99.630
17 Loss: 1.826 | Acc: 99.650
18 Loss: 2.033 | Acc: 99.650
19 Loss: 1.446 | Acc: 99.770
20 Loss: 0.736 | Acc: 99.890
21 Loss: 0.283 | Acc: 99.970
22 Loss: 0.652 | Acc: 99.910
23 Loss: 0.404 | Acc: 99.930
24 Loss: 0.362 | Acc: 99.950
25 Loss: 0.280 | Acc: 99.960
26 Loss: 0.157 | Acc: 99.970
27 Loss: 0.871 | Acc: 99.880
28 Loss: 0.514 | Acc: 99.920
29 Loss: 0.238 | Acc: 99.980
30 Loss: 0.095 | Acc: 99.990
31 Loss: 0.175 | Acc: 99.960
32 Loss: 0.245 | Acc: 99.950
33 Loss: 0.165 | Acc: 99.970
34 Loss: 0.062 | Acc: 99.990
35 Loss: 0.162 | Acc: 99.980
36 Loss: 0.137 | Acc: 99.980
37 Loss: 0.137 | Acc: 99.980
38 Loss: 0.145 | Acc: 99.980
39 Loss: 0.080 | Acc: 99.990
40 Loss: 0.062 | Acc: 99.990
41 Loss: 0.068 | Acc: 99.990
42 Loss: 0.009 | Acc: 100.000
43 Loss: 0.029 | Acc: 100.000
44 Loss: 0.108 | Acc: 99.980
45 Loss: 0.073 | Acc: 99.980
46 Loss: 0.044 | Acc: 99.990
47 Loss: 0.011 | Acc: 100.000
48 Loss: 0.026 | Acc: 99.990
49 Loss: 0.048 | Acc: 99.990
50 Loss: 0.009 | Acc: 100.000
51 Loss: 0.051 | Acc: 99.990
52 Loss: 0.024 | Acc: 99.990
53 Loss: 0.005 | Acc: 100.000
54 Loss: 0.030 | Acc: 99.990
55 Loss: 0.015 | Acc: 100.000
56 Loss: 0.011 | Acc: 100.000
57 Loss: 0.013 | Acc: 100.000
58 Loss: 0.037 | Acc: 99.990
59 Loss: 0.039 | Acc: 99.990
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 6
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 4
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 6
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 4
nodeId:  12 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 5000
nodeId:  13 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  7
0 Train Loss: 80.063 | Train Acc: 61.333
1 Train Loss: 65.837 | Train Acc: 71.320
2 Train Loss: 62.805 | Train Acc: 72.780
3 Train Loss: 59.369 | Train Acc: 74.580
4 Train Loss: 57.407 | Train Acc: 75.393
5 Train Loss: 54.858 | Train Acc: 76.800
6 Train Loss: 53.158 | Train Acc: 77.487
7 Train Loss: 51.271 | Train Acc: 78.540
8 Train Loss: 49.885 | Train Acc: 78.953
9 Train Loss: 48.442 | Train Acc: 79.907
10 Train Loss: 47.017 | Train Acc: 80.600
11 Train Loss: 45.639 | Train Acc: 81.240
12 Train Loss: 44.711 | Train Acc: 81.373
13 Train Loss: 42.473 | Train Acc: 82.587
14 Train Loss: 42.227 | Train Acc: 82.693
15 Train Loss: 40.263 | Train Acc: 83.687
16 Train Loss: 40.127 | Train Acc: 83.680
17 Train Loss: 38.058 | Train Acc: 84.840
18 Train Loss: 37.100 | Train Acc: 85.033
19 Train Loss: 36.401 | Train Acc: 85.500
20 Train Loss: 32.647 | Train Acc: 87.560
21 Train Loss: 31.376 | Train Acc: 88.440
22 Train Loss: 31.182 | Train Acc: 88.333
23 Train Loss: 30.556 | Train Acc: 88.967
24 Train Loss: 30.053 | Train Acc: 88.913
25 Train Loss: 29.650 | Train Acc: 89.260
26 Train Loss: 29.415 | Train Acc: 89.420
27 Train Loss: 29.149 | Train Acc: 89.347
28 Train Loss: 28.613 | Train Acc: 89.540
29 Train Loss: 27.960 | Train Acc: 90.107
30 Train Loss: 27.826 | Train Acc: 90.033
31 Train Loss: 27.287 | Train Acc: 90.193
32 Train Loss: 26.663 | Train Acc: 90.507
33 Train Loss: 26.286 | Train Acc: 91.040
34 Train Loss: 25.963 | Train Acc: 91.000
35 Train Loss: 25.572 | Train Acc: 91.173
36 Train Loss: 25.230 | Train Acc: 91.107
37 Train Loss: 25.102 | Train Acc: 91.187
38 Train Loss: 24.448 | Train Acc: 91.520
39 Train Loss: 24.243 | Train Acc: 91.873
40 Train Loss: 22.640 | Train Acc: 92.740
41 Train Loss: 22.505 | Train Acc: 92.853
42 Train Loss: 22.273 | Train Acc: 93.033
43 Train Loss: 22.123 | Train Acc: 92.987
44 Train Loss: 21.957 | Train Acc: 93.147
45 Train Loss: 21.804 | Train Acc: 93.220
46 Train Loss: 21.743 | Train Acc: 93.320
47 Train Loss: 21.597 | Train Acc: 93.227
48 Train Loss: 21.462 | Train Acc: 93.380
49 Train Loss: 21.253 | Train Acc: 93.613
50 Train Loss: 21.178 | Train Acc: 93.400
51 Train Loss: 21.013 | Train Acc: 93.500
52 Train Loss: 20.830 | Train Acc: 93.453
53 Train Loss: 20.741 | Train Acc: 93.620
54 Train Loss: 20.485 | Train Acc: 93.847
55 Train Loss: 20.347 | Train Acc: 93.967
56 Train Loss: 20.314 | Train Acc: 93.807
57 Train Loss: 20.062 | Train Acc: 93.940
58 Train Loss: 19.995 | Train Acc: 94.060
59 Train Loss: 19.745 | Train Acc: 94.173
60 Train Loss: 19.231 | Train Acc: 94.387
61 Train Loss: 19.202 | Train Acc: 94.400
62 Train Loss: 19.065 | Train Acc: 94.587
63 Train Loss: 19.028 | Train Acc: 94.573
64 Train Loss: 18.973 | Train Acc: 94.587
65 Train Loss: 18.906 | Train Acc: 94.580
66 Train Loss: 18.880 | Train Acc: 94.600
67 Train Loss: 18.806 | Train Acc: 94.673
68 Train Loss: 18.770 | Train Acc: 94.680
69 Train Loss: 18.742 | Train Acc: 94.533
70 Train Loss: 18.616 | Train Acc: 94.800
71 Train Loss: 18.586 | Train Acc: 94.793
72 Train Loss: 18.525 | Train Acc: 94.880
73 Train Loss: 18.509 | Train Acc: 94.867
74 Train Loss: 18.419 | Train Acc: 94.847
75 Train Loss: 18.360 | Train Acc: 94.860
76 Train Loss: 18.289 | Train Acc: 94.880
77 Train Loss: 18.229 | Train Acc: 94.940
78 Train Loss: 18.176 | Train Acc: 94.960
79 Train Loss: 18.117 | Train Acc: 94.907
80 Train Loss: 17.872 | Train Acc: 95.120
81 Train Loss: 17.860 | Train Acc: 95.073
82 Train Loss: 17.817 | Train Acc: 95.220
83 Train Loss: 17.809 | Train Acc: 95.140
84 Train Loss: 17.763 | Train Acc: 95.160
85 Train Loss: 17.764 | Train Acc: 95.153
86 Train Loss: 17.718 | Train Acc: 95.167
87 Train Loss: 17.706 | Train Acc: 95.193
88 Train Loss: 17.691 | Train Acc: 95.180
89 Train Loss: 17.663 | Train Acc: 95.140
90 Train Loss: 17.651 | Train Acc: 95.140
91 Train Loss: 17.613 | Train Acc: 95.260
92 Train Loss: 17.588 | Train Acc: 95.247
93 Train Loss: 17.576 | Train Acc: 95.280
94 Train Loss: 17.541 | Train Acc: 95.227
95 Train Loss: 17.526 | Train Acc: 95.220
96 Train Loss: 17.503 | Train Acc: 95.280
97 Train Loss: 17.470 | Train Acc: 95.307
98 Train Loss: 17.454 | Train Acc: 95.287
99 Train Loss: 17.430 | Train Acc: 95.327
CNN trained successfully...
image_next_flat.shape :  torch.Size([15000, 6400])
printing expected split from k means
{2: 0, 1: 1, 0: 1}
Printing final_dict items...
{2: 0, 1: 1, 0: 1}
Image Statistics before MLP : L R :  5000 10000
expectedMlpLabels.shape :  torch.Size([15000])
0 Loss: 45.729 | Acc: 85.847
1 Loss: 34.466 | Acc: 89.853
2 Loss: 30.115 | Acc: 91.180
3 Loss: 26.977 | Acc: 91.887
4 Loss: 23.226 | Acc: 92.953
5 Loss: 20.029 | Acc: 93.873
6 Loss: 16.655 | Acc: 94.713
7 Loss: 15.422 | Acc: 95.447
8 Loss: 11.708 | Acc: 96.567
9 Loss: 10.680 | Acc: 96.760
10 Loss: 5.457 | Acc: 98.540
11 Loss: 3.672 | Acc: 98.967
12 Loss: 3.514 | Acc: 99.033
13 Loss: 2.379 | Acc: 99.387
14 Loss: 1.980 | Acc: 99.513
15 Loss: 2.470 | Acc: 99.280
16 Loss: 1.992 | Acc: 99.467
17 Loss: 1.693 | Acc: 99.607
18 Loss: 1.855 | Acc: 99.580
19 Loss: 2.129 | Acc: 99.507
20 Loss: 0.965 | Acc: 99.740
21 Loss: 0.875 | Acc: 99.820
22 Loss: 0.570 | Acc: 99.907
23 Loss: 0.535 | Acc: 99.840
24 Loss: 0.640 | Acc: 99.907
25 Loss: 0.259 | Acc: 99.960
26 Loss: 0.148 | Acc: 99.973
27 Loss: 0.863 | Acc: 99.787
28 Loss: 0.520 | Acc: 99.907
29 Loss: 0.270 | Acc: 99.920
30 Loss: 0.340 | Acc: 99.933
31 Loss: 0.370 | Acc: 99.933
32 Loss: 0.113 | Acc: 99.993
33 Loss: 0.315 | Acc: 99.947
34 Loss: 0.115 | Acc: 99.973
35 Loss: 0.176 | Acc: 99.973
36 Loss: 0.363 | Acc: 99.940
37 Loss: 0.102 | Acc: 99.987
38 Loss: 0.189 | Acc: 99.967
39 Loss: 0.170 | Acc: 99.973
40 Loss: 0.106 | Acc: 99.973
41 Loss: 0.106 | Acc: 99.980
42 Loss: 0.058 | Acc: 99.987
43 Loss: 0.077 | Acc: 99.980
44 Loss: 0.199 | Acc: 99.987
45 Loss: 0.080 | Acc: 99.987
46 Loss: 0.193 | Acc: 99.980
47 Loss: 0.107 | Acc: 99.987
48 Loss: 0.036 | Acc: 100.000
49 Loss: 0.404 | Acc: 99.947
50 Loss: 0.097 | Acc: 99.987
51 Loss: 0.125 | Acc: 99.967
52 Loss: 0.077 | Acc: 99.980
53 Loss: 0.077 | Acc: 99.973
54 Loss: 0.036 | Acc: 99.993
55 Loss: 0.044 | Acc: 99.987
56 Loss: 0.087 | Acc: 99.987
57 Loss: 0.202 | Acc: 99.973
58 Loss: 0.029 | Acc: 100.000
59 Loss: 0.103 | Acc: 99.980
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  10000.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 0, 5000, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([10000, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([10000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
nodeId:  14 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 5000
nodeId:  15 , imgTensorShape :  torch.Size([10000, 16, 20, 20])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 10000
Running nodeId:  8
Running nodeId:  9
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 20.048 | Train Acc: 91.090
1 Train Loss: 12.682 | Train Acc: 95.270
2 Train Loss: 10.824 | Train Acc: 95.820
3 Train Loss: 9.837 | Train Acc: 96.310
4 Train Loss: 8.831 | Train Acc: 96.340
5 Train Loss: 7.785 | Train Acc: 96.960
6 Train Loss: 7.712 | Train Acc: 97.020
7 Train Loss: 6.780 | Train Acc: 97.350
8 Train Loss: 6.200 | Train Acc: 97.570
9 Train Loss: 5.587 | Train Acc: 97.930
10 Train Loss: 4.931 | Train Acc: 98.110
11 Train Loss: 4.775 | Train Acc: 98.140
12 Train Loss: 4.127 | Train Acc: 98.550
13 Train Loss: 3.386 | Train Acc: 98.790
14 Train Loss: 3.030 | Train Acc: 98.970
15 Train Loss: 2.793 | Train Acc: 99.110
16 Train Loss: 2.685 | Train Acc: 99.150
17 Train Loss: 2.030 | Train Acc: 99.450
18 Train Loss: 1.743 | Train Acc: 99.550
19 Train Loss: 1.539 | Train Acc: 99.600
20 Train Loss: 0.908 | Train Acc: 99.850
21 Train Loss: 0.768 | Train Acc: 99.920
22 Train Loss: 0.678 | Train Acc: 99.960
23 Train Loss: 0.622 | Train Acc: 99.970
24 Train Loss: 0.605 | Train Acc: 99.980
25 Train Loss: 0.552 | Train Acc: 100.000
26 Train Loss: 0.515 | Train Acc: 99.990
27 Train Loss: 0.473 | Train Acc: 100.000
28 Train Loss: 0.457 | Train Acc: 99.990
29 Train Loss: 0.438 | Train Acc: 100.000
30 Train Loss: 0.401 | Train Acc: 100.000
31 Train Loss: 0.390 | Train Acc: 100.000
32 Train Loss: 0.349 | Train Acc: 100.000
33 Train Loss: 0.361 | Train Acc: 100.000
34 Train Loss: 0.309 | Train Acc: 100.000
35 Train Loss: 0.300 | Train Acc: 100.000
36 Train Loss: 0.274 | Train Acc: 100.000
37 Train Loss: 0.245 | Train Acc: 100.000
38 Train Loss: 0.244 | Train Acc: 100.000
39 Train Loss: 0.248 | Train Acc: 100.000
40 Train Loss: 0.192 | Train Acc: 100.000
41 Train Loss: 0.183 | Train Acc: 100.000
42 Train Loss: 0.181 | Train Acc: 100.000
43 Train Loss: 0.174 | Train Acc: 100.000
44 Train Loss: 0.167 | Train Acc: 100.000
45 Train Loss: 0.163 | Train Acc: 100.000
46 Train Loss: 0.159 | Train Acc: 100.000
47 Train Loss: 0.153 | Train Acc: 100.000
48 Train Loss: 0.152 | Train Acc: 100.000
49 Train Loss: 0.144 | Train Acc: 100.000
50 Train Loss: 0.140 | Train Acc: 100.000
51 Train Loss: 0.135 | Train Acc: 100.000
52 Train Loss: 0.135 | Train Acc: 100.000
53 Train Loss: 0.130 | Train Acc: 100.000
54 Train Loss: 0.122 | Train Acc: 100.000
55 Train Loss: 0.118 | Train Acc: 100.000
56 Train Loss: 0.113 | Train Acc: 100.000
57 Train Loss: 0.110 | Train Acc: 100.000
58 Train Loss: 0.106 | Train Acc: 100.000
59 Train Loss: 0.102 | Train Acc: 100.000
60 Train Loss: 0.095 | Train Acc: 100.000
61 Train Loss: 0.093 | Train Acc: 100.000
62 Train Loss: 0.091 | Train Acc: 100.000
63 Train Loss: 0.090 | Train Acc: 100.000
64 Train Loss: 0.089 | Train Acc: 100.000
65 Train Loss: 0.088 | Train Acc: 100.000
66 Train Loss: 0.085 | Train Acc: 100.000
67 Train Loss: 0.084 | Train Acc: 100.000
68 Train Loss: 0.082 | Train Acc: 100.000
69 Train Loss: 0.081 | Train Acc: 100.000
70 Train Loss: 0.080 | Train Acc: 100.000
71 Train Loss: 0.079 | Train Acc: 100.000
72 Train Loss: 0.077 | Train Acc: 100.000
73 Train Loss: 0.076 | Train Acc: 100.000
74 Train Loss: 0.074 | Train Acc: 100.000
75 Train Loss: 0.072 | Train Acc: 100.000
76 Train Loss: 0.071 | Train Acc: 100.000
77 Train Loss: 0.069 | Train Acc: 100.000
78 Train Loss: 0.068 | Train Acc: 100.000
79 Train Loss: 0.065 | Train Acc: 100.000
80 Train Loss: 0.064 | Train Acc: 100.000
81 Train Loss: 0.062 | Train Acc: 100.000
82 Train Loss: 0.062 | Train Acc: 100.000
83 Train Loss: 0.061 | Train Acc: 100.000
84 Train Loss: 0.061 | Train Acc: 100.000
85 Train Loss: 0.060 | Train Acc: 100.000
86 Train Loss: 0.059 | Train Acc: 100.000
87 Train Loss: 0.059 | Train Acc: 100.000
88 Train Loss: 0.058 | Train Acc: 100.000
89 Train Loss: 0.057 | Train Acc: 100.000
90 Train Loss: 0.057 | Train Acc: 100.000
91 Train Loss: 0.056 | Train Acc: 100.000
92 Train Loss: 0.056 | Train Acc: 100.000
93 Train Loss: 0.055 | Train Acc: 100.000
94 Train Loss: 0.054 | Train Acc: 100.000
95 Train Loss: 0.054 | Train Acc: 100.000
96 Train Loss: 0.054 | Train Acc: 100.000
97 Train Loss: 0.052 | Train Acc: 100.000
98 Train Loss: 0.051 | Train Acc: 100.000
99 Train Loss: 0.051 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([10000, 4096])
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  5000 5000
expectedMlpLabels.shape :  torch.Size([10000])
0 Loss: 30.368 | Acc: 94.590
1 Loss: 16.410 | Acc: 96.880
2 Loss: 13.313 | Acc: 97.690
3 Loss: 10.171 | Acc: 98.240
4 Loss: 8.760 | Acc: 98.340
5 Loss: 7.346 | Acc: 98.600
6 Loss: 6.642 | Acc: 98.840
7 Loss: 7.498 | Acc: 98.700
8 Loss: 3.858 | Acc: 99.390
9 Loss: 5.008 | Acc: 99.140
10 Loss: 1.635 | Acc: 99.800
11 Loss: 0.940 | Acc: 99.830
12 Loss: 1.052 | Acc: 99.830
13 Loss: 1.149 | Acc: 99.830
14 Loss: 0.629 | Acc: 99.910
15 Loss: 1.407 | Acc: 99.790
16 Loss: 0.484 | Acc: 99.920
17 Loss: 0.178 | Acc: 99.970
18 Loss: 1.722 | Acc: 99.720
19 Loss: 0.321 | Acc: 99.940
20 Loss: 0.253 | Acc: 99.960
21 Loss: 0.262 | Acc: 99.950
22 Loss: 0.089 | Acc: 99.990
23 Loss: 0.203 | Acc: 99.960
24 Loss: 0.061 | Acc: 99.990
25 Loss: 0.054 | Acc: 99.980
26 Loss: 0.221 | Acc: 99.960
27 Loss: 0.055 | Acc: 99.990
28 Loss: 0.097 | Acc: 99.970
29 Loss: 0.187 | Acc: 99.950
30 Loss: 0.036 | Acc: 99.990
31 Loss: 0.024 | Acc: 100.000
32 Loss: 0.060 | Acc: 99.990
33 Loss: 0.010 | Acc: 100.000
34 Loss: 0.027 | Acc: 100.000
35 Loss: 0.027 | Acc: 100.000
36 Loss: 0.028 | Acc: 100.000
37 Loss: 0.016 | Acc: 100.000
38 Loss: 0.005 | Acc: 100.000
39 Loss: 0.019 | Acc: 100.000
40 Loss: 0.005 | Acc: 100.000
41 Loss: 0.004 | Acc: 100.000
42 Loss: 0.025 | Acc: 99.990
43 Loss: 0.011 | Acc: 100.000
44 Loss: 0.060 | Acc: 99.990
45 Loss: 0.007 | Acc: 100.000
46 Loss: 0.006 | Acc: 100.000
47 Loss: 0.114 | Acc: 99.990
48 Loss: 0.001 | Acc: 100.000
49 Loss: 0.046 | Acc: 99.990
50 Loss: 0.165 | Acc: 99.990
51 Loss: 0.004 | Acc: 100.000
52 Loss: 0.001 | Acc: 100.000
53 Loss: 0.014 | Acc: 100.000
54 Loss: 0.007 | Acc: 100.000
55 Loss: 0.003 | Acc: 100.000
56 Loss: 0.019 | Acc: 100.000
57 Loss: 0.072 | Acc: 99.980
58 Loss: 0.031 | Acc: 99.990
59 Loss: 0.001 | Acc: 100.000
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 2
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 2
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  16 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 5000
nodeId:  17 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  12
Running nodeId:  13
Running nodeId:  14
Running nodeId:  15
0 Train Loss: 60.143 | Train Acc: 66.230
1 Train Loss: 54.077 | Train Acc: 73.110
2 Train Loss: 49.765 | Train Acc: 74.950
3 Train Loss: 46.430 | Train Acc: 77.850
4 Train Loss: 44.872 | Train Acc: 78.550
5 Train Loss: 42.995 | Train Acc: 79.730
6 Train Loss: 40.880 | Train Acc: 80.930
7 Train Loss: 38.717 | Train Acc: 82.060
8 Train Loss: 37.529 | Train Acc: 83.000
9 Train Loss: 35.566 | Train Acc: 84.400
10 Train Loss: 33.853 | Train Acc: 84.820
11 Train Loss: 32.721 | Train Acc: 85.370
12 Train Loss: 31.508 | Train Acc: 86.000
13 Train Loss: 29.648 | Train Acc: 87.070
14 Train Loss: 28.002 | Train Acc: 88.180
15 Train Loss: 28.115 | Train Acc: 88.050
16 Train Loss: 25.922 | Train Acc: 89.040
17 Train Loss: 25.163 | Train Acc: 89.610
18 Train Loss: 25.210 | Train Acc: 89.290
19 Train Loss: 23.180 | Train Acc: 90.670
20 Train Loss: 20.390 | Train Acc: 92.270
21 Train Loss: 19.501 | Train Acc: 93.000
22 Train Loss: 18.873 | Train Acc: 93.210
23 Train Loss: 18.936 | Train Acc: 93.040
24 Train Loss: 18.305 | Train Acc: 93.330
25 Train Loss: 17.987 | Train Acc: 93.650
26 Train Loss: 17.788 | Train Acc: 93.710
27 Train Loss: 17.393 | Train Acc: 93.980
28 Train Loss: 17.021 | Train Acc: 94.140
29 Train Loss: 16.555 | Train Acc: 94.540
30 Train Loss: 16.243 | Train Acc: 94.610
31 Train Loss: 15.958 | Train Acc: 94.650
32 Train Loss: 15.821 | Train Acc: 94.690
33 Train Loss: 15.658 | Train Acc: 94.840
34 Train Loss: 15.021 | Train Acc: 95.170
35 Train Loss: 14.924 | Train Acc: 95.150
36 Train Loss: 14.593 | Train Acc: 95.540
37 Train Loss: 14.178 | Train Acc: 95.670
38 Train Loss: 13.840 | Train Acc: 95.830
39 Train Loss: 13.669 | Train Acc: 95.930
40 Train Loss: 12.604 | Train Acc: 96.590
41 Train Loss: 12.410 | Train Acc: 96.650
42 Train Loss: 12.358 | Train Acc: 96.740
43 Train Loss: 12.253 | Train Acc: 96.770
44 Train Loss: 12.154 | Train Acc: 96.830
45 Train Loss: 12.052 | Train Acc: 96.940
46 Train Loss: 11.922 | Train Acc: 96.940
47 Train Loss: 11.889 | Train Acc: 96.880
48 Train Loss: 11.743 | Train Acc: 97.000
49 Train Loss: 11.660 | Train Acc: 97.000
50 Train Loss: 11.594 | Train Acc: 97.040
51 Train Loss: 11.390 | Train Acc: 97.210
52 Train Loss: 11.236 | Train Acc: 97.340
53 Train Loss: 11.185 | Train Acc: 97.310
54 Train Loss: 11.063 | Train Acc: 97.350
55 Train Loss: 10.988 | Train Acc: 97.390
56 Train Loss: 10.873 | Train Acc: 97.470
57 Train Loss: 10.730 | Train Acc: 97.530
58 Train Loss: 10.624 | Train Acc: 97.590
59 Train Loss: 10.616 | Train Acc: 97.530
60 Train Loss: 10.140 | Train Acc: 97.960
61 Train Loss: 10.097 | Train Acc: 97.850
62 Train Loss: 10.050 | Train Acc: 97.840
63 Train Loss: 10.050 | Train Acc: 97.830
64 Train Loss: 9.973 | Train Acc: 97.950
65 Train Loss: 9.906 | Train Acc: 97.950
66 Train Loss: 9.888 | Train Acc: 97.970
67 Train Loss: 9.830 | Train Acc: 97.960
68 Train Loss: 9.787 | Train Acc: 97.920
69 Train Loss: 9.801 | Train Acc: 97.920
70 Train Loss: 9.679 | Train Acc: 98.050
71 Train Loss: 9.662 | Train Acc: 98.150
72 Train Loss: 9.615 | Train Acc: 98.080
73 Train Loss: 9.576 | Train Acc: 98.130
74 Train Loss: 9.536 | Train Acc: 98.080
75 Train Loss: 9.492 | Train Acc: 98.100
76 Train Loss: 9.475 | Train Acc: 98.230
77 Train Loss: 9.422 | Train Acc: 98.210
78 Train Loss: 9.385 | Train Acc: 98.170
79 Train Loss: 9.350 | Train Acc: 98.210
80 Train Loss: 9.167 | Train Acc: 98.250
81 Train Loss: 9.138 | Train Acc: 98.310
82 Train Loss: 9.137 | Train Acc: 98.300
83 Train Loss: 9.112 | Train Acc: 98.300
84 Train Loss: 9.088 | Train Acc: 98.300
85 Train Loss: 9.079 | Train Acc: 98.400
86 Train Loss: 9.062 | Train Acc: 98.340
87 Train Loss: 9.034 | Train Acc: 98.310
88 Train Loss: 9.017 | Train Acc: 98.360
89 Train Loss: 9.015 | Train Acc: 98.300
90 Train Loss: 9.013 | Train Acc: 98.420
91 Train Loss: 8.970 | Train Acc: 98.360
92 Train Loss: 8.954 | Train Acc: 98.350
93 Train Loss: 8.929 | Train Acc: 98.420
94 Train Loss: 8.912 | Train Acc: 98.400
95 Train Loss: 8.906 | Train Acc: 98.400
96 Train Loss: 8.884 | Train Acc: 98.430
97 Train Loss: 8.862 | Train Acc: 98.460
98 Train Loss: 8.869 | Train Acc: 98.440
99 Train Loss: 8.850 | Train Acc: 98.430
CNN trained successfully...
image_next_flat.shape :  torch.Size([10000, 4096])
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  5000 5000
expectedMlpLabels.shape :  torch.Size([10000])
0 Loss: 104.073 | Acc: 73.770
1 Loss: 77.941 | Acc: 82.670
2 Loss: 64.506 | Acc: 86.000
3 Loss: 52.161 | Acc: 88.770
4 Loss: 45.750 | Acc: 90.430
5 Loss: 41.799 | Acc: 91.140
6 Loss: 37.827 | Acc: 92.300
7 Loss: 32.176 | Acc: 93.290
8 Loss: 27.596 | Acc: 94.560
9 Loss: 22.759 | Acc: 95.490
10 Loss: 12.067 | Acc: 97.580
11 Loss: 7.752 | Acc: 98.460
12 Loss: 7.818 | Acc: 98.530
13 Loss: 5.583 | Acc: 99.000
14 Loss: 5.388 | Acc: 98.900
15 Loss: 5.378 | Acc: 99.150
16 Loss: 3.569 | Acc: 99.390
17 Loss: 4.108 | Acc: 99.190
18 Loss: 4.656 | Acc: 99.200
19 Loss: 3.395 | Acc: 99.480
20 Loss: 2.721 | Acc: 99.560
21 Loss: 1.710 | Acc: 99.720
22 Loss: 1.309 | Acc: 99.850
23 Loss: 0.770 | Acc: 99.790
24 Loss: 1.196 | Acc: 99.820
25 Loss: 1.631 | Acc: 99.730
26 Loss: 1.491 | Acc: 99.710
27 Loss: 0.932 | Acc: 99.810
28 Loss: 0.837 | Acc: 99.890
29 Loss: 1.882 | Acc: 99.730
30 Loss: 1.216 | Acc: 99.760
31 Loss: 0.398 | Acc: 99.970
32 Loss: 0.721 | Acc: 99.920
33 Loss: 0.387 | Acc: 99.960
34 Loss: 0.461 | Acc: 99.940
35 Loss: 0.619 | Acc: 99.930
36 Loss: 0.218 | Acc: 99.990
37 Loss: 0.225 | Acc: 99.960
38 Loss: 0.232 | Acc: 99.970
39 Loss: 0.171 | Acc: 99.970
40 Loss: 0.318 | Acc: 99.950
41 Loss: 0.236 | Acc: 99.970
42 Loss: 0.379 | Acc: 99.940
43 Loss: 0.102 | Acc: 99.990
44 Loss: 0.145 | Acc: 99.970
45 Loss: 0.177 | Acc: 99.970
46 Loss: 0.129 | Acc: 99.980
47 Loss: 0.240 | Acc: 99.950
48 Loss: 0.268 | Acc: 99.950
49 Loss: 0.326 | Acc: 99.970
50 Loss: 0.187 | Acc: 99.970
51 Loss: 0.165 | Acc: 99.970
52 Loss: 0.107 | Acc: 99.980
53 Loss: 0.048 | Acc: 99.990
54 Loss: 0.122 | Acc: 99.970
55 Loss: 0.164 | Acc: 99.980
56 Loss: 0.264 | Acc: 99.970
57 Loss: 0.051 | Acc: 100.000
58 Loss: 0.046 | Acc: 100.000
59 Loss: 0.065 | Acc: 99.990
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 5
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 3
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 5
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 3
nodeId:  18 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 5000
nodeId:  19 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 58.960
Split Acc: 87.720
# of Left images:  4790.0
# of Right images:  5210.0
giniRightRatio:  0.8438930743697525
giniLeftRatio:  0.8336224999019355
impurityDrop:  0.8344504540816827
giniGain:  0.0655495459183173
lclasses:  [902, 959, 579, 117, 135, 78, 96, 83, 928, 913]
rclasses:  [98, 41, 421, 883, 865, 922, 904, 917, 72, 87]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([4790, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([4790])
rTrainDict[data].shape:  torch.Size([5210, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([5210])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([4790, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4790
nodeId:  3 , imgTensorShape :  torch.Size([5210, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5210
Nodes sizes =  5 5
Node 2 Acc: 69.207
Split Acc: 80.501
# of Left images:  2001.0
# of Right images:  2789.0
giniRightRatio:  0.768945407488133
giniLeftRatio:  0.6635852488548329
impurityDrop:  0.6933535547003118
giniGain:  0.1402689452016237
lclasses:  [789, 57, 83, 38, 50, 19, 17, 28, 838, 82]
rclasses:  [113, 902, 496, 79, 85, 59, 79, 55, 90, 831]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2001, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([2001])
rTrainDict[data].shape:  torch.Size([2789, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([2789])
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([2001, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2001
nodeId:  5 , imgTensorShape :  torch.Size([2789, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2789
Nodes sizes =  2 3
Node 3 Acc: 55.681
Split Acc: 73.896
# of Left images:  2013.0
# of Right images:  3197.0
giniRightRatio:  0.7964318675752575
giniLeftRatio:  0.7265003014434985
impurityDrop:  0.752399261187009
giniGain:  0.09149381318274352
lclasses:  [41, 16, 178, 152, 657, 90, 779, 66, 20, 14]
rclasses:  [57, 25, 243, 731, 208, 832, 125, 851, 52, 73]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2013, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([2013])
rTrainDict[data].shape:  torch.Size([3197, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([3197])
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([2013, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2013
nodeId:  7 , imgTensorShape :  torch.Size([3197, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3197
Nodes sizes =  2 3
Node 4 Acc: 73.163
Split Acc: 73.913
# of Left images:  994.0
# of Right images:  1007.0
giniRightRatio:  0.49062323418296355
giniLeftRatio:  0.38969835107222817
impurityDrop:  0.3910012542305594
giniGain:  0.2725839946242735
lclasses:  [80, 33, 18, 24, 14, 9, 8, 1, 770, 37]
rclasses:  [709, 24, 65, 14, 36, 10, 9, 27, 68, 45]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([994, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([994])
rTrainDict[data].shape:  torch.Size([1007, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([1007])
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([994, 16, 20, 20])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 994
nodeId:  9 , imgTensorShape :  torch.Size([1007, 16, 20, 20])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 1007
Nodes sizes =  1 1
Node 5 Acc: 69.200
Split Acc: 71.997
# of Left images:  986.0
# of Right images:  1803.0
giniRightRatio:  0.7439446611597298
giniLeftRatio:  0.36467543581746886
impurityDrop:  0.5365350903402792
giniGain:  0.23241031714785376
lclasses:  [29, 779, 8, 14, 8, 4, 12, 5, 37, 90]
rclasses:  [84, 123, 488, 65, 77, 55, 67, 50, 53, 741]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([986, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([986])
rTrainDict[data].shape:  torch.Size([1803, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([1803])
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([986, 16, 20, 20])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 986
nodeId:  11 , imgTensorShape :  torch.Size([1803, 16, 20, 20])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1803
Nodes sizes =  1 2
Node 6 Acc: 64.580
Split Acc: 65.176
# of Left images:  1041.0
# of Right images:  972.0
giniRightRatio:  0.6097901742620535
giniLeftRatio:  0.4958101138619207
impurityDrop:  0.48771893673475075
giniGain:  0.23878136470874778
lclasses:  [15, 6, 73, 83, 71, 39, 726, 10, 8, 10]
rclasses:  [26, 10, 105, 69, 586, 51, 53, 56, 12, 4]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1041, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1041])
rTrainDict[data].shape:  torch.Size([972, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([972])
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([1041, 16, 20, 20])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1041
nodeId:  13 , imgTensorShape :  torch.Size([972, 16, 20, 20])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 972
Nodes sizes =  1 1
Node 7 Acc: 52.330
Split Acc: 67.470
# of Left images:  1023.0
# of Right images:  2174.0
giniRightRatio:  0.7588211098970946
giniLeftRatio:  0.4996039287970041
impurityDrop:  0.6368435679166933
giniGain:  0.15958829965856425
lclasses:  [19, 5, 52, 48, 76, 70, 10, 712, 9, 22]
rclasses:  [38, 20, 191, 683, 132, 762, 115, 139, 43, 51]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1023, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1023])
rTrainDict[data].shape:  torch.Size([2174, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([2174])
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([1023, 16, 20, 20])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 1023
nodeId:  15 , imgTensorShape :  torch.Size([2174, 16, 20, 20])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2174
Nodes sizes =  1 2
Node 8 Acc: 77.465
Node 9 Acc: 70.407
Node 10 Acc: 79.006
Node 11 Acc: 65.946
Split Acc: 66.001
# of Left images:  792.0
# of Right images:  1011.0
giniRightRatio:  0.4718384613954707
giniLeftRatio:  0.6307487756351394
impurityDrop:  0.596326066615864
giniGain:  0.14761859454386583
lclasses:  [51, 19, 466, 43, 64, 46, 50, 19, 17, 17]
rclasses:  [33, 104, 22, 22, 13, 9, 17, 31, 36, 724]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([792, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([792])
rTrainDict[data].shape:  torch.Size([1011, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1011])
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([792, 16, 16, 16])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 792
nodeId:  17 , imgTensorShape :  torch.Size([1011, 16, 16, 16])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1011
Nodes sizes =  1 1
Node 12 Acc: 69.741
Node 13 Acc: 60.288
Node 14 Acc: 69.599
Node 15 Acc: 46.688
Split Acc: 47.194
# of Left images:  1078.0
# of Right images:  1096.0
giniRightRatio:  0.7514801667643456
giniLeftRatio:  0.6844944083216015
impurityDrop:  0.6855945393909166
giniGain:  0.07322657050617798
lclasses:  [14, 9, 82, 208, 56, 551, 45, 85, 14, 14]
rclasses:  [24, 11, 109, 475, 76, 211, 70, 54, 29, 37]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1078, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([1078])
rTrainDict[data].shape:  torch.Size([1096, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1096])
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1078, 16, 16, 16])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1078
nodeId:  19 , imgTensorShape :  torch.Size([1096, 16, 16, 16])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 1096
Nodes sizes =  1 1
Node 16 Acc: 58.838
Node 17 Acc: 71.612
Node 18 Acc: 51.113
Node 19 Acc: 43.339
[[709  29  51  24  26  14  15  19  80  33]
 [ 24 779  19  11  10   9   6   5  33 104]
 [ 65   8 466 109 105  82  73  52  18  22]
 [ 14  14  43 475  69 208  83  48  24  22]
 [ 36   8  64  76 586  56  71  76  14  13]
 [ 10   4  46 211  51 551  39  70   9   9]
 [  9  12  50  70  53  45 726  10   8  17]
 [ 27   5  19  54  56  85  10 712   1  31]
 [ 68  37  17  29  12  14   8   9 770  36]
 [ 45  90  17  37   4  14  10  22  37 724]]

#2:: Case 1 WITH BIG_MLP ARCH :-
Acc: 64.980

                                                             1                                                                 
                   ┌─────────────────────────────────────────┴───────────────────────────┐                                     
                   2                                                                     3                                     
       ┌───────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
       4                         5                                         6                           7                       
 ┌─────┴─────┐            ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
 8           9            10                   11                   12            13            14                   15        
                                        ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                        16            17                                                      18            19 

                                                       -1                                                      
                   ┌───────────────────────────────────┴───────────────────────┐                               
                   -1                                                          -1                              
       ┌───────────┴───────────┐                                   ┌───────────┴───────────┐                   
       -1                      -1                                  -1                      -1                  
 ┌─────┴─────┐           ┌─────┴───────────┐                 ┌─────┴─────┐           ┌─────┴───────────┐       
 8           0           1                 -1                6           4           7                 -1      
                                     ┌─────┴─────┐                                               ┌─────┴─────┐ 
                                     2           9                                               5           3 

                                                                         50000                                                                         
                           ┌───────────────────────────────────────────────┴───────────────────────────────┐                                           
                         25000                                                                           25000                                         
           ┌───────────────┴───────────────┐                                               ┌───────────────┴───────────────┐                           
         10000                           15000                                           10000                           15000                         
   ┌───────┴───────┐               ┌───────┴───────────────┐                       ┌───────┴───────┐               ┌───────┴───────────────┐           
  5000            5000            5000                   10000                    5000            5000            5000                   10000         
                                                   ┌───────┴───────┐                                                               ┌───────┴───────┐   
                                                  5000            5000                                                            5000            5000 

                                                   {0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}                                                  
                                   ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────┐                                                       
             {0: 5000, 1: 5000, 2: 5000, 8: 5000, 9: 5000}                                                       {3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000}                                 
               ┌───────────────────┴───────────────────┐                                                           ┌───────────────────┴───────────────────┐                                   
       {0: 5000, 8: 5000}                 {1: 5000, 2: 5000, 9: 5000}                                      {4: 5000, 6: 5000}                 {3: 5000, 5: 5000, 7: 5000}                      
     ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐                             ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐               
 {8: 5000}           {0: 5000}           {1: 5000}                 {2: 5000, 9: 5000}                {6: 5000}           {4: 5000}           {7: 5000}                 {3: 5000, 5: 5000}      
                                                                 ┌─────────┴─────────┐                                                                               ┌─────────┴─────────┐     
                                                             {2: 5000}           {9: 5000}                                                                       {5: 5000}           {3: 5000} 

                                                               87.72                                                               
                       ┌─────────────────────────────────────────┴───────────────────────────┐                                     
               80.50104384133611                                                     73.89635316698656                             
         ┌─────────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
 73.91304347826087           71.99713158838293                         65.17635370094386           67.46950265874257               
  ┌──────┴──────┐             ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
 0.0           0.0           0.0           66.00110926234055           0.0           0.0           0.0           47.19411223551058 
                                            ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                           0.0           0.0                                                     0.0           0.0 

                                                         0.09999999999999987                                                         
                       ┌──────────────────────────────────────────┴───────────────────────────┐                                      
              0.24444444444444458                                                    0.24444444444444458                             
         ┌─────────────┴──────────────┐                                         ┌─────────────┴──────────────┐                       
        0.5                  0.41666666666666674                               0.5                  0.41666666666666674              
  ┌──────┴──────┐             ┌──────┴─────────────┐                     ┌──────┴──────┐             ┌──────┴─────────────┐          
 0.0           0.0           0.0                  0.5                   0.0           0.0           0.0                  0.5         
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐   
                                           0.0           0.0                                                      0.0           0.0  

