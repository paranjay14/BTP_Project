==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  50000 ,  len(valInputDict["data"]):  0 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([50000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 50000
Running nodeId:  1
0 Train Loss: 177.246 | Train Acc: 37.916
1 Train Loss: 148.880 | Train Acc: 47.872
2 Train Loss: 136.418 | Train Acc: 52.378
3 Train Loss: 132.068 | Train Acc: 53.810
4 Train Loss: 126.597 | Train Acc: 55.706
5 Train Loss: 123.646 | Train Acc: 56.838
6 Train Loss: 120.314 | Train Acc: 57.976
7 Train Loss: 118.040 | Train Acc: 58.998
8 Train Loss: 115.639 | Train Acc: 59.652
9 Train Loss: 113.236 | Train Acc: 60.650
10 Train Loss: 111.123 | Train Acc: 61.306
11 Train Loss: 109.876 | Train Acc: 61.812
12 Train Loss: 108.882 | Train Acc: 62.118
13 Train Loss: 106.814 | Train Acc: 62.864
14 Train Loss: 105.334 | Train Acc: 63.560
15 Train Loss: 104.289 | Train Acc: 63.930
16 Train Loss: 103.157 | Train Acc: 64.266
17 Train Loss: 102.024 | Train Acc: 64.552
18 Train Loss: 100.916 | Train Acc: 65.052
19 Train Loss: 99.975 | Train Acc: 65.280
20 Train Loss: 96.271 | Train Acc: 66.900
21 Train Loss: 95.517 | Train Acc: 67.176
22 Train Loss: 94.958 | Train Acc: 67.504
23 Train Loss: 94.489 | Train Acc: 67.512
24 Train Loss: 94.384 | Train Acc: 67.656
25 Train Loss: 93.931 | Train Acc: 67.938
26 Train Loss: 93.572 | Train Acc: 67.698
27 Train Loss: 93.384 | Train Acc: 67.972
28 Train Loss: 92.830 | Train Acc: 68.078
29 Train Loss: 92.200 | Train Acc: 68.328
30 Train Loss: 91.952 | Train Acc: 68.398
31 Train Loss: 91.653 | Train Acc: 68.644
32 Train Loss: 91.270 | Train Acc: 68.636
33 Train Loss: 91.247 | Train Acc: 68.716
34 Train Loss: 90.594 | Train Acc: 68.926
35 Train Loss: 90.446 | Train Acc: 68.916
36 Train Loss: 90.030 | Train Acc: 69.240
37 Train Loss: 89.678 | Train Acc: 69.462
38 Train Loss: 89.364 | Train Acc: 69.388
39 Train Loss: 88.892 | Train Acc: 69.596
40 Train Loss: 87.252 | Train Acc: 70.414
41 Train Loss: 87.089 | Train Acc: 70.472
42 Train Loss: 86.986 | Train Acc: 70.558
43 Train Loss: 86.832 | Train Acc: 70.562
44 Train Loss: 86.686 | Train Acc: 70.734
45 Train Loss: 86.618 | Train Acc: 70.568
46 Train Loss: 86.422 | Train Acc: 70.724
47 Train Loss: 86.407 | Train Acc: 70.610
48 Train Loss: 86.162 | Train Acc: 70.752
49 Train Loss: 86.046 | Train Acc: 70.796
50 Train Loss: 85.935 | Train Acc: 70.818
51 Train Loss: 85.715 | Train Acc: 70.922
52 Train Loss: 85.636 | Train Acc: 70.942
53 Train Loss: 85.556 | Train Acc: 70.856
54 Train Loss: 85.409 | Train Acc: 71.078
55 Train Loss: 85.284 | Train Acc: 71.080
56 Train Loss: 85.140 | Train Acc: 71.170
57 Train Loss: 85.090 | Train Acc: 70.994
58 Train Loss: 84.954 | Train Acc: 71.190
59 Train Loss: 84.663 | Train Acc: 71.310
60 Train Loss: 84.049 | Train Acc: 71.566
61 Train Loss: 83.896 | Train Acc: 71.690
62 Train Loss: 83.814 | Train Acc: 71.764
63 Train Loss: 83.831 | Train Acc: 71.650
64 Train Loss: 83.722 | Train Acc: 71.692
65 Train Loss: 83.690 | Train Acc: 71.778
66 Train Loss: 83.706 | Train Acc: 71.724
67 Train Loss: 83.558 | Train Acc: 71.854
68 Train Loss: 83.566 | Train Acc: 71.836
69 Train Loss: 83.485 | Train Acc: 71.772
70 Train Loss: 83.365 | Train Acc: 71.812
71 Train Loss: 83.350 | Train Acc: 71.888
72 Train Loss: 83.261 | Train Acc: 71.984
73 Train Loss: 83.203 | Train Acc: 71.940
74 Train Loss: 83.159 | Train Acc: 71.918
75 Train Loss: 83.126 | Train Acc: 71.914
76 Train Loss: 83.034 | Train Acc: 71.944
77 Train Loss: 83.033 | Train Acc: 71.984
78 Train Loss: 82.997 | Train Acc: 72.108
79 Train Loss: 82.891 | Train Acc: 71.996
80 Train Loss: 82.602 | Train Acc: 72.186
81 Train Loss: 82.579 | Train Acc: 72.216
82 Train Loss: 82.545 | Train Acc: 72.126
83 Train Loss: 82.493 | Train Acc: 72.244
84 Train Loss: 82.471 | Train Acc: 72.254
85 Train Loss: 82.474 | Train Acc: 72.184
86 Train Loss: 82.447 | Train Acc: 72.186
87 Train Loss: 82.419 | Train Acc: 72.286
88 Train Loss: 82.400 | Train Acc: 72.268
89 Train Loss: 82.407 | Train Acc: 72.258
90 Train Loss: 82.362 | Train Acc: 72.258
91 Train Loss: 82.329 | Train Acc: 72.290
92 Train Loss: 82.317 | Train Acc: 72.218
93 Train Loss: 82.306 | Train Acc: 72.322
94 Train Loss: 82.296 | Train Acc: 72.262
95 Train Loss: 82.259 | Train Acc: 72.246
96 Train Loss: 82.217 | Train Acc: 72.186
97 Train Loss: 82.246 | Train Acc: 72.212
98 Train Loss: 82.167 | Train Acc: 72.318
99 Train Loss: 82.176 | Train Acc: 72.328
CNN trained successfully...
image_next_flat.shape :  torch.Size([50000, 12544])
printing expected split from k means
{9: 0, 1: 0, 8: 0, 7: 1, 2: 1, 6: 1, 4: 1, 5: 1, 0: 0, 3: 1}
Printing final_dict items...
{8: 0, 0: 0, 9: 0, 1: 0, 2: 0, 3: 1, 5: 1, 7: 1, 4: 1, 6: 1}
Image Statistics before MLP : L R :  25000 25000
expectedMlpLabels.shape :  torch.Size([50000])
0 Loss: 83.283 | Acc: 81.434
1 Loss: 72.817 | Acc: 84.106
2 Loss: 69.359 | Acc: 84.896
3 Loss: 66.096 | Acc: 85.778
4 Loss: 63.946 | Acc: 86.238
5 Loss: 61.270 | Acc: 86.758
6 Loss: 59.629 | Acc: 87.168
7 Loss: 57.133 | Acc: 87.650
8 Loss: 55.681 | Acc: 87.926
9 Loss: 54.086 | Acc: 88.256
10 Loss: 48.503 | Acc: 89.508
11 Loss: 46.237 | Acc: 89.868
12 Loss: 44.776 | Acc: 90.314
13 Loss: 43.331 | Acc: 90.614
14 Loss: 41.575 | Acc: 90.982
15 Loss: 40.464 | Acc: 91.256
16 Loss: 39.522 | Acc: 91.498
17 Loss: 38.512 | Acc: 91.740
18 Loss: 37.433 | Acc: 91.964
19 Loss: 35.810 | Acc: 92.320
20 Loss: 32.626 | Acc: 93.168
21 Loss: 30.921 | Acc: 93.464
22 Loss: 30.327 | Acc: 93.588
23 Loss: 29.437 | Acc: 93.776
24 Loss: 28.962 | Acc: 93.776
25 Loss: 27.611 | Acc: 94.104
26 Loss: 27.626 | Acc: 94.212
27 Loss: 27.316 | Acc: 94.278
28 Loss: 26.393 | Acc: 94.544
29 Loss: 25.817 | Acc: 94.738
30 Loss: 23.953 | Acc: 95.080
31 Loss: 24.035 | Acc: 95.098
32 Loss: 23.812 | Acc: 95.042
33 Loss: 23.030 | Acc: 95.172
34 Loss: 22.957 | Acc: 95.262
35 Loss: 22.307 | Acc: 95.464
36 Loss: 21.915 | Acc: 95.620
37 Loss: 21.866 | Acc: 95.516
38 Loss: 22.106 | Acc: 95.392
39 Loss: 21.549 | Acc: 95.534
40 Loss: 20.896 | Acc: 95.728
41 Loss: 20.665 | Acc: 95.796
42 Loss: 20.444 | Acc: 95.868
43 Loss: 20.115 | Acc: 95.878
44 Loss: 20.193 | Acc: 95.880
45 Loss: 19.955 | Acc: 95.890
46 Loss: 19.998 | Acc: 95.872
47 Loss: 19.926 | Acc: 95.914
48 Loss: 20.120 | Acc: 95.980
49 Loss: 19.770 | Acc: 95.868
50 Loss: 19.502 | Acc: 96.032
51 Loss: 19.653 | Acc: 96.004
52 Loss: 19.095 | Acc: 96.100
53 Loss: 19.799 | Acc: 95.986
54 Loss: 19.187 | Acc: 96.202
55 Loss: 19.263 | Acc: 96.064
56 Loss: 18.996 | Acc: 96.028
57 Loss: 18.924 | Acc: 96.204
58 Loss: 18.636 | Acc: 96.134
59 Loss: 18.821 | Acc: 96.130
MLP trained successfully...
# of Left images:  25000.0
# of Right images:  25000.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [5000, 5000, 5000, 0, 0, 0, 0, 0, 5000, 5000]
rclasses:  [0, 0, 0, 5000, 5000, 5000, 5000, 5000, 0, 0]
noOfLeftClasses:  5
noOfRightClasses:  5
lTrainDict[data].shape:  torch.Size([25000, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([25000])
rTrainDict[data].shape:  torch.Size([25000, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([25000])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([25000, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 25000
nodeId:  3 , imgTensorShape :  torch.Size([25000, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 25000
Running nodeId:  2
0 Train Loss: 98.193 | Train Acc: 61.588
1 Train Loss: 78.528 | Train Acc: 70.604
2 Train Loss: 71.946 | Train Acc: 73.448
3 Train Loss: 66.973 | Train Acc: 75.376
4 Train Loss: 63.964 | Train Acc: 76.456
5 Train Loss: 61.498 | Train Acc: 77.476
6 Train Loss: 58.708 | Train Acc: 78.556
7 Train Loss: 56.607 | Train Acc: 79.408
8 Train Loss: 55.340 | Train Acc: 79.972
9 Train Loss: 53.466 | Train Acc: 80.620
10 Train Loss: 52.602 | Train Acc: 80.944
11 Train Loss: 51.409 | Train Acc: 81.652
12 Train Loss: 50.067 | Train Acc: 82.080
13 Train Loss: 48.623 | Train Acc: 82.596
14 Train Loss: 47.302 | Train Acc: 82.896
15 Train Loss: 46.624 | Train Acc: 83.220
16 Train Loss: 45.418 | Train Acc: 84.020
17 Train Loss: 44.458 | Train Acc: 84.052
18 Train Loss: 44.170 | Train Acc: 84.128
19 Train Loss: 42.404 | Train Acc: 84.648
20 Train Loss: 39.624 | Train Acc: 86.004
21 Train Loss: 38.767 | Train Acc: 86.372
22 Train Loss: 38.457 | Train Acc: 86.532
23 Train Loss: 37.990 | Train Acc: 86.680
24 Train Loss: 37.822 | Train Acc: 86.788
25 Train Loss: 37.408 | Train Acc: 86.952
26 Train Loss: 36.897 | Train Acc: 86.996
27 Train Loss: 37.012 | Train Acc: 86.940
28 Train Loss: 36.334 | Train Acc: 87.288
29 Train Loss: 36.126 | Train Acc: 87.364
30 Train Loss: 35.702 | Train Acc: 87.528
31 Train Loss: 35.290 | Train Acc: 87.776
32 Train Loss: 34.721 | Train Acc: 88.076
33 Train Loss: 34.354 | Train Acc: 88.052
34 Train Loss: 34.093 | Train Acc: 88.164
35 Train Loss: 34.482 | Train Acc: 87.952
36 Train Loss: 33.582 | Train Acc: 88.400
37 Train Loss: 33.041 | Train Acc: 88.556
38 Train Loss: 32.826 | Train Acc: 88.668
39 Train Loss: 32.817 | Train Acc: 88.504
40 Train Loss: 31.060 | Train Acc: 89.644
41 Train Loss: 30.774 | Train Acc: 89.776
42 Train Loss: 30.766 | Train Acc: 89.700
43 Train Loss: 30.634 | Train Acc: 89.836
44 Train Loss: 30.399 | Train Acc: 89.724
45 Train Loss: 30.378 | Train Acc: 89.880
46 Train Loss: 30.166 | Train Acc: 90.052
47 Train Loss: 30.156 | Train Acc: 89.904
48 Train Loss: 29.872 | Train Acc: 90.192
49 Train Loss: 29.790 | Train Acc: 90.076
50 Train Loss: 29.616 | Train Acc: 90.152
51 Train Loss: 29.523 | Train Acc: 90.212
52 Train Loss: 29.498 | Train Acc: 90.304
53 Train Loss: 29.365 | Train Acc: 90.256
54 Train Loss: 29.264 | Train Acc: 90.332
55 Train Loss: 29.058 | Train Acc: 90.388
56 Train Loss: 28.893 | Train Acc: 90.504
57 Train Loss: 28.676 | Train Acc: 90.624
58 Train Loss: 28.625 | Train Acc: 90.592
59 Train Loss: 28.483 | Train Acc: 90.548
60 Train Loss: 27.820 | Train Acc: 91.092
61 Train Loss: 27.727 | Train Acc: 91.100
62 Train Loss: 27.688 | Train Acc: 91.196
63 Train Loss: 27.631 | Train Acc: 91.248
64 Train Loss: 27.548 | Train Acc: 91.288
65 Train Loss: 27.518 | Train Acc: 91.164
66 Train Loss: 27.451 | Train Acc: 91.216
67 Train Loss: 27.422 | Train Acc: 91.316
68 Train Loss: 27.312 | Train Acc: 91.408
69 Train Loss: 27.256 | Train Acc: 91.300
70 Train Loss: 27.297 | Train Acc: 91.256
71 Train Loss: 27.185 | Train Acc: 91.280
72 Train Loss: 27.141 | Train Acc: 91.380
73 Train Loss: 27.074 | Train Acc: 91.456
74 Train Loss: 27.038 | Train Acc: 91.520
75 Train Loss: 27.023 | Train Acc: 91.484
76 Train Loss: 26.918 | Train Acc: 91.468
77 Train Loss: 26.845 | Train Acc: 91.520
78 Train Loss: 26.855 | Train Acc: 91.460
79 Train Loss: 26.732 | Train Acc: 91.504
80 Train Loss: 26.479 | Train Acc: 91.776
81 Train Loss: 26.419 | Train Acc: 91.744
82 Train Loss: 26.440 | Train Acc: 91.744
83 Train Loss: 26.415 | Train Acc: 91.708
84 Train Loss: 26.370 | Train Acc: 91.824
85 Train Loss: 26.352 | Train Acc: 91.772
86 Train Loss: 26.330 | Train Acc: 91.768
87 Train Loss: 26.288 | Train Acc: 91.764
88 Train Loss: 26.268 | Train Acc: 91.804
89 Train Loss: 26.281 | Train Acc: 91.900
90 Train Loss: 26.259 | Train Acc: 91.820
91 Train Loss: 26.226 | Train Acc: 91.912
92 Train Loss: 26.181 | Train Acc: 91.880
93 Train Loss: 26.197 | Train Acc: 91.884
94 Train Loss: 26.140 | Train Acc: 91.836
95 Train Loss: 26.103 | Train Acc: 91.864
96 Train Loss: 26.096 | Train Acc: 91.984
97 Train Loss: 26.099 | Train Acc: 91.940
98 Train Loss: 26.095 | Train Acc: 91.896
99 Train Loss: 26.024 | Train Acc: 91.964
CNN trained successfully...
image_next_flat.shape :  torch.Size([25000, 9216])
printing expected split from k means
{2: 0, 3: 0, 4: 1, 0: 0, 1: 1}
Printing final_dict items...
{0: 0, 3: 0, 2: -1, 1: 1, 4: 1}
Image Statistics before MLP : L R :  12500 12500
expectedMlpLabels.shape :  torch.Size([25000])
0 Loss: 93.551 | Acc: 76.988
1 Loss: 77.623 | Acc: 81.048
2 Loss: 73.449 | Acc: 82.204
3 Loss: 69.888 | Acc: 83.052
4 Loss: 69.400 | Acc: 83.180
5 Loss: 65.545 | Acc: 83.728
6 Loss: 65.105 | Acc: 83.672
7 Loss: 63.836 | Acc: 83.992
8 Loss: 60.094 | Acc: 85.200
9 Loss: 59.203 | Acc: 84.872
10 Loss: 53.456 | Acc: 86.200
11 Loss: 52.690 | Acc: 86.240
12 Loss: 51.392 | Acc: 86.428
13 Loss: 49.046 | Acc: 87.028
14 Loss: 48.551 | Acc: 87.380
15 Loss: 47.249 | Acc: 87.612
16 Loss: 46.778 | Acc: 87.664
17 Loss: 44.437 | Acc: 88.284
18 Loss: 43.537 | Acc: 88.688
19 Loss: 42.953 | Acc: 89.044
20 Loss: 39.186 | Acc: 89.664
21 Loss: 37.619 | Acc: 90.024
22 Loss: 37.320 | Acc: 90.452
23 Loss: 36.896 | Acc: 90.440
24 Loss: 35.567 | Acc: 90.696
25 Loss: 35.313 | Acc: 90.900
26 Loss: 34.602 | Acc: 91.112
27 Loss: 33.740 | Acc: 91.088
28 Loss: 33.200 | Acc: 91.360
29 Loss: 32.700 | Acc: 91.540
30 Loss: 30.570 | Acc: 92.084
31 Loss: 29.429 | Acc: 92.392
32 Loss: 29.309 | Acc: 92.688
33 Loss: 28.480 | Acc: 92.784
34 Loss: 29.712 | Acc: 92.500
35 Loss: 28.327 | Acc: 92.924
36 Loss: 27.870 | Acc: 92.904
37 Loss: 27.513 | Acc: 93.028
38 Loss: 27.666 | Acc: 92.988
39 Loss: 27.229 | Acc: 93.316
40 Loss: 25.782 | Acc: 93.696
41 Loss: 26.636 | Acc: 93.248
42 Loss: 25.768 | Acc: 93.648
43 Loss: 25.814 | Acc: 93.616
44 Loss: 24.910 | Acc: 93.772
45 Loss: 25.275 | Acc: 93.780
46 Loss: 25.085 | Acc: 93.816
47 Loss: 25.071 | Acc: 93.812
48 Loss: 25.069 | Acc: 93.892
49 Loss: 25.161 | Acc: 93.884
50 Loss: 24.469 | Acc: 93.968
51 Loss: 24.238 | Acc: 93.900
52 Loss: 24.242 | Acc: 94.072
53 Loss: 24.168 | Acc: 94.008
54 Loss: 24.302 | Acc: 93.964
55 Loss: 23.670 | Acc: 94.184
56 Loss: 24.115 | Acc: 94.172
57 Loss: 24.456 | Acc: 94.056
58 Loss: 23.816 | Acc: 94.228
59 Loss: 24.057 | Acc: 94.264
MLP trained successfully...
# of Left images:  12500.0
# of Right images:  12500.0
giniRightRatio:  0.64
giniLeftRatio:  0.64
impurityDrop:  0.64
giniGain:  0.16000000000000014
lclasses:  [5000, 0, 2500, 5000, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 2500, 0, 5000, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  3
lTrainDict[data].shape:  torch.Size([12500, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([12500])
rTrainDict[data].shape:  torch.Size([12500, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([12500])
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([12500, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12500
nodeId:  5 , imgTensorShape :  torch.Size([12500, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12500
Running nodeId:  3
0 Train Loss: 120.293 | Train Acc: 51.012
1 Train Loss: 102.150 | Train Acc: 59.800
2 Train Loss: 94.951 | Train Acc: 63.096
3 Train Loss: 90.241 | Train Acc: 65.016
4 Train Loss: 87.801 | Train Acc: 65.904
5 Train Loss: 85.206 | Train Acc: 67.252
6 Train Loss: 83.086 | Train Acc: 68.212
7 Train Loss: 81.095 | Train Acc: 68.944
8 Train Loss: 79.138 | Train Acc: 69.952
9 Train Loss: 77.733 | Train Acc: 70.676
10 Train Loss: 76.818 | Train Acc: 70.812
11 Train Loss: 75.312 | Train Acc: 71.168
12 Train Loss: 73.619 | Train Acc: 72.148
13 Train Loss: 72.535 | Train Acc: 72.544
14 Train Loss: 71.051 | Train Acc: 73.076
15 Train Loss: 70.507 | Train Acc: 73.688
16 Train Loss: 69.412 | Train Acc: 73.860
17 Train Loss: 67.405 | Train Acc: 74.776
18 Train Loss: 66.387 | Train Acc: 75.156
19 Train Loss: 65.593 | Train Acc: 75.508
20 Train Loss: 61.732 | Train Acc: 77.472
21 Train Loss: 60.889 | Train Acc: 77.716
22 Train Loss: 60.685 | Train Acc: 77.820
23 Train Loss: 60.020 | Train Acc: 78.316
24 Train Loss: 59.806 | Train Acc: 78.092
25 Train Loss: 59.450 | Train Acc: 78.312
26 Train Loss: 58.850 | Train Acc: 78.296
27 Train Loss: 58.397 | Train Acc: 78.760
28 Train Loss: 58.065 | Train Acc: 78.980
29 Train Loss: 57.627 | Train Acc: 78.844
30 Train Loss: 57.237 | Train Acc: 79.140
31 Train Loss: 56.782 | Train Acc: 79.452
32 Train Loss: 56.578 | Train Acc: 79.588
33 Train Loss: 56.221 | Train Acc: 79.632
34 Train Loss: 55.533 | Train Acc: 79.856
35 Train Loss: 55.159 | Train Acc: 80.076
36 Train Loss: 54.641 | Train Acc: 80.168
37 Train Loss: 54.674 | Train Acc: 80.332
38 Train Loss: 54.009 | Train Acc: 80.612
39 Train Loss: 53.619 | Train Acc: 80.692
40 Train Loss: 51.662 | Train Acc: 81.700
41 Train Loss: 51.416 | Train Acc: 81.856
42 Train Loss: 51.334 | Train Acc: 81.816
43 Train Loss: 51.335 | Train Acc: 81.892
44 Train Loss: 51.017 | Train Acc: 82.048
45 Train Loss: 51.018 | Train Acc: 82.000
46 Train Loss: 50.678 | Train Acc: 82.172
47 Train Loss: 50.524 | Train Acc: 82.196
48 Train Loss: 50.413 | Train Acc: 82.224
49 Train Loss: 50.284 | Train Acc: 82.304
50 Train Loss: 50.049 | Train Acc: 82.372
51 Train Loss: 49.908 | Train Acc: 82.396
52 Train Loss: 49.885 | Train Acc: 82.452
53 Train Loss: 49.616 | Train Acc: 82.488
54 Train Loss: 49.444 | Train Acc: 82.640
55 Train Loss: 49.304 | Train Acc: 82.648
56 Train Loss: 49.021 | Train Acc: 82.804
57 Train Loss: 48.934 | Train Acc: 82.840
58 Train Loss: 48.784 | Train Acc: 82.848
59 Train Loss: 48.709 | Train Acc: 82.988
60 Train Loss: 47.909 | Train Acc: 83.464
61 Train Loss: 47.773 | Train Acc: 83.368
62 Train Loss: 47.710 | Train Acc: 83.440
63 Train Loss: 47.639 | Train Acc: 83.408
64 Train Loss: 47.643 | Train Acc: 83.404
65 Train Loss: 47.518 | Train Acc: 83.556
66 Train Loss: 47.447 | Train Acc: 83.448
67 Train Loss: 47.392 | Train Acc: 83.392
68 Train Loss: 47.296 | Train Acc: 83.568
69 Train Loss: 47.248 | Train Acc: 83.676
70 Train Loss: 47.227 | Train Acc: 83.788
71 Train Loss: 47.328 | Train Acc: 83.652
72 Train Loss: 47.089 | Train Acc: 83.676
73 Train Loss: 46.995 | Train Acc: 83.840
74 Train Loss: 46.970 | Train Acc: 83.836
75 Train Loss: 46.809 | Train Acc: 83.816
76 Train Loss: 46.834 | Train Acc: 83.888
77 Train Loss: 46.703 | Train Acc: 83.880
78 Train Loss: 46.671 | Train Acc: 83.932
79 Train Loss: 46.642 | Train Acc: 83.976
80 Train Loss: 46.252 | Train Acc: 84.032
81 Train Loss: 46.224 | Train Acc: 84.008
82 Train Loss: 46.180 | Train Acc: 84.108
83 Train Loss: 46.174 | Train Acc: 84.128
84 Train Loss: 46.155 | Train Acc: 84.164
85 Train Loss: 46.114 | Train Acc: 84.196
86 Train Loss: 46.090 | Train Acc: 84.204
87 Train Loss: 46.065 | Train Acc: 84.064
88 Train Loss: 46.039 | Train Acc: 84.232
89 Train Loss: 46.001 | Train Acc: 84.240
90 Train Loss: 46.018 | Train Acc: 84.196
91 Train Loss: 45.934 | Train Acc: 84.216
92 Train Loss: 45.926 | Train Acc: 84.300
93 Train Loss: 45.911 | Train Acc: 84.284
94 Train Loss: 45.901 | Train Acc: 84.244
95 Train Loss: 45.841 | Train Acc: 84.312
96 Train Loss: 45.833 | Train Acc: 84.216
97 Train Loss: 45.833 | Train Acc: 84.368
98 Train Loss: 45.769 | Train Acc: 84.340
99 Train Loss: 45.753 | Train Acc: 84.364
CNN trained successfully...
image_next_flat.shape :  torch.Size([25000, 9216])
printing expected split from k means
{3: 0, 4: 0, 0: 0, 1: 1, 2: 0}
Printing final_dict items...
{2: 0, 0: 0, 4: -1, 3: 1, 1: 1}
Image Statistics before MLP : L R :  12500 12500
expectedMlpLabels.shape :  torch.Size([25000])
0 Loss: 111.535 | Acc: 70.992
1 Loss: 99.372 | Acc: 75.128
2 Loss: 95.202 | Acc: 76.168
3 Loss: 92.222 | Acc: 76.868
4 Loss: 88.303 | Acc: 78.136
5 Loss: 86.023 | Acc: 78.464
6 Loss: 83.161 | Acc: 79.232
7 Loss: 82.087 | Acc: 79.304
8 Loss: 79.490 | Acc: 80.180
9 Loss: 76.593 | Acc: 81.212
10 Loss: 69.585 | Acc: 82.724
11 Loss: 66.550 | Acc: 83.564
12 Loss: 64.991 | Acc: 84.056
13 Loss: 61.444 | Acc: 84.920
14 Loss: 58.969 | Acc: 85.492
15 Loss: 59.650 | Acc: 85.564
16 Loss: 54.643 | Acc: 86.888
17 Loss: 52.438 | Acc: 87.604
18 Loss: 51.015 | Acc: 88.124
19 Loss: 48.370 | Acc: 88.768
20 Loss: 41.872 | Acc: 90.444
21 Loss: 39.599 | Acc: 91.008
22 Loss: 37.958 | Acc: 91.596
23 Loss: 37.051 | Acc: 91.740
24 Loss: 36.031 | Acc: 91.860
25 Loss: 33.997 | Acc: 92.424
26 Loss: 32.516 | Acc: 92.772
27 Loss: 31.135 | Acc: 93.464
28 Loss: 30.856 | Acc: 93.224
29 Loss: 29.629 | Acc: 93.812
30 Loss: 26.519 | Acc: 94.508
31 Loss: 26.325 | Acc: 94.504
32 Loss: 25.647 | Acc: 94.600
33 Loss: 25.574 | Acc: 94.644
34 Loss: 24.179 | Acc: 95.008
35 Loss: 23.049 | Acc: 95.352
36 Loss: 23.139 | Acc: 95.392
37 Loss: 22.745 | Acc: 95.376
38 Loss: 21.688 | Acc: 95.592
39 Loss: 21.917 | Acc: 95.500
40 Loss: 20.696 | Acc: 95.904
41 Loss: 20.471 | Acc: 95.856
42 Loss: 20.075 | Acc: 95.948
43 Loss: 19.822 | Acc: 96.188
44 Loss: 19.712 | Acc: 95.968
45 Loss: 19.483 | Acc: 96.100
46 Loss: 19.162 | Acc: 96.124
47 Loss: 19.330 | Acc: 96.100
48 Loss: 18.764 | Acc: 96.284
49 Loss: 19.537 | Acc: 96.216
50 Loss: 18.188 | Acc: 96.452
51 Loss: 18.273 | Acc: 96.444
52 Loss: 18.263 | Acc: 96.352
53 Loss: 17.804 | Acc: 96.500
54 Loss: 17.997 | Acc: 96.424
55 Loss: 18.051 | Acc: 96.532
56 Loss: 17.856 | Acc: 96.488
57 Loss: 17.682 | Acc: 96.564
58 Loss: 17.487 | Acc: 96.588
59 Loss: 17.342 | Acc: 96.676
MLP trained successfully...
# of Left images:  12500.0
# of Right images:  12500.0
giniRightRatio:  0.64
giniLeftRatio:  0.64
impurityDrop:  0.64
giniGain:  0.16000000000000014
lclasses:  [5000, 0, 5000, 0, 2500, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 0, 5000, 2500, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  3
lTrainDict[data].shape:  torch.Size([12500, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([12500])
rTrainDict[data].shape:  torch.Size([12500, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([12500])
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([12500, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12500
nodeId:  7 , imgTensorShape :  torch.Size([12500, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12500
Running nodeId:  4
0 Train Loss: 70.614 | Train Acc: 69.600
1 Train Loss: 55.322 | Train Acc: 77.744
2 Train Loss: 45.873 | Train Acc: 81.632
3 Train Loss: 42.796 | Train Acc: 83.152
4 Train Loss: 40.774 | Train Acc: 84.200
5 Train Loss: 41.146 | Train Acc: 83.736
6 Train Loss: 37.212 | Train Acc: 85.768
7 Train Loss: 36.000 | Train Acc: 85.880
8 Train Loss: 34.227 | Train Acc: 86.848
9 Train Loss: 32.366 | Train Acc: 87.552
10 Train Loss: 31.312 | Train Acc: 88.032
11 Train Loss: 30.073 | Train Acc: 88.408
12 Train Loss: 29.176 | Train Acc: 88.576
13 Train Loss: 29.419 | Train Acc: 88.600
14 Train Loss: 29.331 | Train Acc: 88.936
15 Train Loss: 26.730 | Train Acc: 89.968
16 Train Loss: 24.652 | Train Acc: 90.824
17 Train Loss: 23.829 | Train Acc: 91.144
18 Train Loss: 23.486 | Train Acc: 91.280
19 Train Loss: 22.139 | Train Acc: 91.848
20 Train Loss: 19.623 | Train Acc: 92.976
21 Train Loss: 18.696 | Train Acc: 93.592
22 Train Loss: 19.109 | Train Acc: 93.440
23 Train Loss: 18.092 | Train Acc: 93.808
24 Train Loss: 18.580 | Train Acc: 93.504
25 Train Loss: 18.201 | Train Acc: 93.768
26 Train Loss: 17.478 | Train Acc: 94.160
27 Train Loss: 16.859 | Train Acc: 94.376
28 Train Loss: 17.265 | Train Acc: 93.944
29 Train Loss: 16.342 | Train Acc: 94.536
30 Train Loss: 16.057 | Train Acc: 94.768
31 Train Loss: 16.250 | Train Acc: 94.592
32 Train Loss: 15.718 | Train Acc: 94.816
33 Train Loss: 15.422 | Train Acc: 94.920
34 Train Loss: 15.172 | Train Acc: 95.040
35 Train Loss: 14.487 | Train Acc: 95.496
36 Train Loss: 14.423 | Train Acc: 95.488
37 Train Loss: 14.395 | Train Acc: 95.488
38 Train Loss: 14.051 | Train Acc: 95.704
39 Train Loss: 14.118 | Train Acc: 95.496
40 Train Loss: 12.505 | Train Acc: 96.480
41 Train Loss: 12.356 | Train Acc: 96.512
42 Train Loss: 12.179 | Train Acc: 96.720
43 Train Loss: 12.187 | Train Acc: 96.648
44 Train Loss: 11.860 | Train Acc: 96.688
45 Train Loss: 11.801 | Train Acc: 96.808
46 Train Loss: 11.605 | Train Acc: 96.912
47 Train Loss: 11.500 | Train Acc: 96.896
48 Train Loss: 11.658 | Train Acc: 96.768
49 Train Loss: 11.504 | Train Acc: 96.752
50 Train Loss: 11.340 | Train Acc: 96.904
51 Train Loss: 11.276 | Train Acc: 96.984
52 Train Loss: 11.177 | Train Acc: 97.112
53 Train Loss: 11.057 | Train Acc: 97.024
54 Train Loss: 10.883 | Train Acc: 97.112
55 Train Loss: 10.585 | Train Acc: 97.288
56 Train Loss: 10.814 | Train Acc: 97.128
57 Train Loss: 10.510 | Train Acc: 97.336
58 Train Loss: 10.542 | Train Acc: 97.312
59 Train Loss: 10.464 | Train Acc: 97.264
60 Train Loss: 9.812 | Train Acc: 97.752
61 Train Loss: 9.896 | Train Acc: 97.720
62 Train Loss: 9.730 | Train Acc: 97.792
63 Train Loss: 9.730 | Train Acc: 97.744
64 Train Loss: 9.753 | Train Acc: 97.808
65 Train Loss: 9.615 | Train Acc: 97.800
66 Train Loss: 9.588 | Train Acc: 97.920
67 Train Loss: 9.593 | Train Acc: 97.784
68 Train Loss: 9.490 | Train Acc: 97.832
69 Train Loss: 9.490 | Train Acc: 97.896
70 Train Loss: 9.421 | Train Acc: 97.848
71 Train Loss: 9.390 | Train Acc: 97.952
72 Train Loss: 9.418 | Train Acc: 97.832
73 Train Loss: 9.265 | Train Acc: 97.960
74 Train Loss: 9.333 | Train Acc: 97.888
75 Train Loss: 9.232 | Train Acc: 97.936
76 Train Loss: 9.285 | Train Acc: 97.944
77 Train Loss: 9.169 | Train Acc: 97.976
78 Train Loss: 9.046 | Train Acc: 98.000
79 Train Loss: 9.104 | Train Acc: 98.072
80 Train Loss: 8.892 | Train Acc: 98.192
81 Train Loss: 8.835 | Train Acc: 98.088
82 Train Loss: 8.832 | Train Acc: 98.128
83 Train Loss: 8.832 | Train Acc: 98.136
84 Train Loss: 8.810 | Train Acc: 98.112
85 Train Loss: 8.758 | Train Acc: 98.160
86 Train Loss: 8.760 | Train Acc: 98.224
87 Train Loss: 8.728 | Train Acc: 98.152
88 Train Loss: 8.739 | Train Acc: 98.232
89 Train Loss: 8.687 | Train Acc: 98.280
90 Train Loss: 8.703 | Train Acc: 98.208
91 Train Loss: 8.662 | Train Acc: 98.264
92 Train Loss: 8.659 | Train Acc: 98.200
93 Train Loss: 8.634 | Train Acc: 98.224
94 Train Loss: 8.618 | Train Acc: 98.232
95 Train Loss: 8.607 | Train Acc: 98.288
96 Train Loss: 8.641 | Train Acc: 98.256
97 Train Loss: 8.579 | Train Acc: 98.296
98 Train Loss: 8.549 | Train Acc: 98.264
99 Train Loss: 8.543 | Train Acc: 98.280
CNN trained successfully...
image_next_flat.shape :  torch.Size([12500, 6400])
printing expected split from k means
{1: 0, 0: 1, 2: 1}
Printing final_dict items...
{1: 0, 0: -1, 2: 1}
Image Statistics before MLP : L R :  5000 7500
expectedMlpLabels.shape :  torch.Size([12500])
0 Loss: 89.778 | Acc: 70.685
1 Loss: 76.155 | Acc: 75.758
2 Loss: 71.085 | Acc: 75.863
3 Loss: 70.312 | Acc: 75.782
4 Loss: 67.439 | Acc: 77.524
5 Loss: 65.070 | Acc: 77.863
6 Loss: 65.536 | Acc: 76.976
7 Loss: 66.043 | Acc: 76.597
8 Loss: 61.767 | Acc: 77.863
9 Loss: 60.961 | Acc: 78.129
10 Loss: 57.080 | Acc: 79.282
11 Loss: 56.328 | Acc: 79.476
12 Loss: 53.802 | Acc: 80.266
13 Loss: 52.399 | Acc: 80.685
14 Loss: 53.881 | Acc: 80.290
15 Loss: 50.716 | Acc: 81.161
16 Loss: 49.205 | Acc: 82.185
17 Loss: 47.059 | Acc: 83.056
18 Loss: 46.415 | Acc: 83.177
19 Loss: 45.246 | Acc: 84.137
20 Loss: 40.406 | Acc: 85.589
21 Loss: 39.404 | Acc: 86.113
22 Loss: 38.344 | Acc: 86.379
23 Loss: 36.561 | Acc: 87.218
24 Loss: 35.987 | Acc: 87.718
25 Loss: 34.362 | Acc: 88.750
26 Loss: 33.420 | Acc: 88.879
27 Loss: 33.201 | Acc: 89.065
28 Loss: 31.394 | Acc: 89.758
29 Loss: 32.165 | Acc: 89.371
30 Loss: 29.003 | Acc: 90.395
31 Loss: 27.889 | Acc: 91.056
32 Loss: 26.818 | Acc: 91.621
33 Loss: 25.860 | Acc: 91.944
34 Loss: 25.814 | Acc: 91.935
35 Loss: 26.115 | Acc: 91.968
36 Loss: 24.386 | Acc: 92.556
37 Loss: 23.972 | Acc: 92.694
38 Loss: 23.742 | Acc: 92.597
39 Loss: 23.613 | Acc: 92.927
40 Loss: 22.259 | Acc: 93.323
41 Loss: 21.632 | Acc: 93.605
42 Loss: 21.548 | Acc: 93.427
43 Loss: 21.503 | Acc: 93.565
44 Loss: 21.139 | Acc: 93.677
45 Loss: 20.802 | Acc: 93.871
46 Loss: 20.576 | Acc: 93.944
47 Loss: 19.913 | Acc: 94.024
48 Loss: 20.513 | Acc: 93.992
49 Loss: 19.822 | Acc: 94.339
50 Loss: 19.070 | Acc: 94.435
51 Loss: 19.426 | Acc: 94.290
52 Loss: 19.413 | Acc: 94.516
53 Loss: 19.013 | Acc: 94.621
54 Loss: 19.058 | Acc: 94.573
55 Loss: 19.142 | Acc: 94.637
56 Loss: 18.857 | Acc: 94.718
57 Loss: 19.552 | Acc: 94.323
58 Loss: 18.720 | Acc: 94.573
59 Loss: 18.659 | Acc: 94.871
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  7500.0
giniRightRatio:  0.4444444444444445
giniLeftRatio:  0.5
impurityDrop:  0.4814814814814815
giniGain:  0.1585185185185185
lclasses:  [2500, 2500, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2500, 0, 5000, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([7500, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([7500])
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 5000
nodeId:  9 , imgTensorShape :  torch.Size([7500, 16, 20, 20])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7500
Running nodeId:  5
0 Train Loss: 66.336 | Train Acc: 71.576
1 Train Loss: 47.151 | Train Acc: 81.440
2 Train Loss: 41.819 | Train Acc: 83.416
3 Train Loss: 40.225 | Train Acc: 84.080
4 Train Loss: 36.921 | Train Acc: 85.504
5 Train Loss: 36.059 | Train Acc: 86.008
6 Train Loss: 33.630 | Train Acc: 86.616
7 Train Loss: 31.811 | Train Acc: 87.376
8 Train Loss: 31.296 | Train Acc: 87.600
9 Train Loss: 30.043 | Train Acc: 88.160
10 Train Loss: 28.691 | Train Acc: 88.840
11 Train Loss: 27.688 | Train Acc: 89.272
12 Train Loss: 26.429 | Train Acc: 89.808
13 Train Loss: 25.092 | Train Acc: 90.312
14 Train Loss: 23.913 | Train Acc: 90.928
15 Train Loss: 23.641 | Train Acc: 90.848
16 Train Loss: 22.421 | Train Acc: 91.680
17 Train Loss: 21.754 | Train Acc: 91.656
18 Train Loss: 21.359 | Train Acc: 91.832
19 Train Loss: 20.637 | Train Acc: 92.296
20 Train Loss: 17.634 | Train Acc: 93.520
21 Train Loss: 17.047 | Train Acc: 93.912
22 Train Loss: 16.662 | Train Acc: 94.184
23 Train Loss: 16.554 | Train Acc: 94.288
24 Train Loss: 15.977 | Train Acc: 94.512
25 Train Loss: 15.709 | Train Acc: 94.656
26 Train Loss: 15.471 | Train Acc: 94.616
27 Train Loss: 15.186 | Train Acc: 94.792
28 Train Loss: 14.994 | Train Acc: 94.632
29 Train Loss: 14.659 | Train Acc: 95.104
30 Train Loss: 14.475 | Train Acc: 94.944
31 Train Loss: 13.916 | Train Acc: 95.360
32 Train Loss: 14.067 | Train Acc: 95.176
33 Train Loss: 13.088 | Train Acc: 95.768
34 Train Loss: 13.352 | Train Acc: 95.520
35 Train Loss: 12.574 | Train Acc: 95.880
36 Train Loss: 12.711 | Train Acc: 95.896
37 Train Loss: 12.327 | Train Acc: 96.016
38 Train Loss: 12.034 | Train Acc: 96.048
39 Train Loss: 11.636 | Train Acc: 96.280
40 Train Loss: 10.715 | Train Acc: 96.896
41 Train Loss: 10.495 | Train Acc: 96.896
42 Train Loss: 10.658 | Train Acc: 96.848
43 Train Loss: 10.268 | Train Acc: 97.040
44 Train Loss: 10.180 | Train Acc: 97.144
45 Train Loss: 10.129 | Train Acc: 97.256
46 Train Loss: 10.064 | Train Acc: 97.248
47 Train Loss: 9.832 | Train Acc: 97.488
48 Train Loss: 9.773 | Train Acc: 97.312
49 Train Loss: 9.679 | Train Acc: 97.472
50 Train Loss: 9.544 | Train Acc: 97.336
51 Train Loss: 9.446 | Train Acc: 97.512
52 Train Loss: 9.307 | Train Acc: 97.520
53 Train Loss: 9.233 | Train Acc: 97.544
54 Train Loss: 9.120 | Train Acc: 97.528
55 Train Loss: 9.156 | Train Acc: 97.648
56 Train Loss: 8.870 | Train Acc: 97.704
57 Train Loss: 8.872 | Train Acc: 97.760
58 Train Loss: 8.751 | Train Acc: 97.880
59 Train Loss: 8.609 | Train Acc: 97.856
60 Train Loss: 8.283 | Train Acc: 98.000
61 Train Loss: 8.241 | Train Acc: 98.040
62 Train Loss: 8.191 | Train Acc: 98.104
63 Train Loss: 8.128 | Train Acc: 98.144
64 Train Loss: 8.135 | Train Acc: 98.136
65 Train Loss: 8.066 | Train Acc: 98.152
66 Train Loss: 8.030 | Train Acc: 98.168
67 Train Loss: 8.003 | Train Acc: 98.128
68 Train Loss: 7.985 | Train Acc: 98.112
69 Train Loss: 7.915 | Train Acc: 98.200
70 Train Loss: 7.873 | Train Acc: 98.160
71 Train Loss: 7.949 | Train Acc: 98.120
72 Train Loss: 7.816 | Train Acc: 98.160
73 Train Loss: 7.777 | Train Acc: 98.256
74 Train Loss: 7.735 | Train Acc: 98.256
75 Train Loss: 7.677 | Train Acc: 98.328
76 Train Loss: 7.630 | Train Acc: 98.328
77 Train Loss: 7.602 | Train Acc: 98.280
78 Train Loss: 7.597 | Train Acc: 98.272
79 Train Loss: 7.541 | Train Acc: 98.264
80 Train Loss: 7.387 | Train Acc: 98.456
81 Train Loss: 7.360 | Train Acc: 98.432
82 Train Loss: 7.334 | Train Acc: 98.424
83 Train Loss: 7.314 | Train Acc: 98.464
84 Train Loss: 7.290 | Train Acc: 98.392
85 Train Loss: 7.296 | Train Acc: 98.464
86 Train Loss: 7.280 | Train Acc: 98.464
87 Train Loss: 7.278 | Train Acc: 98.472
88 Train Loss: 7.249 | Train Acc: 98.440
89 Train Loss: 7.244 | Train Acc: 98.480
90 Train Loss: 7.208 | Train Acc: 98.456
91 Train Loss: 7.218 | Train Acc: 98.456
92 Train Loss: 7.187 | Train Acc: 98.456
93 Train Loss: 7.165 | Train Acc: 98.496
94 Train Loss: 7.138 | Train Acc: 98.520
95 Train Loss: 7.144 | Train Acc: 98.528
96 Train Loss: 7.094 | Train Acc: 98.568
97 Train Loss: 7.116 | Train Acc: 98.528
98 Train Loss: 7.092 | Train Acc: 98.520
99 Train Loss: 7.082 | Train Acc: 98.544
CNN trained successfully...
image_next_flat.shape :  torch.Size([12500, 6400])
printing expected split from k means
{2: 1, 0: 1, 1: 0}
Printing final_dict items...
{1: 0, 2: -1, 0: 1}
Image Statistics before MLP : L R :  5000 7500
expectedMlpLabels.shape :  torch.Size([12500])
0 Loss: 82.873 | Acc: 74.266
1 Loss: 72.787 | Acc: 77.040
2 Loss: 70.052 | Acc: 76.484
3 Loss: 65.628 | Acc: 77.476
4 Loss: 64.273 | Acc: 76.895
5 Loss: 63.290 | Acc: 77.266
6 Loss: 60.516 | Acc: 78.685
7 Loss: 58.816 | Acc: 78.363
8 Loss: 59.287 | Acc: 78.718
9 Loss: 58.045 | Acc: 79.605
10 Loss: 51.535 | Acc: 80.823
11 Loss: 50.093 | Acc: 82.073
12 Loss: 49.866 | Acc: 81.702
13 Loss: 48.072 | Acc: 82.968
14 Loss: 48.414 | Acc: 82.911
15 Loss: 45.504 | Acc: 83.718
16 Loss: 45.320 | Acc: 84.500
17 Loss: 44.466 | Acc: 84.468
18 Loss: 42.693 | Acc: 85.145
19 Loss: 40.931 | Acc: 86.000
20 Loss: 37.732 | Acc: 86.919
21 Loss: 36.008 | Acc: 87.790
22 Loss: 35.224 | Acc: 88.137
23 Loss: 35.395 | Acc: 88.137
24 Loss: 34.531 | Acc: 88.710
25 Loss: 31.858 | Acc: 89.565
26 Loss: 32.494 | Acc: 89.556
27 Loss: 30.551 | Acc: 90.484
28 Loss: 29.978 | Acc: 90.363
29 Loss: 30.096 | Acc: 90.444
30 Loss: 26.383 | Acc: 91.887
31 Loss: 25.576 | Acc: 92.153
32 Loss: 24.655 | Acc: 92.371
33 Loss: 24.726 | Acc: 92.427
34 Loss: 25.057 | Acc: 92.274
35 Loss: 23.921 | Acc: 92.887
36 Loss: 23.467 | Acc: 93.089
37 Loss: 22.817 | Acc: 93.290
38 Loss: 22.134 | Acc: 93.532
39 Loss: 21.796 | Acc: 93.274
40 Loss: 20.793 | Acc: 93.863
41 Loss: 20.876 | Acc: 94.024
42 Loss: 20.656 | Acc: 93.847
43 Loss: 20.316 | Acc: 94.185
44 Loss: 19.501 | Acc: 94.605
45 Loss: 19.696 | Acc: 94.145
46 Loss: 19.009 | Acc: 94.444
47 Loss: 19.116 | Acc: 94.484
48 Loss: 19.135 | Acc: 94.460
49 Loss: 18.673 | Acc: 94.895
50 Loss: 18.160 | Acc: 94.976
51 Loss: 17.951 | Acc: 94.790
52 Loss: 17.989 | Acc: 94.839
53 Loss: 18.177 | Acc: 94.935
54 Loss: 18.104 | Acc: 95.000
55 Loss: 18.102 | Acc: 94.750
56 Loss: 18.405 | Acc: 94.944
57 Loss: 18.627 | Acc: 94.871
58 Loss: 17.173 | Acc: 95.065
59 Loss: 17.527 | Acc: 95.081
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  7500.0
giniRightRatio:  0.4444444444444445
giniLeftRatio:  0.5
impurityDrop:  0.4814814814814815
giniGain:  0.1585185185185185
lclasses:  [0, 2500, 2500, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 0, 2500, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([7500, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([7500])
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 5000
nodeId:  11 , imgTensorShape :  torch.Size([7500, 16, 20, 20])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7500
Running nodeId:  6
0 Train Loss: 90.074 | Train Acc: 55.912
1 Train Loss: 76.066 | Train Acc: 65.640
2 Train Loss: 70.457 | Train Acc: 68.568
3 Train Loss: 66.769 | Train Acc: 70.824
4 Train Loss: 64.886 | Train Acc: 71.816
5 Train Loss: 61.957 | Train Acc: 73.008
6 Train Loss: 60.052 | Train Acc: 74.256
7 Train Loss: 60.468 | Train Acc: 73.928
8 Train Loss: 57.040 | Train Acc: 75.184
9 Train Loss: 54.400 | Train Acc: 76.624
10 Train Loss: 52.930 | Train Acc: 77.968
11 Train Loss: 51.135 | Train Acc: 78.544
12 Train Loss: 49.847 | Train Acc: 78.744
13 Train Loss: 49.912 | Train Acc: 79.256
14 Train Loss: 48.153 | Train Acc: 79.880
15 Train Loss: 47.057 | Train Acc: 80.320
16 Train Loss: 45.352 | Train Acc: 81.120
17 Train Loss: 43.074 | Train Acc: 82.176
18 Train Loss: 42.054 | Train Acc: 82.840
19 Train Loss: 40.898 | Train Acc: 83.056
20 Train Loss: 37.227 | Train Acc: 85.128
21 Train Loss: 37.702 | Train Acc: 85.064
22 Train Loss: 36.316 | Train Acc: 85.712
23 Train Loss: 35.453 | Train Acc: 86.288
24 Train Loss: 35.439 | Train Acc: 86.232
25 Train Loss: 34.718 | Train Acc: 86.432
26 Train Loss: 34.079 | Train Acc: 86.768
27 Train Loss: 34.312 | Train Acc: 86.488
28 Train Loss: 33.151 | Train Acc: 87.624
29 Train Loss: 32.847 | Train Acc: 87.208
30 Train Loss: 31.841 | Train Acc: 87.888
31 Train Loss: 31.530 | Train Acc: 88.064
32 Train Loss: 31.256 | Train Acc: 88.392
33 Train Loss: 30.504 | Train Acc: 88.680
34 Train Loss: 30.428 | Train Acc: 88.352
35 Train Loss: 29.906 | Train Acc: 88.832
36 Train Loss: 29.244 | Train Acc: 89.192
37 Train Loss: 28.675 | Train Acc: 89.480
38 Train Loss: 28.257 | Train Acc: 89.688
39 Train Loss: 27.669 | Train Acc: 89.872
40 Train Loss: 25.972 | Train Acc: 91.104
41 Train Loss: 25.728 | Train Acc: 91.392
42 Train Loss: 25.431 | Train Acc: 91.448
43 Train Loss: 25.406 | Train Acc: 91.312
44 Train Loss: 25.221 | Train Acc: 91.352
45 Train Loss: 25.002 | Train Acc: 91.512
46 Train Loss: 24.846 | Train Acc: 91.760
47 Train Loss: 24.498 | Train Acc: 91.928
48 Train Loss: 24.536 | Train Acc: 91.720
49 Train Loss: 24.165 | Train Acc: 91.856
50 Train Loss: 23.990 | Train Acc: 92.144
51 Train Loss: 23.795 | Train Acc: 92.280
52 Train Loss: 23.762 | Train Acc: 92.200
53 Train Loss: 23.554 | Train Acc: 92.128
54 Train Loss: 23.427 | Train Acc: 92.256
55 Train Loss: 23.154 | Train Acc: 92.448
56 Train Loss: 22.929 | Train Acc: 92.544
57 Train Loss: 22.812 | Train Acc: 92.504
58 Train Loss: 22.708 | Train Acc: 92.608
59 Train Loss: 22.356 | Train Acc: 92.888
60 Train Loss: 21.772 | Train Acc: 93.464
61 Train Loss: 21.707 | Train Acc: 93.336
62 Train Loss: 21.616 | Train Acc: 93.440
63 Train Loss: 21.571 | Train Acc: 93.272
64 Train Loss: 21.495 | Train Acc: 93.560
65 Train Loss: 21.504 | Train Acc: 93.496
66 Train Loss: 21.420 | Train Acc: 93.472
67 Train Loss: 21.301 | Train Acc: 93.488
68 Train Loss: 21.259 | Train Acc: 93.552
69 Train Loss: 21.196 | Train Acc: 93.560
70 Train Loss: 21.133 | Train Acc: 93.680
71 Train Loss: 21.054 | Train Acc: 93.648
72 Train Loss: 21.042 | Train Acc: 93.592
73 Train Loss: 21.019 | Train Acc: 93.672
74 Train Loss: 20.799 | Train Acc: 93.776
75 Train Loss: 20.688 | Train Acc: 93.752
76 Train Loss: 20.747 | Train Acc: 93.864
77 Train Loss: 20.676 | Train Acc: 93.792
78 Train Loss: 20.584 | Train Acc: 93.816
79 Train Loss: 20.555 | Train Acc: 93.896
80 Train Loss: 20.241 | Train Acc: 94.064
81 Train Loss: 20.221 | Train Acc: 94.040
82 Train Loss: 20.165 | Train Acc: 94.016
83 Train Loss: 20.171 | Train Acc: 93.992
84 Train Loss: 20.095 | Train Acc: 94.248
85 Train Loss: 20.141 | Train Acc: 94.200
86 Train Loss: 20.066 | Train Acc: 94.184
87 Train Loss: 20.037 | Train Acc: 94.200
88 Train Loss: 20.032 | Train Acc: 94.176
89 Train Loss: 20.008 | Train Acc: 94.200
90 Train Loss: 19.995 | Train Acc: 94.072
91 Train Loss: 19.977 | Train Acc: 94.120
92 Train Loss: 19.904 | Train Acc: 94.288
93 Train Loss: 19.885 | Train Acc: 94.112
94 Train Loss: 19.901 | Train Acc: 94.344
95 Train Loss: 19.843 | Train Acc: 94.216
96 Train Loss: 19.797 | Train Acc: 94.272
97 Train Loss: 19.779 | Train Acc: 94.336
98 Train Loss: 19.734 | Train Acc: 94.440
99 Train Loss: 19.697 | Train Acc: 94.392
CNN trained successfully...
image_next_flat.shape :  torch.Size([12500, 6400])
printing expected split from k means
{0: 0, 1: 0, 2: 1}
Printing final_dict items...
{1: 0, 0: -1, 2: 1}
Image Statistics before MLP : L R :  7500 5000
expectedMlpLabels.shape :  torch.Size([12500])
0 Loss: 97.571 | Acc: 66.911
1 Loss: 88.432 | Acc: 71.000
2 Loss: 83.765 | Acc: 72.653
3 Loss: 80.617 | Acc: 73.548
4 Loss: 77.212 | Acc: 75.065
5 Loss: 73.671 | Acc: 76.742
6 Loss: 70.591 | Acc: 77.573
7 Loss: 68.093 | Acc: 78.056
8 Loss: 64.195 | Acc: 79.113
9 Loss: 61.754 | Acc: 80.403
10 Loss: 52.685 | Acc: 84.226
11 Loss: 45.635 | Acc: 86.702
12 Loss: 43.510 | Acc: 86.919
13 Loss: 39.726 | Acc: 88.323
14 Loss: 37.745 | Acc: 88.911
15 Loss: 35.764 | Acc: 89.984
16 Loss: 31.771 | Acc: 90.903
17 Loss: 28.389 | Acc: 92.468
18 Loss: 26.079 | Acc: 92.895
19 Loss: 23.174 | Acc: 93.927
20 Loss: 18.991 | Acc: 95.129
21 Loss: 16.566 | Acc: 95.855
22 Loss: 15.496 | Acc: 96.282
23 Loss: 14.820 | Acc: 96.419
24 Loss: 13.018 | Acc: 96.871
25 Loss: 11.622 | Acc: 97.323
26 Loss: 11.986 | Acc: 97.161
27 Loss: 11.424 | Acc: 97.339
28 Loss: 10.583 | Acc: 97.581
29 Loss: 10.838 | Acc: 97.524
30 Loss: 8.209 | Acc: 98.298
31 Loss: 7.909 | Acc: 98.226
32 Loss: 7.590 | Acc: 98.266
33 Loss: 6.891 | Acc: 98.532
34 Loss: 7.194 | Acc: 98.516
35 Loss: 6.705 | Acc: 98.613
36 Loss: 6.946 | Acc: 98.427
37 Loss: 6.454 | Acc: 98.621
38 Loss: 6.148 | Acc: 98.750
39 Loss: 5.541 | Acc: 98.790
40 Loss: 4.895 | Acc: 99.137
41 Loss: 5.552 | Acc: 98.960
42 Loss: 5.520 | Acc: 98.927
43 Loss: 5.447 | Acc: 98.944
44 Loss: 5.113 | Acc: 99.000
45 Loss: 5.268 | Acc: 98.960
46 Loss: 4.939 | Acc: 98.968
47 Loss: 5.203 | Acc: 99.000
48 Loss: 4.382 | Acc: 99.137
49 Loss: 4.127 | Acc: 99.161
50 Loss: 4.498 | Acc: 99.121
51 Loss: 4.503 | Acc: 99.129
52 Loss: 4.522 | Acc: 99.129
53 Loss: 4.331 | Acc: 99.089
54 Loss: 4.376 | Acc: 99.210
55 Loss: 3.985 | Acc: 99.266
56 Loss: 4.300 | Acc: 99.153
57 Loss: 4.083 | Acc: 99.218
58 Loss: 3.759 | Acc: 99.234
59 Loss: 4.085 | Acc: 99.177
MLP trained successfully...
# of Left images:  7500.0
# of Right images:  5000.0
giniRightRatio:  0.5
giniLeftRatio:  0.4444444444444445
impurityDrop:  0.41666666666666674
giniGain:  0.22333333333333327
lclasses:  [2500, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2500, 0, 2500, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([7500, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([7500])
rTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([7500, 16, 20, 20])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7500
nodeId:  13 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 5000
Running nodeId:  7
0 Train Loss: 70.010 | Train Acc: 69.072
1 Train Loss: 48.706 | Train Acc: 80.128
2 Train Loss: 45.935 | Train Acc: 81.472
3 Train Loss: 43.231 | Train Acc: 82.648
4 Train Loss: 40.270 | Train Acc: 83.584
5 Train Loss: 38.047 | Train Acc: 84.688
6 Train Loss: 37.179 | Train Acc: 85.152
7 Train Loss: 34.845 | Train Acc: 86.112
8 Train Loss: 34.016 | Train Acc: 86.536
9 Train Loss: 31.795 | Train Acc: 87.800
10 Train Loss: 30.854 | Train Acc: 87.904
11 Train Loss: 30.764 | Train Acc: 87.848
12 Train Loss: 28.594 | Train Acc: 89.096
13 Train Loss: 27.083 | Train Acc: 89.344
14 Train Loss: 27.615 | Train Acc: 89.304
15 Train Loss: 25.246 | Train Acc: 90.120
16 Train Loss: 25.009 | Train Acc: 90.688
17 Train Loss: 22.755 | Train Acc: 91.576
18 Train Loss: 21.228 | Train Acc: 92.320
19 Train Loss: 20.588 | Train Acc: 92.416
20 Train Loss: 17.492 | Train Acc: 94.584
21 Train Loss: 16.900 | Train Acc: 94.552
22 Train Loss: 16.731 | Train Acc: 94.688
23 Train Loss: 16.186 | Train Acc: 94.800
24 Train Loss: 16.193 | Train Acc: 94.712
25 Train Loss: 16.189 | Train Acc: 94.600
26 Train Loss: 15.248 | Train Acc: 95.320
27 Train Loss: 15.391 | Train Acc: 94.912
28 Train Loss: 14.543 | Train Acc: 95.616
29 Train Loss: 13.956 | Train Acc: 95.928
30 Train Loss: 14.179 | Train Acc: 95.656
31 Train Loss: 14.208 | Train Acc: 95.496
32 Train Loss: 13.827 | Train Acc: 95.752
33 Train Loss: 12.973 | Train Acc: 96.288
34 Train Loss: 12.666 | Train Acc: 96.416
35 Train Loss: 12.310 | Train Acc: 96.512
36 Train Loss: 12.208 | Train Acc: 96.480
37 Train Loss: 11.616 | Train Acc: 96.760
38 Train Loss: 11.490 | Train Acc: 96.848
39 Train Loss: 11.336 | Train Acc: 96.960
40 Train Loss: 10.291 | Train Acc: 97.512
41 Train Loss: 9.916 | Train Acc: 97.744
42 Train Loss: 9.844 | Train Acc: 97.752
43 Train Loss: 9.870 | Train Acc: 97.736
44 Train Loss: 9.649 | Train Acc: 97.808
45 Train Loss: 9.635 | Train Acc: 97.720
46 Train Loss: 9.318 | Train Acc: 97.968
47 Train Loss: 9.361 | Train Acc: 97.824
48 Train Loss: 9.234 | Train Acc: 97.928
49 Train Loss: 9.163 | Train Acc: 97.928
50 Train Loss: 9.091 | Train Acc: 97.960
51 Train Loss: 8.958 | Train Acc: 98.032
52 Train Loss: 8.732 | Train Acc: 98.120
53 Train Loss: 8.572 | Train Acc: 98.120
54 Train Loss: 8.486 | Train Acc: 98.240
55 Train Loss: 8.477 | Train Acc: 98.320
56 Train Loss: 8.364 | Train Acc: 98.296
57 Train Loss: 8.210 | Train Acc: 98.296
58 Train Loss: 8.093 | Train Acc: 98.328
59 Train Loss: 8.070 | Train Acc: 98.440
60 Train Loss: 7.609 | Train Acc: 98.616
61 Train Loss: 7.549 | Train Acc: 98.656
62 Train Loss: 7.599 | Train Acc: 98.632
63 Train Loss: 7.535 | Train Acc: 98.592
64 Train Loss: 7.499 | Train Acc: 98.632
65 Train Loss: 7.430 | Train Acc: 98.688
66 Train Loss: 7.382 | Train Acc: 98.704
67 Train Loss: 7.317 | Train Acc: 98.712
68 Train Loss: 7.304 | Train Acc: 98.712
69 Train Loss: 7.247 | Train Acc: 98.752
70 Train Loss: 7.186 | Train Acc: 98.744
71 Train Loss: 7.178 | Train Acc: 98.816
72 Train Loss: 7.098 | Train Acc: 98.784
73 Train Loss: 7.117 | Train Acc: 98.792
74 Train Loss: 7.079 | Train Acc: 98.856
75 Train Loss: 7.013 | Train Acc: 98.832
76 Train Loss: 6.964 | Train Acc: 98.832
77 Train Loss: 6.927 | Train Acc: 98.888
78 Train Loss: 6.854 | Train Acc: 98.920
79 Train Loss: 6.842 | Train Acc: 98.880
80 Train Loss: 6.683 | Train Acc: 98.976
81 Train Loss: 6.639 | Train Acc: 99.000
82 Train Loss: 6.639 | Train Acc: 98.984
83 Train Loss: 6.625 | Train Acc: 98.992
84 Train Loss: 6.611 | Train Acc: 98.984
85 Train Loss: 6.583 | Train Acc: 99.016
86 Train Loss: 6.579 | Train Acc: 99.008
87 Train Loss: 6.560 | Train Acc: 98.984
88 Train Loss: 6.553 | Train Acc: 99.000
89 Train Loss: 6.520 | Train Acc: 99.040
90 Train Loss: 6.503 | Train Acc: 98.976
91 Train Loss: 6.492 | Train Acc: 99.048
92 Train Loss: 6.451 | Train Acc: 99.024
93 Train Loss: 6.467 | Train Acc: 99.000
94 Train Loss: 6.432 | Train Acc: 99.048
95 Train Loss: 6.423 | Train Acc: 99.040
96 Train Loss: 6.403 | Train Acc: 99.120
97 Train Loss: 6.378 | Train Acc: 99.056
98 Train Loss: 6.370 | Train Acc: 99.104
99 Train Loss: 6.358 | Train Acc: 99.072
CNN trained successfully...
image_next_flat.shape :  torch.Size([12500, 6400])
printing expected split from k means
{0: 1, 1: 1, 2: 0}
Printing final_dict items...
{0: 1, 2: -1, 1: 1}
Image Statistics before MLP : L R :  1250 11250
expectedMlpLabels.shape :  torch.Size([12500])
0 Loss: 21.900 | Acc: 70.024
1 Loss: 16.851 | Acc: 76.613
2 Loss: 15.279 | Acc: 77.911
3 Loss: 15.358 | Acc: 79.734
4 Loss: 13.164 | Acc: 81.565
5 Loss: 13.040 | Acc: 81.661
6 Loss: 13.031 | Acc: 81.935
7 Loss: 12.108 | Acc: 83.435
8 Loss: 12.141 | Acc: 82.847
9 Loss: 11.075 | Acc: 84.032
10 Loss: 8.939 | Acc: 88.016
11 Loss: 8.405 | Acc: 88.718
12 Loss: 8.442 | Acc: 88.589
13 Loss: 7.196 | Acc: 89.823
14 Loss: 6.919 | Acc: 90.589
15 Loss: 6.269 | Acc: 91.395
16 Loss: 5.872 | Acc: 91.734
17 Loss: 5.299 | Acc: 92.766
18 Loss: 4.998 | Acc: 93.516
19 Loss: 4.441 | Acc: 93.911
20 Loss: 3.436 | Acc: 95.210
21 Loss: 3.134 | Acc: 95.831
22 Loss: 2.933 | Acc: 96.153
23 Loss: 2.691 | Acc: 96.468
24 Loss: 2.571 | Acc: 96.653
25 Loss: 2.054 | Acc: 97.613
26 Loss: 2.253 | Acc: 97.298
27 Loss: 1.868 | Acc: 97.677
28 Loss: 1.651 | Acc: 98.129
29 Loss: 1.701 | Acc: 98.137
30 Loss: 1.337 | Acc: 98.395
31 Loss: 1.225 | Acc: 98.532
32 Loss: 1.223 | Acc: 98.573
33 Loss: 1.046 | Acc: 98.790
34 Loss: 1.109 | Acc: 98.685
35 Loss: 1.080 | Acc: 98.790
36 Loss: 1.079 | Acc: 98.806
37 Loss: 1.009 | Acc: 99.008
38 Loss: 0.897 | Acc: 99.032
39 Loss: 0.884 | Acc: 98.976
40 Loss: 0.774 | Acc: 99.226
41 Loss: 0.920 | Acc: 99.097
42 Loss: 0.738 | Acc: 99.234
43 Loss: 0.754 | Acc: 99.137
44 Loss: 0.683 | Acc: 99.282
45 Loss: 0.692 | Acc: 99.258
46 Loss: 0.599 | Acc: 99.411
47 Loss: 0.716 | Acc: 99.331
48 Loss: 0.628 | Acc: 99.371
49 Loss: 0.728 | Acc: 99.218
50 Loss: 0.596 | Acc: 99.427
51 Loss: 0.596 | Acc: 99.282
52 Loss: 0.617 | Acc: 99.419
53 Loss: 0.666 | Acc: 99.387
54 Loss: 0.661 | Acc: 99.306
55 Loss: 0.538 | Acc: 99.444
56 Loss: 0.535 | Acc: 99.508
57 Loss: 0.667 | Acc: 99.315
58 Loss: 0.603 | Acc: 99.492
59 Loss: 0.605 | Acc: 99.411
MLP trained successfully...
# of Left images:  1250.0
# of Right images:  11250.0
giniRightRatio:  0.5925925925925926
giniLeftRatio:  0.0
impurityDrop:  0.5267489711934156
giniGain:  0.11325102880658444
lclasses:  [0, 0, 1250, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 5000, 1250, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  3
lTrainDict[data].shape:  torch.Size([1250, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1250])
rTrainDict[data].shape:  torch.Size([11250, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([11250])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
nodeId:  14 , imgTensorShape :  torch.Size([1250, 16, 20, 20])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 1250
nodeId:  15 , imgTensorShape :  torch.Size([11250, 16, 20, 20])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 11250
Running nodeId:  8
0 Train Loss: 34.875 | Train Acc: 85.420
1 Train Loss: 26.488 | Train Acc: 89.320
2 Train Loss: 23.957 | Train Acc: 90.600
3 Train Loss: 21.562 | Train Acc: 91.240
4 Train Loss: 19.467 | Train Acc: 92.060
5 Train Loss: 17.464 | Train Acc: 92.980
6 Train Loss: 15.746 | Train Acc: 93.720
7 Train Loss: 13.880 | Train Acc: 94.680
8 Train Loss: 12.656 | Train Acc: 95.120
9 Train Loss: 11.014 | Train Acc: 95.980
10 Train Loss: 9.442 | Train Acc: 96.640
11 Train Loss: 8.391 | Train Acc: 97.120
12 Train Loss: 7.290 | Train Acc: 97.500
13 Train Loss: 6.701 | Train Acc: 97.900
14 Train Loss: 5.752 | Train Acc: 98.300
15 Train Loss: 4.607 | Train Acc: 98.800
16 Train Loss: 4.324 | Train Acc: 98.840
17 Train Loss: 3.833 | Train Acc: 99.040
18 Train Loss: 3.008 | Train Acc: 99.460
19 Train Loss: 2.508 | Train Acc: 99.680
20 Train Loss: 1.740 | Train Acc: 99.940
21 Train Loss: 1.430 | Train Acc: 99.940
22 Train Loss: 1.343 | Train Acc: 99.940
23 Train Loss: 1.238 | Train Acc: 100.000
24 Train Loss: 1.155 | Train Acc: 100.000
25 Train Loss: 1.104 | Train Acc: 99.980
26 Train Loss: 1.017 | Train Acc: 100.000
27 Train Loss: 0.993 | Train Acc: 99.980
28 Train Loss: 0.898 | Train Acc: 100.000
29 Train Loss: 0.866 | Train Acc: 100.000
30 Train Loss: 0.807 | Train Acc: 100.000
31 Train Loss: 0.767 | Train Acc: 100.000
32 Train Loss: 0.718 | Train Acc: 100.000
33 Train Loss: 0.698 | Train Acc: 100.000
34 Train Loss: 0.687 | Train Acc: 100.000
35 Train Loss: 0.610 | Train Acc: 100.000
36 Train Loss: 0.574 | Train Acc: 100.000
37 Train Loss: 0.530 | Train Acc: 100.000
38 Train Loss: 0.503 | Train Acc: 100.000
39 Train Loss: 0.489 | Train Acc: 100.000
40 Train Loss: 0.418 | Train Acc: 100.000
41 Train Loss: 0.398 | Train Acc: 100.000
42 Train Loss: 0.390 | Train Acc: 100.000
43 Train Loss: 0.383 | Train Acc: 100.000
44 Train Loss: 0.371 | Train Acc: 100.000
45 Train Loss: 0.361 | Train Acc: 100.000
46 Train Loss: 0.354 | Train Acc: 100.000
47 Train Loss: 0.344 | Train Acc: 100.000
48 Train Loss: 0.336 | Train Acc: 100.000
49 Train Loss: 0.328 | Train Acc: 100.000
50 Train Loss: 0.318 | Train Acc: 100.000
51 Train Loss: 0.313 | Train Acc: 100.000
52 Train Loss: 0.301 | Train Acc: 100.000
53 Train Loss: 0.290 | Train Acc: 100.000
54 Train Loss: 0.280 | Train Acc: 100.000
55 Train Loss: 0.272 | Train Acc: 100.000
56 Train Loss: 0.268 | Train Acc: 100.000
57 Train Loss: 0.256 | Train Acc: 100.000
58 Train Loss: 0.252 | Train Acc: 100.000
59 Train Loss: 0.244 | Train Acc: 100.000
60 Train Loss: 0.224 | Train Acc: 100.000
61 Train Loss: 0.220 | Train Acc: 100.000
62 Train Loss: 0.216 | Train Acc: 100.000
63 Train Loss: 0.214 | Train Acc: 100.000
64 Train Loss: 0.212 | Train Acc: 100.000
65 Train Loss: 0.207 | Train Acc: 100.000
66 Train Loss: 0.204 | Train Acc: 100.000
67 Train Loss: 0.200 | Train Acc: 100.000
68 Train Loss: 0.197 | Train Acc: 100.000
69 Train Loss: 0.195 | Train Acc: 100.000
70 Train Loss: 0.192 | Train Acc: 100.000
71 Train Loss: 0.188 | Train Acc: 100.000
72 Train Loss: 0.185 | Train Acc: 100.000
73 Train Loss: 0.181 | Train Acc: 100.000
74 Train Loss: 0.177 | Train Acc: 100.000
75 Train Loss: 0.174 | Train Acc: 100.000
76 Train Loss: 0.172 | Train Acc: 100.000
77 Train Loss: 0.169 | Train Acc: 100.000
78 Train Loss: 0.166 | Train Acc: 100.000
79 Train Loss: 0.160 | Train Acc: 100.000
80 Train Loss: 0.153 | Train Acc: 100.000
81 Train Loss: 0.152 | Train Acc: 100.000
82 Train Loss: 0.150 | Train Acc: 100.000
83 Train Loss: 0.149 | Train Acc: 100.000
84 Train Loss: 0.148 | Train Acc: 100.000
85 Train Loss: 0.147 | Train Acc: 100.000
86 Train Loss: 0.145 | Train Acc: 100.000
87 Train Loss: 0.144 | Train Acc: 100.000
88 Train Loss: 0.143 | Train Acc: 100.000
89 Train Loss: 0.142 | Train Acc: 100.000
90 Train Loss: 0.140 | Train Acc: 100.000
91 Train Loss: 0.138 | Train Acc: 100.000
92 Train Loss: 0.137 | Train Acc: 100.000
93 Train Loss: 0.136 | Train Acc: 100.000
94 Train Loss: 0.134 | Train Acc: 100.000
95 Train Loss: 0.132 | Train Acc: 100.000
96 Train Loss: 0.131 | Train Acc: 100.000
97 Train Loss: 0.130 | Train Acc: 100.000
98 Train Loss: 0.129 | Train Acc: 100.000
99 Train Loss: 0.127 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([5000, 4096])
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  2500 2500
expectedMlpLabels.shape :  torch.Size([5000])
0 Loss: 56.465 | Acc: 88.360
1 Loss: 38.338 | Acc: 92.060
2 Loss: 29.454 | Acc: 94.160
3 Loss: 22.789 | Acc: 95.120
4 Loss: 20.744 | Acc: 96.120
5 Loss: 15.907 | Acc: 96.860
6 Loss: 11.784 | Acc: 97.820
7 Loss: 9.754 | Acc: 97.980
8 Loss: 7.453 | Acc: 98.500
9 Loss: 11.206 | Acc: 97.860
10 Loss: 5.858 | Acc: 99.040
11 Loss: 2.711 | Acc: 99.580
12 Loss: 1.770 | Acc: 99.660
13 Loss: 1.290 | Acc: 99.880
14 Loss: 1.671 | Acc: 99.720
15 Loss: 1.599 | Acc: 99.720
16 Loss: 1.335 | Acc: 99.800
17 Loss: 2.176 | Acc: 99.620
18 Loss: 2.501 | Acc: 99.580
19 Loss: 1.106 | Acc: 99.780
20 Loss: 0.811 | Acc: 99.920
21 Loss: 0.742 | Acc: 99.860
22 Loss: 0.262 | Acc: 99.980
23 Loss: 0.159 | Acc: 100.000
24 Loss: 0.287 | Acc: 99.960
25 Loss: 0.074 | Acc: 100.000
26 Loss: 0.085 | Acc: 100.000
27 Loss: 0.053 | Acc: 100.000
28 Loss: 0.294 | Acc: 99.960
29 Loss: 0.482 | Acc: 99.920
30 Loss: 0.122 | Acc: 99.960
31 Loss: 0.177 | Acc: 99.960
32 Loss: 0.088 | Acc: 100.000
33 Loss: 0.118 | Acc: 99.980
34 Loss: 0.120 | Acc: 100.000
35 Loss: 0.055 | Acc: 100.000
36 Loss: 0.035 | Acc: 100.000
37 Loss: 0.034 | Acc: 100.000
38 Loss: 0.022 | Acc: 100.000
39 Loss: 0.332 | Acc: 99.960
40 Loss: 0.045 | Acc: 100.000
41 Loss: 0.025 | Acc: 100.000
42 Loss: 0.040 | Acc: 100.000
43 Loss: 0.029 | Acc: 100.000
44 Loss: 0.045 | Acc: 100.000
45 Loss: 0.023 | Acc: 100.000
46 Loss: 0.244 | Acc: 99.980
47 Loss: 0.016 | Acc: 100.000
48 Loss: 0.021 | Acc: 100.000
49 Loss: 0.032 | Acc: 100.000
50 Loss: 0.037 | Acc: 100.000
51 Loss: 0.012 | Acc: 100.000
52 Loss: 0.029 | Acc: 100.000
53 Loss: 0.092 | Acc: 99.980
54 Loss: 0.051 | Acc: 99.980
55 Loss: 0.015 | Acc: 100.000
56 Loss: 0.009 | Acc: 100.000
57 Loss: 0.016 | Acc: 100.000
58 Loss: 0.024 | Acc: 100.000
59 Loss: 0.036 | Acc: 100.000
MLP trained successfully...
# of Left images:  2500.0
# of Right images:  2500.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 2500, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2500, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([2500])
rTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([2500])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 2
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 0
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 2
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 0
nodeId:  16 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 16 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 2500
nodeId:  17 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 17 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 2500
Running nodeId:  9
0 Train Loss: 48.311 | Train Acc: 77.360
1 Train Loss: 32.896 | Train Acc: 86.107
2 Train Loss: 27.895 | Train Acc: 88.627
3 Train Loss: 24.654 | Train Acc: 90.040
4 Train Loss: 23.632 | Train Acc: 90.467
5 Train Loss: 22.126 | Train Acc: 91.280
6 Train Loss: 19.485 | Train Acc: 92.293
7 Train Loss: 20.235 | Train Acc: 91.533
8 Train Loss: 19.169 | Train Acc: 92.293
9 Train Loss: 19.897 | Train Acc: 91.973
10 Train Loss: 16.883 | Train Acc: 93.267
11 Train Loss: 15.324 | Train Acc: 93.893
12 Train Loss: 13.370 | Train Acc: 94.560
13 Train Loss: 12.319 | Train Acc: 95.160
14 Train Loss: 11.627 | Train Acc: 95.547
15 Train Loss: 10.559 | Train Acc: 96.213
16 Train Loss: 9.813 | Train Acc: 96.133
17 Train Loss: 9.031 | Train Acc: 96.627
18 Train Loss: 9.008 | Train Acc: 96.600
19 Train Loss: 7.814 | Train Acc: 97.227
20 Train Loss: 6.248 | Train Acc: 97.987
21 Train Loss: 5.818 | Train Acc: 98.253
22 Train Loss: 5.180 | Train Acc: 98.533
23 Train Loss: 5.135 | Train Acc: 98.653
24 Train Loss: 5.152 | Train Acc: 98.560
25 Train Loss: 4.457 | Train Acc: 98.947
26 Train Loss: 4.304 | Train Acc: 99.040
27 Train Loss: 4.158 | Train Acc: 99.160
28 Train Loss: 4.275 | Train Acc: 99.027
29 Train Loss: 3.900 | Train Acc: 99.147
30 Train Loss: 3.915 | Train Acc: 99.213
31 Train Loss: 3.602 | Train Acc: 99.373
32 Train Loss: 3.258 | Train Acc: 99.547
33 Train Loss: 3.301 | Train Acc: 99.373
34 Train Loss: 3.107 | Train Acc: 99.533
35 Train Loss: 3.118 | Train Acc: 99.480
36 Train Loss: 2.785 | Train Acc: 99.720
37 Train Loss: 2.511 | Train Acc: 99.760
38 Train Loss: 2.441 | Train Acc: 99.747
39 Train Loss: 2.413 | Train Acc: 99.787
40 Train Loss: 2.029 | Train Acc: 99.867
41 Train Loss: 1.893 | Train Acc: 99.907
42 Train Loss: 1.858 | Train Acc: 99.920
43 Train Loss: 1.826 | Train Acc: 99.893
44 Train Loss: 1.753 | Train Acc: 99.907
45 Train Loss: 1.774 | Train Acc: 99.960
46 Train Loss: 1.666 | Train Acc: 99.920
47 Train Loss: 1.676 | Train Acc: 99.933
48 Train Loss: 1.598 | Train Acc: 99.933
49 Train Loss: 1.586 | Train Acc: 99.933
50 Train Loss: 1.509 | Train Acc: 99.960
51 Train Loss: 1.494 | Train Acc: 99.960
52 Train Loss: 1.481 | Train Acc: 99.947
53 Train Loss: 1.406 | Train Acc: 99.947
54 Train Loss: 1.389 | Train Acc: 99.960
55 Train Loss: 1.318 | Train Acc: 99.973
56 Train Loss: 1.326 | Train Acc: 99.987
57 Train Loss: 1.247 | Train Acc: 99.973
58 Train Loss: 1.210 | Train Acc: 99.973
59 Train Loss: 1.191 | Train Acc: 99.987
60 Train Loss: 1.089 | Train Acc: 100.000
61 Train Loss: 1.068 | Train Acc: 100.000
62 Train Loss: 1.054 | Train Acc: 100.000
63 Train Loss: 1.045 | Train Acc: 100.000
64 Train Loss: 1.023 | Train Acc: 100.000
65 Train Loss: 1.008 | Train Acc: 100.000
66 Train Loss: 1.016 | Train Acc: 100.000
67 Train Loss: 0.999 | Train Acc: 100.000
68 Train Loss: 0.976 | Train Acc: 100.000
69 Train Loss: 0.986 | Train Acc: 99.987
70 Train Loss: 0.949 | Train Acc: 100.000
71 Train Loss: 0.940 | Train Acc: 100.000
72 Train Loss: 0.926 | Train Acc: 100.000
73 Train Loss: 0.910 | Train Acc: 100.000
74 Train Loss: 0.907 | Train Acc: 100.000
75 Train Loss: 0.883 | Train Acc: 100.000
76 Train Loss: 0.876 | Train Acc: 100.000
77 Train Loss: 0.880 | Train Acc: 100.000
78 Train Loss: 0.853 | Train Acc: 100.000
79 Train Loss: 0.837 | Train Acc: 100.000
80 Train Loss: 0.801 | Train Acc: 100.000
81 Train Loss: 0.797 | Train Acc: 100.000
82 Train Loss: 0.793 | Train Acc: 100.000
83 Train Loss: 0.784 | Train Acc: 100.000
84 Train Loss: 0.783 | Train Acc: 100.000
85 Train Loss: 0.787 | Train Acc: 100.000
86 Train Loss: 0.772 | Train Acc: 100.000
87 Train Loss: 0.767 | Train Acc: 100.000
88 Train Loss: 0.771 | Train Acc: 100.000
89 Train Loss: 0.757 | Train Acc: 100.000
90 Train Loss: 0.755 | Train Acc: 100.000
91 Train Loss: 0.751 | Train Acc: 100.000
92 Train Loss: 0.747 | Train Acc: 100.000
93 Train Loss: 0.734 | Train Acc: 100.000
94 Train Loss: 0.729 | Train Acc: 100.000
95 Train Loss: 0.729 | Train Acc: 100.000
96 Train Loss: 0.718 | Train Acc: 100.000
97 Train Loss: 0.727 | Train Acc: 100.000
98 Train Loss: 0.712 | Train Acc: 100.000
99 Train Loss: 0.711 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([7500, 4096])
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  2500 5000
expectedMlpLabels.shape :  torch.Size([7500])
0 Loss: 43.097 | Acc: 87.041
1 Loss: 25.007 | Acc: 92.257
2 Loss: 18.820 | Acc: 94.284
3 Loss: 15.322 | Acc: 95.459
4 Loss: 10.408 | Acc: 96.932
5 Loss: 9.048 | Acc: 97.392
6 Loss: 8.921 | Acc: 97.446
7 Loss: 6.918 | Acc: 98.054
8 Loss: 4.956 | Acc: 98.554
9 Loss: 5.184 | Acc: 98.581
10 Loss: 1.499 | Acc: 99.622
11 Loss: 1.394 | Acc: 99.662
12 Loss: 1.657 | Acc: 99.595
13 Loss: 0.626 | Acc: 99.851
14 Loss: 0.836 | Acc: 99.757
15 Loss: 0.499 | Acc: 99.892
16 Loss: 0.626 | Acc: 99.878
17 Loss: 0.757 | Acc: 99.811
18 Loss: 1.059 | Acc: 99.784
19 Loss: 0.958 | Acc: 99.716
20 Loss: 0.301 | Acc: 99.919
21 Loss: 0.405 | Acc: 99.905
22 Loss: 0.194 | Acc: 99.973
23 Loss: 0.161 | Acc: 99.973
24 Loss: 0.302 | Acc: 99.932
25 Loss: 0.100 | Acc: 100.000
26 Loss: 0.099 | Acc: 99.973
27 Loss: 0.211 | Acc: 99.959
28 Loss: 0.100 | Acc: 99.986
29 Loss: 0.185 | Acc: 99.959
30 Loss: 0.102 | Acc: 100.000
31 Loss: 0.044 | Acc: 100.000
32 Loss: 0.039 | Acc: 100.000
33 Loss: 0.059 | Acc: 99.986
34 Loss: 0.025 | Acc: 100.000
35 Loss: 0.061 | Acc: 100.000
36 Loss: 0.029 | Acc: 100.000
37 Loss: 0.110 | Acc: 99.973
38 Loss: 0.027 | Acc: 100.000
39 Loss: 0.084 | Acc: 99.973
40 Loss: 0.055 | Acc: 100.000
41 Loss: 0.017 | Acc: 100.000
42 Loss: 0.154 | Acc: 99.973
43 Loss: 0.033 | Acc: 100.000
44 Loss: 0.148 | Acc: 99.986
45 Loss: 0.066 | Acc: 99.973
46 Loss: 0.026 | Acc: 100.000
47 Loss: 0.049 | Acc: 100.000
48 Loss: 0.065 | Acc: 99.986
49 Loss: 0.047 | Acc: 99.986
50 Loss: 0.038 | Acc: 100.000
51 Loss: 0.054 | Acc: 99.986
52 Loss: 0.022 | Acc: 100.000
53 Loss: 0.034 | Acc: 100.000
54 Loss: 0.022 | Acc: 100.000
55 Loss: 0.034 | Acc: 100.000
56 Loss: 0.024 | Acc: 100.000
57 Loss: 0.034 | Acc: 99.986
58 Loss: 0.022 | Acc: 100.000
59 Loss: 0.020 | Acc: 100.000
MLP trained successfully...
# of Left images:  2500.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [2500, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([2500])
rTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  18 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 18 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 2500
nodeId:  19 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 19 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  10
0 Train Loss: 31.120 | Train Acc: 85.140
1 Train Loss: 21.913 | Train Acc: 91.640
2 Train Loss: 18.179 | Train Acc: 92.600
3 Train Loss: 15.479 | Train Acc: 93.660
4 Train Loss: 13.615 | Train Acc: 94.160
5 Train Loss: 13.291 | Train Acc: 94.500
6 Train Loss: 13.826 | Train Acc: 94.400
7 Train Loss: 12.198 | Train Acc: 95.180
8 Train Loss: 9.878 | Train Acc: 96.040
9 Train Loss: 9.583 | Train Acc: 96.360
10 Train Loss: 8.461 | Train Acc: 96.700
11 Train Loss: 7.579 | Train Acc: 97.080
12 Train Loss: 7.354 | Train Acc: 97.180
13 Train Loss: 6.705 | Train Acc: 97.400
14 Train Loss: 6.443 | Train Acc: 97.520
15 Train Loss: 5.477 | Train Acc: 98.060
16 Train Loss: 4.476 | Train Acc: 98.380
17 Train Loss: 3.478 | Train Acc: 98.940
18 Train Loss: 3.721 | Train Acc: 98.860
19 Train Loss: 2.739 | Train Acc: 99.220
20 Train Loss: 2.152 | Train Acc: 99.560
21 Train Loss: 1.757 | Train Acc: 99.700
22 Train Loss: 1.716 | Train Acc: 99.800
23 Train Loss: 1.539 | Train Acc: 99.780
24 Train Loss: 1.381 | Train Acc: 99.820
25 Train Loss: 1.287 | Train Acc: 99.820
26 Train Loss: 1.206 | Train Acc: 99.880
27 Train Loss: 1.118 | Train Acc: 99.940
28 Train Loss: 1.021 | Train Acc: 99.900
29 Train Loss: 0.936 | Train Acc: 99.960
30 Train Loss: 0.868 | Train Acc: 99.900
31 Train Loss: 0.780 | Train Acc: 99.960
32 Train Loss: 0.720 | Train Acc: 99.960
33 Train Loss: 0.656 | Train Acc: 99.960
34 Train Loss: 0.625 | Train Acc: 100.000
35 Train Loss: 0.566 | Train Acc: 99.980
36 Train Loss: 0.544 | Train Acc: 99.980
37 Train Loss: 0.465 | Train Acc: 100.000
38 Train Loss: 0.475 | Train Acc: 100.000
39 Train Loss: 0.437 | Train Acc: 100.000
40 Train Loss: 0.375 | Train Acc: 100.000
41 Train Loss: 0.335 | Train Acc: 100.000
42 Train Loss: 0.332 | Train Acc: 100.000
43 Train Loss: 0.316 | Train Acc: 100.000
44 Train Loss: 0.309 | Train Acc: 100.000
45 Train Loss: 0.302 | Train Acc: 100.000
46 Train Loss: 0.296 | Train Acc: 100.000
47 Train Loss: 0.284 | Train Acc: 100.000
48 Train Loss: 0.282 | Train Acc: 100.000
49 Train Loss: 0.262 | Train Acc: 100.000
50 Train Loss: 0.252 | Train Acc: 100.000
51 Train Loss: 0.259 | Train Acc: 100.000
52 Train Loss: 0.251 | Train Acc: 100.000
53 Train Loss: 0.244 | Train Acc: 100.000
54 Train Loss: 0.222 | Train Acc: 100.000
55 Train Loss: 0.224 | Train Acc: 100.000
56 Train Loss: 0.222 | Train Acc: 100.000
57 Train Loss: 0.205 | Train Acc: 100.000
58 Train Loss: 0.193 | Train Acc: 100.000
59 Train Loss: 0.186 | Train Acc: 100.000
60 Train Loss: 0.174 | Train Acc: 100.000
61 Train Loss: 0.169 | Train Acc: 100.000
62 Train Loss: 0.170 | Train Acc: 100.000
63 Train Loss: 0.167 | Train Acc: 100.000
64 Train Loss: 0.163 | Train Acc: 100.000
65 Train Loss: 0.163 | Train Acc: 100.000
66 Train Loss: 0.157 | Train Acc: 100.000
67 Train Loss: 0.155 | Train Acc: 100.000
68 Train Loss: 0.155 | Train Acc: 100.000
69 Train Loss: 0.151 | Train Acc: 100.000
70 Train Loss: 0.151 | Train Acc: 100.000
71 Train Loss: 0.144 | Train Acc: 100.000
72 Train Loss: 0.142 | Train Acc: 100.000
73 Train Loss: 0.141 | Train Acc: 100.000
74 Train Loss: 0.137 | Train Acc: 100.000
75 Train Loss: 0.136 | Train Acc: 100.000
76 Train Loss: 0.129 | Train Acc: 100.000
77 Train Loss: 0.130 | Train Acc: 100.000
78 Train Loss: 0.126 | Train Acc: 100.000
79 Train Loss: 0.124 | Train Acc: 100.000
80 Train Loss: 0.117 | Train Acc: 100.000
81 Train Loss: 0.117 | Train Acc: 100.000
82 Train Loss: 0.115 | Train Acc: 100.000
83 Train Loss: 0.114 | Train Acc: 100.000
84 Train Loss: 0.114 | Train Acc: 100.000
85 Train Loss: 0.113 | Train Acc: 100.000
86 Train Loss: 0.113 | Train Acc: 100.000
87 Train Loss: 0.111 | Train Acc: 100.000
88 Train Loss: 0.109 | Train Acc: 100.000
89 Train Loss: 0.108 | Train Acc: 100.000
90 Train Loss: 0.106 | Train Acc: 100.000
91 Train Loss: 0.105 | Train Acc: 100.000
92 Train Loss: 0.105 | Train Acc: 100.000
93 Train Loss: 0.104 | Train Acc: 100.000
94 Train Loss: 0.104 | Train Acc: 100.000
95 Train Loss: 0.103 | Train Acc: 100.000
96 Train Loss: 0.100 | Train Acc: 100.000
97 Train Loss: 0.099 | Train Acc: 100.000
98 Train Loss: 0.098 | Train Acc: 100.000
99 Train Loss: 0.097 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([5000, 4096])
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  2500 2500
expectedMlpLabels.shape :  torch.Size([5000])
0 Loss: 36.358 | Acc: 93.160
1 Loss: 20.583 | Acc: 95.920
2 Loss: 16.997 | Acc: 96.800
3 Loss: 13.424 | Acc: 97.440
4 Loss: 10.232 | Acc: 98.200
5 Loss: 14.739 | Acc: 97.880
6 Loss: 7.510 | Acc: 98.500
7 Loss: 5.036 | Acc: 99.160
8 Loss: 6.504 | Acc: 98.860
9 Loss: 6.072 | Acc: 98.900
10 Loss: 2.678 | Acc: 99.540
11 Loss: 1.138 | Acc: 99.860
12 Loss: 0.988 | Acc: 99.880
13 Loss: 0.762 | Acc: 99.900
14 Loss: 0.336 | Acc: 99.980
15 Loss: 0.141 | Acc: 100.000
16 Loss: 0.248 | Acc: 99.960
17 Loss: 0.334 | Acc: 99.960
18 Loss: 0.227 | Acc: 99.960
19 Loss: 3.560 | Acc: 99.540
20 Loss: 0.731 | Acc: 99.920
21 Loss: 0.428 | Acc: 99.980
22 Loss: 0.260 | Acc: 99.980
23 Loss: 0.206 | Acc: 99.980
24 Loss: 0.235 | Acc: 99.960
25 Loss: 0.128 | Acc: 99.980
26 Loss: 0.252 | Acc: 99.960
27 Loss: 0.072 | Acc: 100.000
28 Loss: 0.059 | Acc: 100.000
29 Loss: 0.124 | Acc: 99.980
30 Loss: 0.067 | Acc: 100.000
31 Loss: 0.064 | Acc: 100.000
32 Loss: 0.062 | Acc: 100.000
33 Loss: 0.048 | Acc: 100.000
34 Loss: 0.085 | Acc: 99.980
35 Loss: 0.048 | Acc: 100.000
36 Loss: 0.027 | Acc: 100.000
37 Loss: 0.034 | Acc: 100.000
38 Loss: 0.057 | Acc: 100.000
39 Loss: 0.025 | Acc: 100.000
40 Loss: 0.027 | Acc: 100.000
41 Loss: 0.027 | Acc: 100.000
42 Loss: 0.026 | Acc: 100.000
43 Loss: 0.018 | Acc: 100.000
44 Loss: 0.039 | Acc: 100.000
45 Loss: 0.026 | Acc: 100.000
46 Loss: 0.023 | Acc: 100.000
47 Loss: 0.020 | Acc: 100.000
48 Loss: 0.065 | Acc: 99.980
49 Loss: 0.104 | Acc: 99.980
50 Loss: 0.023 | Acc: 100.000
51 Loss: 0.038 | Acc: 100.000
52 Loss: 0.035 | Acc: 100.000
53 Loss: 0.022 | Acc: 100.000
54 Loss: 0.020 | Acc: 100.000
55 Loss: 0.024 | Acc: 100.000
56 Loss: 0.052 | Acc: 99.980
57 Loss: 0.034 | Acc: 100.000
58 Loss: 0.013 | Acc: 100.000
59 Loss: 0.120 | Acc: 99.980
MLP trained successfully...
# of Left images:  2500.0
# of Right images:  2500.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 2500, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2500, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([2500])
rTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([2500])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 9
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 9
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 2
nodeId:  20 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 20 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 2500
nodeId:  21 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 21 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 2500
Running nodeId:  11
0 Train Loss: 47.314 | Train Acc: 78.413
1 Train Loss: 32.241 | Train Acc: 86.653
2 Train Loss: 29.408 | Train Acc: 87.640
3 Train Loss: 26.719 | Train Acc: 88.733
4 Train Loss: 27.273 | Train Acc: 88.653
5 Train Loss: 24.130 | Train Acc: 90.053
6 Train Loss: 24.606 | Train Acc: 90.187
7 Train Loss: 23.121 | Train Acc: 90.480
8 Train Loss: 21.758 | Train Acc: 91.107
9 Train Loss: 21.064 | Train Acc: 91.547
10 Train Loss: 19.742 | Train Acc: 91.973
11 Train Loss: 17.633 | Train Acc: 93.120
12 Train Loss: 17.430 | Train Acc: 93.053
13 Train Loss: 15.387 | Train Acc: 93.640
14 Train Loss: 15.507 | Train Acc: 94.107
15 Train Loss: 14.258 | Train Acc: 94.267
16 Train Loss: 14.145 | Train Acc: 94.413
17 Train Loss: 12.463 | Train Acc: 95.293
18 Train Loss: 12.311 | Train Acc: 95.093
19 Train Loss: 11.231 | Train Acc: 95.707
20 Train Loss: 8.669 | Train Acc: 97.093
21 Train Loss: 7.909 | Train Acc: 97.533
22 Train Loss: 7.599 | Train Acc: 97.693
23 Train Loss: 7.383 | Train Acc: 97.787
24 Train Loss: 7.136 | Train Acc: 97.787
25 Train Loss: 7.024 | Train Acc: 97.760
26 Train Loss: 6.896 | Train Acc: 97.853
27 Train Loss: 6.365 | Train Acc: 98.133
28 Train Loss: 6.248 | Train Acc: 98.227
29 Train Loss: 5.968 | Train Acc: 98.387
30 Train Loss: 6.288 | Train Acc: 98.027
31 Train Loss: 5.998 | Train Acc: 98.307
32 Train Loss: 5.470 | Train Acc: 98.520
33 Train Loss: 5.541 | Train Acc: 98.440
34 Train Loss: 4.951 | Train Acc: 98.693
35 Train Loss: 4.836 | Train Acc: 98.773
36 Train Loss: 4.394 | Train Acc: 98.987
37 Train Loss: 4.413 | Train Acc: 99.053
38 Train Loss: 4.285 | Train Acc: 99.080
39 Train Loss: 3.822 | Train Acc: 99.373
40 Train Loss: 3.521 | Train Acc: 99.373
41 Train Loss: 3.411 | Train Acc: 99.493
42 Train Loss: 3.215 | Train Acc: 99.520
43 Train Loss: 3.174 | Train Acc: 99.573
44 Train Loss: 3.082 | Train Acc: 99.600
45 Train Loss: 3.043 | Train Acc: 99.587
46 Train Loss: 2.936 | Train Acc: 99.573
47 Train Loss: 2.924 | Train Acc: 99.693
48 Train Loss: 2.873 | Train Acc: 99.680
49 Train Loss: 2.813 | Train Acc: 99.640
50 Train Loss: 2.779 | Train Acc: 99.693
51 Train Loss: 2.684 | Train Acc: 99.800
52 Train Loss: 2.628 | Train Acc: 99.707
53 Train Loss: 2.505 | Train Acc: 99.760
54 Train Loss: 2.476 | Train Acc: 99.720
55 Train Loss: 2.433 | Train Acc: 99.733
56 Train Loss: 2.430 | Train Acc: 99.773
57 Train Loss: 2.392 | Train Acc: 99.800
58 Train Loss: 2.280 | Train Acc: 99.827
59 Train Loss: 2.195 | Train Acc: 99.867
60 Train Loss: 2.059 | Train Acc: 99.880
61 Train Loss: 2.053 | Train Acc: 99.893
62 Train Loss: 2.032 | Train Acc: 99.920
63 Train Loss: 1.988 | Train Acc: 99.920
64 Train Loss: 1.961 | Train Acc: 99.893
65 Train Loss: 1.968 | Train Acc: 99.920
66 Train Loss: 1.941 | Train Acc: 99.907
67 Train Loss: 1.921 | Train Acc: 99.920
68 Train Loss: 1.892 | Train Acc: 99.920
69 Train Loss: 1.881 | Train Acc: 99.933
70 Train Loss: 1.857 | Train Acc: 99.947
71 Train Loss: 1.827 | Train Acc: 99.947
72 Train Loss: 1.824 | Train Acc: 99.933
73 Train Loss: 1.765 | Train Acc: 99.933
74 Train Loss: 1.752 | Train Acc: 99.947
75 Train Loss: 1.761 | Train Acc: 99.960
76 Train Loss: 1.740 | Train Acc: 99.960
77 Train Loss: 1.720 | Train Acc: 99.947
78 Train Loss: 1.705 | Train Acc: 99.960
79 Train Loss: 1.665 | Train Acc: 99.947
80 Train Loss: 1.624 | Train Acc: 99.960
81 Train Loss: 1.598 | Train Acc: 99.973
82 Train Loss: 1.620 | Train Acc: 99.960
83 Train Loss: 1.586 | Train Acc: 99.960
84 Train Loss: 1.579 | Train Acc: 99.960
85 Train Loss: 1.573 | Train Acc: 99.973
86 Train Loss: 1.571 | Train Acc: 99.973
87 Train Loss: 1.552 | Train Acc: 99.960
88 Train Loss: 1.549 | Train Acc: 99.960
89 Train Loss: 1.562 | Train Acc: 99.960
90 Train Loss: 1.527 | Train Acc: 99.960
91 Train Loss: 1.519 | Train Acc: 99.960
92 Train Loss: 1.520 | Train Acc: 99.973
93 Train Loss: 1.486 | Train Acc: 99.973
94 Train Loss: 1.503 | Train Acc: 99.973
95 Train Loss: 1.490 | Train Acc: 99.973
96 Train Loss: 1.485 | Train Acc: 99.960
97 Train Loss: 1.474 | Train Acc: 99.973
98 Train Loss: 1.472 | Train Acc: 99.960
99 Train Loss: 1.477 | Train Acc: 99.987
CNN trained successfully...
image_next_flat.shape :  torch.Size([7500, 4096])
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  5000 2500
expectedMlpLabels.shape :  torch.Size([7500])
0 Loss: 41.132 | Acc: 87.338
1 Loss: 27.133 | Acc: 92.122
2 Loss: 21.160 | Acc: 93.351
3 Loss: 16.389 | Acc: 94.892
4 Loss: 15.417 | Acc: 95.568
5 Loss: 12.191 | Acc: 96.284
6 Loss: 8.907 | Acc: 97.324
7 Loss: 8.073 | Acc: 97.473
8 Loss: 6.750 | Acc: 97.838
9 Loss: 6.008 | Acc: 98.243
10 Loss: 2.536 | Acc: 99.324
11 Loss: 1.204 | Acc: 99.703
12 Loss: 1.268 | Acc: 99.689
13 Loss: 1.290 | Acc: 99.689
14 Loss: 0.782 | Acc: 99.784
15 Loss: 1.712 | Acc: 99.446
16 Loss: 0.809 | Acc: 99.797
17 Loss: 0.761 | Acc: 99.811
18 Loss: 0.823 | Acc: 99.770
19 Loss: 0.555 | Acc: 99.851
20 Loss: 0.296 | Acc: 99.946
21 Loss: 0.324 | Acc: 99.946
22 Loss: 0.479 | Acc: 99.878
23 Loss: 0.325 | Acc: 99.932
24 Loss: 0.206 | Acc: 99.959
25 Loss: 0.221 | Acc: 99.973
26 Loss: 0.154 | Acc: 99.986
27 Loss: 0.122 | Acc: 99.986
28 Loss: 0.149 | Acc: 99.959
29 Loss: 0.075 | Acc: 100.000
30 Loss: 0.080 | Acc: 100.000
31 Loss: 0.070 | Acc: 100.000
32 Loss: 0.040 | Acc: 100.000
33 Loss: 0.054 | Acc: 100.000
34 Loss: 0.077 | Acc: 99.973
35 Loss: 0.127 | Acc: 99.973
36 Loss: 0.043 | Acc: 100.000
37 Loss: 0.034 | Acc: 100.000
38 Loss: 0.044 | Acc: 100.000
39 Loss: 0.040 | Acc: 100.000
40 Loss: 0.112 | Acc: 99.986
41 Loss: 0.068 | Acc: 99.986
42 Loss: 0.046 | Acc: 100.000
43 Loss: 0.022 | Acc: 100.000
44 Loss: 0.027 | Acc: 100.000
45 Loss: 0.043 | Acc: 100.000
46 Loss: 0.024 | Acc: 100.000
47 Loss: 0.053 | Acc: 99.986
48 Loss: 0.030 | Acc: 100.000
49 Loss: 0.035 | Acc: 100.000
50 Loss: 0.044 | Acc: 100.000
51 Loss: 0.031 | Acc: 100.000
52 Loss: 0.020 | Acc: 100.000
53 Loss: 0.042 | Acc: 100.000
54 Loss: 0.022 | Acc: 100.000
55 Loss: 0.027 | Acc: 100.000
56 Loss: 0.028 | Acc: 100.000
57 Loss: 0.020 | Acc: 100.000
58 Loss: 0.052 | Acc: 100.000
59 Loss: 0.022 | Acc: 100.000
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  2500.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 2500, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([2500])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  22 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 22 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 5000
nodeId:  23 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 23 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 2500
Running nodeId:  12
0 Train Loss: 61.819 | Train Acc: 65.933
1 Train Loss: 54.632 | Train Acc: 70.987
2 Train Loss: 52.586 | Train Acc: 73.440
3 Train Loss: 49.769 | Train Acc: 75.507
4 Train Loss: 48.521 | Train Acc: 75.853
5 Train Loss: 45.161 | Train Acc: 77.987
6 Train Loss: 44.193 | Train Acc: 78.853
7 Train Loss: 42.182 | Train Acc: 80.453
8 Train Loss: 41.428 | Train Acc: 80.733
9 Train Loss: 43.484 | Train Acc: 78.840
10 Train Loss: 37.513 | Train Acc: 82.707
11 Train Loss: 35.762 | Train Acc: 83.693
12 Train Loss: 34.757 | Train Acc: 84.347
13 Train Loss: 32.298 | Train Acc: 85.733
14 Train Loss: 30.547 | Train Acc: 86.800
15 Train Loss: 29.509 | Train Acc: 87.240
16 Train Loss: 28.323 | Train Acc: 87.813
17 Train Loss: 27.490 | Train Acc: 88.187
18 Train Loss: 25.903 | Train Acc: 89.347
19 Train Loss: 24.741 | Train Acc: 89.947
20 Train Loss: 21.656 | Train Acc: 91.787
21 Train Loss: 20.443 | Train Acc: 92.720
22 Train Loss: 20.291 | Train Acc: 92.360
23 Train Loss: 19.613 | Train Acc: 93.133
24 Train Loss: 19.016 | Train Acc: 93.293
25 Train Loss: 19.045 | Train Acc: 93.067
26 Train Loss: 17.913 | Train Acc: 93.920
27 Train Loss: 18.176 | Train Acc: 93.667
28 Train Loss: 16.987 | Train Acc: 94.467
29 Train Loss: 16.022 | Train Acc: 94.693
30 Train Loss: 16.601 | Train Acc: 94.640
31 Train Loss: 15.693 | Train Acc: 94.960
32 Train Loss: 15.127 | Train Acc: 95.413
33 Train Loss: 14.765 | Train Acc: 95.507
34 Train Loss: 14.789 | Train Acc: 95.467
35 Train Loss: 14.022 | Train Acc: 95.747
36 Train Loss: 13.793 | Train Acc: 95.853
37 Train Loss: 13.454 | Train Acc: 96.040
38 Train Loss: 13.092 | Train Acc: 96.333
39 Train Loss: 12.633 | Train Acc: 96.400
40 Train Loss: 11.762 | Train Acc: 96.907
41 Train Loss: 11.392 | Train Acc: 97.040
42 Train Loss: 11.355 | Train Acc: 97.067
43 Train Loss: 11.168 | Train Acc: 97.200
44 Train Loss: 11.000 | Train Acc: 97.227
45 Train Loss: 11.091 | Train Acc: 97.240
46 Train Loss: 10.987 | Train Acc: 97.280
47 Train Loss: 10.632 | Train Acc: 97.360
48 Train Loss: 10.489 | Train Acc: 97.440
49 Train Loss: 10.460 | Train Acc: 97.493
50 Train Loss: 10.311 | Train Acc: 97.693
51 Train Loss: 10.036 | Train Acc: 97.667
52 Train Loss: 9.954 | Train Acc: 97.827
53 Train Loss: 9.854 | Train Acc: 97.773
54 Train Loss: 9.773 | Train Acc: 97.720
55 Train Loss: 9.843 | Train Acc: 97.920
56 Train Loss: 9.764 | Train Acc: 97.800
57 Train Loss: 9.492 | Train Acc: 97.893
58 Train Loss: 9.351 | Train Acc: 98.040
59 Train Loss: 9.182 | Train Acc: 97.987
60 Train Loss: 8.842 | Train Acc: 98.267
61 Train Loss: 8.796 | Train Acc: 98.320
62 Train Loss: 8.751 | Train Acc: 98.227
63 Train Loss: 8.630 | Train Acc: 98.347
64 Train Loss: 8.639 | Train Acc: 98.333
65 Train Loss: 8.733 | Train Acc: 98.360
66 Train Loss: 8.520 | Train Acc: 98.427
67 Train Loss: 8.469 | Train Acc: 98.547
68 Train Loss: 8.477 | Train Acc: 98.427
69 Train Loss: 8.423 | Train Acc: 98.467
70 Train Loss: 8.409 | Train Acc: 98.493
71 Train Loss: 8.277 | Train Acc: 98.587
72 Train Loss: 8.209 | Train Acc: 98.600
73 Train Loss: 8.273 | Train Acc: 98.533
74 Train Loss: 8.203 | Train Acc: 98.573
75 Train Loss: 8.081 | Train Acc: 98.600
76 Train Loss: 8.021 | Train Acc: 98.693
77 Train Loss: 8.031 | Train Acc: 98.693
78 Train Loss: 7.952 | Train Acc: 98.667
79 Train Loss: 7.856 | Train Acc: 98.760
80 Train Loss: 7.768 | Train Acc: 98.800
81 Train Loss: 7.782 | Train Acc: 98.787
82 Train Loss: 7.707 | Train Acc: 98.827
83 Train Loss: 7.705 | Train Acc: 98.813
84 Train Loss: 7.688 | Train Acc: 98.760
85 Train Loss: 7.649 | Train Acc: 98.733
86 Train Loss: 7.630 | Train Acc: 98.813
87 Train Loss: 7.623 | Train Acc: 98.853
88 Train Loss: 7.595 | Train Acc: 98.867
89 Train Loss: 7.580 | Train Acc: 98.813
90 Train Loss: 7.553 | Train Acc: 98.880
91 Train Loss: 7.516 | Train Acc: 98.867
92 Train Loss: 7.509 | Train Acc: 98.853
93 Train Loss: 7.513 | Train Acc: 98.853
94 Train Loss: 7.462 | Train Acc: 98.853
95 Train Loss: 7.463 | Train Acc: 98.800
96 Train Loss: 7.464 | Train Acc: 98.853
97 Train Loss: 7.429 | Train Acc: 98.893
98 Train Loss: 7.403 | Train Acc: 98.880
99 Train Loss: 7.365 | Train Acc: 98.880
CNN trained successfully...
image_next_flat.shape :  torch.Size([7500, 4096])
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics before MLP : L R :  2500 5000
expectedMlpLabels.shape :  torch.Size([7500])
0 Loss: 76.354 | Acc: 68.284
1 Loss: 55.421 | Acc: 80.324
2 Loss: 41.677 | Acc: 85.311
3 Loss: 33.793 | Acc: 88.757
4 Loss: 24.295 | Acc: 92.081
5 Loss: 18.234 | Acc: 94.027
6 Loss: 16.131 | Acc: 95.270
7 Loss: 12.812 | Acc: 96.568
8 Loss: 11.461 | Acc: 96.811
9 Loss: 9.513 | Acc: 97.338
10 Loss: 4.070 | Acc: 98.959
11 Loss: 2.915 | Acc: 99.338
12 Loss: 2.275 | Acc: 99.514
13 Loss: 2.092 | Acc: 99.527
14 Loss: 1.288 | Acc: 99.743
15 Loss: 1.260 | Acc: 99.689
16 Loss: 1.411 | Acc: 99.703
17 Loss: 0.868 | Acc: 99.838
18 Loss: 0.769 | Acc: 99.838
19 Loss: 1.463 | Acc: 99.730
20 Loss: 0.859 | Acc: 99.851
21 Loss: 0.517 | Acc: 99.919
22 Loss: 0.464 | Acc: 99.932
23 Loss: 0.371 | Acc: 99.946
24 Loss: 0.290 | Acc: 99.959
25 Loss: 0.370 | Acc: 99.905
26 Loss: 0.444 | Acc: 99.959
27 Loss: 0.503 | Acc: 99.932
28 Loss: 0.648 | Acc: 99.892
29 Loss: 0.284 | Acc: 99.986
30 Loss: 0.213 | Acc: 99.986
31 Loss: 0.155 | Acc: 100.000
32 Loss: 0.170 | Acc: 100.000
33 Loss: 0.134 | Acc: 100.000
34 Loss: 0.195 | Acc: 99.959
35 Loss: 0.171 | Acc: 99.986
36 Loss: 0.109 | Acc: 100.000
37 Loss: 0.169 | Acc: 99.959
38 Loss: 0.108 | Acc: 100.000
39 Loss: 0.117 | Acc: 99.986
40 Loss: 0.088 | Acc: 99.986
41 Loss: 0.092 | Acc: 100.000
42 Loss: 0.115 | Acc: 99.986
43 Loss: 0.079 | Acc: 100.000
44 Loss: 0.102 | Acc: 100.000
45 Loss: 0.095 | Acc: 100.000
46 Loss: 0.098 | Acc: 99.986
47 Loss: 0.079 | Acc: 100.000
48 Loss: 0.076 | Acc: 100.000
49 Loss: 0.058 | Acc: 100.000
50 Loss: 0.084 | Acc: 99.986
51 Loss: 0.136 | Acc: 99.973
52 Loss: 0.064 | Acc: 100.000
53 Loss: 0.110 | Acc: 99.986
54 Loss: 0.090 | Acc: 100.000
55 Loss: 0.090 | Acc: 99.986
56 Loss: 0.084 | Acc: 100.000
57 Loss: 0.136 | Acc: 99.986
58 Loss: 0.069 | Acc: 100.000
59 Loss: 0.110 | Acc: 99.986
MLP trained successfully...
# of Left images:  2500.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [2500, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([2500])
rTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 5
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 5
nodeId:  24 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 24 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 2500
nodeId:  25 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 25 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  13
0 Train Loss: 79.065 | Train Acc: 50.080
1 Train Loss: 62.969 | Train Acc: 55.640
2 Train Loss: 59.202 | Train Acc: 71.240
3 Train Loss: 55.645 | Train Acc: 76.220
4 Train Loss: 48.398 | Train Acc: 78.540
5 Train Loss: 47.184 | Train Acc: 79.040
6 Train Loss: 41.753 | Train Acc: 81.520
7 Train Loss: 40.647 | Train Acc: 83.000
8 Train Loss: 39.292 | Train Acc: 83.160
9 Train Loss: 35.694 | Train Acc: 84.880
10 Train Loss: 36.151 | Train Acc: 84.100
11 Train Loss: 34.432 | Train Acc: 84.680
12 Train Loss: 34.644 | Train Acc: 85.120
13 Train Loss: 31.536 | Train Acc: 87.140
14 Train Loss: 30.407 | Train Acc: 86.800
15 Train Loss: 27.894 | Train Acc: 88.340
16 Train Loss: 26.733 | Train Acc: 88.460
17 Train Loss: 25.583 | Train Acc: 89.380
18 Train Loss: 24.360 | Train Acc: 90.200
19 Train Loss: 22.019 | Train Acc: 91.080
20 Train Loss: 18.981 | Train Acc: 92.680
21 Train Loss: 17.744 | Train Acc: 93.000
22 Train Loss: 17.548 | Train Acc: 93.180
23 Train Loss: 16.253 | Train Acc: 93.720
24 Train Loss: 16.417 | Train Acc: 93.800
25 Train Loss: 14.441 | Train Acc: 94.600
26 Train Loss: 14.045 | Train Acc: 95.300
27 Train Loss: 13.340 | Train Acc: 95.340
28 Train Loss: 12.916 | Train Acc: 95.320
29 Train Loss: 11.802 | Train Acc: 96.060
30 Train Loss: 10.996 | Train Acc: 96.160
31 Train Loss: 10.681 | Train Acc: 96.600
32 Train Loss: 9.831 | Train Acc: 96.860
33 Train Loss: 9.186 | Train Acc: 97.480
34 Train Loss: 8.549 | Train Acc: 97.560
35 Train Loss: 7.999 | Train Acc: 97.700
36 Train Loss: 7.566 | Train Acc: 97.840
37 Train Loss: 7.705 | Train Acc: 97.980
38 Train Loss: 6.734 | Train Acc: 98.480
39 Train Loss: 6.195 | Train Acc: 98.460
40 Train Loss: 5.667 | Train Acc: 99.040
41 Train Loss: 5.256 | Train Acc: 99.240
42 Train Loss: 5.056 | Train Acc: 99.340
43 Train Loss: 4.814 | Train Acc: 99.360
44 Train Loss: 4.656 | Train Acc: 99.340
45 Train Loss: 4.495 | Train Acc: 99.480
46 Train Loss: 4.375 | Train Acc: 99.500
47 Train Loss: 4.398 | Train Acc: 99.400
48 Train Loss: 4.078 | Train Acc: 99.560
49 Train Loss: 3.989 | Train Acc: 99.600
50 Train Loss: 4.042 | Train Acc: 99.620
51 Train Loss: 3.790 | Train Acc: 99.680
52 Train Loss: 3.577 | Train Acc: 99.680
53 Train Loss: 3.575 | Train Acc: 99.760
54 Train Loss: 3.437 | Train Acc: 99.700
55 Train Loss: 3.239 | Train Acc: 99.740
56 Train Loss: 3.127 | Train Acc: 99.820
57 Train Loss: 3.037 | Train Acc: 99.860
58 Train Loss: 3.107 | Train Acc: 99.880
59 Train Loss: 2.756 | Train Acc: 99.800
60 Train Loss: 2.700 | Train Acc: 99.880
61 Train Loss: 2.564 | Train Acc: 99.880
62 Train Loss: 2.530 | Train Acc: 99.900
63 Train Loss: 2.476 | Train Acc: 99.920
64 Train Loss: 2.436 | Train Acc: 99.920
65 Train Loss: 2.447 | Train Acc: 99.880
66 Train Loss: 2.296 | Train Acc: 99.940
67 Train Loss: 2.306 | Train Acc: 99.900
68 Train Loss: 2.310 | Train Acc: 99.900
69 Train Loss: 2.300 | Train Acc: 99.920
70 Train Loss: 2.218 | Train Acc: 99.960
71 Train Loss: 2.188 | Train Acc: 99.940
72 Train Loss: 2.144 | Train Acc: 99.960
73 Train Loss: 2.103 | Train Acc: 99.940
74 Train Loss: 2.088 | Train Acc: 99.960
75 Train Loss: 2.011 | Train Acc: 99.940
76 Train Loss: 2.061 | Train Acc: 99.960
77 Train Loss: 1.945 | Train Acc: 99.980
78 Train Loss: 1.971 | Train Acc: 99.960
79 Train Loss: 1.952 | Train Acc: 99.960
80 Train Loss: 1.848 | Train Acc: 99.980
81 Train Loss: 1.801 | Train Acc: 99.960
82 Train Loss: 1.819 | Train Acc: 99.980
83 Train Loss: 1.804 | Train Acc: 99.980
84 Train Loss: 1.775 | Train Acc: 99.980
85 Train Loss: 1.762 | Train Acc: 99.980
86 Train Loss: 1.762 | Train Acc: 99.980
87 Train Loss: 1.745 | Train Acc: 99.980
88 Train Loss: 1.720 | Train Acc: 99.980
89 Train Loss: 1.726 | Train Acc: 99.980
90 Train Loss: 1.689 | Train Acc: 99.980
91 Train Loss: 1.686 | Train Acc: 99.980
92 Train Loss: 1.677 | Train Acc: 99.980
93 Train Loss: 1.678 | Train Acc: 99.980
94 Train Loss: 1.645 | Train Acc: 99.980
95 Train Loss: 1.625 | Train Acc: 99.980
96 Train Loss: 1.638 | Train Acc: 99.980
97 Train Loss: 1.635 | Train Acc: 99.980
98 Train Loss: 1.605 | Train Acc: 99.980
99 Train Loss: 1.584 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([5000, 4096])
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  2500 2500
expectedMlpLabels.shape :  torch.Size([5000])
0 Loss: 88.658 | Acc: 80.420
1 Loss: 53.382 | Acc: 89.140
2 Loss: 42.264 | Acc: 90.880
3 Loss: 29.895 | Acc: 93.420
4 Loss: 24.820 | Acc: 95.000
5 Loss: 17.890 | Acc: 96.780
6 Loss: 14.578 | Acc: 97.520
7 Loss: 11.011 | Acc: 98.320
8 Loss: 8.596 | Acc: 98.080
9 Loss: 6.251 | Acc: 98.920
10 Loss: 2.128 | Acc: 99.700
11 Loss: 0.957 | Acc: 99.920
12 Loss: 0.672 | Acc: 99.940
13 Loss: 0.934 | Acc: 99.900
14 Loss: 0.663 | Acc: 99.960
15 Loss: 0.846 | Acc: 99.880
16 Loss: 0.810 | Acc: 99.860
17 Loss: 1.203 | Acc: 99.800
18 Loss: 0.422 | Acc: 99.960
19 Loss: 0.503 | Acc: 99.900
20 Loss: 0.231 | Acc: 99.980
21 Loss: 0.279 | Acc: 99.940
22 Loss: 0.189 | Acc: 99.980
23 Loss: 0.225 | Acc: 99.980
24 Loss: 0.263 | Acc: 99.980
25 Loss: 0.128 | Acc: 100.000
26 Loss: 0.102 | Acc: 100.000
27 Loss: 0.092 | Acc: 100.000
28 Loss: 0.076 | Acc: 100.000
29 Loss: 0.063 | Acc: 100.000
30 Loss: 0.082 | Acc: 100.000
31 Loss: 0.061 | Acc: 100.000
32 Loss: 0.058 | Acc: 100.000
33 Loss: 0.048 | Acc: 100.000
34 Loss: 0.053 | Acc: 100.000
35 Loss: 0.043 | Acc: 100.000
36 Loss: 0.060 | Acc: 100.000
37 Loss: 0.061 | Acc: 100.000
38 Loss: 0.083 | Acc: 100.000
39 Loss: 0.040 | Acc: 100.000
40 Loss: 0.030 | Acc: 100.000
41 Loss: 0.044 | Acc: 100.000
42 Loss: 0.030 | Acc: 100.000
43 Loss: 0.028 | Acc: 100.000
44 Loss: 0.164 | Acc: 99.980
45 Loss: 0.044 | Acc: 100.000
46 Loss: 0.030 | Acc: 100.000
47 Loss: 0.084 | Acc: 100.000
48 Loss: 0.076 | Acc: 99.980
49 Loss: 0.041 | Acc: 100.000
50 Loss: 0.019 | Acc: 100.000
51 Loss: 0.066 | Acc: 100.000
52 Loss: 0.023 | Acc: 100.000
53 Loss: 0.043 | Acc: 100.000
54 Loss: 0.029 | Acc: 100.000
55 Loss: 0.023 | Acc: 100.000
56 Loss: 0.040 | Acc: 100.000
57 Loss: 0.027 | Acc: 100.000
58 Loss: 0.017 | Acc: 100.000
59 Loss: 0.020 | Acc: 100.000
MLP trained successfully...
# of Left images:  2500.0
# of Right images:  2500.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [2500, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 2500, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([2500])
rTrainDict[data].shape:  torch.Size([2500, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([2500])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 7
nodeId:  26 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 26 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 2500
nodeId:  27 , imgTensorShape :  torch.Size([2500, 16, 16, 16])
nodeId: 27 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 2500
Running nodeId:  14
Running nodeId:  15
0 Train Loss: 68.332 | Train Acc: 73.333
1 Train Loss: 48.996 | Train Acc: 80.267
2 Train Loss: 41.502 | Train Acc: 83.467
3 Train Loss: 36.700 | Train Acc: 85.342
4 Train Loss: 34.872 | Train Acc: 86.258
5 Train Loss: 34.035 | Train Acc: 86.613
6 Train Loss: 31.033 | Train Acc: 87.716
7 Train Loss: 30.317 | Train Acc: 88.080
8 Train Loss: 27.436 | Train Acc: 89.316
9 Train Loss: 25.713 | Train Acc: 90.124
10 Train Loss: 24.671 | Train Acc: 90.507
11 Train Loss: 22.804 | Train Acc: 91.209
12 Train Loss: 22.001 | Train Acc: 91.396
13 Train Loss: 20.517 | Train Acc: 92.107
14 Train Loss: 19.556 | Train Acc: 92.471
15 Train Loss: 17.237 | Train Acc: 93.796
16 Train Loss: 17.686 | Train Acc: 93.333
17 Train Loss: 15.179 | Train Acc: 94.507
18 Train Loss: 14.545 | Train Acc: 94.969
19 Train Loss: 13.554 | Train Acc: 95.138
20 Train Loss: 11.042 | Train Acc: 96.453
21 Train Loss: 10.468 | Train Acc: 96.924
22 Train Loss: 10.346 | Train Acc: 96.844
23 Train Loss: 9.896 | Train Acc: 97.076
24 Train Loss: 9.610 | Train Acc: 97.164
25 Train Loss: 9.666 | Train Acc: 97.129
26 Train Loss: 9.287 | Train Acc: 97.404
27 Train Loss: 8.620 | Train Acc: 97.644
28 Train Loss: 8.678 | Train Acc: 97.644
29 Train Loss: 8.571 | Train Acc: 97.644
30 Train Loss: 8.489 | Train Acc: 97.493
31 Train Loss: 7.993 | Train Acc: 97.911
32 Train Loss: 7.406 | Train Acc: 98.284
33 Train Loss: 7.386 | Train Acc: 98.222
34 Train Loss: 7.002 | Train Acc: 98.409
35 Train Loss: 6.743 | Train Acc: 98.613
36 Train Loss: 6.785 | Train Acc: 98.427
37 Train Loss: 6.409 | Train Acc: 98.747
38 Train Loss: 6.140 | Train Acc: 98.818
39 Train Loss: 5.865 | Train Acc: 98.800
40 Train Loss: 5.213 | Train Acc: 99.289
41 Train Loss: 5.111 | Train Acc: 99.369
42 Train Loss: 4.985 | Train Acc: 99.316
43 Train Loss: 4.938 | Train Acc: 99.360
44 Train Loss: 4.824 | Train Acc: 99.369
45 Train Loss: 4.747 | Train Acc: 99.342
46 Train Loss: 4.659 | Train Acc: 99.413
47 Train Loss: 4.562 | Train Acc: 99.520
48 Train Loss: 4.507 | Train Acc: 99.476
49 Train Loss: 4.428 | Train Acc: 99.396
50 Train Loss: 4.383 | Train Acc: 99.502
51 Train Loss: 4.333 | Train Acc: 99.493
52 Train Loss: 4.185 | Train Acc: 99.529
53 Train Loss: 4.177 | Train Acc: 99.484
54 Train Loss: 4.108 | Train Acc: 99.609
55 Train Loss: 3.984 | Train Acc: 99.600
56 Train Loss: 3.981 | Train Acc: 99.582
57 Train Loss: 3.868 | Train Acc: 99.627
58 Train Loss: 3.839 | Train Acc: 99.564
59 Train Loss: 3.740 | Train Acc: 99.680
60 Train Loss: 3.485 | Train Acc: 99.698
61 Train Loss: 3.420 | Train Acc: 99.733
62 Train Loss: 3.428 | Train Acc: 99.742
63 Train Loss: 3.357 | Train Acc: 99.751
64 Train Loss: 3.351 | Train Acc: 99.724
65 Train Loss: 3.353 | Train Acc: 99.778
66 Train Loss: 3.322 | Train Acc: 99.769
67 Train Loss: 3.288 | Train Acc: 99.751
68 Train Loss: 3.253 | Train Acc: 99.822
69 Train Loss: 3.297 | Train Acc: 99.778
70 Train Loss: 3.208 | Train Acc: 99.813
71 Train Loss: 3.170 | Train Acc: 99.778
72 Train Loss: 3.175 | Train Acc: 99.813
73 Train Loss: 3.143 | Train Acc: 99.804
74 Train Loss: 3.102 | Train Acc: 99.831
75 Train Loss: 3.062 | Train Acc: 99.796
76 Train Loss: 3.055 | Train Acc: 99.804
77 Train Loss: 3.012 | Train Acc: 99.849
78 Train Loss: 2.988 | Train Acc: 99.804
79 Train Loss: 2.961 | Train Acc: 99.849
80 Train Loss: 2.865 | Train Acc: 99.858
81 Train Loss: 2.852 | Train Acc: 99.876
82 Train Loss: 2.838 | Train Acc: 99.858
83 Train Loss: 2.841 | Train Acc: 99.858
84 Train Loss: 2.835 | Train Acc: 99.867
85 Train Loss: 2.804 | Train Acc: 99.858
86 Train Loss: 2.806 | Train Acc: 99.858
87 Train Loss: 2.788 | Train Acc: 99.876
88 Train Loss: 2.778 | Train Acc: 99.884
89 Train Loss: 2.765 | Train Acc: 99.867
90 Train Loss: 2.751 | Train Acc: 99.849
91 Train Loss: 2.744 | Train Acc: 99.867
92 Train Loss: 2.742 | Train Acc: 99.884
93 Train Loss: 2.724 | Train Acc: 99.876
94 Train Loss: 2.717 | Train Acc: 99.884
95 Train Loss: 2.692 | Train Acc: 99.884
96 Train Loss: 2.699 | Train Acc: 99.867
97 Train Loss: 2.667 | Train Acc: 99.884
98 Train Loss: 2.685 | Train Acc: 99.884
99 Train Loss: 2.656 | Train Acc: 99.867
CNN trained successfully...
image_next_flat.shape :  torch.Size([11250, 4096])
printing expected split from k means
{0: 0, 1: 1, 2: 0}
Printing final_dict items...
{0: 1, 2: -1, 1: 1}
Image Statistics before MLP : L R :  625 10625
expectedMlpLabels.shape :  torch.Size([11250])
0 Loss: 24.137 | Acc: 69.875
1 Loss: 9.136 | Acc: 79.857
2 Loss: 8.018 | Acc: 81.375
3 Loss: 8.374 | Acc: 80.223
4 Loss: 7.477 | Acc: 84.107
5 Loss: 7.374 | Acc: 85.312
6 Loss: 7.676 | Acc: 80.732
7 Loss: 5.655 | Acc: 86.688
8 Loss: 5.367 | Acc: 86.759
9 Loss: 4.972 | Acc: 88.170
10 Loss: 5.049 | Acc: 88.500
11 Loss: 3.929 | Acc: 90.714
12 Loss: 3.621 | Acc: 92.455
13 Loss: 3.522 | Acc: 91.429
14 Loss: 3.266 | Acc: 92.777
15 Loss: 3.382 | Acc: 92.179
16 Loss: 2.718 | Acc: 93.920
17 Loss: 3.263 | Acc: 92.616
18 Loss: 3.069 | Acc: 93.179
19 Loss: 2.841 | Acc: 93.589
20 Loss: 2.231 | Acc: 94.839
21 Loss: 2.035 | Acc: 95.384
22 Loss: 1.965 | Acc: 95.438
23 Loss: 1.784 | Acc: 95.982
24 Loss: 1.702 | Acc: 96.027
25 Loss: 1.660 | Acc: 96.134
26 Loss: 1.701 | Acc: 96.045
27 Loss: 1.536 | Acc: 96.312
28 Loss: 1.523 | Acc: 96.402
29 Loss: 1.425 | Acc: 96.571
30 Loss: 1.203 | Acc: 97.170
31 Loss: 1.149 | Acc: 97.018
32 Loss: 1.119 | Acc: 97.232
33 Loss: 1.105 | Acc: 97.339
34 Loss: 1.081 | Acc: 97.098
35 Loss: 1.008 | Acc: 97.277
36 Loss: 0.977 | Acc: 97.464
37 Loss: 0.894 | Acc: 97.580
38 Loss: 0.969 | Acc: 97.688
39 Loss: 0.885 | Acc: 97.634
40 Loss: 0.776 | Acc: 97.991
41 Loss: 0.842 | Acc: 97.884
42 Loss: 0.734 | Acc: 98.196
43 Loss: 0.735 | Acc: 98.018
44 Loss: 0.797 | Acc: 98.054
45 Loss: 0.730 | Acc: 98.107
46 Loss: 0.728 | Acc: 98.179
47 Loss: 0.677 | Acc: 98.188
48 Loss: 0.628 | Acc: 98.250
49 Loss: 0.707 | Acc: 98.286
50 Loss: 0.672 | Acc: 98.232
51 Loss: 0.691 | Acc: 98.348
52 Loss: 0.575 | Acc: 98.357
53 Loss: 0.603 | Acc: 98.438
54 Loss: 0.641 | Acc: 98.304
55 Loss: 0.615 | Acc: 98.411
56 Loss: 0.631 | Acc: 98.384
57 Loss: 0.672 | Acc: 98.357
58 Loss: 0.625 | Acc: 98.366
59 Loss: 0.589 | Acc: 98.393
MLP trained successfully...
# of Left images:  625.0
# of Right images:  10625.0
giniRightRatio:  0.5536332179930795
giniLeftRatio:  0.0
impurityDrop:  0.5210665581111337
giniGain:  0.07152603448145889
lclasses:  [0, 0, 625, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 5000, 625, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  3
lTrainDict[data].shape:  torch.Size([625, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([625])
rTrainDict[data].shape:  torch.Size([10625, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([10625])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
nodeId:  28 , imgTensorShape :  torch.Size([625, 16, 16, 16])
nodeId: 28 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 625
nodeId:  29 , imgTensorShape :  torch.Size([10625, 16, 16, 16])
nodeId: 29 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 10625
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
Running nodeId:  20
Running nodeId:  21
Running nodeId:  22
Running nodeId:  23
Running nodeId:  24
Running nodeId:  25
Running nodeId:  26
Running nodeId:  27
Running nodeId:  28
Running nodeId:  29
0 Train Loss: 61.668 | Train Acc: 79.379
1 Train Loss: 43.319 | Train Acc: 83.520
2 Train Loss: 36.619 | Train Acc: 85.581
3 Train Loss: 36.460 | Train Acc: 86.136
4 Train Loss: 32.122 | Train Acc: 87.859
5 Train Loss: 30.148 | Train Acc: 88.584
6 Train Loss: 28.348 | Train Acc: 89.440
7 Train Loss: 27.683 | Train Acc: 89.948
8 Train Loss: 26.525 | Train Acc: 90.118
9 Train Loss: 24.479 | Train Acc: 90.729
10 Train Loss: 23.028 | Train Acc: 91.021
11 Train Loss: 22.506 | Train Acc: 91.680
12 Train Loss: 22.050 | Train Acc: 91.576
13 Train Loss: 21.648 | Train Acc: 92.047
14 Train Loss: 20.342 | Train Acc: 92.235
15 Train Loss: 17.999 | Train Acc: 93.045
16 Train Loss: 18.891 | Train Acc: 92.885
17 Train Loss: 16.088 | Train Acc: 93.995
18 Train Loss: 16.958 | Train Acc: 93.788
19 Train Loss: 15.507 | Train Acc: 94.099
20 Train Loss: 11.682 | Train Acc: 96.066
21 Train Loss: 11.222 | Train Acc: 96.188
22 Train Loss: 11.082 | Train Acc: 96.151
23 Train Loss: 10.881 | Train Acc: 96.311
24 Train Loss: 10.109 | Train Acc: 96.565
25 Train Loss: 9.888 | Train Acc: 96.687
26 Train Loss: 9.637 | Train Acc: 96.640
27 Train Loss: 9.877 | Train Acc: 96.781
28 Train Loss: 9.288 | Train Acc: 97.167
29 Train Loss: 8.662 | Train Acc: 97.355
30 Train Loss: 8.549 | Train Acc: 97.384
31 Train Loss: 9.052 | Train Acc: 97.016
32 Train Loss: 8.270 | Train Acc: 97.374
33 Train Loss: 8.029 | Train Acc: 97.666
34 Train Loss: 7.623 | Train Acc: 97.515
35 Train Loss: 7.568 | Train Acc: 97.741
36 Train Loss: 7.354 | Train Acc: 97.713
37 Train Loss: 6.807 | Train Acc: 98.155
38 Train Loss: 6.434 | Train Acc: 98.372
39 Train Loss: 6.281 | Train Acc: 98.447
40 Train Loss: 5.630 | Train Acc: 98.701
41 Train Loss: 5.359 | Train Acc: 98.908
42 Train Loss: 5.278 | Train Acc: 98.908
43 Train Loss: 5.257 | Train Acc: 98.965
44 Train Loss: 5.137 | Train Acc: 98.974
45 Train Loss: 5.070 | Train Acc: 99.087
46 Train Loss: 5.166 | Train Acc: 98.993
47 Train Loss: 4.952 | Train Acc: 99.040
48 Train Loss: 4.989 | Train Acc: 99.040
49 Train Loss: 4.701 | Train Acc: 99.049
50 Train Loss: 4.822 | Train Acc: 99.087
51 Train Loss: 4.599 | Train Acc: 99.228
52 Train Loss: 4.729 | Train Acc: 99.049
53 Train Loss: 4.519 | Train Acc: 99.228
54 Train Loss: 4.505 | Train Acc: 99.275
55 Train Loss: 4.342 | Train Acc: 99.304
56 Train Loss: 4.165 | Train Acc: 99.379
57 Train Loss: 4.199 | Train Acc: 99.266
58 Train Loss: 4.097 | Train Acc: 99.407
59 Train Loss: 4.039 | Train Acc: 99.416
60 Train Loss: 3.730 | Train Acc: 99.548
61 Train Loss: 3.721 | Train Acc: 99.576
62 Train Loss: 3.683 | Train Acc: 99.548
63 Train Loss: 3.615 | Train Acc: 99.558
64 Train Loss: 3.637 | Train Acc: 99.576
65 Train Loss: 3.581 | Train Acc: 99.605
66 Train Loss: 3.521 | Train Acc: 99.642
67 Train Loss: 3.574 | Train Acc: 99.586
68 Train Loss: 3.489 | Train Acc: 99.642
69 Train Loss: 3.490 | Train Acc: 99.689
70 Train Loss: 3.487 | Train Acc: 99.680
71 Train Loss: 3.350 | Train Acc: 99.624
72 Train Loss: 3.417 | Train Acc: 99.633
73 Train Loss: 3.402 | Train Acc: 99.671
74 Train Loss: 3.337 | Train Acc: 99.689
75 Train Loss: 3.342 | Train Acc: 99.699
76 Train Loss: 3.296 | Train Acc: 99.680
77 Train Loss: 3.216 | Train Acc: 99.727
78 Train Loss: 3.237 | Train Acc: 99.689
79 Train Loss: 3.257 | Train Acc: 99.680
80 Train Loss: 3.079 | Train Acc: 99.765
81 Train Loss: 3.086 | Train Acc: 99.755
82 Train Loss: 3.070 | Train Acc: 99.755
83 Train Loss: 3.059 | Train Acc: 99.765
84 Train Loss: 3.058 | Train Acc: 99.718
85 Train Loss: 3.041 | Train Acc: 99.765
86 Train Loss: 3.022 | Train Acc: 99.755
87 Train Loss: 3.012 | Train Acc: 99.793
88 Train Loss: 3.000 | Train Acc: 99.793
89 Train Loss: 3.012 | Train Acc: 99.784
90 Train Loss: 2.988 | Train Acc: 99.821
91 Train Loss: 2.988 | Train Acc: 99.765
92 Train Loss: 2.960 | Train Acc: 99.821
93 Train Loss: 2.935 | Train Acc: 99.784
94 Train Loss: 2.917 | Train Acc: 99.802
95 Train Loss: 2.913 | Train Acc: 99.765
96 Train Loss: 2.899 | Train Acc: 99.831
97 Train Loss: 2.916 | Train Acc: 99.821
98 Train Loss: 2.886 | Train Acc: 99.821
99 Train Loss: 2.888 | Train Acc: 99.812
CNN trained successfully...
image_next_flat.shape :  torch.Size([10625, 2304])
printing expected split from k means
{1: 1, 0: 0, 2: 0}
Printing final_dict items...
{0: 1, 1: -1, 2: 0}
Image Statistics before MLP : L R :  3125 7500
expectedMlpLabels.shape :  torch.Size([10625])
0 Loss: 75.305 | Acc: 61.377
1 Loss: 67.271 | Acc: 66.094
2 Loss: 64.174 | Acc: 67.840
3 Loss: 61.625 | Acc: 69.726
4 Loss: 59.301 | Acc: 70.094
5 Loss: 59.613 | Acc: 69.406
6 Loss: 56.772 | Acc: 71.349
7 Loss: 56.374 | Acc: 71.745
8 Loss: 55.854 | Acc: 72.019
9 Loss: 54.921 | Acc: 71.679
10 Loss: 51.441 | Acc: 73.991
11 Loss: 50.619 | Acc: 73.991
12 Loss: 50.208 | Acc: 74.330
13 Loss: 50.582 | Acc: 73.755
14 Loss: 50.534 | Acc: 73.877
15 Loss: 48.235 | Acc: 75.604
16 Loss: 49.197 | Acc: 74.981
17 Loss: 48.015 | Acc: 75.396
18 Loss: 47.542 | Acc: 75.651
19 Loss: 47.975 | Acc: 75.142
20 Loss: 45.643 | Acc: 76.453
21 Loss: 44.475 | Acc: 77.340
22 Loss: 44.305 | Acc: 77.509
23 Loss: 44.601 | Acc: 77.302
24 Loss: 44.416 | Acc: 77.481
25 Loss: 43.496 | Acc: 77.745
26 Loss: 43.504 | Acc: 78.104
27 Loss: 43.022 | Acc: 77.858
28 Loss: 42.441 | Acc: 78.443
29 Loss: 42.283 | Acc: 78.245
30 Loss: 41.509 | Acc: 78.953
31 Loss: 41.302 | Acc: 79.009
32 Loss: 41.178 | Acc: 78.708
33 Loss: 40.374 | Acc: 79.415
34 Loss: 40.776 | Acc: 79.557
35 Loss: 40.041 | Acc: 79.660
36 Loss: 40.010 | Acc: 79.462
37 Loss: 39.615 | Acc: 80.170
38 Loss: 40.047 | Acc: 79.642
39 Loss: 38.532 | Acc: 80.434
40 Loss: 39.076 | Acc: 80.057
41 Loss: 38.440 | Acc: 80.434
42 Loss: 38.122 | Acc: 80.698
43 Loss: 38.120 | Acc: 80.425
44 Loss: 38.134 | Acc: 80.642
45 Loss: 37.987 | Acc: 80.538
46 Loss: 37.988 | Acc: 80.396
47 Loss: 37.834 | Acc: 80.472
48 Loss: 37.594 | Acc: 80.849
49 Loss: 37.695 | Acc: 80.755
50 Loss: 37.161 | Acc: 81.160
51 Loss: 37.520 | Acc: 80.925
52 Loss: 37.104 | Acc: 80.972
53 Loss: 36.752 | Acc: 81.160
54 Loss: 37.121 | Acc: 81.302
55 Loss: 37.443 | Acc: 80.519
56 Loss: 37.314 | Acc: 80.981
57 Loss: 36.887 | Acc: 80.991
58 Loss: 36.764 | Acc: 81.142
59 Loss: 36.886 | Acc: 81.075
MLP trained successfully...
# of Left images:  3125.0
# of Right images:  7500.0
giniRightRatio:  0.4444444444444445
giniLeftRatio:  0.32
impurityDrop:  0.3925925925925926
giniGain:  0.16104062540048691
lclasses:  [0, 2500, 625, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 2500, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([3125, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([3125])
rTrainDict[data].shape:  torch.Size([7500, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([7500])
RETURNING FROM WORK...
nodeId:  30 , imgTensorShape :  torch.Size([3125, 16, 12, 12])
nodeId: 30 ,  parentId: 29 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 3125
nodeId:  31 , imgTensorShape :  torch.Size([7500, 16, 12, 12])
nodeId: 31 ,  parentId: 29 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7500
Running nodeId:  30
0 Train Loss: 33.893 | Train Acc: 87.484
1 Train Loss: 14.263 | Train Acc: 94.258
2 Train Loss: 11.454 | Train Acc: 95.484
3 Train Loss: 10.306 | Train Acc: 96.129
4 Train Loss: 9.860 | Train Acc: 96.581
5 Train Loss: 8.325 | Train Acc: 96.968
6 Train Loss: 6.351 | Train Acc: 97.581
7 Train Loss: 7.346 | Train Acc: 97.419
8 Train Loss: 5.009 | Train Acc: 98.484
9 Train Loss: 4.597 | Train Acc: 98.548
10 Train Loss: 4.503 | Train Acc: 98.484
11 Train Loss: 3.398 | Train Acc: 98.968
12 Train Loss: 3.188 | Train Acc: 98.903
13 Train Loss: 3.453 | Train Acc: 98.935
14 Train Loss: 2.048 | Train Acc: 99.484
15 Train Loss: 1.700 | Train Acc: 99.484
16 Train Loss: 1.367 | Train Acc: 99.710
17 Train Loss: 1.147 | Train Acc: 99.677
18 Train Loss: 0.876 | Train Acc: 99.871
19 Train Loss: 0.605 | Train Acc: 99.935
20 Train Loss: 0.464 | Train Acc: 100.000
21 Train Loss: 0.407 | Train Acc: 100.000
22 Train Loss: 0.393 | Train Acc: 100.000
23 Train Loss: 0.364 | Train Acc: 100.000
24 Train Loss: 0.331 | Train Acc: 100.000
25 Train Loss: 0.296 | Train Acc: 100.000
26 Train Loss: 0.289 | Train Acc: 100.000
27 Train Loss: 0.260 | Train Acc: 100.000
28 Train Loss: 0.260 | Train Acc: 100.000
29 Train Loss: 0.213 | Train Acc: 100.000
30 Train Loss: 0.217 | Train Acc: 100.000
31 Train Loss: 0.195 | Train Acc: 100.000
32 Train Loss: 0.174 | Train Acc: 100.000
33 Train Loss: 0.167 | Train Acc: 100.000
34 Train Loss: 0.150 | Train Acc: 100.000
35 Train Loss: 0.142 | Train Acc: 100.000
36 Train Loss: 0.122 | Train Acc: 100.000
37 Train Loss: 0.126 | Train Acc: 100.000
38 Train Loss: 0.114 | Train Acc: 100.000
39 Train Loss: 0.107 | Train Acc: 100.000
40 Train Loss: 0.097 | Train Acc: 100.000
41 Train Loss: 0.091 | Train Acc: 100.000
42 Train Loss: 0.090 | Train Acc: 100.000
43 Train Loss: 0.087 | Train Acc: 100.000
44 Train Loss: 0.084 | Train Acc: 100.000
45 Train Loss: 0.079 | Train Acc: 100.000
46 Train Loss: 0.080 | Train Acc: 100.000
47 Train Loss: 0.079 | Train Acc: 100.000
48 Train Loss: 0.076 | Train Acc: 100.000
49 Train Loss: 0.073 | Train Acc: 100.000
50 Train Loss: 0.069 | Train Acc: 100.000
51 Train Loss: 0.068 | Train Acc: 100.000
52 Train Loss: 0.066 | Train Acc: 100.000
53 Train Loss: 0.066 | Train Acc: 100.000
54 Train Loss: 0.060 | Train Acc: 100.000
55 Train Loss: 0.060 | Train Acc: 100.000
56 Train Loss: 0.057 | Train Acc: 100.000
57 Train Loss: 0.054 | Train Acc: 100.000
58 Train Loss: 0.051 | Train Acc: 100.000
59 Train Loss: 0.051 | Train Acc: 100.000
60 Train Loss: 0.047 | Train Acc: 100.000
61 Train Loss: 0.045 | Train Acc: 100.000
62 Train Loss: 0.045 | Train Acc: 100.000
63 Train Loss: 0.045 | Train Acc: 100.000
64 Train Loss: 0.044 | Train Acc: 100.000
65 Train Loss: 0.043 | Train Acc: 100.000
66 Train Loss: 0.043 | Train Acc: 100.000
67 Train Loss: 0.042 | Train Acc: 100.000
68 Train Loss: 0.041 | Train Acc: 100.000
69 Train Loss: 0.040 | Train Acc: 100.000
70 Train Loss: 0.039 | Train Acc: 100.000
71 Train Loss: 0.039 | Train Acc: 100.000
72 Train Loss: 0.037 | Train Acc: 100.000
73 Train Loss: 0.036 | Train Acc: 100.000
74 Train Loss: 0.036 | Train Acc: 100.000
75 Train Loss: 0.034 | Train Acc: 100.000
76 Train Loss: 0.033 | Train Acc: 100.000
77 Train Loss: 0.033 | Train Acc: 100.000
78 Train Loss: 0.033 | Train Acc: 100.000
79 Train Loss: 0.032 | Train Acc: 100.000
80 Train Loss: 0.030 | Train Acc: 100.000
81 Train Loss: 0.030 | Train Acc: 100.000
82 Train Loss: 0.030 | Train Acc: 100.000
83 Train Loss: 0.029 | Train Acc: 100.000
84 Train Loss: 0.029 | Train Acc: 100.000
85 Train Loss: 0.028 | Train Acc: 100.000
86 Train Loss: 0.028 | Train Acc: 100.000
87 Train Loss: 0.028 | Train Acc: 100.000
88 Train Loss: 0.028 | Train Acc: 100.000
89 Train Loss: 0.027 | Train Acc: 100.000
90 Train Loss: 0.027 | Train Acc: 100.000
91 Train Loss: 0.026 | Train Acc: 100.000
92 Train Loss: 0.026 | Train Acc: 100.000
93 Train Loss: 0.026 | Train Acc: 100.000
94 Train Loss: 0.026 | Train Acc: 100.000
95 Train Loss: 0.025 | Train Acc: 100.000
96 Train Loss: 0.025 | Train Acc: 100.000
97 Train Loss: 0.025 | Train Acc: 100.000
98 Train Loss: 0.024 | Train Acc: 100.000
99 Train Loss: 0.024 | Train Acc: 100.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([3125, 1024])
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{0: 1, 1: 0}
Image Statistics before MLP : L R :  625 2500
expectedMlpLabels.shape :  torch.Size([3125])
0 Loss: 15.801 | Acc: 94.900
1 Loss: 7.036 | Acc: 96.900
2 Loss: 2.990 | Acc: 98.733
3 Loss: 2.662 | Acc: 98.867
4 Loss: 1.622 | Acc: 99.333
5 Loss: 2.747 | Acc: 98.900
6 Loss: 2.311 | Acc: 99.000
7 Loss: 0.946 | Acc: 99.567
8 Loss: 1.684 | Acc: 99.333
9 Loss: 1.034 | Acc: 99.500
10 Loss: 0.093 | Acc: 100.000
11 Loss: 0.129 | Acc: 99.967
12 Loss: 0.086 | Acc: 99.967
13 Loss: 0.024 | Acc: 100.000
14 Loss: 0.042 | Acc: 99.967
15 Loss: 0.268 | Acc: 99.867
16 Loss: 0.236 | Acc: 99.900
17 Loss: 0.033 | Acc: 100.000
18 Loss: 0.023 | Acc: 100.000
19 Loss: 0.057 | Acc: 100.000
20 Loss: 0.026 | Acc: 99.967
21 Loss: 0.012 | Acc: 100.000
22 Loss: 0.079 | Acc: 99.967
23 Loss: 0.032 | Acc: 100.000
24 Loss: 0.004 | Acc: 100.000
25 Loss: 0.039 | Acc: 99.967
26 Loss: 0.005 | Acc: 100.000
27 Loss: 0.025 | Acc: 100.000
28 Loss: 0.001 | Acc: 100.000
29 Loss: 0.065 | Acc: 100.000
30 Loss: 0.009 | Acc: 100.000
31 Loss: 0.022 | Acc: 100.000
32 Loss: 0.003 | Acc: 100.000
33 Loss: 0.036 | Acc: 100.000
34 Loss: 0.013 | Acc: 100.000
35 Loss: 0.003 | Acc: 100.000
36 Loss: 0.002 | Acc: 100.000
37 Loss: 0.007 | Acc: 100.000
38 Loss: 0.002 | Acc: 100.000
39 Loss: 0.002 | Acc: 100.000
40 Loss: 0.002 | Acc: 100.000
41 Loss: 0.001 | Acc: 100.000
42 Loss: 0.087 | Acc: 99.967
43 Loss: 0.003 | Acc: 100.000
44 Loss: 0.011 | Acc: 100.000
45 Loss: 0.014 | Acc: 100.000
46 Loss: 0.003 | Acc: 100.000
47 Loss: 0.002 | Acc: 100.000
48 Loss: 0.002 | Acc: 100.000
49 Loss: 0.004 | Acc: 100.000
50 Loss: 0.004 | Acc: 100.000
51 Loss: 0.003 | Acc: 100.000
52 Loss: 0.002 | Acc: 100.000
53 Loss: 0.001 | Acc: 100.000
54 Loss: 0.001 | Acc: 100.000
55 Loss: 0.005 | Acc: 100.000
56 Loss: 0.005 | Acc: 100.000
57 Loss: 0.002 | Acc: 100.000
58 Loss: 0.005 | Acc: 100.000
59 Loss: 0.018 | Acc: 99.967
MLP trained successfully...
# of Left images:  625.0
# of Right images:  2500.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.32
lclasses:  [0, 625, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2500, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([625, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([625])
rTrainDict[data].shape:  torch.Size([2500, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([2500])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  32 , imgTensorShape :  torch.Size([625, 16, 8, 8])
nodeId: 32 ,  parentId: 30 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 625
nodeId:  33 , imgTensorShape :  torch.Size([2500, 16, 8, 8])
nodeId: 33 ,  parentId: 30 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 2500
Running nodeId:  31
0 Train Loss: 40.370 | Train Acc: 81.933
1 Train Loss: 27.529 | Train Acc: 88.560
2 Train Loss: 22.984 | Train Acc: 90.747
3 Train Loss: 20.635 | Train Acc: 91.747
4 Train Loss: 18.328 | Train Acc: 92.493
5 Train Loss: 19.033 | Train Acc: 92.387
6 Train Loss: 17.590 | Train Acc: 92.707
7 Train Loss: 14.901 | Train Acc: 94.013
8 Train Loss: 14.794 | Train Acc: 93.920
9 Train Loss: 13.908 | Train Acc: 94.200
10 Train Loss: 11.603 | Train Acc: 95.373
11 Train Loss: 11.236 | Train Acc: 95.533
12 Train Loss: 12.792 | Train Acc: 94.613
13 Train Loss: 10.176 | Train Acc: 96.013
14 Train Loss: 9.064 | Train Acc: 96.667
15 Train Loss: 7.676 | Train Acc: 97.373
16 Train Loss: 8.169 | Train Acc: 97.053
17 Train Loss: 7.694 | Train Acc: 97.400
18 Train Loss: 6.933 | Train Acc: 97.347
19 Train Loss: 7.891 | Train Acc: 96.840
20 Train Loss: 4.829 | Train Acc: 98.693
21 Train Loss: 4.876 | Train Acc: 98.533
22 Train Loss: 4.175 | Train Acc: 98.907
23 Train Loss: 4.093 | Train Acc: 98.920
24 Train Loss: 4.088 | Train Acc: 98.827
25 Train Loss: 3.979 | Train Acc: 98.973
26 Train Loss: 3.694 | Train Acc: 99.253
27 Train Loss: 3.628 | Train Acc: 99.107
28 Train Loss: 3.397 | Train Acc: 99.293
29 Train Loss: 3.437 | Train Acc: 99.067
30 Train Loss: 3.143 | Train Acc: 99.320
31 Train Loss: 2.968 | Train Acc: 99.400
32 Train Loss: 3.154 | Train Acc: 99.373
33 Train Loss: 2.892 | Train Acc: 99.453
34 Train Loss: 2.639 | Train Acc: 99.387
35 Train Loss: 2.531 | Train Acc: 99.507
36 Train Loss: 2.344 | Train Acc: 99.653
37 Train Loss: 2.302 | Train Acc: 99.547
38 Train Loss: 2.277 | Train Acc: 99.667
39 Train Loss: 2.057 | Train Acc: 99.693
40 Train Loss: 1.809 | Train Acc: 99.893
41 Train Loss: 1.751 | Train Acc: 99.800
42 Train Loss: 1.740 | Train Acc: 99.827
43 Train Loss: 1.680 | Train Acc: 99.893
44 Train Loss: 1.667 | Train Acc: 99.867
45 Train Loss: 1.640 | Train Acc: 99.853
46 Train Loss: 1.623 | Train Acc: 99.853
47 Train Loss: 1.582 | Train Acc: 99.893
48 Train Loss: 1.543 | Train Acc: 99.867
49 Train Loss: 1.559 | Train Acc: 99.867
50 Train Loss: 1.476 | Train Acc: 99.907
51 Train Loss: 1.466 | Train Acc: 99.867
52 Train Loss: 1.419 | Train Acc: 99.933
53 Train Loss: 1.442 | Train Acc: 99.907
54 Train Loss: 1.367 | Train Acc: 99.907
55 Train Loss: 1.325 | Train Acc: 99.907
56 Train Loss: 1.260 | Train Acc: 99.947
57 Train Loss: 1.295 | Train Acc: 99.893
58 Train Loss: 1.238 | Train Acc: 99.947
59 Train Loss: 1.189 | Train Acc: 99.947
60 Train Loss: 1.117 | Train Acc: 99.947
61 Train Loss: 1.084 | Train Acc: 99.960
62 Train Loss: 1.095 | Train Acc: 99.960
63 Train Loss: 1.077 | Train Acc: 99.947
64 Train Loss: 1.081 | Train Acc: 99.973
65 Train Loss: 1.036 | Train Acc: 99.973
66 Train Loss: 1.031 | Train Acc: 99.973
67 Train Loss: 1.019 | Train Acc: 99.960
68 Train Loss: 1.013 | Train Acc: 99.973
69 Train Loss: 0.996 | Train Acc: 99.960
70 Train Loss: 0.990 | Train Acc: 99.973
71 Train Loss: 0.980 | Train Acc: 99.960
72 Train Loss: 0.954 | Train Acc: 99.960
73 Train Loss: 0.954 | Train Acc: 99.973
74 Train Loss: 0.975 | Train Acc: 99.947
75 Train Loss: 0.927 | Train Acc: 99.960
76 Train Loss: 0.932 | Train Acc: 99.960
77 Train Loss: 0.917 | Train Acc: 99.960
78 Train Loss: 0.911 | Train Acc: 99.973
79 Train Loss: 0.900 | Train Acc: 99.973
80 Train Loss: 0.847 | Train Acc: 99.973
81 Train Loss: 0.846 | Train Acc: 99.973
82 Train Loss: 0.840 | Train Acc: 99.973
83 Train Loss: 0.836 | Train Acc: 99.973
84 Train Loss: 0.835 | Train Acc: 99.973
85 Train Loss: 0.832 | Train Acc: 99.973
86 Train Loss: 0.821 | Train Acc: 99.973
87 Train Loss: 0.812 | Train Acc: 99.973
88 Train Loss: 0.804 | Train Acc: 99.973
89 Train Loss: 0.815 | Train Acc: 99.973
90 Train Loss: 0.794 | Train Acc: 99.973
91 Train Loss: 0.787 | Train Acc: 99.973
92 Train Loss: 0.799 | Train Acc: 99.973
93 Train Loss: 0.791 | Train Acc: 99.973
94 Train Loss: 0.785 | Train Acc: 99.973
95 Train Loss: 0.786 | Train Acc: 99.973
96 Train Loss: 0.775 | Train Acc: 99.973
97 Train Loss: 0.770 | Train Acc: 99.973
98 Train Loss: 0.766 | Train Acc: 99.973
99 Train Loss: 0.770 | Train Acc: 99.973
CNN trained successfully...
image_next_flat.shape :  torch.Size([7500, 1024])
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  5000 2500
expectedMlpLabels.shape :  torch.Size([7500])
0 Loss: 33.562 | Acc: 89.716
1 Loss: 15.288 | Acc: 95.486
2 Loss: 15.142 | Acc: 95.324
3 Loss: 7.361 | Acc: 97.730
4 Loss: 7.678 | Acc: 97.689
5 Loss: 5.945 | Acc: 98.297
6 Loss: 5.757 | Acc: 98.419
7 Loss: 4.563 | Acc: 98.770
8 Loss: 3.424 | Acc: 99.162
9 Loss: 3.827 | Acc: 98.946
10 Loss: 1.663 | Acc: 99.689
11 Loss: 1.978 | Acc: 99.419
12 Loss: 1.157 | Acc: 99.676
13 Loss: 0.926 | Acc: 99.797
14 Loss: 0.806 | Acc: 99.784
15 Loss: 0.839 | Acc: 99.797
16 Loss: 1.438 | Acc: 99.662
17 Loss: 0.529 | Acc: 99.878
18 Loss: 2.001 | Acc: 99.365
19 Loss: 0.823 | Acc: 99.770
20 Loss: 0.411 | Acc: 99.892
21 Loss: 0.273 | Acc: 99.932
22 Loss: 0.182 | Acc: 99.986
23 Loss: 0.422 | Acc: 99.905
24 Loss: 0.224 | Acc: 99.959
25 Loss: 0.753 | Acc: 99.811
26 Loss: 0.248 | Acc: 99.932
27 Loss: 0.220 | Acc: 99.946
28 Loss: 0.120 | Acc: 99.973
29 Loss: 0.056 | Acc: 100.000
30 Loss: 0.093 | Acc: 99.959
31 Loss: 0.078 | Acc: 99.986
32 Loss: 0.080 | Acc: 99.986
33 Loss: 0.041 | Acc: 100.000
34 Loss: 0.043 | Acc: 100.000
35 Loss: 0.078 | Acc: 99.986
36 Loss: 0.144 | Acc: 99.973
37 Loss: 0.059 | Acc: 100.000
38 Loss: 0.073 | Acc: 99.986
39 Loss: 0.081 | Acc: 100.000
40 Loss: 0.062 | Acc: 99.986
41 Loss: 0.053 | Acc: 99.986
42 Loss: 0.028 | Acc: 100.000
43 Loss: 0.032 | Acc: 100.000
44 Loss: 0.024 | Acc: 100.000
45 Loss: 0.022 | Acc: 100.000
46 Loss: 0.018 | Acc: 100.000
47 Loss: 0.017 | Acc: 100.000
48 Loss: 0.028 | Acc: 100.000
49 Loss: 0.039 | Acc: 99.986
50 Loss: 0.020 | Acc: 100.000
51 Loss: 0.012 | Acc: 100.000
52 Loss: 0.037 | Acc: 100.000
53 Loss: 0.056 | Acc: 99.986
54 Loss: 0.044 | Acc: 99.986
55 Loss: 0.019 | Acc: 100.000
56 Loss: 0.027 | Acc: 100.000
57 Loss: 0.023 | Acc: 100.000
58 Loss: 0.068 | Acc: 99.986
59 Loss: 0.018 | Acc: 100.000
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  2500.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 2500, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([2500, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([2500])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 4
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 4
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  34 , imgTensorShape :  torch.Size([5000, 16, 8, 8])
nodeId: 34 ,  parentId: 31 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 5000
nodeId:  35 , imgTensorShape :  torch.Size([2500, 16, 8, 8])
nodeId: 35 ,  parentId: 31 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 2500
Running nodeId:  32
Running nodeId:  33
Running nodeId:  34
Running nodeId:  35
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 58.960
Split Acc: 86.900
# of Left images:  4920.0
# of Right images:  5080.0
giniRightRatio:  0.843493861987724
giniLeftRatio:  0.8397589067354088
impurityDrop:  0.8398765431213085
giniGain:  0.06012345687869147
lclasses:  [914, 955, 588, 124, 163, 106, 115, 107, 936, 912]
rclasses:  [86, 45, 412, 876, 837, 894, 885, 893, 64, 88]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([4920, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([4920])
rTrainDict[data].shape:  torch.Size([5080, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([5080])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([4920, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4920
nodeId:  3 , imgTensorShape :  torch.Size([5080, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5080
Nodes sizes =  5 5
Node 2 Acc: 67.703
Split Acc: 81.138
# of Left images:  2534.0
# of Right images:  2386.0
giniRightRatio:  0.7266493775860725
giniLeftRatio:  0.7523769863245807
impurityDrop:  0.7539728312924345
giniGain:  0.08578607544297423
lclasses:  [832, 64, 358, 65, 111, 53, 49, 59, 856, 87]
rclasses:  [82, 891, 230, 59, 52, 53, 66, 48, 80, 825]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2534, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([2534])
rTrainDict[data].shape:  torch.Size([2386, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([2386])
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([2534, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2534
nodeId:  5 , imgTensorShape :  torch.Size([2386, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2386
Nodes sizes =  3 3
Node 3 Acc: 56.516
Split Acc: 75.177
# of Left images:  2667.0
# of Right images:  2413.0
giniRightRatio:  0.7831924361909666
giniLeftRatio:  0.792823562971389
impurityDrop:  0.7938373657903809
giniGain:  0.049656496197343136
lclasses:  [41, 27, 218, 706, 168, 784, 118, 514, 38, 53]
rclasses:  [45, 18, 194, 170, 669, 110, 767, 379, 26, 35]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([2667, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([2667])
rTrainDict[data].shape:  torch.Size([2413, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([2413])
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([2667, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2667
nodeId:  7 , imgTensorShape :  torch.Size([2413, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2413
Nodes sizes =  3 3
Node 4 Acc: 68.272
Split Acc: 77.032
# of Left images:  1101.0
# of Right images:  1433.0
giniRightRatio:  0.6138995631337689
giniLeftRatio:  0.7221921117042469
impurityDrop:  0.6971027005909192
giniGain:  0.055274285733661555
lclasses:  [475, 18, 311, 39, 75, 33, 37, 40, 47, 26]
rclasses:  [357, 46, 47, 26, 36, 20, 12, 19, 809, 61]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1101, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1101])
rTrainDict[data].shape:  torch.Size([1433, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([1433])
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([1101, 16, 20, 20])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1101
nodeId:  9 , imgTensorShape :  torch.Size([1433, 16, 20, 20])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1433
Nodes sizes =  2 2
Node 5 Acc: 70.704
Split Acc: 79.044
# of Left images:  809.0
# of Right images:  1577.0
giniRightRatio:  0.6096137042915177
giniLeftRatio:  0.7384935544347353
impurityDrop:  0.6757289856902895
giniGain:  0.05092039189578301
lclasses:  [24, 35, 205, 36, 37, 40, 41, 23, 21, 347]
rclasses:  [58, 856, 25, 23, 15, 13, 25, 25, 59, 478]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([809, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([809])
rTrainDict[data].shape:  torch.Size([1577, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([1577])
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([809, 16, 20, 20])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: 20 ,  rchildId: 21 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 809
nodeId:  11 , imgTensorShape :  torch.Size([1577, 16, 20, 20])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 22 ,  rchildId: 23 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1577
Nodes sizes =  2 2
Node 6 Acc: 50.544
Split Acc: 66.179
# of Left images:  1630.0
# of Right images:  1037.0
giniRightRatio:  0.7619896054284624
giniLeftRatio:  0.7415423990364712
impurityDrop:  0.7298498306753808
giniGain:  0.06297373229600822
lclasses:  [23, 14, 137, 452, 99, 657, 88, 112, 22, 26]
rclasses:  [18, 13, 81, 254, 69, 127, 30, 402, 16, 27]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1630, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1630])
rTrainDict[data].shape:  torch.Size([1037, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([1037])
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([1630, 16, 20, 20])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: 24 ,  rchildId: 25 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1630
nodeId:  13 , imgTensorShape :  torch.Size([1037, 16, 20, 20])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: 26 ,  rchildId: 27 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1037
Nodes sizes =  2 2
Node 7 Acc: 61.666
Split Acc: 74.389
# of Left images:  217.0
# of Right images:  2196.0
giniRightRatio:  0.7656817661520697
giniLeftRatio:  0.38306186158126104
impurityDrop:  0.7278727865109653
giniGain:  0.05531964968000125
lclasses:  [3, 2, 4, 6, 18, 9, 2, 169, 0, 4]
rclasses:  [42, 16, 190, 164, 651, 101, 765, 210, 26, 31]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([217, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([217])
rTrainDict[data].shape:  torch.Size([2196, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([2196])
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([217, 16, 20, 20])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 217
nodeId:  15 , imgTensorShape :  torch.Size([2196, 16, 20, 20])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 28 ,  rchildId: 29 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2196
Nodes sizes =  1 3
Node 8 Acc: 62.579
Split Acc: 62.216
# of Left images:  485.0
# of Right images:  616.0
giniRightRatio:  0.5021978832855457
giniLeftRatio:  0.6838728876607503
impurityDrop:  0.6452374565355039
giniGain:  0.076954655168743
lclasses:  [47, 3, 257, 26, 56, 24, 31, 24, 12, 5]
rclasses:  [428, 15, 54, 13, 19, 9, 6, 16, 35, 21]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([485, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([485])
rTrainDict[data].shape:  torch.Size([616, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([616])
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([485, 16, 16, 16])
nodeId: 16 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 485
nodeId:  17 , imgTensorShape :  torch.Size([616, 16, 16, 16])
nodeId: 17 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 616
Nodes sizes =  1 1
Node 9 Acc: 71.738
Split Acc: 71.738
# of Left images:  400.0
# of Right images:  1033.0
giniRightRatio:  0.42956866765565005
giniLeftRatio:  0.5669875
impurityDrop:  0.48278021938627924
giniGain:  0.13111934374748968
lclasses:  [257, 13, 21, 5, 18, 6, 3, 16, 38, 23]
rclasses:  [100, 33, 26, 21, 18, 14, 9, 3, 771, 38]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([400, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([400])
rTrainDict[data].shape:  torch.Size([1033, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1033])
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([400, 16, 16, 16])
nodeId: 18 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 400
nodeId:  19 , imgTensorShape :  torch.Size([1033, 16, 16, 16])
nodeId: 19 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 1033
Nodes sizes =  1 1
Node 10 Acc: 65.884
Split Acc: 65.637
# of Left images:  430.0
# of Right images:  379.0
giniRightRatio:  0.6948573178967009
giniLeftRatio:  0.39280692266089784
impurityDrop:  0.3521616188165022
giniGain:  0.3863319356182331
lclasses:  [16, 25, 7, 11, 3, 8, 7, 8, 12, 333]
rclasses:  [8, 10, 198, 25, 34, 32, 34, 15, 9, 14]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([430, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([430])
rTrainDict[data].shape:  torch.Size([379, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([379])
RETURNING FROM WORK...
nodeId:  20 , imgTensorShape :  torch.Size([430, 16, 16, 16])
nodeId: 20 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 430
nodeId:  21 , imgTensorShape :  torch.Size([379, 16, 16, 16])
nodeId: 21 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 379
Nodes sizes =  1 1
Node 11 Acc: 73.050
Split Acc: 74.192
# of Left images:  1019.0
# of Right images:  558.0
giniRightRatio:  0.5020554720520034
giniLeftRatio:  0.39494549583430044
impurityDrop:  0.30645499576913726
giniGain:  0.30315870852238047
lclasses:  [30, 785, 14, 16, 13, 7, 11, 10, 40, 93]
rclasses:  [28, 71, 11, 7, 2, 6, 14, 15, 19, 385]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1019, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([1019])
rTrainDict[data].shape:  torch.Size([558, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([558])
RETURNING FROM WORK...
nodeId:  22 , imgTensorShape :  torch.Size([1019, 16, 16, 16])
nodeId: 22 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 1019
nodeId:  23 , imgTensorShape :  torch.Size([558, 16, 16, 16])
nodeId: 23 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 558
Nodes sizes =  1 1
Node 12 Acc: 46.442
Split Acc: 47.117
# of Left images:  531.0
# of Right images:  1099.0
giniRightRatio:  0.7001666665286748
giniLeftRatio:  0.7429679991204456
impurityDrop:  0.7208468372349808
giniGain:  0.02069556180149046
lclasses:  [12, 7, 47, 229, 38, 118, 30, 35, 11, 4]
rclasses:  [11, 7, 90, 223, 61, 539, 58, 77, 11, 22]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([531, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([531])
rTrainDict[data].shape:  torch.Size([1099, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1099])
RETURNING FROM WORK...
nodeId:  24 , imgTensorShape :  torch.Size([531, 16, 16, 16])
nodeId: 24 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 531
nodeId:  25 , imgTensorShape :  torch.Size([1099, 16, 16, 16])
nodeId: 25 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1099
Nodes sizes =  1 1
Node 13 Acc: 54.388
Split Acc: 54.966
# of Left images:  500.0
# of Right images:  537.0
giniRightRatio:  0.538227063241888
giniLeftRatio:  0.7618959999999999
impurityDrop:  0.7464849186963683
giniGain:  0.015504686732094042
lclasses:  [11, 7, 55, 213, 38, 81, 24, 45, 10, 16]
rclasses:  [7, 6, 26, 41, 31, 46, 6, 357, 6, 11]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([500, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([500])
rTrainDict[data].shape:  torch.Size([537, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([537])
RETURNING FROM WORK...
nodeId:  26 , imgTensorShape :  torch.Size([500, 16, 16, 16])
nodeId: 26 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 500
nodeId:  27 , imgTensorShape :  torch.Size([537, 16, 16, 16])
nodeId: 27 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 537
Nodes sizes =  1 1
Node 14 Acc: 77.880
Node 15 Acc: 60.519
Split Acc: 73.634
# of Left images:  88.0
# of Right images:  2108.0
giniRightRatio:  0.7542091391248305
giniLeftRatio:  0.5165289256198348
impurityDrop:  0.7442870049747168
giniGain:  0.02139476117735295
lclasses:  [1, 0, 4, 4, 8, 6, 1, 60, 1, 3]
rclasses:  [41, 16, 186, 160, 643, 95, 764, 150, 25, 28]
noOfLeftClasses:  9
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([88, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([88])
rTrainDict[data].shape:  torch.Size([2108, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([2108])
RETURNING FROM WORK...
nodeId:  28 , imgTensorShape :  torch.Size([88, 16, 16, 16])
nodeId: 28 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 88
nodeId:  29 , imgTensorShape :  torch.Size([2108, 16, 16, 16])
nodeId: 29 ,  parentId: 15 ,  level: 4 ,  lchildId: 30 ,  rchildId: 31 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2108
Nodes sizes =  1 3
Node 16 Acc: 52.990
Node 17 Acc: 69.481
Node 18 Acc: 64.250
Node 19 Acc: 74.637
Node 20 Acc: 77.442
Node 21 Acc: 52.243
Node 22 Acc: 77.036
Node 23 Acc: 68.996
Node 24 Acc: 43.126
Node 25 Acc: 49.045
Node 26 Acc: 42.600
Node 27 Acc: 66.480
Node 28 Acc: 68.182
Node 29 Acc: 60.294
Split Acc: 66.603
# of Left images:  940.0
# of Right images:  1168.0
giniRightRatio:  0.7090727036029274
giniLeftRatio:  0.5199071978270711
impurityDrop:  0.5568333410778376
giniGain:  0.1973757980469929
lclasses:  [14, 7, 57, 56, 60, 31, 640, 57, 7, 11]
rclasses:  [27, 9, 129, 104, 583, 64, 124, 93, 18, 17]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([940, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([940])
rTrainDict[data].shape:  torch.Size([1168, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([1168])
RETURNING FROM WORK...
nodeId:  30 , imgTensorShape :  torch.Size([940, 16, 12, 12])
nodeId: 30 ,  parentId: 29 ,  level: 5 ,  lchildId: 32 ,  rchildId: 33 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 940
nodeId:  31 , imgTensorShape :  torch.Size([1168, 16, 12, 12])
nodeId: 31 ,  parentId: 29 ,  level: 5 ,  lchildId: 34 ,  rchildId: 35 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1168
Nodes sizes =  2 2
Node 30 Acc: 71.915
Split Acc: 71.596
# of Left images:  72.0
# of Right images:  868.0
giniRightRatio:  0.45420108730276715
giniLeftRatio:  0.6496913580246914
impurityDrop:  0.47041687012762723
giniGain:  0.04949032769944384
lclasses:  [2, 1, 2, 3, 15, 4, 6, 39, 0, 0]
rclasses:  [12, 6, 55, 53, 45, 27, 634, 18, 7, 11]
noOfLeftClasses:  8
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([72, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([72])
rTrainDict[data].shape:  torch.Size([868, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([868])
RETURNING FROM WORK...
nodeId:  32 , imgTensorShape :  torch.Size([72, 16, 8, 8])
nodeId: 32 ,  parentId: 30 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 72
nodeId:  33 , imgTensorShape :  torch.Size([868, 16, 8, 8])
nodeId: 33 ,  parentId: 30 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 868
Nodes sizes =  1 1
Node 31 Acc: 51.370
Split Acc: 50.771
# of Left images:  1020.0
# of Right images:  148.0
giniRightRatio:  0.787253469685902
giniLeftRatio:  0.6783890811226451
impurityDrop:  0.03697187283102288
giniGain:  0.6721008307719045
lclasses:  [24, 7, 109, 84, 545, 59, 76, 92, 10, 14]
rclasses:  [3, 2, 20, 20, 38, 5, 48, 1, 8, 3]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1020, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([1020])
rTrainDict[data].shape:  torch.Size([148, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([148])
RETURNING FROM WORK...
nodeId:  34 , imgTensorShape :  torch.Size([1020, 16, 8, 8])
nodeId: 34 ,  parentId: 31 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 1020
nodeId:  35 , imgTensorShape :  torch.Size([148, 16, 8, 8])
nodeId: 35 ,  parentId: 31 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 148
Nodes sizes =  1 1
Node 32 Acc: 54.167
Node 33 Acc: 73.041
Node 34 Acc: 53.431
Node 35 Acc: 32.432
[[685  30  55  23  24  11  15  13 100  44]
 [ 28 785  13  14   7   7   8   9  33  96]
 [ 75  14 455 102 109  90  75  36  26  18]
 [ 18  16  51 442  84 223  73  54  21  18]
 [ 37  13  90  76 545  61  83  72  18   5]
 [ 15   7  56 199  59 539  32  65  14  14]
 [  9  11  65  54  76  58 682  15   9  21]
 [ 32  10  39  80  92  77  19 625   3  23]
 [ 73  40  21  21  10  11  15   7 771  31]
 [ 44  93  19  20  14  22  14  18  38 718]]

#3:: Case 1 WITH BIG_MLP ARCH AND EXACTLY EQUAL DATA POINTS DISTRIBUTION (in Num_Classes being Odd too):-
Acc: 62.470
                                                                                                           1                                                                                                                                       
                                                                                                                                  
                                                   2                                                                                                               3                                                                               
                                                                                                                                               
                       4                                                       5                                                       6                                         7                                                                 
                                                                                                                                      
         8                           9                           10                          11                          12                          13                   14                   15                                                  
                                                                                                                     
  16            17            18            19            20            21            22            23            24            25            26            27                          28                                 29                      
                                                                                                                                                                                                                      
                                                                                                                                                                                                             30                          31        
                                                                                                                                                                                                                     
                                                                                                                                                                                                      32            33            34            35 
                                                                                           -1                                                                                                                  
                                                                                                              
                                           -1                                                                                              -1                                                                  
                                                                                                                         
                   -1                                              -1                                              -1                                  -1                                                      
                                                                                                                 
       -1                      -1                      -1                      -1                      -1                      -1                7                 -1                                          
                                                                                                  
 2           0           0           8           9           2           1           9           3           5           3           7                       7                             -1                  
                                                                                                                                                                                      
                                                                                                                                                                               -1                      -1      
                                                                                                                                                                                     
                                                                                                                                                                         7           6           4           6 
                                                                                                               50000                                                                                                                                                    
                                                                                                                                            
                                                     25000                                                                                                                  25000                                                                                     
                                                                                                                                                            
                    12500                                                            12500                                                          12500                                     12500                                                                     
                                                                                                                                              
       5000                            7500                            5000                            7500                          7500                            5000              1250                 11250                                                       
                                                                                                                      2500          2500            2500            5000            2500            2500            5000            2500           2500            5000            2500            2500                     625                                  10625                         
                                                                                                                                                                                                                                         
                                                                                                                                                                                                                             3125                            7500         
                                                                                                                                                                                                                                          
                                                                                                                                                                                                                       625            2500            5000            2500 
                                                                                                          86.9                                                                                                                                     
                                                                                                                                  
                                           81.13821138211382                                                                                               75.17716535433071                                                                       
                                                                                                                                               
               77.03235990528808                                        79.0444258172674                                       66.17922759655043                         74.38872772482387                                                         
                                                                                                                                      
 62.21616712079928           71.73761339846476           65.63658838071693           74.19150285351934           47.11656441717791           54.96624879459981           0.0           73.63387978142076                                           
                                                                                                                     
 0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0           0.0                         0.0                          66.6034155597723               
                                                                                                                                                                                                                      
                                                                                                                                                                                                     71.59574468085107           50.77054794520548 
                                                                                                                                                                                                                     
                                                                                                                                                                                                     0.0           0.0           0.0           0.0 
                                                                                                      0.09999999999999987                                                                                                                                    
                                                                                                                                        
                                            0.16000000000000014                                                                                                 0.16000000000000014                                                                          
                                                                                                                                                      
               0.1585185185185185                                        0.1585185185185185                                         0.22333333333333327                        0.11325102880658444                                                           
                                                                                                                                            
        0.5                   0.4444444444444445                  0.5                   0.4444444444444445            0.4444444444444445                  0.5                   0.0           0.07152603448145889                                            
                                                                                                                               
 0.0           0.0            0.0           0.0            0.0           0.0            0.0           0.0             0.0           0.0            0.0           0.0                          0.0                        0.16104062540048691                 
                                                                                                                                                                                                                               
                                                                                                                                                                                                                   0.32                  0.4444444444444445  
                                                                                                                                                                                                                               
                                                                                                                                                                                                            0.0           0.0            0.0           0.0  

                                                                                                                                                                                                                                                                                                                      
                                                                                                                                                                                                                                                                                               {6: 2500, 7: 625}                       {4: 5000, 6: 2500}      
                                                                                                                                                                                                                                                                                                                     
                                                                                                                                                                                                                                                                                          {7: 625}           {6: 2500}           {4: 5000}           {6: 2500} 









                             {0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}                                                                                                                                                      
                                                                                                                                 
               {0: 5000, 1: 5000, 2: 5000, 8: 5000, 9: 5000}                                     {3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000}                                                                                             
                                                                                                      
{0: 5000, 2: 2500, 8: 5000}                    {1: 5000, 2: 2500, 9: 5000}                      {3: 5000, 5: 5000, 7: 2500}                                 {4: 5000, 6: 5000, 7: 2500}                                                                                  
                                                                                                
{0: 2500, 2: 2500}    {0: 2500, 8: 5000}          {2: 2500, 9: 2500}           {1: 5000, 9: 2500}            {3: 2500, 5: 5000}           {3: 2500, 7: 2500}      {7: 1250}   {4: 5000, 6: 5000, 7: 1250}                                                              
                                                                                         
 {2: 2500}          {0: 2500}   {0: 2500}          {8: 5000}        {9: 2500}      {2: 2500}      {1: 5000}      {9: 2500}       {3: 2500}      {5: 5000}    {3: 2500}      {7: 2500}       {7: 625}               {4: 5000, 6: 5000, 7: 625}                      







