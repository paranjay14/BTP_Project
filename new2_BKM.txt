['options.ckptDir: newDir2_BKM', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 16', 'options.mlpFC1: 516', 'options.mlpFC2: 16']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 177.956 | Train Acc: 37.506 
1 Train Loss: 145.234 | Train Acc: 49.384 
2 Train Loss: 136.029 | Train Acc: 52.553 
3 Train Loss: 130.495 | Train Acc: 54.624 
4 Train Loss: 126.714 | Train Acc: 55.814 
5 Train Loss: 123.980 | Train Acc: 56.949 
6 Train Loss: 121.057 | Train Acc: 57.814 
7 Train Loss: 118.400 | Train Acc: 59.047 
8 Train Loss: 115.725 | Train Acc: 59.947 
9 Train Loss: 113.133 | Train Acc: 60.778 
10 Train Loss: 110.440 | Train Acc: 61.871 
11 Train Loss: 108.610 | Train Acc: 62.447 
12 Train Loss: 106.663 | Train Acc: 63.131 
13 Train Loss: 105.405 | Train Acc: 63.439 
14 Train Loss: 103.329 | Train Acc: 64.208 
15 Train Loss: 101.570 | Train Acc: 64.833 
16 Train Loss: 100.632 | Train Acc: 65.310 
17 Train Loss: 99.249 | Train Acc: 65.859 
18 Train Loss: 97.858 | Train Acc: 66.114 
19 Train Loss: 96.561 | Train Acc: 66.716 
20 Train Loss: 93.073 | Train Acc: 68.184 
21 Train Loss: 92.450 | Train Acc: 68.184 
22 Train Loss: 91.767 | Train Acc: 68.563 
23 Train Loss: 91.453 | Train Acc: 68.465 
24 Train Loss: 90.543 | Train Acc: 68.929 
25 Train Loss: 90.315 | Train Acc: 69.082 
26 Train Loss: 90.020 | Train Acc: 69.096 
27 Train Loss: 89.560 | Train Acc: 69.296 
28 Train Loss: 88.968 | Train Acc: 69.524 
29 Train Loss: 88.610 | Train Acc: 69.608 
30 Train Loss: 88.114 | Train Acc: 69.902 
31 Train Loss: 87.722 | Train Acc: 70.104 
32 Train Loss: 87.169 | Train Acc: 70.116 
33 Train Loss: 86.493 | Train Acc: 70.280 
34 Train Loss: 86.249 | Train Acc: 70.476 
35 Train Loss: 85.617 | Train Acc: 70.753 
36 Train Loss: 85.302 | Train Acc: 70.957 
37 Train Loss: 84.776 | Train Acc: 71.186 
38 Train Loss: 84.499 | Train Acc: 71.284 
39 Train Loss: 83.934 | Train Acc: 71.312 
40 Train Loss: 82.320 | Train Acc: 71.996 
41 Train Loss: 81.999 | Train Acc: 72.224 
42 Train Loss: 81.669 | Train Acc: 72.347 
43 Train Loss: 81.580 | Train Acc: 72.437 
44 Train Loss: 81.344 | Train Acc: 72.520 
45 Train Loss: 81.283 | Train Acc: 72.429 
46 Train Loss: 81.186 | Train Acc: 72.631 
47 Train Loss: 81.020 | Train Acc: 72.508 
48 Train Loss: 80.742 | Train Acc: 72.682 
49 Train Loss: 80.627 | Train Acc: 72.751 
50 Train Loss: 80.462 | Train Acc: 72.855 
51 Train Loss: 80.187 | Train Acc: 73.000 
52 Train Loss: 80.194 | Train Acc: 72.910 
53 Train Loss: 80.012 | Train Acc: 72.957 
54 Train Loss: 79.738 | Train Acc: 73.037 
55 Train Loss: 79.447 | Train Acc: 73.200 
56 Train Loss: 79.390 | Train Acc: 73.245 
57 Train Loss: 79.152 | Train Acc: 73.324 
58 Train Loss: 79.075 | Train Acc: 73.161 
59 Train Loss: 78.819 | Train Acc: 73.376 
60 Train Loss: 78.056 | Train Acc: 73.741 
61 Train Loss: 78.025 | Train Acc: 73.908 
62 Train Loss: 77.882 | Train Acc: 73.888 
63 Train Loss: 77.874 | Train Acc: 73.851 
64 Train Loss: 77.801 | Train Acc: 73.849 
65 Train Loss: 77.711 | Train Acc: 73.859 
66 Train Loss: 77.614 | Train Acc: 73.935 
67 Train Loss: 77.616 | Train Acc: 73.888 
68 Train Loss: 77.543 | Train Acc: 73.929 
69 Train Loss: 77.411 | Train Acc: 74.065 
70 Train Loss: 77.398 | Train Acc: 74.059 
71 Train Loss: 77.324 | Train Acc: 74.027 
72 Train Loss: 77.247 | Train Acc: 74.002 
73 Train Loss: 77.214 | Train Acc: 74.114 
74 Train Loss: 77.100 | Train Acc: 74.133 
75 Train Loss: 77.033 | Train Acc: 74.214 
76 Train Loss: 77.028 | Train Acc: 74.176 
77 Train Loss: 76.922 | Train Acc: 74.114 
78 Train Loss: 76.770 | Train Acc: 74.190 
79 Train Loss: 76.740 | Train Acc: 74.276 
80 Train Loss: 76.404 | Train Acc: 74.416 
81 Train Loss: 76.379 | Train Acc: 74.408 
82 Train Loss: 76.358 | Train Acc: 74.402 
83 Train Loss: 76.324 | Train Acc: 74.418 
84 Train Loss: 76.298 | Train Acc: 74.480 
85 Train Loss: 76.261 | Train Acc: 74.506 
86 Train Loss: 76.250 | Train Acc: 74.429 
87 Train Loss: 76.233 | Train Acc: 74.498 
88 Train Loss: 76.177 | Train Acc: 74.527 
89 Train Loss: 76.203 | Train Acc: 74.390 
90 Train Loss: 76.134 | Train Acc: 74.514 
91 Train Loss: 76.109 | Train Acc: 74.484 
92 Train Loss: 76.074 | Train Acc: 74.465 
93 Train Loss: 76.065 | Train Acc: 74.535 
94 Train Loss: 76.007 | Train Acc: 74.518 
95 Train Loss: 75.997 | Train Acc: 74.531 
96 Train Loss: 75.989 | Train Acc: 74.531 
97 Train Loss: 75.932 | Train Acc: 74.518 
98 Train Loss: 75.886 | Train Acc: 74.629 
99 Train Loss: 75.880 | Train Acc: 74.588 
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 12544])
Time Taken by Kmeans is  3.8846640586853027
Kmeans completed successfully...
printing expected split from k means
{8: 0, 5: 1, 9: 0, 2: 1, 4: 1, 0: 0, 1: 0, 7: 1, 6: 1, 3: 1}
Printing final_dict items...
{8: 0, 0: 0, 9: 0, 1: 0, 2: 0, 3: 1, 7: 1, 5: 1, 4: 1, 6: 1}
Image Statistics before MLP : L R :  24500 24500
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 82.449 | Acc: 81.676
1 Loss: 71.246 | Acc: 84.569
2 Loss: 66.419 | Acc: 85.506
3 Loss: 63.399 | Acc: 86.400
4 Loss: 60.262 | Acc: 87.004
5 Loss: 57.863 | Acc: 87.531
6 Loss: 56.188 | Acc: 87.898
7 Loss: 53.361 | Acc: 88.506
8 Loss: 51.836 | Acc: 88.659
9 Loss: 49.227 | Acc: 89.180
10 Loss: 42.912 | Acc: 90.827
11 Loss: 40.721 | Acc: 91.198
12 Loss: 39.216 | Acc: 91.502
13 Loss: 37.470 | Acc: 91.886
14 Loss: 36.336 | Acc: 92.147
15 Loss: 34.991 | Acc: 92.380
16 Loss: 33.009 | Acc: 92.935
17 Loss: 32.534 | Acc: 93.092
18 Loss: 31.245 | Acc: 93.218
19 Loss: 30.550 | Acc: 93.492
20 Loss: 26.207 | Acc: 94.449
21 Loss: 25.439 | Acc: 94.800
22 Loss: 24.805 | Acc: 94.839
23 Loss: 23.590 | Acc: 95.053
24 Loss: 23.246 | Acc: 95.220
25 Loss: 22.806 | Acc: 95.276
26 Loss: 22.192 | Acc: 95.341
27 Loss: 21.312 | Acc: 95.651
28 Loss: 21.117 | Acc: 95.694
29 Loss: 20.373 | Acc: 95.906
30 Loss: 19.029 | Acc: 96.227
31 Loss: 18.308 | Acc: 96.343
32 Loss: 18.153 | Acc: 96.331
33 Loss: 17.754 | Acc: 96.429
34 Loss: 17.775 | Acc: 96.439
35 Loss: 17.564 | Acc: 96.420
36 Loss: 17.098 | Acc: 96.602
37 Loss: 16.988 | Acc: 96.659
38 Loss: 16.445 | Acc: 96.778
39 Loss: 16.230 | Acc: 96.733
40 Loss: 16.184 | Acc: 96.794
41 Loss: 14.963 | Acc: 97.069
42 Loss: 15.077 | Acc: 97.069
43 Loss: 15.600 | Acc: 96.884
44 Loss: 15.210 | Acc: 96.982
45 Loss: 15.153 | Acc: 97.055
46 Loss: 15.081 | Acc: 97.027
47 Loss: 14.558 | Acc: 97.151
48 Loss: 14.766 | Acc: 97.151
49 Loss: 15.128 | Acc: 97.035
50 Loss: 14.535 | Acc: 97.212
51 Loss: 14.460 | Acc: 97.190
52 Loss: 14.326 | Acc: 97.120
53 Loss: 14.116 | Acc: 97.286
54 Loss: 14.704 | Acc: 97.139
55 Loss: 14.317 | Acc: 97.214
56 Loss: 13.987 | Acc: 97.243
57 Loss: 14.363 | Acc: 97.086
58 Loss: 14.344 | Acc: 97.216
59 Loss: 14.438 | Acc: 97.116
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([24500])
rTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([24500])
lValDict[data].shape:  torch.Size([500, 3, 32, 32])   lValDict[label].shape:  torch.Size([500])
rValDict[data].shape:  torch.Size([500, 3, 32, 32])   rValDict[label].shape:  torch.Size([500])
# of Left images:  24500.0
# of Right images:  24500.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [4900, 4900, 4900, 0, 0, 0, 0, 0, 4900, 4900]
rclasses:  [0, 0, 0, 4900, 4900, 4900, 4900, 4900, 0, 0]
noOfLeftClasses:  5
noOfRightClasses:  5
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
nodeId:  3 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
Running nodeId:  2
0 Train Loss: 131.676 | Train Acc: 48.131 
1 Train Loss: 102.917 | Train Acc: 60.286 
2 Train Loss: 95.868 | Train Acc: 63.237 
3 Train Loss: 91.361 | Train Acc: 64.767 
4 Train Loss: 87.670 | Train Acc: 66.555 
5 Train Loss: 83.855 | Train Acc: 68.322 
6 Train Loss: 80.525 | Train Acc: 69.600 
7 Train Loss: 78.034 | Train Acc: 70.539 
8 Train Loss: 75.428 | Train Acc: 71.882 
9 Train Loss: 73.515 | Train Acc: 72.771 
10 Train Loss: 71.734 | Train Acc: 73.371 
11 Train Loss: 69.336 | Train Acc: 74.543 
12 Train Loss: 67.837 | Train Acc: 75.167 
13 Train Loss: 65.709 | Train Acc: 75.829 
14 Train Loss: 64.639 | Train Acc: 76.122 
15 Train Loss: 62.346 | Train Acc: 77.204 
16 Train Loss: 60.673 | Train Acc: 77.763 
17 Train Loss: 59.327 | Train Acc: 78.237 
18 Train Loss: 58.116 | Train Acc: 78.996 
19 Train Loss: 57.539 | Train Acc: 79.131 
20 Train Loss: 53.310 | Train Acc: 80.955 
21 Train Loss: 53.102 | Train Acc: 80.943 
22 Train Loss: 52.323 | Train Acc: 81.453 
23 Train Loss: 51.957 | Train Acc: 81.392 
24 Train Loss: 51.567 | Train Acc: 81.588 
25 Train Loss: 50.914 | Train Acc: 82.020 
26 Train Loss: 50.675 | Train Acc: 82.265 
27 Train Loss: 50.326 | Train Acc: 82.204 
28 Train Loss: 49.887 | Train Acc: 82.196 
29 Train Loss: 49.883 | Train Acc: 82.220 
30 Train Loss: 48.955 | Train Acc: 82.673 
31 Train Loss: 48.458 | Train Acc: 83.135 
32 Train Loss: 47.967 | Train Acc: 83.143 
33 Train Loss: 47.487 | Train Acc: 83.273 
34 Train Loss: 47.008 | Train Acc: 83.567 
35 Train Loss: 46.682 | Train Acc: 83.469 
36 Train Loss: 46.033 | Train Acc: 84.008 
37 Train Loss: 45.723 | Train Acc: 84.110 
38 Train Loss: 45.351 | Train Acc: 84.192 
39 Train Loss: 44.680 | Train Acc: 84.539 
40 Train Loss: 43.287 | Train Acc: 85.122 
41 Train Loss: 43.113 | Train Acc: 85.224 
42 Train Loss: 42.854 | Train Acc: 85.318 
43 Train Loss: 42.776 | Train Acc: 85.404 
44 Train Loss: 42.666 | Train Acc: 85.171 
45 Train Loss: 42.645 | Train Acc: 85.449 
46 Train Loss: 42.204 | Train Acc: 85.518 
47 Train Loss: 42.167 | Train Acc: 85.743 
48 Train Loss: 42.180 | Train Acc: 85.567 
49 Train Loss: 41.824 | Train Acc: 85.800 
50 Train Loss: 41.718 | Train Acc: 85.751 
51 Train Loss: 41.590 | Train Acc: 85.776 
52 Train Loss: 41.402 | Train Acc: 85.788 
53 Train Loss: 41.540 | Train Acc: 85.898 
54 Train Loss: 41.254 | Train Acc: 85.939 
55 Train Loss: 40.959 | Train Acc: 86.012 
56 Train Loss: 40.936 | Train Acc: 86.135 
57 Train Loss: 40.714 | Train Acc: 86.082 
58 Train Loss: 40.682 | Train Acc: 86.196 
59 Train Loss: 40.442 | Train Acc: 86.171 
60 Train Loss: 39.822 | Train Acc: 86.637 
61 Train Loss: 39.763 | Train Acc: 86.616 
62 Train Loss: 39.640 | Train Acc: 86.612 
63 Train Loss: 39.618 | Train Acc: 86.616 
64 Train Loss: 39.562 | Train Acc: 86.600 
65 Train Loss: 39.470 | Train Acc: 86.702 
66 Train Loss: 39.470 | Train Acc: 86.857 
67 Train Loss: 39.389 | Train Acc: 86.771 
68 Train Loss: 39.356 | Train Acc: 86.763 
69 Train Loss: 39.262 | Train Acc: 86.845 
70 Train Loss: 39.252 | Train Acc: 86.767 
71 Train Loss: 39.129 | Train Acc: 86.886 
72 Train Loss: 39.051 | Train Acc: 86.943 
73 Train Loss: 39.191 | Train Acc: 86.841 
74 Train Loss: 39.057 | Train Acc: 87.016 
75 Train Loss: 38.999 | Train Acc: 86.869 
76 Train Loss: 38.966 | Train Acc: 86.902 
77 Train Loss: 38.774 | Train Acc: 87.065 
78 Train Loss: 38.789 | Train Acc: 87.106 
79 Train Loss: 38.749 | Train Acc: 86.992 
80 Train Loss: 38.453 | Train Acc: 87.265 
81 Train Loss: 38.406 | Train Acc: 87.241 
82 Train Loss: 38.374 | Train Acc: 87.343 
83 Train Loss: 38.380 | Train Acc: 87.257 
84 Train Loss: 38.337 | Train Acc: 87.192 
85 Train Loss: 38.358 | Train Acc: 87.269 
86 Train Loss: 38.279 | Train Acc: 87.163 
87 Train Loss: 38.250 | Train Acc: 87.294 
88 Train Loss: 38.239 | Train Acc: 87.282 
89 Train Loss: 38.228 | Train Acc: 87.335 
90 Train Loss: 38.219 | Train Acc: 87.245 
91 Train Loss: 38.176 | Train Acc: 87.351 
92 Train Loss: 38.200 | Train Acc: 87.196 
93 Train Loss: 38.133 | Train Acc: 87.359 
94 Train Loss: 38.128 | Train Acc: 87.278 
95 Train Loss: 38.093 | Train Acc: 87.396 
96 Train Loss: 38.052 | Train Acc: 87.331 
97 Train Loss: 38.029 | Train Acc: 87.371 
98 Train Loss: 38.050 | Train Acc: 87.282 
99 Train Loss: 38.017 | Train Acc: 87.416 
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Time Taken by Kmeans is  1.9020028114318848
Kmeans completed successfully...
printing expected split from k means
{3: 0, 0: 0, 2: 1, 4: 1, 1: 1}
Printing final_dict items...
{3: 0, 0: 0, 4: -1, 1: 1, 2: 1}
Image Statistics before MLP : L R :  12250 12250
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 116.002 | Acc: 70.510
1 Loss: 103.030 | Acc: 74.796
2 Loss: 99.308 | Acc: 75.208
3 Loss: 92.454 | Acc: 77.731
4 Loss: 88.243 | Acc: 78.710
5 Loss: 85.930 | Acc: 79.347
6 Loss: 82.457 | Acc: 79.955
7 Loss: 78.988 | Acc: 81.073
8 Loss: 77.492 | Acc: 81.286
9 Loss: 74.752 | Acc: 82.176
10 Loss: 66.512 | Acc: 83.878
11 Loss: 64.657 | Acc: 84.465
12 Loss: 64.172 | Acc: 84.718
13 Loss: 61.640 | Acc: 85.155
14 Loss: 58.776 | Acc: 86.139
15 Loss: 58.967 | Acc: 85.820
16 Loss: 55.992 | Acc: 86.727
17 Loss: 54.724 | Acc: 87.102
18 Loss: 53.671 | Acc: 87.473
19 Loss: 51.678 | Acc: 87.755
20 Loss: 46.271 | Acc: 89.282
21 Loss: 44.746 | Acc: 89.731
22 Loss: 43.355 | Acc: 90.171
23 Loss: 41.444 | Acc: 90.453
24 Loss: 41.965 | Acc: 90.473
25 Loss: 39.833 | Acc: 90.694
26 Loss: 38.624 | Acc: 91.273
27 Loss: 38.090 | Acc: 91.453
28 Loss: 35.453 | Acc: 92.020
29 Loss: 35.943 | Acc: 91.902
30 Loss: 33.476 | Acc: 92.718
31 Loss: 32.142 | Acc: 92.861
32 Loss: 33.094 | Acc: 92.571
33 Loss: 31.940 | Acc: 93.061
34 Loss: 31.116 | Acc: 93.355
35 Loss: 31.290 | Acc: 93.053
36 Loss: 29.881 | Acc: 93.469
37 Loss: 29.843 | Acc: 93.624
38 Loss: 29.657 | Acc: 93.678
39 Loss: 28.331 | Acc: 93.918
40 Loss: 27.900 | Acc: 93.910
41 Loss: 27.118 | Acc: 94.286
42 Loss: 27.971 | Acc: 94.155
43 Loss: 26.919 | Acc: 94.343
44 Loss: 26.763 | Acc: 94.273
45 Loss: 26.857 | Acc: 94.237
46 Loss: 26.296 | Acc: 94.465
47 Loss: 25.771 | Acc: 94.612
48 Loss: 26.542 | Acc: 94.351
49 Loss: 25.530 | Acc: 94.727
50 Loss: 25.593 | Acc: 94.563
51 Loss: 25.364 | Acc: 94.682
52 Loss: 25.677 | Acc: 94.588
53 Loss: 25.407 | Acc: 94.571
54 Loss: 25.398 | Acc: 94.678
55 Loss: 25.148 | Acc: 94.751
56 Loss: 25.072 | Acc: 94.771
57 Loss: 24.600 | Acc: 94.882
58 Loss: 24.825 | Acc: 94.837
59 Loss: 25.195 | Acc: 94.780
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([12250, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([12250])
rTrainDict[data].shape:  torch.Size([12250, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([12250])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  12250.0
# of Right images:  12250.0
giniRightRatio:  0.64
giniLeftRatio:  0.64
impurityDrop:  0.64
giniGain:  0.16000000000000014
lclasses:  [4900, 0, 0, 4900, 2450, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 0, 2450, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([12250, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12250
nodeId:  5 , imgTensorShape :  torch.Size([12250, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12250
Running nodeId:  3
0 Train Loss: 141.127 | Train Acc: 39.898 
1 Train Loss: 119.588 | Train Acc: 52.008 
2 Train Loss: 112.127 | Train Acc: 55.184 
3 Train Loss: 107.151 | Train Acc: 57.682 
4 Train Loss: 104.002 | Train Acc: 59.082 
5 Train Loss: 101.199 | Train Acc: 60.229 
6 Train Loss: 97.964 | Train Acc: 61.620 
7 Train Loss: 95.988 | Train Acc: 62.624 
8 Train Loss: 94.236 | Train Acc: 63.167 
9 Train Loss: 91.254 | Train Acc: 64.914 
10 Train Loss: 88.214 | Train Acc: 66.273 
11 Train Loss: 86.794 | Train Acc: 66.567 
12 Train Loss: 84.647 | Train Acc: 67.224 
13 Train Loss: 83.383 | Train Acc: 68.110 
14 Train Loss: 81.266 | Train Acc: 68.763 
15 Train Loss: 79.308 | Train Acc: 69.788 
16 Train Loss: 78.225 | Train Acc: 70.371 
17 Train Loss: 77.281 | Train Acc: 70.686 
18 Train Loss: 75.797 | Train Acc: 71.322 
19 Train Loss: 75.847 | Train Acc: 71.253 
20 Train Loss: 71.360 | Train Acc: 73.314 
21 Train Loss: 70.531 | Train Acc: 73.567 
22 Train Loss: 70.086 | Train Acc: 73.747 
23 Train Loss: 70.005 | Train Acc: 73.780 
24 Train Loss: 69.409 | Train Acc: 73.967 
25 Train Loss: 68.956 | Train Acc: 74.151 
26 Train Loss: 68.612 | Train Acc: 74.429 
27 Train Loss: 68.199 | Train Acc: 74.600 
28 Train Loss: 67.490 | Train Acc: 74.816 
29 Train Loss: 67.664 | Train Acc: 74.816 
30 Train Loss: 67.031 | Train Acc: 75.106 
31 Train Loss: 66.974 | Train Acc: 75.196 
32 Train Loss: 66.126 | Train Acc: 75.306 
33 Train Loss: 66.415 | Train Acc: 75.155 
34 Train Loss: 65.699 | Train Acc: 75.690 
35 Train Loss: 65.392 | Train Acc: 75.820 
36 Train Loss: 65.157 | Train Acc: 75.800 
37 Train Loss: 64.891 | Train Acc: 75.820 
38 Train Loss: 64.669 | Train Acc: 75.878 
39 Train Loss: 64.185 | Train Acc: 76.388 
40 Train Loss: 62.410 | Train Acc: 77.376 
41 Train Loss: 62.205 | Train Acc: 77.208 
42 Train Loss: 61.964 | Train Acc: 77.420 
43 Train Loss: 61.864 | Train Acc: 77.486 
44 Train Loss: 61.913 | Train Acc: 77.629 
45 Train Loss: 61.613 | Train Acc: 77.616 
46 Train Loss: 61.546 | Train Acc: 77.420 
47 Train Loss: 61.361 | Train Acc: 77.624 
48 Train Loss: 61.219 | Train Acc: 77.739 
49 Train Loss: 61.097 | Train Acc: 77.686 
50 Train Loss: 60.941 | Train Acc: 77.743 
51 Train Loss: 60.745 | Train Acc: 77.731 
52 Train Loss: 60.851 | Train Acc: 77.869 
53 Train Loss: 60.687 | Train Acc: 78.098 
54 Train Loss: 60.401 | Train Acc: 78.257 
55 Train Loss: 60.549 | Train Acc: 78.012 
56 Train Loss: 60.160 | Train Acc: 78.188 
57 Train Loss: 60.082 | Train Acc: 78.188 
58 Train Loss: 59.933 | Train Acc: 78.388 
59 Train Loss: 59.927 | Train Acc: 78.327 
60 Train Loss: 59.118 | Train Acc: 78.906 
61 Train Loss: 59.075 | Train Acc: 78.641 
62 Train Loss: 58.958 | Train Acc: 78.812 
63 Train Loss: 58.911 | Train Acc: 78.820 
64 Train Loss: 58.833 | Train Acc: 78.792 
65 Train Loss: 58.847 | Train Acc: 78.869 
66 Train Loss: 58.792 | Train Acc: 78.861 
67 Train Loss: 58.737 | Train Acc: 78.955 
68 Train Loss: 58.686 | Train Acc: 78.894 
69 Train Loss: 58.684 | Train Acc: 78.902 
70 Train Loss: 58.629 | Train Acc: 78.951 
71 Train Loss: 58.572 | Train Acc: 78.878 
72 Train Loss: 58.518 | Train Acc: 78.935 
73 Train Loss: 58.436 | Train Acc: 78.951 
74 Train Loss: 58.455 | Train Acc: 78.935 
75 Train Loss: 58.311 | Train Acc: 79.033 
76 Train Loss: 58.281 | Train Acc: 79.078 
77 Train Loss: 58.214 | Train Acc: 79.069 
78 Train Loss: 58.263 | Train Acc: 78.959 
79 Train Loss: 58.158 | Train Acc: 79.131 
80 Train Loss: 57.799 | Train Acc: 79.327 
81 Train Loss: 57.800 | Train Acc: 79.343 
82 Train Loss: 57.749 | Train Acc: 79.343 
83 Train Loss: 57.739 | Train Acc: 79.380 
84 Train Loss: 57.706 | Train Acc: 79.371 
85 Train Loss: 57.677 | Train Acc: 79.408 
86 Train Loss: 57.659 | Train Acc: 79.371 
87 Train Loss: 57.627 | Train Acc: 79.412 
88 Train Loss: 57.632 | Train Acc: 79.347 
89 Train Loss: 57.608 | Train Acc: 79.449 
90 Train Loss: 57.576 | Train Acc: 79.478 
91 Train Loss: 57.618 | Train Acc: 79.441 
92 Train Loss: 57.554 | Train Acc: 79.396 
93 Train Loss: 57.553 | Train Acc: 79.400 
94 Train Loss: 57.513 | Train Acc: 79.461 
95 Train Loss: 57.500 | Train Acc: 79.522 
96 Train Loss: 57.502 | Train Acc: 79.453 
97 Train Loss: 57.461 | Train Acc: 79.531 
98 Train Loss: 57.431 | Train Acc: 79.539 
99 Train Loss: 57.393 | Train Acc: 79.522 
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Time Taken by Kmeans is  2.0057761669158936
Kmeans completed successfully...
printing expected split from k means
{2: 1, 4: 0, 1: 1, 3: 1, 0: 1}
Printing final_dict items...
{4: 0, 0: 0, 2: -1, 1: 1, 3: 1}
Image Statistics before MLP : L R :  12250 12250
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 120.874 | Acc: 67.024
1 Loss: 112.630 | Acc: 70.890
2 Loss: 107.652 | Acc: 72.763
3 Loss: 102.298 | Acc: 73.739
4 Loss: 100.029 | Acc: 74.869
5 Loss: 96.207 | Acc: 76.033
6 Loss: 94.130 | Acc: 76.600
7 Loss: 91.653 | Acc: 77.176
8 Loss: 89.231 | Acc: 78.008
9 Loss: 86.028 | Acc: 78.914
10 Loss: 78.812 | Acc: 80.902
11 Loss: 76.328 | Acc: 81.563
12 Loss: 73.374 | Acc: 82.490
13 Loss: 71.252 | Acc: 82.992
14 Loss: 67.984 | Acc: 83.951
15 Loss: 65.590 | Acc: 84.457
16 Loss: 65.243 | Acc: 84.518
17 Loss: 62.362 | Acc: 85.404
18 Loss: 60.161 | Acc: 86.102
19 Loss: 59.029 | Acc: 86.576
20 Loss: 50.495 | Acc: 88.673
21 Loss: 49.112 | Acc: 88.898
22 Loss: 46.802 | Acc: 89.584
23 Loss: 46.274 | Acc: 89.576
24 Loss: 44.686 | Acc: 90.110
25 Loss: 43.371 | Acc: 90.563
26 Loss: 42.510 | Acc: 90.718
27 Loss: 41.469 | Acc: 90.951
28 Loss: 39.621 | Acc: 91.253
29 Loss: 38.744 | Acc: 91.522
30 Loss: 36.688 | Acc: 92.196
31 Loss: 35.282 | Acc: 92.282
32 Loss: 33.535 | Acc: 92.878
33 Loss: 34.169 | Acc: 92.759
34 Loss: 33.585 | Acc: 92.878
35 Loss: 32.786 | Acc: 93.061
36 Loss: 32.807 | Acc: 92.988
37 Loss: 31.740 | Acc: 93.437
38 Loss: 31.448 | Acc: 93.396
39 Loss: 31.066 | Acc: 93.347
40 Loss: 29.753 | Acc: 93.722
41 Loss: 29.358 | Acc: 93.984
42 Loss: 29.825 | Acc: 93.722
43 Loss: 29.001 | Acc: 93.922
44 Loss: 28.800 | Acc: 94.118
45 Loss: 28.560 | Acc: 94.029
46 Loss: 28.620 | Acc: 93.841
47 Loss: 28.536 | Acc: 93.939
48 Loss: 28.064 | Acc: 94.122
49 Loss: 28.120 | Acc: 94.073
50 Loss: 27.719 | Acc: 94.176
51 Loss: 27.409 | Acc: 94.441
52 Loss: 26.571 | Acc: 94.437
53 Loss: 27.383 | Acc: 94.290
54 Loss: 26.701 | Acc: 94.567
55 Loss: 26.951 | Acc: 94.461
56 Loss: 25.922 | Acc: 94.739
57 Loss: 26.796 | Acc: 94.441
58 Loss: 27.352 | Acc: 94.453
59 Loss: 27.014 | Acc: 94.331
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([12250, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([12250])
rTrainDict[data].shape:  torch.Size([12250, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([12250])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  12250.0
# of Right images:  12250.0
giniRightRatio:  0.64
giniLeftRatio:  0.64
impurityDrop:  0.64
giniGain:  0.16000000000000014
lclasses:  [4900, 0, 2450, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 2450, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([12250, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12250
nodeId:  7 , imgTensorShape :  torch.Size([12250, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 12250
Running nodeId:  4
0 Train Loss: 91.743 | Train Acc: 57.110 
1 Train Loss: 76.611 | Train Acc: 66.571 
2 Train Loss: 65.198 | Train Acc: 72.588 
3 Train Loss: 61.077 | Train Acc: 74.539 
4 Train Loss: 58.424 | Train Acc: 75.943 
5 Train Loss: 61.021 | Train Acc: 74.629 
6 Train Loss: 55.615 | Train Acc: 77.469 
7 Train Loss: 52.583 | Train Acc: 78.678 
8 Train Loss: 51.754 | Train Acc: 79.306 
9 Train Loss: 50.750 | Train Acc: 79.551 
10 Train Loss: 48.246 | Train Acc: 80.963 
11 Train Loss: 48.233 | Train Acc: 80.743 
12 Train Loss: 44.799 | Train Acc: 82.204 
13 Train Loss: 46.193 | Train Acc: 81.649 
14 Train Loss: 46.353 | Train Acc: 81.502 
15 Train Loss: 44.845 | Train Acc: 82.367 
16 Train Loss: 42.497 | Train Acc: 83.420 
17 Train Loss: 41.496 | Train Acc: 83.535 
18 Train Loss: 39.971 | Train Acc: 84.465 
19 Train Loss: 38.982 | Train Acc: 84.882 
20 Train Loss: 35.941 | Train Acc: 86.433 
21 Train Loss: 34.963 | Train Acc: 86.767 
22 Train Loss: 35.539 | Train Acc: 86.653 
23 Train Loss: 34.121 | Train Acc: 87.265 
24 Train Loss: 35.584 | Train Acc: 86.441 
25 Train Loss: 35.085 | Train Acc: 86.620 
26 Train Loss: 34.021 | Train Acc: 87.273 
27 Train Loss: 33.340 | Train Acc: 87.624 
28 Train Loss: 32.999 | Train Acc: 87.796 
29 Train Loss: 32.375 | Train Acc: 88.057 
30 Train Loss: 31.959 | Train Acc: 88.245 
31 Train Loss: 32.181 | Train Acc: 88.122 
32 Train Loss: 31.795 | Train Acc: 88.139 
33 Train Loss: 31.578 | Train Acc: 88.318 
34 Train Loss: 31.228 | Train Acc: 88.457 
35 Train Loss: 30.900 | Train Acc: 88.294 
36 Train Loss: 30.881 | Train Acc: 88.661 
37 Train Loss: 30.034 | Train Acc: 88.784 
38 Train Loss: 31.186 | Train Acc: 88.245 
39 Train Loss: 29.898 | Train Acc: 89.192 
40 Train Loss: 28.240 | Train Acc: 90.000 
41 Train Loss: 27.857 | Train Acc: 90.261 
42 Train Loss: 27.901 | Train Acc: 90.073 
43 Train Loss: 28.025 | Train Acc: 89.706 
44 Train Loss: 27.620 | Train Acc: 90.229 
45 Train Loss: 27.521 | Train Acc: 90.139 
46 Train Loss: 27.250 | Train Acc: 90.400 
47 Train Loss: 27.285 | Train Acc: 90.531 
48 Train Loss: 27.387 | Train Acc: 90.457 
49 Train Loss: 26.884 | Train Acc: 90.596 
50 Train Loss: 27.095 | Train Acc: 90.302 
51 Train Loss: 26.756 | Train Acc: 90.620 
52 Train Loss: 26.666 | Train Acc: 90.694 
53 Train Loss: 26.842 | Train Acc: 90.563 
54 Train Loss: 26.330 | Train Acc: 90.865 
55 Train Loss: 26.156 | Train Acc: 90.939 
56 Train Loss: 26.330 | Train Acc: 90.637 
57 Train Loss: 26.150 | Train Acc: 90.833 
58 Train Loss: 26.359 | Train Acc: 90.661 
59 Train Loss: 26.168 | Train Acc: 90.653 
60 Train Loss: 25.331 | Train Acc: 91.184 
61 Train Loss: 25.293 | Train Acc: 91.355 
62 Train Loss: 25.167 | Train Acc: 91.273 
63 Train Loss: 25.256 | Train Acc: 91.257 
64 Train Loss: 25.047 | Train Acc: 91.576 
65 Train Loss: 24.963 | Train Acc: 91.257 
66 Train Loss: 24.902 | Train Acc: 91.412 
67 Train Loss: 24.815 | Train Acc: 91.576 
68 Train Loss: 24.841 | Train Acc: 91.461 
69 Train Loss: 24.923 | Train Acc: 91.494 
70 Train Loss: 24.893 | Train Acc: 91.461 
71 Train Loss: 24.834 | Train Acc: 91.592 
72 Train Loss: 24.756 | Train Acc: 91.616 
73 Train Loss: 24.602 | Train Acc: 91.665 
74 Train Loss: 24.691 | Train Acc: 91.714 
75 Train Loss: 24.525 | Train Acc: 91.706 
76 Train Loss: 24.770 | Train Acc: 91.429 
77 Train Loss: 24.511 | Train Acc: 91.747 
78 Train Loss: 24.327 | Train Acc: 91.771 
79 Train Loss: 24.307 | Train Acc: 91.927 
80 Train Loss: 24.129 | Train Acc: 92.008 
81 Train Loss: 24.044 | Train Acc: 92.065 
82 Train Loss: 24.000 | Train Acc: 91.984 
83 Train Loss: 24.074 | Train Acc: 91.951 
84 Train Loss: 23.989 | Train Acc: 92.024 
85 Train Loss: 23.962 | Train Acc: 91.976 
86 Train Loss: 23.963 | Train Acc: 92.131 
87 Train Loss: 23.933 | Train Acc: 92.024 
88 Train Loss: 23.916 | Train Acc: 92.082 
89 Train Loss: 23.882 | Train Acc: 92.008 
90 Train Loss: 23.939 | Train Acc: 91.976 
91 Train Loss: 23.871 | Train Acc: 92.122 
92 Train Loss: 23.868 | Train Acc: 92.237 
93 Train Loss: 23.832 | Train Acc: 92.155 
94 Train Loss: 23.765 | Train Acc: 92.049 
95 Train Loss: 23.835 | Train Acc: 92.033 
96 Train Loss: 23.793 | Train Acc: 92.131 
97 Train Loss: 23.754 | Train Acc: 92.065 
98 Train Loss: 23.764 | Train Acc: 92.147 
99 Train Loss: 23.712 | Train Acc: 92.220 
CNN trained successfully...
image_next_flat.shape :  torch.Size([12250, 12544])
Time Taken by Kmeans is  1.0949723720550537
Kmeans completed successfully...
printing expected split from k means
{2: 0, 1: 1, 0: 1}
Printing final_dict items...
{2: 0, 0: -1, 1: 1}
Image Statistics before MLP : L R :  4900 7350
expectedMlpLabels.shape :  torch.Size([12250])
0 Loss: 107.674 | Acc: 62.049
1 Loss: 101.302 | Acc: 66.213
2 Loss: 91.410 | Acc: 70.426
3 Loss: 92.405 | Acc: 69.090
4 Loss: 83.574 | Acc: 71.926
5 Loss: 81.444 | Acc: 74.238
6 Loss: 84.009 | Acc: 71.861
7 Loss: 77.752 | Acc: 73.746
8 Loss: 73.995 | Acc: 75.992
9 Loss: 73.403 | Acc: 75.410
10 Loss: 68.647 | Acc: 77.115
11 Loss: 66.504 | Acc: 77.574
12 Loss: 65.125 | Acc: 77.574
13 Loss: 64.110 | Acc: 78.197
14 Loss: 61.135 | Acc: 79.795
15 Loss: 63.853 | Acc: 78.139
16 Loss: 59.430 | Acc: 79.770
17 Loss: 57.540 | Acc: 80.598
18 Loss: 56.642 | Acc: 80.631
19 Loss: 57.040 | Acc: 80.574
20 Loss: 52.982 | Acc: 82.320
21 Loss: 50.676 | Acc: 82.869
22 Loss: 50.127 | Acc: 83.426
23 Loss: 49.268 | Acc: 83.320
24 Loss: 48.580 | Acc: 83.639
25 Loss: 47.819 | Acc: 83.959
26 Loss: 46.877 | Acc: 84.189
27 Loss: 45.876 | Acc: 84.943
28 Loss: 45.721 | Acc: 84.820
29 Loss: 43.460 | Acc: 85.770
30 Loss: 42.093 | Acc: 86.205
31 Loss: 40.706 | Acc: 86.746
32 Loss: 40.197 | Acc: 86.721
33 Loss: 40.063 | Acc: 86.934
34 Loss: 39.705 | Acc: 87.000
35 Loss: 38.945 | Acc: 87.459
36 Loss: 38.327 | Acc: 87.959
37 Loss: 38.380 | Acc: 87.533
38 Loss: 37.122 | Acc: 88.082
39 Loss: 36.799 | Acc: 88.189
40 Loss: 36.338 | Acc: 88.402
41 Loss: 35.661 | Acc: 88.770
42 Loss: 35.556 | Acc: 88.623
43 Loss: 35.807 | Acc: 88.574
44 Loss: 35.311 | Acc: 88.975
45 Loss: 34.989 | Acc: 89.025
46 Loss: 35.323 | Acc: 88.607
47 Loss: 34.949 | Acc: 88.811
48 Loss: 34.520 | Acc: 89.311
49 Loss: 35.175 | Acc: 89.131
50 Loss: 34.145 | Acc: 89.279
51 Loss: 34.259 | Acc: 88.984
52 Loss: 34.460 | Acc: 89.279
53 Loss: 33.646 | Acc: 89.311
54 Loss: 34.086 | Acc: 89.254
55 Loss: 33.858 | Acc: 89.295
56 Loss: 33.360 | Acc: 89.566
57 Loss: 33.360 | Acc: 89.680
58 Loss: 33.250 | Acc: 89.779
59 Loss: 33.773 | Acc: 89.615
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([7350, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([7350])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  7350.0
giniRightRatio:  0.4444444444444445
giniLeftRatio:  0.5
impurityDrop:  0.4814814814814815
giniGain:  0.1585185185185185
lclasses:  [2450, 0, 2450, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2450, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 4900
nodeId:  9 , imgTensorShape :  torch.Size([7350, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7350
Running nodeId:  5
0 Train Loss: 82.209 | Train Acc: 64.073 
1 Train Loss: 62.357 | Train Acc: 74.024 
2 Train Loss: 55.015 | Train Acc: 77.584 
3 Train Loss: 49.844 | Train Acc: 79.453 
4 Train Loss: 45.054 | Train Acc: 81.878 
5 Train Loss: 45.243 | Train Acc: 81.910 
6 Train Loss: 41.963 | Train Acc: 83.265 
7 Train Loss: 40.554 | Train Acc: 84.335 
8 Train Loss: 41.034 | Train Acc: 83.682 
9 Train Loss: 41.720 | Train Acc: 83.714 
10 Train Loss: 42.054 | Train Acc: 83.061 
11 Train Loss: 37.676 | Train Acc: 84.922 
12 Train Loss: 38.266 | Train Acc: 84.792 
13 Train Loss: 35.740 | Train Acc: 86.041 
14 Train Loss: 35.650 | Train Acc: 85.657 
15 Train Loss: 33.955 | Train Acc: 87.045 
16 Train Loss: 35.017 | Train Acc: 86.482 
17 Train Loss: 32.770 | Train Acc: 87.322 
18 Train Loss: 32.040 | Train Acc: 87.445 
19 Train Loss: 32.394 | Train Acc: 87.282 
20 Train Loss: 28.388 | Train Acc: 89.388 
21 Train Loss: 27.450 | Train Acc: 89.984 
22 Train Loss: 27.343 | Train Acc: 90.000 
23 Train Loss: 27.548 | Train Acc: 89.739 
24 Train Loss: 26.169 | Train Acc: 90.482 
25 Train Loss: 26.545 | Train Acc: 90.229 
26 Train Loss: 25.480 | Train Acc: 90.873 
27 Train Loss: 25.681 | Train Acc: 90.473 
28 Train Loss: 25.373 | Train Acc: 90.947 
29 Train Loss: 25.435 | Train Acc: 90.653 
30 Train Loss: 24.425 | Train Acc: 91.298 
31 Train Loss: 24.804 | Train Acc: 90.955 
32 Train Loss: 24.520 | Train Acc: 90.996 
33 Train Loss: 23.567 | Train Acc: 91.527 
34 Train Loss: 23.742 | Train Acc: 91.502 
35 Train Loss: 22.860 | Train Acc: 91.845 
36 Train Loss: 23.881 | Train Acc: 91.216 
37 Train Loss: 22.977 | Train Acc: 91.869 
38 Train Loss: 22.182 | Train Acc: 92.204 
39 Train Loss: 23.195 | Train Acc: 91.706 
40 Train Loss: 20.802 | Train Acc: 92.865 
41 Train Loss: 20.778 | Train Acc: 92.857 
42 Train Loss: 20.953 | Train Acc: 92.816 
43 Train Loss: 20.524 | Train Acc: 93.061 
44 Train Loss: 20.493 | Train Acc: 92.906 
45 Train Loss: 20.254 | Train Acc: 92.890 
46 Train Loss: 20.137 | Train Acc: 93.314 
47 Train Loss: 19.842 | Train Acc: 93.461 
48 Train Loss: 19.934 | Train Acc: 93.404 
49 Train Loss: 20.136 | Train Acc: 93.249 
50 Train Loss: 19.729 | Train Acc: 93.306 
51 Train Loss: 19.526 | Train Acc: 93.502 
52 Train Loss: 19.424 | Train Acc: 93.518 
53 Train Loss: 19.369 | Train Acc: 93.584 
54 Train Loss: 19.394 | Train Acc: 93.616 
55 Train Loss: 19.134 | Train Acc: 93.673 
56 Train Loss: 19.000 | Train Acc: 93.633 
57 Train Loss: 18.808 | Train Acc: 93.837 
58 Train Loss: 18.834 | Train Acc: 93.706 
59 Train Loss: 19.148 | Train Acc: 93.543 
60 Train Loss: 18.289 | Train Acc: 94.122 
61 Train Loss: 18.041 | Train Acc: 94.392 
62 Train Loss: 18.085 | Train Acc: 94.269 
63 Train Loss: 17.969 | Train Acc: 94.449 
64 Train Loss: 17.989 | Train Acc: 94.294 
65 Train Loss: 17.949 | Train Acc: 94.269 
66 Train Loss: 17.896 | Train Acc: 94.188 
67 Train Loss: 17.782 | Train Acc: 94.367 
68 Train Loss: 17.608 | Train Acc: 94.539 
69 Train Loss: 17.677 | Train Acc: 94.457 
70 Train Loss: 17.538 | Train Acc: 94.514 
71 Train Loss: 17.767 | Train Acc: 94.400 
72 Train Loss: 17.652 | Train Acc: 94.465 
73 Train Loss: 17.860 | Train Acc: 94.408 
74 Train Loss: 17.519 | Train Acc: 94.514 
75 Train Loss: 17.439 | Train Acc: 94.563 
76 Train Loss: 17.449 | Train Acc: 94.604 
77 Train Loss: 17.338 | Train Acc: 94.637 
78 Train Loss: 17.289 | Train Acc: 94.620 
79 Train Loss: 17.236 | Train Acc: 94.669 
80 Train Loss: 17.034 | Train Acc: 94.849 
81 Train Loss: 17.022 | Train Acc: 94.710 
82 Train Loss: 16.991 | Train Acc: 94.841 
83 Train Loss: 16.976 | Train Acc: 94.873 
84 Train Loss: 16.976 | Train Acc: 94.816 
85 Train Loss: 17.015 | Train Acc: 94.759 
86 Train Loss: 17.016 | Train Acc: 94.759 
87 Train Loss: 16.966 | Train Acc: 94.808 
88 Train Loss: 16.878 | Train Acc: 94.824 
89 Train Loss: 16.910 | Train Acc: 94.857 
90 Train Loss: 16.798 | Train Acc: 94.873 
91 Train Loss: 17.000 | Train Acc: 94.743 
92 Train Loss: 16.801 | Train Acc: 94.865 
93 Train Loss: 16.850 | Train Acc: 94.914 
94 Train Loss: 16.697 | Train Acc: 94.906 
95 Train Loss: 16.851 | Train Acc: 94.898 
96 Train Loss: 16.766 | Train Acc: 94.931 
97 Train Loss: 16.774 | Train Acc: 94.914 
98 Train Loss: 16.740 | Train Acc: 94.922 
99 Train Loss: 16.769 | Train Acc: 94.922 
CNN trained successfully...
image_next_flat.shape :  torch.Size([12250, 12544])
Time Taken by Kmeans is  1.1044971942901611
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1, 2: 0}
Printing final_dict items...
{0: 1, 2: -1, 1: 1}
Image Statistics before MLP : L R :  1225 11025
expectedMlpLabels.shape :  torch.Size([12250])
0 Loss: 27.642 | Acc: 66.902
1 Loss: 23.224 | Acc: 69.762
2 Loss: 21.865 | Acc: 70.328
3 Loss: 21.183 | Acc: 71.156
4 Loss: 19.764 | Acc: 74.320
5 Loss: 18.489 | Acc: 73.385
6 Loss: 17.572 | Acc: 77.713
7 Loss: 17.152 | Acc: 76.451
8 Loss: 16.918 | Acc: 78.713
9 Loss: 16.261 | Acc: 79.279
10 Loss: 12.690 | Acc: 84.721
11 Loss: 11.573 | Acc: 85.910
12 Loss: 10.513 | Acc: 87.975
13 Loss: 9.918 | Acc: 87.598
14 Loss: 8.481 | Acc: 89.615
15 Loss: 7.552 | Acc: 91.008
16 Loss: 7.060 | Acc: 91.820
17 Loss: 6.732 | Acc: 92.377
18 Loss: 6.107 | Acc: 92.910
19 Loss: 4.811 | Acc: 94.631
20 Loss: 3.704 | Acc: 96.098
21 Loss: 3.406 | Acc: 96.164
22 Loss: 3.336 | Acc: 96.549
23 Loss: 2.889 | Acc: 96.787
24 Loss: 2.828 | Acc: 96.951
25 Loss: 2.455 | Acc: 97.557
26 Loss: 2.461 | Acc: 97.459
27 Loss: 2.688 | Acc: 97.213
28 Loss: 2.218 | Acc: 97.869
29 Loss: 2.060 | Acc: 98.164
30 Loss: 1.801 | Acc: 98.180
31 Loss: 1.667 | Acc: 98.443
32 Loss: 1.515 | Acc: 98.746
33 Loss: 1.589 | Acc: 98.352
34 Loss: 1.430 | Acc: 98.680
35 Loss: 1.394 | Acc: 98.713
36 Loss: 1.268 | Acc: 98.967
37 Loss: 1.197 | Acc: 99.033
38 Loss: 1.403 | Acc: 98.803
39 Loss: 1.284 | Acc: 98.885
40 Loss: 1.028 | Acc: 99.090
41 Loss: 0.949 | Acc: 99.156
42 Loss: 1.062 | Acc: 99.090
43 Loss: 1.028 | Acc: 99.139
44 Loss: 1.104 | Acc: 98.959
45 Loss: 0.905 | Acc: 99.148
46 Loss: 1.119 | Acc: 99.033
47 Loss: 1.088 | Acc: 99.049
48 Loss: 1.142 | Acc: 99.074
49 Loss: 0.916 | Acc: 99.197
50 Loss: 0.825 | Acc: 99.352
51 Loss: 0.890 | Acc: 99.303
52 Loss: 0.873 | Acc: 99.287
53 Loss: 0.839 | Acc: 99.303
54 Loss: 0.808 | Acc: 99.377
55 Loss: 0.885 | Acc: 99.172
56 Loss: 0.905 | Acc: 99.262
57 Loss: 0.867 | Acc: 99.361
58 Loss: 0.869 | Acc: 99.148
59 Loss: 1.051 | Acc: 99.213
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([1225, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1225])
rTrainDict[data].shape:  torch.Size([11025, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([11025])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  1225.0
# of Right images:  11025.0
giniRightRatio:  0.5925925925925926
giniLeftRatio:  0.0
impurityDrop:  0.5267489711934156
giniGain:  0.11325102880658444
lclasses:  [0, 0, 1225, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 4900, 1225, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  3
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 9
nodeId:  10 , imgTensorShape :  torch.Size([1225, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1225
nodeId:  11 , imgTensorShape :  torch.Size([11025, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 11025
Running nodeId:  6
0 Train Loss: 99.032 | Train Acc: 53.176 
1 Train Loss: 88.390 | Train Acc: 60.433 
2 Train Loss: 83.280 | Train Acc: 64.171 
3 Train Loss: 78.579 | Train Acc: 66.376 
4 Train Loss: 74.681 | Train Acc: 68.245 
5 Train Loss: 72.086 | Train Acc: 69.290 
6 Train Loss: 69.504 | Train Acc: 71.094 
7 Train Loss: 72.871 | Train Acc: 69.576 
8 Train Loss: 67.470 | Train Acc: 71.633 
9 Train Loss: 66.130 | Train Acc: 72.898 
10 Train Loss: 64.763 | Train Acc: 73.265 
11 Train Loss: 62.921 | Train Acc: 73.829 
12 Train Loss: 60.492 | Train Acc: 75.045 
13 Train Loss: 62.797 | Train Acc: 74.318 
14 Train Loss: 58.695 | Train Acc: 75.829 
15 Train Loss: 59.341 | Train Acc: 75.192 
16 Train Loss: 56.528 | Train Acc: 76.808 
17 Train Loss: 55.386 | Train Acc: 77.306 
18 Train Loss: 53.918 | Train Acc: 77.771 
19 Train Loss: 52.878 | Train Acc: 78.318 
20 Train Loss: 49.885 | Train Acc: 80.049 
21 Train Loss: 49.896 | Train Acc: 80.180 
22 Train Loss: 48.192 | Train Acc: 80.669 
23 Train Loss: 47.990 | Train Acc: 80.678 
24 Train Loss: 47.818 | Train Acc: 80.710 
25 Train Loss: 47.904 | Train Acc: 80.669 
26 Train Loss: 46.966 | Train Acc: 81.200 
27 Train Loss: 47.363 | Train Acc: 80.906 
28 Train Loss: 46.823 | Train Acc: 81.518 
29 Train Loss: 45.961 | Train Acc: 81.771 
30 Train Loss: 45.174 | Train Acc: 81.861 
31 Train Loss: 45.211 | Train Acc: 82.180 
32 Train Loss: 44.691 | Train Acc: 82.563 
33 Train Loss: 43.671 | Train Acc: 82.776 
34 Train Loss: 43.783 | Train Acc: 82.890 
35 Train Loss: 43.298 | Train Acc: 82.890 
36 Train Loss: 44.153 | Train Acc: 82.482 
37 Train Loss: 42.754 | Train Acc: 83.453 
38 Train Loss: 42.199 | Train Acc: 83.788 
39 Train Loss: 41.644 | Train Acc: 83.780 
40 Train Loss: 40.287 | Train Acc: 84.522 
41 Train Loss: 40.067 | Train Acc: 84.710 
42 Train Loss: 39.914 | Train Acc: 84.743 
43 Train Loss: 39.957 | Train Acc: 84.694 
44 Train Loss: 40.121 | Train Acc: 84.571 
45 Train Loss: 39.759 | Train Acc: 84.694 
46 Train Loss: 39.300 | Train Acc: 85.102 
47 Train Loss: 39.297 | Train Acc: 85.086 
48 Train Loss: 39.218 | Train Acc: 84.988 
49 Train Loss: 38.925 | Train Acc: 85.314 
50 Train Loss: 38.975 | Train Acc: 85.020 
51 Train Loss: 38.766 | Train Acc: 85.086 
52 Train Loss: 38.833 | Train Acc: 85.167 
53 Train Loss: 38.497 | Train Acc: 85.273 
54 Train Loss: 38.441 | Train Acc: 85.151 
55 Train Loss: 38.093 | Train Acc: 85.543 
56 Train Loss: 38.478 | Train Acc: 85.429 
57 Train Loss: 37.791 | Train Acc: 85.837 
58 Train Loss: 38.084 | Train Acc: 85.355 
59 Train Loss: 37.652 | Train Acc: 85.788 
60 Train Loss: 36.983 | Train Acc: 86.098 
61 Train Loss: 37.132 | Train Acc: 86.131 
62 Train Loss: 36.761 | Train Acc: 86.596 
63 Train Loss: 36.879 | Train Acc: 86.073 
64 Train Loss: 36.742 | Train Acc: 86.588 
65 Train Loss: 36.869 | Train Acc: 86.220 
66 Train Loss: 36.765 | Train Acc: 86.237 
67 Train Loss: 36.640 | Train Acc: 86.310 
68 Train Loss: 36.579 | Train Acc: 86.424 
69 Train Loss: 36.526 | Train Acc: 86.490 
70 Train Loss: 36.668 | Train Acc: 86.237 
71 Train Loss: 36.434 | Train Acc: 86.539 
72 Train Loss: 36.449 | Train Acc: 86.384 
73 Train Loss: 36.272 | Train Acc: 86.269 
74 Train Loss: 36.302 | Train Acc: 86.629 
75 Train Loss: 36.189 | Train Acc: 86.310 
76 Train Loss: 36.397 | Train Acc: 86.490 
77 Train Loss: 36.211 | Train Acc: 86.580 
78 Train Loss: 36.080 | Train Acc: 86.743 
79 Train Loss: 36.117 | Train Acc: 86.710 
80 Train Loss: 35.714 | Train Acc: 87.020 
81 Train Loss: 35.657 | Train Acc: 86.988 
82 Train Loss: 35.637 | Train Acc: 86.816 
83 Train Loss: 35.680 | Train Acc: 86.841 
84 Train Loss: 35.565 | Train Acc: 87.110 
85 Train Loss: 35.622 | Train Acc: 86.718 
86 Train Loss: 35.590 | Train Acc: 87.069 
87 Train Loss: 35.508 | Train Acc: 87.110 
88 Train Loss: 35.594 | Train Acc: 86.833 
89 Train Loss: 35.541 | Train Acc: 86.882 
90 Train Loss: 35.547 | Train Acc: 86.906 
91 Train Loss: 35.556 | Train Acc: 86.824 
92 Train Loss: 35.468 | Train Acc: 87.110 
93 Train Loss: 35.459 | Train Acc: 87.004 
94 Train Loss: 35.509 | Train Acc: 86.980 
95 Train Loss: 35.366 | Train Acc: 87.004 
96 Train Loss: 35.368 | Train Acc: 87.110 
97 Train Loss: 35.377 | Train Acc: 86.947 
98 Train Loss: 35.310 | Train Acc: 87.151 
99 Train Loss: 35.312 | Train Acc: 87.167 
CNN trained successfully...
image_next_flat.shape :  torch.Size([12250, 12544])
Time Taken by Kmeans is  1.0838968753814697
Kmeans completed successfully...
printing expected split from k means
{1: 0, 0: 0, 2: 1}
Printing final_dict items...
{0: 1, 2: -1, 1: 0}
Image Statistics before MLP : L R :  4900 7350
expectedMlpLabels.shape :  torch.Size([12250])
0 Loss: 114.678 | Acc: 52.418
1 Loss: 110.411 | Acc: 58.303
2 Loss: 109.482 | Acc: 59.508
3 Loss: 108.152 | Acc: 58.541
4 Loss: 108.487 | Acc: 57.311
5 Loss: 106.399 | Acc: 59.230
6 Loss: 103.512 | Acc: 62.352
7 Loss: 101.648 | Acc: 62.885
8 Loss: 100.567 | Acc: 65.180
9 Loss: 98.750 | Acc: 65.320
10 Loss: 94.456 | Acc: 67.090
11 Loss: 91.910 | Acc: 67.795
12 Loss: 90.526 | Acc: 69.016
13 Loss: 88.273 | Acc: 69.770
14 Loss: 85.606 | Acc: 70.738
15 Loss: 82.844 | Acc: 71.967
16 Loss: 82.147 | Acc: 72.361
17 Loss: 81.214 | Acc: 72.164
18 Loss: 75.931 | Acc: 74.705
19 Loss: 79.632 | Acc: 74.295
20 Loss: 68.915 | Acc: 78.090
21 Loss: 66.325 | Acc: 78.951
22 Loss: 64.133 | Acc: 80.123
23 Loss: 60.637 | Acc: 81.525
24 Loss: 59.288 | Acc: 82.189
25 Loss: 57.253 | Acc: 82.500
26 Loss: 55.449 | Acc: 83.525
27 Loss: 53.038 | Acc: 84.680
28 Loss: 51.215 | Acc: 85.033
29 Loss: 49.620 | Acc: 85.664
30 Loss: 45.817 | Acc: 87.131
31 Loss: 44.309 | Acc: 87.713
32 Loss: 43.574 | Acc: 88.197
33 Loss: 43.234 | Acc: 87.738
34 Loss: 41.694 | Acc: 88.615
35 Loss: 39.815 | Acc: 89.230
36 Loss: 40.419 | Acc: 88.836
37 Loss: 38.696 | Acc: 89.992
38 Loss: 38.290 | Acc: 89.672
39 Loss: 37.460 | Acc: 89.943
40 Loss: 35.763 | Acc: 90.574
41 Loss: 35.011 | Acc: 90.713
42 Loss: 34.756 | Acc: 91.131
43 Loss: 34.603 | Acc: 90.934
44 Loss: 34.377 | Acc: 91.066
45 Loss: 33.232 | Acc: 91.393
46 Loss: 32.735 | Acc: 91.779
47 Loss: 32.246 | Acc: 92.090
48 Loss: 32.454 | Acc: 91.582
49 Loss: 32.380 | Acc: 91.746
50 Loss: 31.895 | Acc: 92.066
51 Loss: 31.106 | Acc: 92.016
52 Loss: 30.672 | Acc: 92.115
53 Loss: 31.229 | Acc: 92.115
54 Loss: 31.187 | Acc: 92.131
55 Loss: 31.130 | Acc: 92.049
56 Loss: 30.511 | Acc: 92.328
57 Loss: 30.178 | Acc: 92.475
58 Loss: 30.744 | Acc: 92.344
59 Loss: 30.651 | Acc: 92.369
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([7350, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([7350])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  7350.0
giniRightRatio:  0.4444444444444445
giniLeftRatio:  0.5
impurityDrop:  0.4814814814814815
giniGain:  0.1585185185185185
lclasses:  [0, 2450, 2450, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 2450, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 4900
nodeId:  13 , imgTensorShape :  torch.Size([7350, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7350
Running nodeId:  7
0 Train Loss: 102.421 | Train Acc: 52.833 
1 Train Loss: 85.290 | Train Acc: 64.571 
2 Train Loss: 77.902 | Train Acc: 67.233 
3 Train Loss: 72.702 | Train Acc: 70.090 
4 Train Loss: 69.052 | Train Acc: 71.600 
5 Train Loss: 63.280 | Train Acc: 74.327 
6 Train Loss: 62.776 | Train Acc: 74.482 
7 Train Loss: 58.514 | Train Acc: 76.882 
8 Train Loss: 55.768 | Train Acc: 77.624 
9 Train Loss: 55.506 | Train Acc: 77.959 
10 Train Loss: 52.957 | Train Acc: 79.037 
11 Train Loss: 54.610 | Train Acc: 78.588 
12 Train Loss: 52.757 | Train Acc: 79.494 
13 Train Loss: 49.192 | Train Acc: 80.849 
14 Train Loss: 52.441 | Train Acc: 79.273 
15 Train Loss: 48.596 | Train Acc: 80.988 
16 Train Loss: 48.246 | Train Acc: 81.102 
17 Train Loss: 45.914 | Train Acc: 82.024 
18 Train Loss: 44.683 | Train Acc: 82.710 
19 Train Loss: 44.595 | Train Acc: 82.555 
20 Train Loss: 39.889 | Train Acc: 84.939 
21 Train Loss: 39.402 | Train Acc: 85.004 
22 Train Loss: 39.763 | Train Acc: 84.637 
23 Train Loss: 38.571 | Train Acc: 85.429 
24 Train Loss: 38.526 | Train Acc: 85.461 
25 Train Loss: 40.074 | Train Acc: 84.694 
26 Train Loss: 37.773 | Train Acc: 85.861 
27 Train Loss: 37.640 | Train Acc: 85.641 
28 Train Loss: 37.226 | Train Acc: 85.918 
29 Train Loss: 36.309 | Train Acc: 86.351 
30 Train Loss: 37.423 | Train Acc: 85.763 
31 Train Loss: 36.269 | Train Acc: 86.131 
32 Train Loss: 37.021 | Train Acc: 85.943 
33 Train Loss: 36.261 | Train Acc: 86.286 
34 Train Loss: 35.346 | Train Acc: 86.645 
35 Train Loss: 35.080 | Train Acc: 86.669 
36 Train Loss: 34.294 | Train Acc: 86.996 
37 Train Loss: 34.409 | Train Acc: 86.955 
38 Train Loss: 34.353 | Train Acc: 87.224 
39 Train Loss: 33.263 | Train Acc: 87.657 
40 Train Loss: 32.250 | Train Acc: 88.057 
41 Train Loss: 31.139 | Train Acc: 88.833 
42 Train Loss: 31.592 | Train Acc: 88.637 
43 Train Loss: 31.857 | Train Acc: 88.482 
44 Train Loss: 31.209 | Train Acc: 88.596 
45 Train Loss: 30.978 | Train Acc: 88.784 
46 Train Loss: 30.587 | Train Acc: 89.053 
47 Train Loss: 30.810 | Train Acc: 88.906 
48 Train Loss: 30.502 | Train Acc: 88.947 
49 Train Loss: 30.766 | Train Acc: 88.882 
50 Train Loss: 30.287 | Train Acc: 89.078 
51 Train Loss: 30.070 | Train Acc: 88.988 
52 Train Loss: 30.091 | Train Acc: 89.029 
53 Train Loss: 29.883 | Train Acc: 89.331 
54 Train Loss: 29.802 | Train Acc: 89.412 
55 Train Loss: 29.652 | Train Acc: 89.478 
56 Train Loss: 29.949 | Train Acc: 89.290 
57 Train Loss: 29.102 | Train Acc: 89.747 
58 Train Loss: 29.511 | Train Acc: 89.510 
59 Train Loss: 29.907 | Train Acc: 89.306 
60 Train Loss: 28.382 | Train Acc: 90.073 
61 Train Loss: 28.392 | Train Acc: 90.171 
62 Train Loss: 28.457 | Train Acc: 90.155 
63 Train Loss: 28.255 | Train Acc: 90.310 
64 Train Loss: 28.150 | Train Acc: 90.261 
65 Train Loss: 28.096 | Train Acc: 90.229 
66 Train Loss: 28.073 | Train Acc: 90.367 
67 Train Loss: 28.020 | Train Acc: 90.384 
68 Train Loss: 28.032 | Train Acc: 90.147 
69 Train Loss: 27.889 | Train Acc: 90.376 
70 Train Loss: 27.643 | Train Acc: 90.335 
71 Train Loss: 27.771 | Train Acc: 90.327 
72 Train Loss: 27.706 | Train Acc: 90.416 
73 Train Loss: 27.887 | Train Acc: 90.278 
74 Train Loss: 27.660 | Train Acc: 90.580 
75 Train Loss: 27.581 | Train Acc: 90.433 
76 Train Loss: 27.580 | Train Acc: 90.637 
77 Train Loss: 27.751 | Train Acc: 90.237 
78 Train Loss: 27.343 | Train Acc: 90.784 
79 Train Loss: 27.350 | Train Acc: 90.604 
80 Train Loss: 27.245 | Train Acc: 90.596 
81 Train Loss: 27.040 | Train Acc: 90.890 
82 Train Loss: 27.158 | Train Acc: 90.857 
83 Train Loss: 27.107 | Train Acc: 90.784 
84 Train Loss: 27.075 | Train Acc: 90.873 
85 Train Loss: 27.074 | Train Acc: 90.792 
86 Train Loss: 27.080 | Train Acc: 90.784 
87 Train Loss: 27.026 | Train Acc: 90.702 
88 Train Loss: 26.992 | Train Acc: 90.637 
89 Train Loss: 26.990 | Train Acc: 90.727 
90 Train Loss: 26.985 | Train Acc: 90.890 
91 Train Loss: 26.874 | Train Acc: 90.890 
92 Train Loss: 26.889 | Train Acc: 90.873 
93 Train Loss: 26.916 | Train Acc: 90.955 
94 Train Loss: 26.757 | Train Acc: 90.824 
95 Train Loss: 26.806 | Train Acc: 90.906 
96 Train Loss: 26.806 | Train Acc: 90.873 
97 Train Loss: 26.795 | Train Acc: 90.947 
98 Train Loss: 26.732 | Train Acc: 90.914 
99 Train Loss: 26.775 | Train Acc: 90.898 
CNN trained successfully...
image_next_flat.shape :  torch.Size([12250, 12544])
Time Taken by Kmeans is  1.217705488204956
Kmeans completed successfully...
printing expected split from k means
{0: 0, 2: 0, 1: 1}
Printing final_dict items...
{2: 0, 0: -1, 1: 1}
Image Statistics before MLP : L R :  7350 4900
expectedMlpLabels.shape :  torch.Size([12250])
0 Loss: 106.543 | Acc: 59.926
1 Loss: 92.537 | Acc: 68.057
2 Loss: 86.270 | Acc: 70.549
3 Loss: 82.850 | Acc: 71.590
4 Loss: 84.188 | Acc: 70.877
5 Loss: 79.632 | Acc: 72.467
6 Loss: 76.037 | Acc: 74.164
7 Loss: 75.756 | Acc: 74.139
8 Loss: 73.462 | Acc: 74.738
9 Loss: 77.322 | Acc: 73.385
10 Loss: 66.918 | Acc: 76.582
11 Loss: 65.261 | Acc: 77.082
12 Loss: 63.234 | Acc: 78.148
13 Loss: 61.442 | Acc: 78.492
14 Loss: 63.505 | Acc: 77.869
15 Loss: 59.639 | Acc: 79.180
16 Loss: 57.621 | Acc: 80.156
17 Loss: 58.006 | Acc: 79.902
18 Loss: 55.422 | Acc: 80.959
19 Loss: 56.342 | Acc: 80.205
20 Loss: 51.012 | Acc: 82.467
21 Loss: 49.104 | Acc: 83.303
22 Loss: 48.690 | Acc: 83.270
23 Loss: 48.318 | Acc: 83.434
24 Loss: 45.628 | Acc: 83.943
25 Loss: 45.328 | Acc: 84.410
26 Loss: 45.255 | Acc: 84.262
27 Loss: 43.569 | Acc: 85.041
28 Loss: 42.510 | Acc: 85.246
29 Loss: 40.308 | Acc: 86.123
30 Loss: 38.906 | Acc: 86.410
31 Loss: 38.301 | Acc: 86.975
32 Loss: 38.025 | Acc: 87.221
33 Loss: 36.763 | Acc: 87.557
34 Loss: 36.621 | Acc: 87.557
35 Loss: 36.676 | Acc: 87.705
36 Loss: 35.014 | Acc: 88.041
37 Loss: 34.291 | Acc: 88.557
38 Loss: 33.928 | Acc: 88.590
39 Loss: 33.578 | Acc: 88.918
40 Loss: 32.294 | Acc: 89.246
41 Loss: 31.752 | Acc: 89.074
42 Loss: 31.980 | Acc: 89.525
43 Loss: 31.448 | Acc: 89.525
44 Loss: 30.747 | Acc: 89.705
45 Loss: 31.093 | Acc: 89.656
46 Loss: 30.839 | Acc: 89.893
47 Loss: 30.315 | Acc: 90.066
48 Loss: 30.396 | Acc: 90.025
49 Loss: 30.295 | Acc: 90.180
50 Loss: 30.296 | Acc: 89.926
51 Loss: 29.768 | Acc: 90.246
52 Loss: 29.047 | Acc: 90.541
53 Loss: 29.328 | Acc: 90.516
54 Loss: 29.303 | Acc: 90.500
55 Loss: 28.875 | Acc: 90.213
56 Loss: 28.979 | Acc: 90.500
57 Loss: 28.884 | Acc: 90.410
58 Loss: 28.520 | Acc: 90.385
59 Loss: 28.771 | Acc: 90.680
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([7350, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([7350])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([0, 3, 32, 32])   rValDict[label].shape:  torch.Size([0])
# of Left images:  7350.0
# of Right images:  4900.0
giniRightRatio:  0.5
giniLeftRatio:  0.4444444444444445
impurityDrop:  0.41666666666666674
giniGain:  0.22333333333333327
lclasses:  [2450, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2450, 2450, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([7350, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7350
nodeId:  15 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 4900
Running nodeId:  8
0 Train Loss: 42.966 | Train Acc: 79.612 
1 Train Loss: 34.522 | Train Acc: 84.918 
2 Train Loss: 29.562 | Train Acc: 87.408 
3 Train Loss: 27.515 | Train Acc: 88.367 
4 Train Loss: 24.870 | Train Acc: 89.592 
5 Train Loss: 23.625 | Train Acc: 90.041 
6 Train Loss: 22.559 | Train Acc: 90.816 
7 Train Loss: 20.586 | Train Acc: 91.490 
8 Train Loss: 19.703 | Train Acc: 92.102 
9 Train Loss: 18.762 | Train Acc: 92.388 
10 Train Loss: 18.632 | Train Acc: 92.796 
11 Train Loss: 16.674 | Train Acc: 93.510 
12 Train Loss: 16.819 | Train Acc: 93.571 
13 Train Loss: 15.690 | Train Acc: 93.918 
14 Train Loss: 14.626 | Train Acc: 94.653 
15 Train Loss: 13.440 | Train Acc: 95.000 
16 Train Loss: 12.480 | Train Acc: 95.408 
17 Train Loss: 11.526 | Train Acc: 95.959 
18 Train Loss: 11.441 | Train Acc: 95.939 
19 Train Loss: 10.691 | Train Acc: 96.143 
20 Train Loss: 9.008 | Train Acc: 97.265 
21 Train Loss: 8.150 | Train Acc: 97.633 
22 Train Loss: 7.863 | Train Acc: 97.735 
23 Train Loss: 8.287 | Train Acc: 97.694 
24 Train Loss: 7.876 | Train Acc: 97.837 
25 Train Loss: 7.592 | Train Acc: 98.224 
26 Train Loss: 7.092 | Train Acc: 98.286 
27 Train Loss: 7.091 | Train Acc: 98.143 
28 Train Loss: 6.920 | Train Acc: 98.122 
29 Train Loss: 6.839 | Train Acc: 98.429 
30 Train Loss: 6.502 | Train Acc: 98.531 
31 Train Loss: 6.129 | Train Acc: 98.755 
32 Train Loss: 6.080 | Train Acc: 98.653 
33 Train Loss: 6.305 | Train Acc: 98.510 
34 Train Loss: 5.962 | Train Acc: 98.592 
35 Train Loss: 5.662 | Train Acc: 98.918 
36 Train Loss: 5.443 | Train Acc: 98.980 
37 Train Loss: 5.757 | Train Acc: 98.592 
38 Train Loss: 5.277 | Train Acc: 99.082 
39 Train Loss: 4.897 | Train Acc: 99.224 
40 Train Loss: 4.321 | Train Acc: 99.408 
41 Train Loss: 4.186 | Train Acc: 99.571 
42 Train Loss: 4.196 | Train Acc: 99.469 
43 Train Loss: 4.089 | Train Acc: 99.490 
44 Train Loss: 3.986 | Train Acc: 99.694 
45 Train Loss: 4.038 | Train Acc: 99.531 
46 Train Loss: 3.935 | Train Acc: 99.612 
47 Train Loss: 3.959 | Train Acc: 99.653 
48 Train Loss: 3.807 | Train Acc: 99.633 
49 Train Loss: 3.751 | Train Acc: 99.592 
50 Train Loss: 3.778 | Train Acc: 99.653 
51 Train Loss: 3.717 | Train Acc: 99.612 
52 Train Loss: 3.646 | Train Acc: 99.612 
53 Train Loss: 3.549 | Train Acc: 99.694 
54 Train Loss: 3.567 | Train Acc: 99.735 
55 Train Loss: 3.491 | Train Acc: 99.673 
56 Train Loss: 3.444 | Train Acc: 99.694 
57 Train Loss: 3.482 | Train Acc: 99.612 
58 Train Loss: 3.314 | Train Acc: 99.694 
59 Train Loss: 3.445 | Train Acc: 99.755 
60 Train Loss: 3.130 | Train Acc: 99.755 
61 Train Loss: 3.044 | Train Acc: 99.816 
62 Train Loss: 3.008 | Train Acc: 99.796 
63 Train Loss: 3.050 | Train Acc: 99.735 
64 Train Loss: 3.009 | Train Acc: 99.776 
65 Train Loss: 2.929 | Train Acc: 99.816 
66 Train Loss: 2.984 | Train Acc: 99.776 
67 Train Loss: 2.903 | Train Acc: 99.816 
68 Train Loss: 2.902 | Train Acc: 99.796 
69 Train Loss: 2.898 | Train Acc: 99.776 
70 Train Loss: 2.852 | Train Acc: 99.857 
71 Train Loss: 2.818 | Train Acc: 99.816 
72 Train Loss: 2.808 | Train Acc: 99.837 
73 Train Loss: 2.789 | Train Acc: 99.816 
74 Train Loss: 2.767 | Train Acc: 99.816 
75 Train Loss: 2.751 | Train Acc: 99.857 
76 Train Loss: 2.752 | Train Acc: 99.816 
77 Train Loss: 2.712 | Train Acc: 99.837 
78 Train Loss: 2.673 | Train Acc: 99.857 
79 Train Loss: 2.686 | Train Acc: 99.816 
80 Train Loss: 2.593 | Train Acc: 99.837 
81 Train Loss: 2.573 | Train Acc: 99.837 
82 Train Loss: 2.556 | Train Acc: 99.898 
83 Train Loss: 2.570 | Train Acc: 99.837 
84 Train Loss: 2.551 | Train Acc: 99.837 
85 Train Loss: 2.542 | Train Acc: 99.857 
86 Train Loss: 2.530 | Train Acc: 99.878 
87 Train Loss: 2.529 | Train Acc: 99.878 
88 Train Loss: 2.526 | Train Acc: 99.878 
89 Train Loss: 2.492 | Train Acc: 99.878 
90 Train Loss: 2.490 | Train Acc: 99.857 
91 Train Loss: 2.495 | Train Acc: 99.857 
92 Train Loss: 2.482 | Train Acc: 99.857 
93 Train Loss: 2.478 | Train Acc: 99.878 
94 Train Loss: 2.469 | Train Acc: 99.898 
95 Train Loss: 2.463 | Train Acc: 99.898 
96 Train Loss: 2.470 | Train Acc: 99.878 
97 Train Loss: 2.456 | Train Acc: 99.898 
98 Train Loss: 2.451 | Train Acc: 99.898 
99 Train Loss: 2.427 | Train Acc: 99.878 
CNN trained successfully...
image_next_flat.shape :  torch.Size([4900, 12544])
Time Taken by Kmeans is  0.825157642364502
Kmeans completed successfully...
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  2450 2450
expectedMlpLabels.shape :  torch.Size([4900])
0 Loss: 72.859 | Acc: 84.000
1 Loss: 55.549 | Acc: 88.333
2 Loss: 47.902 | Acc: 90.000
3 Loss: 44.290 | Acc: 91.062
4 Loss: 37.024 | Acc: 92.625
5 Loss: 33.328 | Acc: 92.833
6 Loss: 27.081 | Acc: 94.354
7 Loss: 25.695 | Acc: 94.708
8 Loss: 22.432 | Acc: 95.604
9 Loss: 17.744 | Acc: 96.542
10 Loss: 11.303 | Acc: 97.812
11 Loss: 7.946 | Acc: 98.458
12 Loss: 7.122 | Acc: 98.625
13 Loss: 7.042 | Acc: 98.688
14 Loss: 5.976 | Acc: 98.812
15 Loss: 6.489 | Acc: 98.833
16 Loss: 6.453 | Acc: 98.979
17 Loss: 4.571 | Acc: 99.208
18 Loss: 4.442 | Acc: 99.208
19 Loss: 2.897 | Acc: 99.417
20 Loss: 2.236 | Acc: 99.646
21 Loss: 1.599 | Acc: 99.729
22 Loss: 0.913 | Acc: 99.875
23 Loss: 1.226 | Acc: 99.833
24 Loss: 0.920 | Acc: 99.875
25 Loss: 1.255 | Acc: 99.833
26 Loss: 1.244 | Acc: 99.792
27 Loss: 0.753 | Acc: 99.896
28 Loss: 1.099 | Acc: 99.833
29 Loss: 1.257 | Acc: 99.812
30 Loss: 1.001 | Acc: 99.771
31 Loss: 0.389 | Acc: 99.979
32 Loss: 0.607 | Acc: 99.896
33 Loss: 0.488 | Acc: 99.979
34 Loss: 0.426 | Acc: 99.958
35 Loss: 0.379 | Acc: 99.979
36 Loss: 0.529 | Acc: 99.938
37 Loss: 0.319 | Acc: 99.958
38 Loss: 0.663 | Acc: 99.917
39 Loss: 0.557 | Acc: 99.896
40 Loss: 0.353 | Acc: 99.958
41 Loss: 0.250 | Acc: 100.000
42 Loss: 0.465 | Acc: 99.979
43 Loss: 0.347 | Acc: 99.979
44 Loss: 0.209 | Acc: 99.979
45 Loss: 0.165 | Acc: 100.000
46 Loss: 0.289 | Acc: 99.979
47 Loss: 0.236 | Acc: 99.979
48 Loss: 0.246 | Acc: 99.958
49 Loss: 0.178 | Acc: 100.000
50 Loss: 0.235 | Acc: 99.958
51 Loss: 0.216 | Acc: 99.979
52 Loss: 0.226 | Acc: 99.979
53 Loss: 0.265 | Acc: 99.979
54 Loss: 0.202 | Acc: 99.979
55 Loss: 0.167 | Acc: 100.000
56 Loss: 0.173 | Acc: 99.979
57 Loss: 0.182 | Acc: 100.000
58 Loss: 0.204 | Acc: 99.979
59 Loss: 0.331 | Acc: 99.938
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2450])
rTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2450])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([0, 3, 32, 32])   rValDict[label].shape:  torch.Size([0])
# of Left images:  2450.0
# of Right images:  2450.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 2450, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2450, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 9
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 0
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 9
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 0
nodeId:  16 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 16 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 2450
nodeId:  17 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 17 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 2450
Running nodeId:  9
0 Train Loss: 63.619 | Train Acc: 68.816 
1 Train Loss: 55.339 | Train Acc: 72.980 
2 Train Loss: 50.734 | Train Acc: 76.871 
3 Train Loss: 46.550 | Train Acc: 78.803 
4 Train Loss: 44.900 | Train Acc: 80.000 
5 Train Loss: 44.174 | Train Acc: 80.531 
6 Train Loss: 42.501 | Train Acc: 81.197 
7 Train Loss: 41.940 | Train Acc: 81.578 
8 Train Loss: 41.373 | Train Acc: 82.095 
9 Train Loss: 42.824 | Train Acc: 81.116 
10 Train Loss: 38.970 | Train Acc: 83.306 
11 Train Loss: 37.003 | Train Acc: 83.946 
12 Train Loss: 37.410 | Train Acc: 83.782 
13 Train Loss: 34.957 | Train Acc: 85.293 
14 Train Loss: 34.426 | Train Acc: 85.252 
15 Train Loss: 34.309 | Train Acc: 85.320 
16 Train Loss: 33.187 | Train Acc: 86.204 
17 Train Loss: 32.937 | Train Acc: 86.245 
18 Train Loss: 32.456 | Train Acc: 86.259 
19 Train Loss: 30.142 | Train Acc: 87.850 
20 Train Loss: 28.481 | Train Acc: 88.122 
21 Train Loss: 27.820 | Train Acc: 88.939 
22 Train Loss: 27.198 | Train Acc: 89.197 
23 Train Loss: 26.615 | Train Acc: 89.524 
24 Train Loss: 26.807 | Train Acc: 89.510 
25 Train Loss: 25.944 | Train Acc: 89.701 
26 Train Loss: 25.520 | Train Acc: 90.095 
27 Train Loss: 25.179 | Train Acc: 90.095 
28 Train Loss: 25.481 | Train Acc: 90.340 
29 Train Loss: 25.280 | Train Acc: 90.150 
30 Train Loss: 25.147 | Train Acc: 90.218 
31 Train Loss: 24.643 | Train Acc: 90.463 
32 Train Loss: 24.261 | Train Acc: 90.544 
33 Train Loss: 23.697 | Train Acc: 91.129 
34 Train Loss: 24.126 | Train Acc: 90.680 
35 Train Loss: 24.031 | Train Acc: 90.599 
36 Train Loss: 22.964 | Train Acc: 91.279 
37 Train Loss: 23.134 | Train Acc: 91.156 
38 Train Loss: 23.009 | Train Acc: 91.265 
39 Train Loss: 22.774 | Train Acc: 91.293 
40 Train Loss: 21.464 | Train Acc: 92.286 
41 Train Loss: 21.222 | Train Acc: 92.136 
42 Train Loss: 20.966 | Train Acc: 92.163 
43 Train Loss: 20.866 | Train Acc: 92.639 
44 Train Loss: 20.757 | Train Acc: 92.395 
45 Train Loss: 21.300 | Train Acc: 92.054 
46 Train Loss: 20.912 | Train Acc: 92.544 
47 Train Loss: 20.805 | Train Acc: 92.490 
48 Train Loss: 20.472 | Train Acc: 92.667 
49 Train Loss: 20.575 | Train Acc: 92.381 
50 Train Loss: 20.205 | Train Acc: 92.585 
51 Train Loss: 20.639 | Train Acc: 92.435 
52 Train Loss: 20.153 | Train Acc: 92.490 
53 Train Loss: 20.107 | Train Acc: 92.721 
54 Train Loss: 19.945 | Train Acc: 92.857 
55 Train Loss: 19.919 | Train Acc: 92.735 
56 Train Loss: 19.902 | Train Acc: 92.762 
57 Train Loss: 19.690 | Train Acc: 93.075 
58 Train Loss: 19.798 | Train Acc: 92.667 
59 Train Loss: 19.619 | Train Acc: 92.735 
60 Train Loss: 19.120 | Train Acc: 93.170 
61 Train Loss: 19.018 | Train Acc: 93.333 
62 Train Loss: 18.872 | Train Acc: 93.347 
63 Train Loss: 18.951 | Train Acc: 93.265 
64 Train Loss: 18.797 | Train Acc: 93.469 
65 Train Loss: 18.838 | Train Acc: 93.333 
66 Train Loss: 18.878 | Train Acc: 93.469 
67 Train Loss: 18.694 | Train Acc: 93.524 
68 Train Loss: 18.625 | Train Acc: 93.578 
69 Train Loss: 19.170 | Train Acc: 93.401 
70 Train Loss: 18.605 | Train Acc: 93.537 
71 Train Loss: 18.563 | Train Acc: 93.469 
72 Train Loss: 18.620 | Train Acc: 93.456 
73 Train Loss: 18.527 | Train Acc: 93.578 
74 Train Loss: 18.578 | Train Acc: 93.510 
75 Train Loss: 18.591 | Train Acc: 93.497 
76 Train Loss: 18.438 | Train Acc: 93.714 
77 Train Loss: 18.614 | Train Acc: 93.401 
78 Train Loss: 18.528 | Train Acc: 93.320 
79 Train Loss: 18.347 | Train Acc: 93.578 
80 Train Loss: 18.182 | Train Acc: 93.714 
81 Train Loss: 18.117 | Train Acc: 93.918 
82 Train Loss: 18.173 | Train Acc: 93.769 
83 Train Loss: 18.098 | Train Acc: 93.850 
84 Train Loss: 18.102 | Train Acc: 93.782 
85 Train Loss: 18.175 | Train Acc: 93.755 
86 Train Loss: 18.022 | Train Acc: 93.905 
87 Train Loss: 18.052 | Train Acc: 93.782 
88 Train Loss: 18.073 | Train Acc: 93.728 
89 Train Loss: 18.095 | Train Acc: 93.741 
90 Train Loss: 18.027 | Train Acc: 93.728 
91 Train Loss: 18.008 | Train Acc: 93.796 
92 Train Loss: 18.125 | Train Acc: 93.714 
93 Train Loss: 17.940 | Train Acc: 93.769 
94 Train Loss: 17.941 | Train Acc: 93.850 
95 Train Loss: 17.953 | Train Acc: 93.782 
96 Train Loss: 17.900 | Train Acc: 93.891 
97 Train Loss: 17.942 | Train Acc: 93.810 
98 Train Loss: 17.951 | Train Acc: 94.000 
99 Train Loss: 17.931 | Train Acc: 93.755 
CNN trained successfully...
image_next_flat.shape :  torch.Size([7350, 12544])
Time Taken by Kmeans is  1.2795414924621582
Kmeans completed successfully...
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics before MLP : L R :  2450 4900
expectedMlpLabels.shape :  torch.Size([7350])
0 Loss: 69.847 | Acc: 76.097
1 Loss: 52.713 | Acc: 83.583
2 Loss: 45.542 | Acc: 85.694
3 Loss: 38.517 | Acc: 87.431
4 Loss: 34.806 | Acc: 89.042
5 Loss: 31.970 | Acc: 90.139
6 Loss: 30.192 | Acc: 90.542
7 Loss: 24.154 | Acc: 92.819
8 Loss: 20.386 | Acc: 93.722
9 Loss: 19.025 | Acc: 94.306
10 Loss: 12.324 | Acc: 96.319
11 Loss: 9.220 | Acc: 97.222
12 Loss: 8.893 | Acc: 97.431
13 Loss: 7.044 | Acc: 97.944
14 Loss: 6.151 | Acc: 98.375
15 Loss: 7.221 | Acc: 97.931
16 Loss: 5.759 | Acc: 98.653
17 Loss: 4.362 | Acc: 98.847
18 Loss: 5.441 | Acc: 98.444
19 Loss: 5.358 | Acc: 98.597
20 Loss: 3.115 | Acc: 99.319
21 Loss: 2.451 | Acc: 99.403
22 Loss: 1.955 | Acc: 99.528
23 Loss: 2.279 | Acc: 99.389
24 Loss: 2.052 | Acc: 99.514
25 Loss: 1.984 | Acc: 99.500
26 Loss: 2.107 | Acc: 99.542
27 Loss: 1.453 | Acc: 99.611
28 Loss: 1.187 | Acc: 99.750
29 Loss: 1.424 | Acc: 99.569
30 Loss: 1.170 | Acc: 99.764
31 Loss: 1.184 | Acc: 99.778
32 Loss: 1.196 | Acc: 99.708
33 Loss: 1.142 | Acc: 99.750
34 Loss: 0.938 | Acc: 99.847
35 Loss: 0.917 | Acc: 99.750
36 Loss: 0.945 | Acc: 99.792
37 Loss: 0.915 | Acc: 99.847
38 Loss: 0.648 | Acc: 99.917
39 Loss: 1.185 | Acc: 99.764
40 Loss: 0.930 | Acc: 99.778
41 Loss: 0.806 | Acc: 99.833
42 Loss: 0.942 | Acc: 99.736
43 Loss: 0.702 | Acc: 99.889
44 Loss: 0.595 | Acc: 99.875
45 Loss: 0.629 | Acc: 99.875
46 Loss: 0.699 | Acc: 99.944
47 Loss: 0.765 | Acc: 99.861
48 Loss: 0.653 | Acc: 99.847
49 Loss: 0.611 | Acc: 99.903
50 Loss: 0.643 | Acc: 99.861
51 Loss: 0.570 | Acc: 99.833
52 Loss: 0.747 | Acc: 99.833
53 Loss: 0.630 | Acc: 99.875
54 Loss: 0.524 | Acc: 99.931
55 Loss: 0.690 | Acc: 99.819
56 Loss: 0.852 | Acc: 99.833
57 Loss: 0.766 | Acc: 99.778
58 Loss: 0.706 | Acc: 99.847
59 Loss: 0.480 | Acc: 99.931
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2450])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  2450.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [2450, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  18 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 18 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 2450
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 72.550 | Train Acc: 73.415 
1 Train Loss: 48.557 | Train Acc: 82.059 
2 Train Loss: 47.394 | Train Acc: 81.995 
3 Train Loss: 41.333 | Train Acc: 84.372 
4 Train Loss: 38.179 | Train Acc: 85.370 
5 Train Loss: 39.736 | Train Acc: 85.288 
6 Train Loss: 38.615 | Train Acc: 85.370 
7 Train Loss: 36.794 | Train Acc: 86.014 
8 Train Loss: 35.121 | Train Acc: 86.558 
9 Train Loss: 33.345 | Train Acc: 87.320 
10 Train Loss: 32.255 | Train Acc: 87.746 
11 Train Loss: 31.024 | Train Acc: 88.562 
12 Train Loss: 32.533 | Train Acc: 87.982 
13 Train Loss: 30.926 | Train Acc: 88.082 
14 Train Loss: 28.559 | Train Acc: 89.188 
15 Train Loss: 29.002 | Train Acc: 89.034 
16 Train Loss: 28.725 | Train Acc: 89.342 
17 Train Loss: 27.214 | Train Acc: 90.122 
18 Train Loss: 28.693 | Train Acc: 89.215 
19 Train Loss: 25.486 | Train Acc: 90.440 
20 Train Loss: 22.437 | Train Acc: 91.819 
21 Train Loss: 21.588 | Train Acc: 92.408 
22 Train Loss: 20.872 | Train Acc: 92.517 
23 Train Loss: 20.506 | Train Acc: 92.989 
24 Train Loss: 20.610 | Train Acc: 92.680 
25 Train Loss: 20.211 | Train Acc: 93.107 
26 Train Loss: 19.671 | Train Acc: 93.170 
27 Train Loss: 19.487 | Train Acc: 93.333 
28 Train Loss: 19.741 | Train Acc: 92.916 
29 Train Loss: 18.884 | Train Acc: 93.442 
30 Train Loss: 19.040 | Train Acc: 93.415 
31 Train Loss: 18.249 | Train Acc: 93.841 
32 Train Loss: 18.365 | Train Acc: 93.814 
33 Train Loss: 18.269 | Train Acc: 93.633 
34 Train Loss: 17.759 | Train Acc: 94.041 
35 Train Loss: 17.343 | Train Acc: 94.132 
36 Train Loss: 17.383 | Train Acc: 94.068 
37 Train Loss: 17.351 | Train Acc: 94.222 
38 Train Loss: 16.434 | Train Acc: 94.712 
39 Train Loss: 16.365 | Train Acc: 94.512 
40 Train Loss: 16.271 | Train Acc: 94.576 
41 Train Loss: 15.318 | Train Acc: 95.147 
42 Train Loss: 15.044 | Train Acc: 95.383 
43 Train Loss: 14.757 | Train Acc: 95.556 
44 Train Loss: 14.970 | Train Acc: 95.465 
45 Train Loss: 14.946 | Train Acc: 95.247 
46 Train Loss: 14.702 | Train Acc: 95.447 
47 Train Loss: 14.531 | Train Acc: 95.673 
48 Train Loss: 14.568 | Train Acc: 95.574 
49 Train Loss: 14.148 | Train Acc: 95.692 
50 Train Loss: 14.173 | Train Acc: 95.746 
51 Train Loss: 14.142 | Train Acc: 95.701 
52 Train Loss: 14.032 | Train Acc: 96.000 
53 Train Loss: 14.449 | Train Acc: 95.483 
54 Train Loss: 13.644 | Train Acc: 96.027 
55 Train Loss: 13.827 | Train Acc: 95.819 
56 Train Loss: 13.795 | Train Acc: 96.063 
57 Train Loss: 13.413 | Train Acc: 96.009 
58 Train Loss: 13.460 | Train Acc: 96.036 
59 Train Loss: 13.319 | Train Acc: 96.263 
60 Train Loss: 12.872 | Train Acc: 96.354 
61 Train Loss: 12.825 | Train Acc: 96.481 
62 Train Loss: 12.953 | Train Acc: 96.363 
63 Train Loss: 13.046 | Train Acc: 96.209 
64 Train Loss: 12.924 | Train Acc: 96.299 
65 Train Loss: 12.719 | Train Acc: 96.481 
66 Train Loss: 12.568 | Train Acc: 96.626 
67 Train Loss: 12.683 | Train Acc: 96.290 
68 Train Loss: 12.683 | Train Acc: 96.508 
69 Train Loss: 12.487 | Train Acc: 96.517 
70 Train Loss: 12.718 | Train Acc: 96.426 
71 Train Loss: 12.498 | Train Acc: 96.608 
72 Train Loss: 12.488 | Train Acc: 96.626 
73 Train Loss: 12.467 | Train Acc: 96.499 
74 Train Loss: 12.444 | Train Acc: 96.635 
75 Train Loss: 12.493 | Train Acc: 96.662 
76 Train Loss: 12.372 | Train Acc: 96.599 
77 Train Loss: 12.306 | Train Acc: 96.689 
78 Train Loss: 12.307 | Train Acc: 96.590 
79 Train Loss: 12.243 | Train Acc: 96.762 
80 Train Loss: 12.033 | Train Acc: 96.834 
81 Train Loss: 12.077 | Train Acc: 96.807 
82 Train Loss: 11.987 | Train Acc: 96.689 
83 Train Loss: 11.968 | Train Acc: 96.780 
84 Train Loss: 11.973 | Train Acc: 96.925 
85 Train Loss: 11.961 | Train Acc: 96.825 
86 Train Loss: 11.925 | Train Acc: 96.798 
87 Train Loss: 11.964 | Train Acc: 96.825 
88 Train Loss: 11.823 | Train Acc: 97.034 
89 Train Loss: 11.938 | Train Acc: 96.844 
90 Train Loss: 11.831 | Train Acc: 96.898 
91 Train Loss: 11.843 | Train Acc: 96.844 
92 Train Loss: 11.831 | Train Acc: 96.916 
93 Train Loss: 11.881 | Train Acc: 96.898 
94 Train Loss: 11.783 | Train Acc: 96.989 
95 Train Loss: 11.800 | Train Acc: 96.998 
96 Train Loss: 11.761 | Train Acc: 96.871 
97 Train Loss: 11.794 | Train Acc: 96.943 
98 Train Loss: 11.738 | Train Acc: 96.934 
99 Train Loss: 11.731 | Train Acc: 96.961 
CNN trained successfully...
image_next_flat.shape :  torch.Size([11025, 12544])
Time Taken by Kmeans is  1.0309908390045166
Kmeans completed successfully...
printing expected split from k means
{1: 0, 0: 1, 2: 1}
Printing final_dict items...
{1: 1, 0: -1, 2: 0}
Image Statistics before MLP : L R :  3675 7350
expectedMlpLabels.shape :  torch.Size([11025])
0 Loss: 71.920 | Acc: 68.773
1 Loss: 66.121 | Acc: 72.236
2 Loss: 64.513 | Acc: 72.236
3 Loss: 60.703 | Acc: 74.373
4 Loss: 59.695 | Acc: 74.109
5 Loss: 60.437 | Acc: 73.718
6 Loss: 59.180 | Acc: 74.645
7 Loss: 56.873 | Acc: 75.664
8 Loss: 56.434 | Acc: 75.764
9 Loss: 55.285 | Acc: 76.218
10 Loss: 51.173 | Acc: 78.082
11 Loss: 49.278 | Acc: 78.955
12 Loss: 49.349 | Acc: 78.491
13 Loss: 46.635 | Acc: 80.064
14 Loss: 46.744 | Acc: 80.173
15 Loss: 44.012 | Acc: 81.536
16 Loss: 42.075 | Acc: 82.500
17 Loss: 43.033 | Acc: 81.991
18 Loss: 40.339 | Acc: 83.136
19 Loss: 38.772 | Acc: 84.209
20 Loss: 33.728 | Acc: 86.582
21 Loss: 32.151 | Acc: 87.809
22 Loss: 30.600 | Acc: 87.873
23 Loss: 29.141 | Acc: 89.118
24 Loss: 29.179 | Acc: 89.055
25 Loss: 26.265 | Acc: 90.464
26 Loss: 25.960 | Acc: 90.618
27 Loss: 24.237 | Acc: 91.245
28 Loss: 23.246 | Acc: 92.036
29 Loss: 22.424 | Acc: 92.100
30 Loss: 20.713 | Acc: 92.845
31 Loss: 18.685 | Acc: 93.818
32 Loss: 18.669 | Acc: 93.782
33 Loss: 17.884 | Acc: 94.018
34 Loss: 17.659 | Acc: 94.191
35 Loss: 17.027 | Acc: 94.191
36 Loss: 16.356 | Acc: 94.773
37 Loss: 15.537 | Acc: 95.036
38 Loss: 15.939 | Acc: 94.882
39 Loss: 15.152 | Acc: 95.318
40 Loss: 14.501 | Acc: 95.345
41 Loss: 14.418 | Acc: 95.509
42 Loss: 13.438 | Acc: 95.791
43 Loss: 13.264 | Acc: 95.927
44 Loss: 13.115 | Acc: 95.882
45 Loss: 13.594 | Acc: 95.882
46 Loss: 12.605 | Acc: 96.227
47 Loss: 12.772 | Acc: 96.127
48 Loss: 12.354 | Acc: 96.209
49 Loss: 12.080 | Acc: 96.300
50 Loss: 11.798 | Acc: 96.545
51 Loss: 11.795 | Acc: 96.482
52 Loss: 12.220 | Acc: 96.264
53 Loss: 11.886 | Acc: 96.509
54 Loss: 11.657 | Acc: 96.509
55 Loss: 11.444 | Acc: 96.591
56 Loss: 11.847 | Acc: 96.318
57 Loss: 11.291 | Acc: 96.564
58 Loss: 11.226 | Acc: 96.700
59 Loss: 11.268 | Acc: 96.600
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([3675, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([3675])
rTrainDict[data].shape:  torch.Size([7350, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([7350])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  3675.0
# of Right images:  7350.0
giniRightRatio:  0.4444444444444445
giniLeftRatio:  0.4444444444444445
impurityDrop:  0.4444444444444445
giniGain:  0.14814814814814808
lclasses:  [2450, 0, 1225, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2450, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  2
RETURNING FROM WORK...
nodeId:  20 , imgTensorShape :  torch.Size([3675, 3, 32, 32])
nodeId: 20 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 3675
nodeId:  21 , imgTensorShape :  torch.Size([7350, 3, 32, 32])
nodeId: 21 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 7350
Running nodeId:  12
0 Train Loss: 62.999 | Train Acc: 64.041 
1 Train Loss: 50.985 | Train Acc: 75.122 
2 Train Loss: 46.672 | Train Acc: 78.347 
3 Train Loss: 43.050 | Train Acc: 80.347 
4 Train Loss: 39.701 | Train Acc: 81.551 
5 Train Loss: 37.537 | Train Acc: 83.714 
6 Train Loss: 35.980 | Train Acc: 83.980 
7 Train Loss: 33.817 | Train Acc: 85.041 
8 Train Loss: 33.056 | Train Acc: 85.633 
9 Train Loss: 30.718 | Train Acc: 87.122 
10 Train Loss: 29.368 | Train Acc: 87.918 
11 Train Loss: 29.611 | Train Acc: 87.837 
12 Train Loss: 27.174 | Train Acc: 88.612 
13 Train Loss: 26.057 | Train Acc: 89.102 
14 Train Loss: 25.946 | Train Acc: 89.490 
15 Train Loss: 24.550 | Train Acc: 90.102 
16 Train Loss: 23.661 | Train Acc: 90.612 
17 Train Loss: 23.802 | Train Acc: 90.612 
18 Train Loss: 23.150 | Train Acc: 90.714 
19 Train Loss: 21.074 | Train Acc: 91.878 
20 Train Loss: 18.311 | Train Acc: 93.388 
21 Train Loss: 17.866 | Train Acc: 93.571 
22 Train Loss: 17.522 | Train Acc: 93.531 
23 Train Loss: 17.182 | Train Acc: 93.980 
24 Train Loss: 16.967 | Train Acc: 93.939 
25 Train Loss: 16.313 | Train Acc: 94.408 
26 Train Loss: 16.343 | Train Acc: 94.429 
27 Train Loss: 15.672 | Train Acc: 94.755 
28 Train Loss: 15.371 | Train Acc: 94.653 
29 Train Loss: 15.179 | Train Acc: 94.939 
30 Train Loss: 14.833 | Train Acc: 95.143 
31 Train Loss: 14.419 | Train Acc: 95.347 
32 Train Loss: 14.371 | Train Acc: 95.102 
33 Train Loss: 13.904 | Train Acc: 95.245 
34 Train Loss: 13.717 | Train Acc: 95.510 
35 Train Loss: 13.315 | Train Acc: 96.041 
36 Train Loss: 13.186 | Train Acc: 95.592 
37 Train Loss: 13.056 | Train Acc: 95.694 
38 Train Loss: 12.632 | Train Acc: 96.000 
39 Train Loss: 12.154 | Train Acc: 96.510 
40 Train Loss: 11.338 | Train Acc: 96.735 
41 Train Loss: 11.208 | Train Acc: 97.061 
42 Train Loss: 11.097 | Train Acc: 97.163 
43 Train Loss: 10.905 | Train Acc: 97.245 
44 Train Loss: 10.793 | Train Acc: 97.347 
45 Train Loss: 10.627 | Train Acc: 97.306 
46 Train Loss: 10.557 | Train Acc: 97.327 
47 Train Loss: 10.545 | Train Acc: 97.510 
48 Train Loss: 10.406 | Train Acc: 97.449 
49 Train Loss: 10.239 | Train Acc: 97.571 
50 Train Loss: 10.102 | Train Acc: 97.755 
51 Train Loss: 10.023 | Train Acc: 97.837 
52 Train Loss: 9.986 | Train Acc: 97.878 
53 Train Loss: 9.920 | Train Acc: 97.735 
54 Train Loss: 9.813 | Train Acc: 97.796 
55 Train Loss: 10.036 | Train Acc: 97.735 
56 Train Loss: 9.553 | Train Acc: 98.143 
57 Train Loss: 9.483 | Train Acc: 97.980 
58 Train Loss: 9.362 | Train Acc: 98.204 
59 Train Loss: 9.269 | Train Acc: 98.102 
60 Train Loss: 9.029 | Train Acc: 98.122 
61 Train Loss: 8.900 | Train Acc: 98.531 
62 Train Loss: 8.839 | Train Acc: 98.367 
63 Train Loss: 8.766 | Train Acc: 98.429 
64 Train Loss: 8.726 | Train Acc: 98.449 
65 Train Loss: 8.681 | Train Acc: 98.531 
66 Train Loss: 8.660 | Train Acc: 98.429 
67 Train Loss: 8.645 | Train Acc: 98.653 
68 Train Loss: 8.538 | Train Acc: 98.571 
69 Train Loss: 8.539 | Train Acc: 98.673 
70 Train Loss: 8.533 | Train Acc: 98.429 
71 Train Loss: 8.445 | Train Acc: 98.755 
72 Train Loss: 8.429 | Train Acc: 98.673 
73 Train Loss: 8.417 | Train Acc: 98.633 
74 Train Loss: 8.379 | Train Acc: 98.592 
75 Train Loss: 8.277 | Train Acc: 98.612 
76 Train Loss: 8.265 | Train Acc: 98.653 
77 Train Loss: 8.229 | Train Acc: 98.571 
78 Train Loss: 8.210 | Train Acc: 98.776 
79 Train Loss: 8.194 | Train Acc: 98.837 
80 Train Loss: 8.051 | Train Acc: 98.673 
81 Train Loss: 7.985 | Train Acc: 98.796 
82 Train Loss: 7.962 | Train Acc: 98.796 
83 Train Loss: 7.966 | Train Acc: 98.694 
84 Train Loss: 7.920 | Train Acc: 98.837 
85 Train Loss: 7.919 | Train Acc: 98.878 
86 Train Loss: 7.911 | Train Acc: 98.898 
87 Train Loss: 7.904 | Train Acc: 98.816 
88 Train Loss: 7.880 | Train Acc: 98.776 
89 Train Loss: 7.857 | Train Acc: 98.857 
90 Train Loss: 7.838 | Train Acc: 98.837 
91 Train Loss: 7.843 | Train Acc: 98.837 
92 Train Loss: 7.792 | Train Acc: 98.918 
93 Train Loss: 7.804 | Train Acc: 98.939 
94 Train Loss: 7.800 | Train Acc: 99.061 
95 Train Loss: 7.744 | Train Acc: 98.816 
96 Train Loss: 7.724 | Train Acc: 98.959 
97 Train Loss: 7.736 | Train Acc: 98.918 
98 Train Loss: 7.727 | Train Acc: 98.918 
99 Train Loss: 7.695 | Train Acc: 98.878 
CNN trained successfully...
image_next_flat.shape :  torch.Size([4900, 12544])
Time Taken by Kmeans is  0.8316049575805664
Kmeans completed successfully...
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  2450 2450
expectedMlpLabels.shape :  torch.Size([4900])
0 Loss: 106.743 | Acc: 72.958
1 Loss: 83.005 | Acc: 81.083
2 Loss: 73.807 | Acc: 83.688
3 Loss: 66.458 | Acc: 85.375
4 Loss: 59.409 | Acc: 86.688
5 Loss: 54.116 | Acc: 88.792
6 Loss: 49.456 | Acc: 89.354
7 Loss: 46.242 | Acc: 89.646
8 Loss: 38.791 | Acc: 91.604
9 Loss: 33.457 | Acc: 92.896
10 Loss: 22.902 | Acc: 95.417
11 Loss: 17.373 | Acc: 96.750
12 Loss: 18.043 | Acc: 96.604
13 Loss: 14.443 | Acc: 97.292
14 Loss: 11.922 | Acc: 97.479
15 Loss: 10.275 | Acc: 97.979
16 Loss: 10.780 | Acc: 97.833
17 Loss: 9.355 | Acc: 98.438
18 Loss: 10.851 | Acc: 97.979
19 Loss: 6.968 | Acc: 98.875
20 Loss: 4.209 | Acc: 99.333
21 Loss: 3.939 | Acc: 99.417
22 Loss: 3.076 | Acc: 99.500
23 Loss: 2.774 | Acc: 99.521
24 Loss: 2.551 | Acc: 99.562
25 Loss: 2.358 | Acc: 99.688
26 Loss: 2.102 | Acc: 99.646
27 Loss: 2.547 | Acc: 99.562
28 Loss: 1.866 | Acc: 99.729
29 Loss: 1.699 | Acc: 99.812
30 Loss: 2.082 | Acc: 99.854
31 Loss: 1.304 | Acc: 99.792
32 Loss: 1.815 | Acc: 99.750
33 Loss: 0.830 | Acc: 99.938
34 Loss: 1.169 | Acc: 99.896
35 Loss: 0.808 | Acc: 99.938
36 Loss: 1.143 | Acc: 99.875
37 Loss: 1.037 | Acc: 99.875
38 Loss: 1.262 | Acc: 99.812
39 Loss: 0.913 | Acc: 99.854
40 Loss: 0.819 | Acc: 99.854
41 Loss: 1.032 | Acc: 99.896
42 Loss: 0.964 | Acc: 99.833
43 Loss: 0.854 | Acc: 99.854
44 Loss: 0.524 | Acc: 99.958
45 Loss: 0.738 | Acc: 99.875
46 Loss: 0.552 | Acc: 99.958
47 Loss: 0.409 | Acc: 99.979
48 Loss: 0.544 | Acc: 99.958
49 Loss: 0.681 | Acc: 99.917
50 Loss: 0.549 | Acc: 99.938
51 Loss: 0.586 | Acc: 99.958
52 Loss: 0.507 | Acc: 99.938
53 Loss: 0.424 | Acc: 99.979
54 Loss: 0.695 | Acc: 99.917
55 Loss: 0.818 | Acc: 99.854
56 Loss: 0.431 | Acc: 99.958
57 Loss: 0.535 | Acc: 99.938
58 Loss: 0.493 | Acc: 99.938
59 Loss: 0.489 | Acc: 99.958
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2450])
rTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2450])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([0, 3, 32, 32])   rValDict[label].shape:  torch.Size([0])
# of Left images:  2450.0
# of Right images:  2450.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 2450, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2450, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 5
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 5
nodeId:  22 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 22 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 2450
nodeId:  23 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 23 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 2450
Running nodeId:  13
0 Train Loss: 65.053 | Train Acc: 68.204 
1 Train Loss: 52.662 | Train Acc: 76.449 
2 Train Loss: 45.211 | Train Acc: 80.803 
3 Train Loss: 43.925 | Train Acc: 81.116 
4 Train Loss: 43.604 | Train Acc: 81.224 
5 Train Loss: 43.420 | Train Acc: 80.912 
6 Train Loss: 42.691 | Train Acc: 81.973 
7 Train Loss: 40.035 | Train Acc: 83.184 
8 Train Loss: 41.040 | Train Acc: 82.844 
9 Train Loss: 40.225 | Train Acc: 83.020 
10 Train Loss: 36.955 | Train Acc: 84.912 
11 Train Loss: 36.242 | Train Acc: 85.265 
12 Train Loss: 37.350 | Train Acc: 84.803 
13 Train Loss: 35.084 | Train Acc: 85.810 
14 Train Loss: 33.114 | Train Acc: 86.680 
15 Train Loss: 32.353 | Train Acc: 86.952 
16 Train Loss: 33.704 | Train Acc: 86.218 
17 Train Loss: 30.886 | Train Acc: 88.177 
18 Train Loss: 35.959 | Train Acc: 85.537 
19 Train Loss: 29.105 | Train Acc: 88.571 
20 Train Loss: 27.937 | Train Acc: 89.061 
21 Train Loss: 26.870 | Train Acc: 89.701 
22 Train Loss: 27.758 | Train Acc: 89.075 
23 Train Loss: 26.495 | Train Acc: 89.946 
24 Train Loss: 25.878 | Train Acc: 90.340 
25 Train Loss: 25.958 | Train Acc: 89.918 
26 Train Loss: 25.415 | Train Acc: 90.422 
27 Train Loss: 25.812 | Train Acc: 90.245 
28 Train Loss: 25.047 | Train Acc: 90.476 
29 Train Loss: 24.706 | Train Acc: 90.694 
30 Train Loss: 24.652 | Train Acc: 90.476 
31 Train Loss: 25.072 | Train Acc: 90.014 
32 Train Loss: 23.621 | Train Acc: 91.361 
33 Train Loss: 23.923 | Train Acc: 90.844 
34 Train Loss: 24.657 | Train Acc: 90.150 
35 Train Loss: 23.086 | Train Acc: 91.347 
36 Train Loss: 22.502 | Train Acc: 91.497 
37 Train Loss: 23.602 | Train Acc: 90.789 
38 Train Loss: 22.160 | Train Acc: 91.646 
39 Train Loss: 22.769 | Train Acc: 91.116 
40 Train Loss: 21.133 | Train Acc: 92.122 
41 Train Loss: 20.580 | Train Acc: 92.490 
42 Train Loss: 20.712 | Train Acc: 92.612 
43 Train Loss: 20.214 | Train Acc: 92.721 
44 Train Loss: 20.759 | Train Acc: 92.136 
45 Train Loss: 20.722 | Train Acc: 92.204 
46 Train Loss: 20.071 | Train Acc: 92.667 
47 Train Loss: 20.198 | Train Acc: 92.803 
48 Train Loss: 19.843 | Train Acc: 93.061 
49 Train Loss: 19.843 | Train Acc: 92.871 
50 Train Loss: 19.821 | Train Acc: 92.939 
51 Train Loss: 19.693 | Train Acc: 93.020 
52 Train Loss: 19.532 | Train Acc: 92.980 
53 Train Loss: 19.484 | Train Acc: 92.776 
54 Train Loss: 19.351 | Train Acc: 93.116 
55 Train Loss: 19.660 | Train Acc: 92.844 
56 Train Loss: 19.045 | Train Acc: 93.224 
57 Train Loss: 19.715 | Train Acc: 92.789 
58 Train Loss: 19.177 | Train Acc: 93.197 
59 Train Loss: 19.027 | Train Acc: 93.156 
60 Train Loss: 18.457 | Train Acc: 93.374 
61 Train Loss: 18.239 | Train Acc: 93.701 
62 Train Loss: 18.251 | Train Acc: 93.565 
63 Train Loss: 18.065 | Train Acc: 93.483 
64 Train Loss: 18.058 | Train Acc: 93.891 
65 Train Loss: 18.160 | Train Acc: 93.660 
66 Train Loss: 17.981 | Train Acc: 93.728 
67 Train Loss: 17.798 | Train Acc: 93.769 
68 Train Loss: 17.873 | Train Acc: 93.850 
69 Train Loss: 18.048 | Train Acc: 93.633 
70 Train Loss: 17.816 | Train Acc: 93.864 
71 Train Loss: 17.818 | Train Acc: 93.741 
72 Train Loss: 17.870 | Train Acc: 93.619 
73 Train Loss: 17.964 | Train Acc: 93.646 
74 Train Loss: 17.806 | Train Acc: 93.782 
75 Train Loss: 17.504 | Train Acc: 93.769 
76 Train Loss: 17.500 | Train Acc: 94.068 
77 Train Loss: 17.586 | Train Acc: 93.986 
78 Train Loss: 17.485 | Train Acc: 93.959 
79 Train Loss: 17.384 | Train Acc: 93.986 
80 Train Loss: 17.186 | Train Acc: 94.136 
81 Train Loss: 17.424 | Train Acc: 93.973 
82 Train Loss: 17.160 | Train Acc: 94.163 
83 Train Loss: 17.142 | Train Acc: 94.095 
84 Train Loss: 17.137 | Train Acc: 94.204 
85 Train Loss: 17.015 | Train Acc: 94.109 
86 Train Loss: 17.156 | Train Acc: 94.245 
87 Train Loss: 17.118 | Train Acc: 94.177 
88 Train Loss: 17.060 | Train Acc: 94.163 
89 Train Loss: 17.000 | Train Acc: 94.150 
90 Train Loss: 16.958 | Train Acc: 94.245 
91 Train Loss: 17.013 | Train Acc: 94.204 
92 Train Loss: 16.973 | Train Acc: 94.259 
93 Train Loss: 17.033 | Train Acc: 94.231 
94 Train Loss: 17.035 | Train Acc: 94.095 
95 Train Loss: 16.997 | Train Acc: 94.299 
96 Train Loss: 16.855 | Train Acc: 94.340 
97 Train Loss: 17.013 | Train Acc: 94.204 
98 Train Loss: 16.903 | Train Acc: 94.190 
99 Train Loss: 16.789 | Train Acc: 94.463 
CNN trained successfully...
image_next_flat.shape :  torch.Size([7350, 12544])
Time Taken by Kmeans is  1.372817039489746
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 1, 1: 0}
Image Statistics before MLP : L R :  2450 4900
expectedMlpLabels.shape :  torch.Size([7350])
0 Loss: 73.984 | Acc: 72.847
1 Loss: 56.614 | Acc: 83.000
2 Loss: 47.771 | Acc: 85.819
3 Loss: 45.750 | Acc: 85.792
4 Loss: 40.219 | Acc: 87.694
5 Loss: 36.353 | Acc: 89.792
6 Loss: 34.650 | Acc: 89.722
7 Loss: 30.541 | Acc: 91.306
8 Loss: 29.867 | Acc: 91.042
9 Loss: 24.175 | Acc: 93.042
10 Loss: 17.475 | Acc: 95.042
11 Loss: 16.287 | Acc: 95.319
12 Loss: 13.738 | Acc: 96.014
13 Loss: 13.143 | Acc: 96.389
14 Loss: 12.648 | Acc: 96.236
15 Loss: 10.649 | Acc: 96.958
16 Loss: 8.963 | Acc: 97.250
17 Loss: 9.011 | Acc: 97.514
18 Loss: 6.928 | Acc: 98.028
19 Loss: 6.033 | Acc: 98.278
20 Loss: 4.810 | Acc: 98.611
21 Loss: 4.330 | Acc: 98.861
22 Loss: 2.986 | Acc: 99.319
23 Loss: 3.052 | Acc: 99.111
24 Loss: 3.187 | Acc: 99.278
25 Loss: 2.959 | Acc: 99.403
26 Loss: 2.394 | Acc: 99.514
27 Loss: 2.188 | Acc: 99.486
28 Loss: 2.200 | Acc: 99.514
29 Loss: 2.353 | Acc: 99.472
30 Loss: 1.818 | Acc: 99.694
31 Loss: 1.999 | Acc: 99.542
32 Loss: 1.866 | Acc: 99.528
33 Loss: 1.415 | Acc: 99.736
34 Loss: 1.604 | Acc: 99.708
35 Loss: 1.679 | Acc: 99.708
36 Loss: 1.083 | Acc: 99.819
37 Loss: 1.223 | Acc: 99.694
38 Loss: 1.225 | Acc: 99.764
39 Loss: 1.119 | Acc: 99.778
40 Loss: 0.968 | Acc: 99.875
41 Loss: 1.150 | Acc: 99.806
42 Loss: 0.910 | Acc: 99.847
43 Loss: 0.808 | Acc: 99.875
44 Loss: 0.929 | Acc: 99.833
45 Loss: 0.806 | Acc: 99.764
46 Loss: 0.769 | Acc: 99.903
47 Loss: 0.786 | Acc: 99.847
48 Loss: 0.833 | Acc: 99.819
49 Loss: 0.854 | Acc: 99.847
50 Loss: 0.711 | Acc: 99.903
51 Loss: 0.781 | Acc: 99.903
52 Loss: 0.916 | Acc: 99.778
53 Loss: 1.071 | Acc: 99.778
54 Loss: 0.824 | Acc: 99.861
55 Loss: 0.780 | Acc: 99.903
56 Loss: 0.719 | Acc: 99.875
57 Loss: 0.686 | Acc: 99.875
58 Loss: 0.797 | Acc: 99.847
59 Loss: 0.631 | Acc: 99.931
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2450])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  2450.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [0, 2450, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 3
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 3
nodeId:  24 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 24 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 2450
nodeId:  25 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 25 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  14
0 Train Loss: 63.444 | Train Acc: 64.490 
1 Train Loss: 54.694 | Train Acc: 74.163 
2 Train Loss: 46.277 | Train Acc: 78.612 
3 Train Loss: 46.048 | Train Acc: 79.374 
4 Train Loss: 46.125 | Train Acc: 78.299 
5 Train Loss: 43.985 | Train Acc: 79.741 
6 Train Loss: 42.406 | Train Acc: 80.463 
7 Train Loss: 45.178 | Train Acc: 80.980 
8 Train Loss: 42.598 | Train Acc: 80.735 
9 Train Loss: 39.304 | Train Acc: 81.878 
10 Train Loss: 39.995 | Train Acc: 82.313 
11 Train Loss: 37.716 | Train Acc: 82.599 
12 Train Loss: 36.252 | Train Acc: 84.136 
13 Train Loss: 37.094 | Train Acc: 83.605 
14 Train Loss: 34.999 | Train Acc: 85.034 
15 Train Loss: 33.685 | Train Acc: 84.898 
16 Train Loss: 33.686 | Train Acc: 85.102 
17 Train Loss: 32.640 | Train Acc: 86.014 
18 Train Loss: 32.740 | Train Acc: 85.755 
19 Train Loss: 31.866 | Train Acc: 85.959 
20 Train Loss: 28.536 | Train Acc: 87.878 
21 Train Loss: 27.798 | Train Acc: 88.422 
22 Train Loss: 27.041 | Train Acc: 88.748 
23 Train Loss: 28.036 | Train Acc: 88.367 
24 Train Loss: 25.985 | Train Acc: 89.156 
25 Train Loss: 26.212 | Train Acc: 89.551 
26 Train Loss: 26.048 | Train Acc: 89.170 
27 Train Loss: 25.414 | Train Acc: 89.524 
28 Train Loss: 25.414 | Train Acc: 89.633 
29 Train Loss: 25.068 | Train Acc: 89.646 
30 Train Loss: 25.331 | Train Acc: 89.864 
31 Train Loss: 24.389 | Train Acc: 90.340 
32 Train Loss: 24.547 | Train Acc: 89.932 
33 Train Loss: 24.362 | Train Acc: 90.381 
34 Train Loss: 23.460 | Train Acc: 90.463 
35 Train Loss: 22.730 | Train Acc: 91.061 
36 Train Loss: 23.198 | Train Acc: 90.898 
37 Train Loss: 23.008 | Train Acc: 90.585 
38 Train Loss: 22.851 | Train Acc: 90.980 
39 Train Loss: 21.816 | Train Acc: 91.293 
40 Train Loss: 21.941 | Train Acc: 91.401 
41 Train Loss: 21.250 | Train Acc: 91.823 
42 Train Loss: 20.787 | Train Acc: 92.395 
43 Train Loss: 21.124 | Train Acc: 92.054 
44 Train Loss: 20.654 | Train Acc: 92.136 
45 Train Loss: 20.218 | Train Acc: 92.109 
46 Train Loss: 20.246 | Train Acc: 92.476 
47 Train Loss: 20.343 | Train Acc: 92.422 
48 Train Loss: 20.033 | Train Acc: 92.612 
49 Train Loss: 20.022 | Train Acc: 92.612 
50 Train Loss: 19.657 | Train Acc: 92.857 
51 Train Loss: 19.696 | Train Acc: 92.803 
52 Train Loss: 19.387 | Train Acc: 92.912 
53 Train Loss: 19.825 | Train Acc: 92.912 
54 Train Loss: 19.578 | Train Acc: 92.789 
55 Train Loss: 19.227 | Train Acc: 92.993 
56 Train Loss: 19.020 | Train Acc: 93.279 
57 Train Loss: 18.957 | Train Acc: 93.116 
58 Train Loss: 18.655 | Train Acc: 93.156 
59 Train Loss: 18.786 | Train Acc: 93.293 
60 Train Loss: 18.237 | Train Acc: 93.565 
61 Train Loss: 18.206 | Train Acc: 93.497 
62 Train Loss: 18.373 | Train Acc: 93.537 
63 Train Loss: 18.261 | Train Acc: 93.714 
64 Train Loss: 17.966 | Train Acc: 93.592 
65 Train Loss: 17.955 | Train Acc: 93.714 
66 Train Loss: 17.756 | Train Acc: 93.741 
67 Train Loss: 17.755 | Train Acc: 93.918 
68 Train Loss: 17.834 | Train Acc: 93.782 
69 Train Loss: 17.685 | Train Acc: 93.905 
70 Train Loss: 17.622 | Train Acc: 94.000 
71 Train Loss: 17.842 | Train Acc: 93.687 
72 Train Loss: 17.587 | Train Acc: 94.136 
73 Train Loss: 17.483 | Train Acc: 93.687 
74 Train Loss: 17.361 | Train Acc: 94.163 
75 Train Loss: 17.403 | Train Acc: 93.932 
76 Train Loss: 17.453 | Train Acc: 94.190 
77 Train Loss: 17.390 | Train Acc: 93.973 
78 Train Loss: 17.269 | Train Acc: 93.796 
79 Train Loss: 17.159 | Train Acc: 94.109 
80 Train Loss: 17.096 | Train Acc: 94.122 
81 Train Loss: 16.963 | Train Acc: 94.041 
82 Train Loss: 16.910 | Train Acc: 94.286 
83 Train Loss: 16.995 | Train Acc: 94.204 
84 Train Loss: 16.881 | Train Acc: 94.041 
85 Train Loss: 17.023 | Train Acc: 94.231 
86 Train Loss: 16.839 | Train Acc: 94.503 
87 Train Loss: 16.993 | Train Acc: 94.082 
88 Train Loss: 16.841 | Train Acc: 94.245 
89 Train Loss: 16.842 | Train Acc: 94.245 
90 Train Loss: 16.778 | Train Acc: 94.354 
91 Train Loss: 16.713 | Train Acc: 94.422 
92 Train Loss: 16.739 | Train Acc: 94.259 
93 Train Loss: 16.759 | Train Acc: 94.354 
94 Train Loss: 16.776 | Train Acc: 94.190 
95 Train Loss: 16.727 | Train Acc: 94.041 
96 Train Loss: 16.718 | Train Acc: 94.340 
97 Train Loss: 16.682 | Train Acc: 94.367 
98 Train Loss: 16.671 | Train Acc: 94.313 
99 Train Loss: 16.584 | Train Acc: 94.340 
CNN trained successfully...
image_next_flat.shape :  torch.Size([7350, 12544])
Time Taken by Kmeans is  0.7508647441864014
Kmeans completed successfully...
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics before MLP : L R :  2450 4900
expectedMlpLabels.shape :  torch.Size([7350])
0 Loss: 77.681 | Acc: 70.208
1 Loss: 57.408 | Acc: 80.319
2 Loss: 48.292 | Acc: 83.681
3 Loss: 45.426 | Acc: 84.778
4 Loss: 37.797 | Acc: 87.653
5 Loss: 36.079 | Acc: 88.403
6 Loss: 29.705 | Acc: 90.597
7 Loss: 26.148 | Acc: 91.444
8 Loss: 20.792 | Acc: 93.014
9 Loss: 21.490 | Acc: 93.306
10 Loss: 13.081 | Acc: 95.708
11 Loss: 11.590 | Acc: 96.514
12 Loss: 9.413 | Acc: 97.236
13 Loss: 8.161 | Acc: 97.597
14 Loss: 7.261 | Acc: 97.889
15 Loss: 6.416 | Acc: 98.181
16 Loss: 6.027 | Acc: 98.208
17 Loss: 4.468 | Acc: 98.806
18 Loss: 4.443 | Acc: 98.625
19 Loss: 4.392 | Acc: 98.944
20 Loss: 2.624 | Acc: 99.361
21 Loss: 2.506 | Acc: 99.347
22 Loss: 1.911 | Acc: 99.681
23 Loss: 2.054 | Acc: 99.458
24 Loss: 2.076 | Acc: 99.486
25 Loss: 1.714 | Acc: 99.625
26 Loss: 1.719 | Acc: 99.597
27 Loss: 1.583 | Acc: 99.708
28 Loss: 1.419 | Acc: 99.722
29 Loss: 1.131 | Acc: 99.750
30 Loss: 0.880 | Acc: 99.778
31 Loss: 1.032 | Acc: 99.792
32 Loss: 0.738 | Acc: 99.792
33 Loss: 0.978 | Acc: 99.792
34 Loss: 1.120 | Acc: 99.778
35 Loss: 0.894 | Acc: 99.792
36 Loss: 0.785 | Acc: 99.819
37 Loss: 0.779 | Acc: 99.806
38 Loss: 0.903 | Acc: 99.792
39 Loss: 0.718 | Acc: 99.833
40 Loss: 0.762 | Acc: 99.806
41 Loss: 0.590 | Acc: 99.861
42 Loss: 0.787 | Acc: 99.819
43 Loss: 0.759 | Acc: 99.861
44 Loss: 0.517 | Acc: 99.917
45 Loss: 0.640 | Acc: 99.889
46 Loss: 0.450 | Acc: 99.944
47 Loss: 0.743 | Acc: 99.819
48 Loss: 0.377 | Acc: 99.972
49 Loss: 0.552 | Acc: 99.847
50 Loss: 0.477 | Acc: 99.917
51 Loss: 0.484 | Acc: 99.944
52 Loss: 0.510 | Acc: 99.903
53 Loss: 0.437 | Acc: 99.917
54 Loss: 0.588 | Acc: 99.903
55 Loss: 0.388 | Acc: 99.944
56 Loss: 0.538 | Acc: 99.889
57 Loss: 0.752 | Acc: 99.889
58 Loss: 0.581 | Acc: 99.889
59 Loss: 0.451 | Acc: 99.903
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2450])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  2450.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [2450, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 4
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 4
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  26 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 26 ,  parentId: 14 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 2450
nodeId:  27 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 27 ,  parentId: 14 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  15
0 Train Loss: 56.269 | Train Acc: 70.061 
1 Train Loss: 47.308 | Train Acc: 77.388 
2 Train Loss: 42.894 | Train Acc: 79.673 
3 Train Loss: 39.716 | Train Acc: 82.571 
4 Train Loss: 37.665 | Train Acc: 83.510 
5 Train Loss: 35.895 | Train Acc: 84.306 
6 Train Loss: 35.071 | Train Acc: 84.633 
7 Train Loss: 34.766 | Train Acc: 85.531 
8 Train Loss: 33.921 | Train Acc: 84.857 
9 Train Loss: 31.157 | Train Acc: 87.653 
10 Train Loss: 30.471 | Train Acc: 87.449 
11 Train Loss: 29.323 | Train Acc: 87.878 
12 Train Loss: 29.027 | Train Acc: 87.551 
13 Train Loss: 26.558 | Train Acc: 88.796 
14 Train Loss: 25.614 | Train Acc: 89.408 
15 Train Loss: 24.914 | Train Acc: 89.673 
16 Train Loss: 23.507 | Train Acc: 90.857 
17 Train Loss: 22.746 | Train Acc: 91.061 
18 Train Loss: 22.015 | Train Acc: 91.061 
19 Train Loss: 20.346 | Train Acc: 92.224 
20 Train Loss: 17.925 | Train Acc: 93.837 
21 Train Loss: 17.421 | Train Acc: 94.000 
22 Train Loss: 17.438 | Train Acc: 93.878 
23 Train Loss: 17.585 | Train Acc: 93.245 
24 Train Loss: 16.372 | Train Acc: 94.490 
25 Train Loss: 16.406 | Train Acc: 94.367 
26 Train Loss: 16.212 | Train Acc: 94.245 
27 Train Loss: 15.935 | Train Acc: 94.918 
28 Train Loss: 15.248 | Train Acc: 95.061 
29 Train Loss: 15.280 | Train Acc: 94.878 
30 Train Loss: 15.079 | Train Acc: 95.082 
31 Train Loss: 14.387 | Train Acc: 95.429 
32 Train Loss: 14.241 | Train Acc: 95.347 
33 Train Loss: 13.857 | Train Acc: 95.653 
34 Train Loss: 13.596 | Train Acc: 95.776 
35 Train Loss: 13.245 | Train Acc: 95.898 
36 Train Loss: 14.437 | Train Acc: 95.184 
37 Train Loss: 13.516 | Train Acc: 96.020 
38 Train Loss: 12.562 | Train Acc: 96.531 
39 Train Loss: 12.812 | Train Acc: 95.857 
40 Train Loss: 11.783 | Train Acc: 96.918 
41 Train Loss: 11.214 | Train Acc: 97.184 
42 Train Loss: 11.396 | Train Acc: 97.286 
43 Train Loss: 11.104 | Train Acc: 97.327 
44 Train Loss: 11.260 | Train Acc: 97.061 
45 Train Loss: 11.038 | Train Acc: 97.347 
46 Train Loss: 10.887 | Train Acc: 97.245 
47 Train Loss: 10.810 | Train Acc: 97.388 
48 Train Loss: 10.832 | Train Acc: 97.449 
49 Train Loss: 10.763 | Train Acc: 97.551 
50 Train Loss: 10.437 | Train Acc: 97.633 
51 Train Loss: 10.470 | Train Acc: 97.490 
52 Train Loss: 10.264 | Train Acc: 97.551 
53 Train Loss: 10.325 | Train Acc: 97.714 
54 Train Loss: 10.218 | Train Acc: 97.755 
55 Train Loss: 10.164 | Train Acc: 97.755 
56 Train Loss: 10.024 | Train Acc: 97.633 
57 Train Loss: 10.040 | Train Acc: 97.694 
58 Train Loss: 9.871 | Train Acc: 97.551 
59 Train Loss: 9.711 | Train Acc: 97.857 
60 Train Loss: 9.432 | Train Acc: 98.245 
61 Train Loss: 9.302 | Train Acc: 97.959 
62 Train Loss: 9.428 | Train Acc: 97.980 
63 Train Loss: 9.309 | Train Acc: 98.041 
64 Train Loss: 9.250 | Train Acc: 98.163 
65 Train Loss: 9.156 | Train Acc: 98.143 
66 Train Loss: 9.122 | Train Acc: 98.041 
67 Train Loss: 9.095 | Train Acc: 98.102 
68 Train Loss: 9.090 | Train Acc: 98.184 
69 Train Loss: 9.047 | Train Acc: 98.143 
70 Train Loss: 9.073 | Train Acc: 98.184 
71 Train Loss: 9.091 | Train Acc: 98.143 
72 Train Loss: 8.934 | Train Acc: 98.286 
73 Train Loss: 8.871 | Train Acc: 98.286 
74 Train Loss: 8.847 | Train Acc: 98.327 
75 Train Loss: 8.807 | Train Acc: 98.204 
76 Train Loss: 8.739 | Train Acc: 98.184 
77 Train Loss: 8.736 | Train Acc: 98.327 
78 Train Loss: 8.675 | Train Acc: 98.306 
79 Train Loss: 8.665 | Train Acc: 98.327 
80 Train Loss: 8.473 | Train Acc: 98.388 
81 Train Loss: 8.472 | Train Acc: 98.449 
82 Train Loss: 8.452 | Train Acc: 98.367 
83 Train Loss: 8.432 | Train Acc: 98.367 
84 Train Loss: 8.424 | Train Acc: 98.449 
85 Train Loss: 8.384 | Train Acc: 98.449 
86 Train Loss: 8.374 | Train Acc: 98.347 
87 Train Loss: 8.363 | Train Acc: 98.469 
88 Train Loss: 8.334 | Train Acc: 98.490 
89 Train Loss: 8.336 | Train Acc: 98.408 
90 Train Loss: 8.340 | Train Acc: 98.490 
91 Train Loss: 8.304 | Train Acc: 98.449 
92 Train Loss: 8.284 | Train Acc: 98.490 
93 Train Loss: 8.294 | Train Acc: 98.490 
94 Train Loss: 8.258 | Train Acc: 98.510 
95 Train Loss: 8.292 | Train Acc: 98.510 
96 Train Loss: 8.259 | Train Acc: 98.449 
97 Train Loss: 8.204 | Train Acc: 98.490 
98 Train Loss: 8.204 | Train Acc: 98.469 
99 Train Loss: 8.178 | Train Acc: 98.592 
CNN trained successfully...
image_next_flat.shape :  torch.Size([4900, 12544])
Time Taken by Kmeans is  0.9048774242401123
Kmeans completed successfully...
printing expected split from k means
{0: 1, 1: 0}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  2450 2450
expectedMlpLabels.shape :  torch.Size([4900])
0 Loss: 97.911 | Acc: 76.146
1 Loss: 76.276 | Acc: 83.646
2 Loss: 67.329 | Acc: 85.042
3 Loss: 59.823 | Acc: 87.688
4 Loss: 53.129 | Acc: 88.146
5 Loss: 48.074 | Acc: 90.083
6 Loss: 42.923 | Acc: 90.312
7 Loss: 38.610 | Acc: 92.292
8 Loss: 31.458 | Acc: 93.521
9 Loss: 29.134 | Acc: 94.521
10 Loss: 15.357 | Acc: 97.021
11 Loss: 14.046 | Acc: 97.188
12 Loss: 10.818 | Acc: 97.917
13 Loss: 7.693 | Acc: 98.667
14 Loss: 9.489 | Acc: 98.375
15 Loss: 5.759 | Acc: 99.021
16 Loss: 6.825 | Acc: 98.812
17 Loss: 5.968 | Acc: 98.938
18 Loss: 5.042 | Acc: 99.104
19 Loss: 5.162 | Acc: 99.188
20 Loss: 4.079 | Acc: 99.500
21 Loss: 2.529 | Acc: 99.646
22 Loss: 2.337 | Acc: 99.646
23 Loss: 1.421 | Acc: 99.833
24 Loss: 1.326 | Acc: 99.875
25 Loss: 1.620 | Acc: 99.708
26 Loss: 3.019 | Acc: 99.625
27 Loss: 1.005 | Acc: 99.896
28 Loss: 1.079 | Acc: 99.854
29 Loss: 1.003 | Acc: 99.812
30 Loss: 0.938 | Acc: 99.896
31 Loss: 0.619 | Acc: 99.979
32 Loss: 0.750 | Acc: 99.917
33 Loss: 0.778 | Acc: 99.938
34 Loss: 0.530 | Acc: 99.938
35 Loss: 0.558 | Acc: 99.938
36 Loss: 0.723 | Acc: 99.896
37 Loss: 0.660 | Acc: 99.917
38 Loss: 1.026 | Acc: 99.875
39 Loss: 0.953 | Acc: 99.896
40 Loss: 0.783 | Acc: 99.854
41 Loss: 0.518 | Acc: 99.958
42 Loss: 0.778 | Acc: 99.917
43 Loss: 0.512 | Acc: 99.917
44 Loss: 0.636 | Acc: 99.875
45 Loss: 0.396 | Acc: 99.938
46 Loss: 0.561 | Acc: 99.938
47 Loss: 0.454 | Acc: 99.958
48 Loss: 0.373 | Acc: 99.958
49 Loss: 0.368 | Acc: 99.958
50 Loss: 0.317 | Acc: 99.979
51 Loss: 0.322 | Acc: 99.979
52 Loss: 0.332 | Acc: 99.979
53 Loss: 0.364 | Acc: 99.958
54 Loss: 0.504 | Acc: 99.958
55 Loss: 0.366 | Acc: 99.958
56 Loss: 0.313 | Acc: 99.979
57 Loss: 0.708 | Acc: 99.896
58 Loss: 0.268 | Acc: 100.000
59 Loss: 0.430 | Acc: 99.938
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2450])
rTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2450])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([0, 3, 32, 32])   rValDict[label].shape:  torch.Size([0])
# of Left images:  2450.0
# of Right images:  2450.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 2450, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2450, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 5
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 4
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 5
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 4
nodeId:  28 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 28 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 2450
nodeId:  29 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 29 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 2450
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
Running nodeId:  20
0 Train Loss: 69.806 | Train Acc: 61.796 
1 Train Loss: 68.303 | Train Acc: 66.748 
2 Train Loss: 66.512 | Train Acc: 67.483 
3 Train Loss: 59.738 | Train Acc: 70.177 
4 Train Loss: 56.499 | Train Acc: 71.320 
5 Train Loss: 57.641 | Train Acc: 70.558 
6 Train Loss: 54.013 | Train Acc: 73.660 
7 Train Loss: 52.601 | Train Acc: 74.912 
8 Train Loss: 48.876 | Train Acc: 76.844 
9 Train Loss: 48.250 | Train Acc: 77.469 
10 Train Loss: 48.317 | Train Acc: 78.422 
11 Train Loss: 51.537 | Train Acc: 76.626 
12 Train Loss: 48.715 | Train Acc: 76.517 
13 Train Loss: 44.791 | Train Acc: 79.293 
14 Train Loss: 46.161 | Train Acc: 78.531 
15 Train Loss: 44.438 | Train Acc: 80.082 
16 Train Loss: 40.478 | Train Acc: 82.340 
17 Train Loss: 44.080 | Train Acc: 79.293 
18 Train Loss: 40.487 | Train Acc: 81.442 
19 Train Loss: 43.312 | Train Acc: 80.163 
20 Train Loss: 38.200 | Train Acc: 83.347 
21 Train Loss: 34.702 | Train Acc: 85.741 
22 Train Loss: 34.246 | Train Acc: 85.660 
23 Train Loss: 32.932 | Train Acc: 86.503 
24 Train Loss: 31.739 | Train Acc: 87.374 
25 Train Loss: 32.051 | Train Acc: 86.966 
26 Train Loss: 32.434 | Train Acc: 86.259 
27 Train Loss: 31.867 | Train Acc: 87.429 
28 Train Loss: 30.093 | Train Acc: 88.190 
29 Train Loss: 29.596 | Train Acc: 88.463 
30 Train Loss: 29.590 | Train Acc: 87.810 
31 Train Loss: 28.535 | Train Acc: 88.707 
32 Train Loss: 28.952 | Train Acc: 88.490 
33 Train Loss: 27.938 | Train Acc: 89.170 
34 Train Loss: 28.353 | Train Acc: 88.408 
35 Train Loss: 26.752 | Train Acc: 89.660 
36 Train Loss: 27.225 | Train Acc: 89.197 
37 Train Loss: 25.580 | Train Acc: 89.878 
38 Train Loss: 26.372 | Train Acc: 89.660 
39 Train Loss: 26.718 | Train Acc: 89.034 
40 Train Loss: 23.198 | Train Acc: 91.646 
41 Train Loss: 24.164 | Train Acc: 90.776 
42 Train Loss: 23.925 | Train Acc: 90.884 
43 Train Loss: 22.737 | Train Acc: 91.619 
44 Train Loss: 22.910 | Train Acc: 91.646 
45 Train Loss: 22.817 | Train Acc: 91.429 
46 Train Loss: 22.845 | Train Acc: 91.429 
47 Train Loss: 22.172 | Train Acc: 91.728 
48 Train Loss: 22.108 | Train Acc: 91.374 
49 Train Loss: 21.723 | Train Acc: 92.082 
50 Train Loss: 21.119 | Train Acc: 92.544 
51 Train Loss: 22.257 | Train Acc: 91.510 
52 Train Loss: 22.165 | Train Acc: 91.429 
53 Train Loss: 21.855 | Train Acc: 91.728 
54 Train Loss: 20.728 | Train Acc: 92.571 
55 Train Loss: 21.170 | Train Acc: 92.299 
56 Train Loss: 20.752 | Train Acc: 92.463 
57 Train Loss: 21.029 | Train Acc: 92.354 
58 Train Loss: 20.474 | Train Acc: 92.571 
59 Train Loss: 20.118 | Train Acc: 93.252 
60 Train Loss: 19.567 | Train Acc: 93.306 
61 Train Loss: 19.697 | Train Acc: 93.224 
62 Train Loss: 19.584 | Train Acc: 93.279 
63 Train Loss: 19.351 | Train Acc: 93.361 
64 Train Loss: 19.313 | Train Acc: 93.252 
65 Train Loss: 19.291 | Train Acc: 93.361 
66 Train Loss: 19.390 | Train Acc: 93.143 
67 Train Loss: 19.174 | Train Acc: 93.306 
68 Train Loss: 19.203 | Train Acc: 93.170 
69 Train Loss: 19.213 | Train Acc: 93.333 
70 Train Loss: 19.458 | Train Acc: 92.952 
71 Train Loss: 18.965 | Train Acc: 93.469 
72 Train Loss: 18.785 | Train Acc: 93.769 
73 Train Loss: 18.954 | Train Acc: 93.660 
74 Train Loss: 18.722 | Train Acc: 93.605 
75 Train Loss: 18.569 | Train Acc: 93.769 
76 Train Loss: 18.578 | Train Acc: 93.850 
77 Train Loss: 18.475 | Train Acc: 93.796 
78 Train Loss: 18.678 | Train Acc: 93.850 
79 Train Loss: 18.454 | Train Acc: 93.741 
80 Train Loss: 18.008 | Train Acc: 94.014 
81 Train Loss: 18.014 | Train Acc: 93.850 
82 Train Loss: 18.006 | Train Acc: 93.959 
83 Train Loss: 17.951 | Train Acc: 94.122 
84 Train Loss: 17.957 | Train Acc: 94.068 
85 Train Loss: 17.876 | Train Acc: 94.095 
86 Train Loss: 17.872 | Train Acc: 94.122 
87 Train Loss: 17.853 | Train Acc: 94.095 
88 Train Loss: 17.796 | Train Acc: 94.068 
89 Train Loss: 17.877 | Train Acc: 94.150 
90 Train Loss: 18.022 | Train Acc: 93.905 
91 Train Loss: 17.841 | Train Acc: 94.204 
92 Train Loss: 17.773 | Train Acc: 93.986 
93 Train Loss: 17.704 | Train Acc: 94.231 
94 Train Loss: 17.656 | Train Acc: 94.313 
95 Train Loss: 17.787 | Train Acc: 94.150 
96 Train Loss: 17.687 | Train Acc: 94.177 
97 Train Loss: 17.638 | Train Acc: 94.231 
98 Train Loss: 17.570 | Train Acc: 94.177 
99 Train Loss: 17.550 | Train Acc: 94.286 
CNN trained successfully...
image_next_flat.shape :  torch.Size([3675, 12544])
Time Taken by Kmeans is  0.7344529628753662
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 1, 1: 0}
Image Statistics before MLP : L R :  1225 2450
expectedMlpLabels.shape :  torch.Size([3675])
0 Loss: 90.324 | Acc: 65.667
1 Loss: 69.349 | Acc: 74.083
2 Loss: 58.565 | Acc: 80.000
3 Loss: 51.310 | Acc: 83.639
4 Loss: 43.137 | Acc: 85.917
5 Loss: 37.974 | Acc: 87.417
6 Loss: 31.831 | Acc: 89.889
7 Loss: 24.748 | Acc: 91.861
8 Loss: 24.215 | Acc: 92.083
9 Loss: 17.707 | Acc: 94.417
10 Loss: 9.721 | Acc: 97.528
11 Loss: 6.662 | Acc: 98.167
12 Loss: 5.860 | Acc: 98.667
13 Loss: 5.629 | Acc: 98.500
14 Loss: 4.423 | Acc: 98.944
15 Loss: 3.039 | Acc: 99.361
16 Loss: 2.806 | Acc: 99.472
17 Loss: 3.461 | Acc: 99.167
18 Loss: 2.043 | Acc: 99.583
19 Loss: 1.631 | Acc: 99.639
20 Loss: 1.344 | Acc: 99.667
21 Loss: 1.271 | Acc: 99.694
22 Loss: 1.174 | Acc: 99.750
23 Loss: 1.272 | Acc: 99.778
24 Loss: 0.932 | Acc: 99.806
25 Loss: 0.917 | Acc: 99.778
26 Loss: 0.864 | Acc: 99.778
27 Loss: 0.549 | Acc: 99.972
28 Loss: 0.679 | Acc: 99.917
29 Loss: 0.754 | Acc: 99.778
30 Loss: 0.699 | Acc: 99.806
31 Loss: 0.643 | Acc: 99.889
32 Loss: 0.513 | Acc: 99.917
33 Loss: 0.625 | Acc: 99.917
34 Loss: 0.420 | Acc: 99.917
35 Loss: 0.371 | Acc: 99.944
36 Loss: 0.382 | Acc: 99.972
37 Loss: 0.398 | Acc: 99.944
38 Loss: 0.267 | Acc: 100.000
39 Loss: 0.450 | Acc: 99.889
40 Loss: 0.350 | Acc: 99.944
41 Loss: 0.436 | Acc: 99.889
42 Loss: 0.211 | Acc: 99.972
43 Loss: 0.302 | Acc: 99.972
44 Loss: 0.341 | Acc: 99.972
45 Loss: 0.258 | Acc: 99.972
46 Loss: 0.224 | Acc: 100.000
47 Loss: 0.263 | Acc: 99.972
48 Loss: 0.270 | Acc: 99.972
49 Loss: 0.304 | Acc: 99.944
50 Loss: 0.259 | Acc: 99.972
51 Loss: 0.262 | Acc: 99.944
52 Loss: 0.157 | Acc: 100.000
53 Loss: 0.299 | Acc: 99.972
54 Loss: 0.188 | Acc: 99.972
55 Loss: 0.134 | Acc: 100.000
56 Loss: 0.195 | Acc: 99.972
57 Loss: 0.480 | Acc: 99.944
58 Loss: 0.285 | Acc: 99.972
59 Loss: 0.201 | Acc: 100.000
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([1225, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1225])
rTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2450])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([0, 3, 32, 32])   rValDict[label].shape:  torch.Size([0])
# of Left images:  1225.0
# of Right images:  2450.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [0, 1225, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [2450, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 9
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 1
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 9
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 1
nodeId:  30 , imgTensorShape :  torch.Size([1225, 3, 32, 32])
nodeId: 30 ,  parentId: 20 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1225
nodeId:  31 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 31 ,  parentId: 20 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 2450
Running nodeId:  21
0 Train Loss: 46.556 | Train Acc: 77.741 
1 Train Loss: 31.199 | Train Acc: 87.510 
2 Train Loss: 24.846 | Train Acc: 89.918 
3 Train Loss: 27.568 | Train Acc: 88.939 
4 Train Loss: 22.567 | Train Acc: 91.116 
5 Train Loss: 19.014 | Train Acc: 92.762 
6 Train Loss: 18.624 | Train Acc: 92.762 
7 Train Loss: 14.987 | Train Acc: 94.082 
8 Train Loss: 12.818 | Train Acc: 95.184 
9 Train Loss: 12.121 | Train Acc: 95.388 
10 Train Loss: 13.271 | Train Acc: 94.871 
11 Train Loss: 11.375 | Train Acc: 95.646 
12 Train Loss: 10.059 | Train Acc: 96.327 
13 Train Loss: 9.966 | Train Acc: 96.435 
14 Train Loss: 10.656 | Train Acc: 95.633 
15 Train Loss: 9.719 | Train Acc: 96.422 
16 Train Loss: 8.926 | Train Acc: 96.558 
17 Train Loss: 7.784 | Train Acc: 97.034 
18 Train Loss: 9.954 | Train Acc: 96.313 
19 Train Loss: 6.359 | Train Acc: 97.823 
20 Train Loss: 5.518 | Train Acc: 98.082 
21 Train Loss: 5.659 | Train Acc: 97.878 
22 Train Loss: 5.169 | Train Acc: 98.327 
23 Train Loss: 5.828 | Train Acc: 97.932 
24 Train Loss: 4.937 | Train Acc: 98.381 
25 Train Loss: 5.153 | Train Acc: 98.286 
26 Train Loss: 4.945 | Train Acc: 98.367 
27 Train Loss: 4.558 | Train Acc: 98.612 
28 Train Loss: 4.419 | Train Acc: 98.571 
29 Train Loss: 4.290 | Train Acc: 98.694 
30 Train Loss: 4.250 | Train Acc: 98.735 
31 Train Loss: 4.522 | Train Acc: 98.707 
32 Train Loss: 4.339 | Train Acc: 98.707 
33 Train Loss: 3.844 | Train Acc: 99.034 
34 Train Loss: 3.816 | Train Acc: 98.952 
35 Train Loss: 3.893 | Train Acc: 98.925 
36 Train Loss: 3.523 | Train Acc: 99.170 
37 Train Loss: 3.493 | Train Acc: 99.048 
38 Train Loss: 3.346 | Train Acc: 99.265 
39 Train Loss: 3.280 | Train Acc: 99.211 
40 Train Loss: 2.951 | Train Acc: 99.252 
41 Train Loss: 2.860 | Train Acc: 99.483 
42 Train Loss: 2.727 | Train Acc: 99.401 
43 Train Loss: 2.737 | Train Acc: 99.401 
44 Train Loss: 2.720 | Train Acc: 99.456 
45 Train Loss: 2.634 | Train Acc: 99.537 
46 Train Loss: 2.580 | Train Acc: 99.510 
47 Train Loss: 2.532 | Train Acc: 99.510 
48 Train Loss: 2.655 | Train Acc: 99.456 
49 Train Loss: 2.483 | Train Acc: 99.578 
50 Train Loss: 2.430 | Train Acc: 99.633 
51 Train Loss: 2.416 | Train Acc: 99.578 
52 Train Loss: 2.701 | Train Acc: 99.483 
53 Train Loss: 2.314 | Train Acc: 99.660 
54 Train Loss: 2.316 | Train Acc: 99.633 
55 Train Loss: 2.183 | Train Acc: 99.687 
56 Train Loss: 2.248 | Train Acc: 99.633 
57 Train Loss: 2.155 | Train Acc: 99.728 
58 Train Loss: 2.071 | Train Acc: 99.673 
59 Train Loss: 2.069 | Train Acc: 99.673 
60 Train Loss: 1.951 | Train Acc: 99.810 
61 Train Loss: 1.900 | Train Acc: 99.850 
62 Train Loss: 1.886 | Train Acc: 99.837 
63 Train Loss: 1.858 | Train Acc: 99.782 
64 Train Loss: 1.859 | Train Acc: 99.810 
65 Train Loss: 1.847 | Train Acc: 99.782 
66 Train Loss: 1.861 | Train Acc: 99.769 
67 Train Loss: 1.822 | Train Acc: 99.864 
68 Train Loss: 1.837 | Train Acc: 99.823 
69 Train Loss: 1.793 | Train Acc: 99.850 
70 Train Loss: 1.774 | Train Acc: 99.796 
71 Train Loss: 1.744 | Train Acc: 99.850 
72 Train Loss: 1.790 | Train Acc: 99.796 
73 Train Loss: 1.745 | Train Acc: 99.878 
74 Train Loss: 1.749 | Train Acc: 99.796 
75 Train Loss: 1.887 | Train Acc: 99.755 
76 Train Loss: 1.877 | Train Acc: 99.769 
77 Train Loss: 1.785 | Train Acc: 99.782 
78 Train Loss: 1.740 | Train Acc: 99.823 
79 Train Loss: 1.657 | Train Acc: 99.878 
80 Train Loss: 1.588 | Train Acc: 99.878 
81 Train Loss: 1.577 | Train Acc: 99.878 
82 Train Loss: 1.604 | Train Acc: 99.891 
83 Train Loss: 1.572 | Train Acc: 99.905 
84 Train Loss: 1.582 | Train Acc: 99.878 
85 Train Loss: 1.580 | Train Acc: 99.891 
86 Train Loss: 1.593 | Train Acc: 99.864 
87 Train Loss: 1.534 | Train Acc: 99.891 
88 Train Loss: 1.585 | Train Acc: 99.891 
89 Train Loss: 1.564 | Train Acc: 99.850 
90 Train Loss: 1.583 | Train Acc: 99.905 
91 Train Loss: 1.550 | Train Acc: 99.891 
92 Train Loss: 1.554 | Train Acc: 99.905 
93 Train Loss: 1.532 | Train Acc: 99.918 
94 Train Loss: 1.510 | Train Acc: 99.891 
95 Train Loss: 1.505 | Train Acc: 99.891 
96 Train Loss: 1.513 | Train Acc: 99.918 
97 Train Loss: 1.502 | Train Acc: 99.905 
98 Train Loss: 1.539 | Train Acc: 99.918 
99 Train Loss: 1.490 | Train Acc: 99.918 
CNN trained successfully...
image_next_flat.shape :  torch.Size([7350, 12544])
Time Taken by Kmeans is  1.0473992824554443
Kmeans completed successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics before MLP : L R :  2450 4900
expectedMlpLabels.shape :  torch.Size([7350])
0 Loss: 37.958 | Acc: 87.708
1 Loss: 21.388 | Acc: 93.417
2 Loss: 18.479 | Acc: 94.542
3 Loss: 16.212 | Acc: 95.042
4 Loss: 14.343 | Acc: 95.486
5 Loss: 12.063 | Acc: 96.222
6 Loss: 9.975 | Acc: 96.972
7 Loss: 8.544 | Acc: 97.444
8 Loss: 6.914 | Acc: 98.083
9 Loss: 6.702 | Acc: 97.833
10 Loss: 3.967 | Acc: 98.861
11 Loss: 2.403 | Acc: 99.292
12 Loss: 1.585 | Acc: 99.556
13 Loss: 1.402 | Acc: 99.694
14 Loss: 2.658 | Acc: 99.236
15 Loss: 1.145 | Acc: 99.694
16 Loss: 0.772 | Acc: 99.750
17 Loss: 0.835 | Acc: 99.847
18 Loss: 0.627 | Acc: 99.875
19 Loss: 1.279 | Acc: 99.667
20 Loss: 0.459 | Acc: 99.944
21 Loss: 0.533 | Acc: 99.847
22 Loss: 0.278 | Acc: 99.958
23 Loss: 0.246 | Acc: 99.958
24 Loss: 0.246 | Acc: 99.944
25 Loss: 0.174 | Acc: 99.986
26 Loss: 0.091 | Acc: 99.986
27 Loss: 0.352 | Acc: 99.917
28 Loss: 0.110 | Acc: 99.986
29 Loss: 0.198 | Acc: 99.958
30 Loss: 0.196 | Acc: 99.944
31 Loss: 0.173 | Acc: 99.972
32 Loss: 0.059 | Acc: 100.000
33 Loss: 0.073 | Acc: 100.000
34 Loss: 0.064 | Acc: 100.000
35 Loss: 0.164 | Acc: 99.972
36 Loss: 0.070 | Acc: 100.000
37 Loss: 0.146 | Acc: 99.958
38 Loss: 0.087 | Acc: 99.986
39 Loss: 0.036 | Acc: 100.000
40 Loss: 0.071 | Acc: 99.986
41 Loss: 0.057 | Acc: 100.000
42 Loss: 0.135 | Acc: 99.972
43 Loss: 0.053 | Acc: 100.000
44 Loss: 0.034 | Acc: 100.000
45 Loss: 0.057 | Acc: 99.986
46 Loss: 0.040 | Acc: 100.000
47 Loss: 0.041 | Acc: 100.000
48 Loss: 0.028 | Acc: 100.000
49 Loss: 0.071 | Acc: 99.986
50 Loss: 0.102 | Acc: 99.986
51 Loss: 0.040 | Acc: 100.000
52 Loss: 0.036 | Acc: 100.000
53 Loss: 0.067 | Acc: 99.986
54 Loss: 0.044 | Acc: 100.000
55 Loss: 0.040 | Acc: 100.000
56 Loss: 0.030 | Acc: 100.000
57 Loss: 0.023 | Acc: 100.000
58 Loss: 0.032 | Acc: 100.000
59 Loss: 0.059 | Acc: 99.986
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([2450, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2450])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([0, 3, 32, 32])   lValDict[label].shape:  torch.Size([0])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  2450.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.4444444444444445
lclasses:  [2450, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 2
nodeId:  32 , imgTensorShape :  torch.Size([2450, 3, 32, 32])
nodeId: 32 ,  parentId: 21 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 2450
nodeId:  33 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 33 ,  parentId: 21 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  22
Running nodeId:  23
Running nodeId:  24
Running nodeId:  25
Running nodeId:  26
Running nodeId:  27
Running nodeId:  28
Running nodeId:  29
Running nodeId:  30
Running nodeId:  31
Running nodeId:  32
Running nodeId:  33
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 61.210
Split Acc: 87.130
lTrainDict[data].shape:  torch.Size([4931, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4931])
rTrainDict[data].shape:  torch.Size([5069, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([5069])
# of Left images:  4931.0
# of Right images:  5069.0
giniRightRatio:  0.8425833577514108
giniLeftRatio:  0.8393246390536184
impurityDrop:  0.8394133554040417
giniGain:  0.060586644595958306
lclasses:  [915, 951, 592, 146, 155, 107, 102, 99, 947, 917]
rclasses:  [85, 49, 408, 854, 845, 893, 898, 901, 53, 83]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([4931, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4931
nodeId:  3 , imgTensorShape :  torch.Size([5069, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5069
Nodes sizes =  5 5
Node 2 Acc: 66.214
Split Acc: 79.213
lTrainDict[data].shape:  torch.Size([2438, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2438])
rTrainDict[data].shape:  torch.Size([2493, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2493])
# of Left images:  2438.0
# of Right images:  2493.0
giniRightRatio:  0.7919387280776065
giniLeftRatio:  0.7393592429411
impurityDrop:  0.7405192396047614
giniGain:  0.09880539944885702
lclasses:  [803, 111, 100, 52, 58, 21, 22, 37, 854, 380]
rclasses:  [112, 840, 492, 94, 97, 86, 80, 62, 93, 537]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([2438, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2438
nodeId:  5 , imgTensorShape :  torch.Size([2493, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2493
Nodes sizes =  3 3
Node 3 Acc: 56.717
Split Acc: 74.433
lTrainDict[data].shape:  torch.Size([2569, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2569])
rTrainDict[data].shape:  torch.Size([2500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2500])
# of Left images:  2569.0
# of Right images:  2500.0
giniRightRatio:  0.7859052799999999
giniLeftRatio:  0.782947443096803
impurityDrop:  0.7828658067982747
giniGain:  0.059717550953136134
lclasses:  [38, 23, 159, 605, 185, 611, 72, 789, 34, 53]
rclasses:  [47, 26, 249, 249, 660, 282, 826, 112, 19, 30]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([2569, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2569
nodeId:  7 , imgTensorShape :  torch.Size([2500, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2500
Nodes sizes =  3 3
Node 4 Acc: 68.499
Split Acc: 77.974
lTrainDict[data].shape:  torch.Size([1037, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1037])
rTrainDict[data].shape:  torch.Size([1401, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1401])
# of Left images:  1037.0
# of Right images:  1401.0
giniRightRatio:  0.6192038826146921
giniLeftRatio:  0.7098939991760969
impurityDrop:  0.6863313992986155
giniGain:  0.05302784364248447
lclasses:  [443, 61, 55, 22, 22, 9, 10, 21, 75, 319]
rclasses:  [360, 50, 45, 30, 36, 12, 12, 16, 779, 61]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([1037, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1037
nodeId:  9 , imgTensorShape :  torch.Size([1401, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1401
Nodes sizes =  2 2
Node 5 Acc: 62.174
Split Acc: 73.446
lTrainDict[data].shape:  torch.Size([259, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([259])
rTrainDict[data].shape:  torch.Size([2234, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2234])
# of Left images:  259.0
# of Right images:  2234.0
giniRightRatio:  0.7868234792484345
giniLeftRatio:  0.4707741387278067
impurityDrop:  0.7501821277735722
giniGain:  0.041756600304034275
lclasses:  [7, 32, 6, 5, 2, 3, 4, 8, 7, 185]
rclasses:  [105, 808, 486, 89, 95, 83, 76, 54, 86, 352]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([259, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 259
nodeId:  11 , imgTensorShape :  torch.Size([2234, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 20 ,  rchildId: 21 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 2234
Nodes sizes =  1 3
Node 6 Acc: 54.146
Split Acc: 62.515
lTrainDict[data].shape:  torch.Size([1073, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1073])
rTrainDict[data].shape:  torch.Size([1496, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1496])
# of Left images:  1073.0
# of Right images:  1496.0
giniRightRatio:  0.789683362406703
giniLeftRatio:  0.7208504258991131
impurityDrop:  0.7403132147645614
giniGain:  0.04263422833224162
lclasses:  [17, 3, 60, 118, 70, 330, 13, 435, 11, 16]
rclasses:  [21, 20, 99, 487, 115, 281, 59, 354, 23, 37]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([1073, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: 22 ,  rchildId: 23 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1073
nodeId:  13 , imgTensorShape :  torch.Size([1496, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: 24 ,  rchildId: 25 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1496
Nodes sizes =  2 2
Node 7 Acc: 57.720
Split Acc: 65.560
lTrainDict[data].shape:  torch.Size([1555, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1555])
rTrainDict[data].shape:  torch.Size([945, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([945])
# of Left images:  1555.0
# of Right images:  945.0
giniRightRatio:  0.782504409171076
giniLeftRatio:  0.693812512277582
impurityDrop:  0.6365616581981837
giniGain:  0.14934362180181626
lclasses:  [33, 20, 142, 128, 319, 73, 770, 45, 11, 14]
rclasses:  [14, 6, 107, 121, 341, 209, 56, 67, 8, 16]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([1555, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: 26 ,  rchildId: 27 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1555
nodeId:  15 , imgTensorShape :  torch.Size([945, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 28 ,  rchildId: 29 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 945
Nodes sizes =  2 2
Node 8 Acc: 66.056
Split Acc: 67.020
lTrainDict[data].shape:  torch.Size([424, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([424])
rTrainDict[data].shape:  torch.Size([613, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([613])
# of Left images:  424.0
# of Right images:  613.0
giniRightRatio:  0.5317947994645646
giniLeftRatio:  0.529314257742969
impurityDrop:  0.5300790577191217
giniGain:  0.17981494145697519
lclasses:  [32, 46, 9, 8, 3, 3, 7, 9, 23, 284]
rclasses:  [411, 15, 46, 14, 19, 6, 3, 12, 52, 35]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([424, 3, 32, 32])
nodeId: 16 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 424
nodeId:  17 , imgTensorShape :  torch.Size([613, 3, 32, 32])
nodeId: 17 ,  parentId: 8 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 613
Nodes sizes =  1 1
Node 9 Acc: 68.166
Split Acc: 70.021
lTrainDict[data].shape:  torch.Size([393, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([393])
rTrainDict[data].shape:  torch.Size([1008, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1008])
# of Left images:  393.0
# of Right images:  1008.0
giniRightRatio:  0.4557331034265559
giniLeftRatio:  0.5741701144066975
impurityDrop:  0.5019094380646468
giniGain:  0.11729444455004523
lclasses:  [249, 12, 27, 11, 15, 5, 3, 9, 47, 15]
rclasses:  [111, 38, 18, 19, 21, 7, 9, 7, 732, 46]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([393, 3, 32, 32])
nodeId: 18 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 393
nodeId:  19 , imgTensorShape :  torch.Size([1008, 3, 32, 32])
nodeId: 19 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 1008
Nodes sizes =  1 1
Node 10 Acc: 71.429
Node 11 Acc: 59.758
Split Acc: 69.338
lTrainDict[data].shape:  torch.Size([886, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([886])
rTrainDict[data].shape:  torch.Size([1348, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1348])
# of Left images:  886.0
# of Right images:  1348.0
giniRightRatio:  0.7994214970634592
giniLeftRatio:  0.5907444114364914
impurityDrop:  0.6622643028012236
giniGain:  0.12455917644721093
lclasses:  [24, 499, 9, 18, 5, 7, 16, 10, 34, 264]
rclasses:  [81, 309, 477, 71, 90, 76, 60, 44, 52, 88]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  20 , imgTensorShape :  torch.Size([886, 3, 32, 32])
nodeId: 20 ,  parentId: 11 ,  level: 4 ,  lchildId: 30 ,  rchildId: 31 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 886
nodeId:  21 , imgTensorShape :  torch.Size([1348, 3, 32, 32])
nodeId: 21 ,  parentId: 11 ,  level: 4 ,  lchildId: 32 ,  rchildId: 33 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1348
Nodes sizes =  2 2
Node 12 Acc: 60.671
Split Acc: 62.349
lTrainDict[data].shape:  torch.Size([539, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([539])
rTrainDict[data].shape:  torch.Size([534, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([534])
# of Left images:  539.0
# of Right images:  534.0
giniRightRatio:  0.6512505435621204
giniLeftRatio:  0.48733826470375635
impurityDrop:  0.4858035055384159
giniGain:  0.2350469203606972
lclasses:  [9, 1, 30, 15, 49, 40, 5, 379, 4, 7]
rclasses:  [8, 2, 30, 103, 21, 290, 8, 56, 7, 9]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  22 , imgTensorShape :  torch.Size([539, 3, 32, 32])
nodeId: 22 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 539
nodeId:  23 , imgTensorShape :  torch.Size([534, 3, 32, 32])
nodeId: 23 ,  parentId: 12 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 534
Nodes sizes =  1 1
Node 13 Acc: 47.393
Split Acc: 48.864
lTrainDict[data].shape:  torch.Size([438, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([438])
rTrainDict[data].shape:  torch.Size([1058, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1058])
# of Left images:  438.0
# of Right images:  1058.0
giniRightRatio:  0.7466132553843076
giniLeftRatio:  0.5648026521548758
impurityDrop:  0.671345727771367
giniGain:  0.11833763463533598
lclasses:  [5, 4, 16, 37, 31, 41, 6, 281, 4, 13]
rclasses:  [16, 16, 83, 450, 84, 240, 53, 73, 19, 24]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  24 , imgTensorShape :  torch.Size([438, 3, 32, 32])
nodeId: 24 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 438
nodeId:  25 , imgTensorShape :  torch.Size([1058, 3, 32, 32])
nodeId: 25 ,  parentId: 13 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 1058
Nodes sizes =  1 1
Node 14 Acc: 59.357
Split Acc: 61.093
lTrainDict[data].shape:  torch.Size([427, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([427])
rTrainDict[data].shape:  torch.Size([1128, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1128])
# of Left images:  427.0
# of Right images:  1128.0
giniRightRatio:  0.552567463910266
giniLeftRatio:  0.7043640890916968
impurityDrop:  0.6100294842582012
giniGain:  0.08378302801938076
lclasses:  [18, 7, 56, 41, 215, 25, 35, 25, 2, 3]
rclasses:  [15, 13, 86, 87, 104, 48, 735, 20, 9, 11]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  26 , imgTensorShape :  torch.Size([427, 3, 32, 32])
nodeId: 26 ,  parentId: 14 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 427
nodeId:  27 , imgTensorShape :  torch.Size([1128, 3, 32, 32])
nodeId: 27 ,  parentId: 14 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1128
Nodes sizes =  1 1
Node 15 Acc: 48.360
Split Acc: 48.889
lTrainDict[data].shape:  torch.Size([423, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([423])
rTrainDict[data].shape:  torch.Size([522, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([522])
# of Left images:  423.0
# of Right images:  522.0
giniRightRatio:  0.6426212181265688
giniLeftRatio:  0.7774927485203629
impurityDrop:  0.7519136651698157
giniGain:  0.030590744001260273
lclasses:  [6, 4, 40, 75, 45, 166, 37, 39, 4, 7]
rclasses:  [8, 2, 67, 46, 296, 43, 19, 28, 4, 9]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  28 , imgTensorShape :  torch.Size([423, 3, 32, 32])
nodeId: 28 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 423
nodeId:  29 , imgTensorShape :  torch.Size([522, 3, 32, 32])
nodeId: 29 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 522
Nodes sizes =  1 1
Node 16 Acc: 66.981
Node 17 Acc: 67.047
Node 18 Acc: 63.359
Node 19 Acc: 72.619
Node 20 Acc: 66.930
Split Acc: 67.946
lTrainDict[data].shape:  torch.Size([299, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([299])
rTrainDict[data].shape:  torch.Size([587, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([587])
# of Left images:  299.0
# of Right images:  587.0
giniRightRatio:  0.4362609520879708
giniLeftRatio:  0.6101721457254393
impurityDrop:  0.5248460404995603
giniGain:  0.06589837093693107
lclasses:  [10, 69, 4, 10, 2, 5, 6, 9, 12, 172]
rclasses:  [14, 430, 5, 8, 3, 2, 10, 1, 22, 92]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  30 , imgTensorShape :  torch.Size([299, 3, 32, 32])
nodeId: 30 ,  parentId: 20 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 299
nodeId:  31 , imgTensorShape :  torch.Size([587, 3, 32, 32])
nodeId: 31 ,  parentId: 20 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 587
Nodes sizes =  1 1
Node 21 Acc: 55.415
Split Acc: 55.490
lTrainDict[data].shape:  torch.Size([427, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([427])
rTrainDict[data].shape:  torch.Size([921, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([921])
# of Left images:  427.0
# of Right images:  921.0
giniRightRatio:  0.713276061873925
giniLeftRatio:  0.5357348529306912
impurityDrop:  0.6309632538188101
giniGain:  0.1684582432446491
lclasses:  [21, 283, 12, 7, 3, 6, 4, 7, 30, 54]
rclasses:  [60, 26, 465, 64, 87, 70, 56, 37, 22, 34]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  32 , imgTensorShape :  torch.Size([427, 3, 32, 32])
nodeId: 32 ,  parentId: 21 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 427
nodeId:  33 , imgTensorShape :  torch.Size([921, 3, 32, 32])
nodeId: 33 ,  parentId: 21 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 921
Nodes sizes =  1 1
Node 22 Acc: 70.315
Node 23 Acc: 54.307
Node 24 Acc: 64.155
Node 25 Acc: 42.533
Node 26 Acc: 50.351
Node 27 Acc: 65.160
Node 28 Acc: 39.243
Node 29 Acc: 56.705
Node 30 Acc: 57.525
Node 31 Acc: 73.254
Node 32 Acc: 66.276
Node 33 Acc: 50.489
[[660  35  60  16  26  14  15  14 111  49]
 [ 27 713  26  16   9   6  13   5  38 147]
 [ 73  17 465  83 123  70  86  46  18  19]
 [ 25  15  64 450  87 178  87  52  19  23]
 [ 34   6  87  84 511  66 104  80  21   7]
 [ 11   8  70 240  68 456  48  81   7  11]
 [  6  14  56  53  54  45 735  11   9  17]
 [ 21   8  37  73  53  95  20 660   7  26]
 [ 99  52  22  19   6  11   9   8 732  42]
 [ 50 146  34  24  12  16  11  20  46 641]]

Final Acc: 60.230

Level 0 Acc: 61.210
Level 1 Acc: 61.400
Level 2 Acc: 60.540
Level 3 Acc: 59.000
Level 4 Acc: 60.130
Level 5 Acc: 60.230

                                                                                                           1                                                                                                                         
                                                                                                                    
                                                   3                                                                                                               2                                                                 
                                                                                                                                 
                       6                                                       7                                                       4                                         5                                                   
                                                                                                          
         12                          13                          14                          15                          8                           9                    10                                 11                      
                                                                                                              
  22            23            24            25            26            27            28            29            16            17            18            19                                 20                          21        
                                                                                                                                                                                                       
                                                                                                                                                                                        30            31            32            33 

                                                                                           -1                                                                                                      
                                                                                                  
                                           -1                                                                                              -1                                                      
                                                                                                             
                   -1                                              -1                                              -1                                  -1                                          
                                                                                         
       -1                      -1                      -1                      -1                      -1                      -1                9                             -1                  
                                                                                            
 7           5           7           3           4           6           5           4           9           0           0           8                             -1                      -1      
                                                                                                                                                                         
                                                                                                                                                             9           1           1           2 

                                                                                                                         49000                                                                                                                                         
                                                                                                                                      
                                                         24500                                                                                                                           24500                                                                         
                                                                                                                                                     
                         12250                                                           12250                                                           12250                                           12250                                                         
                                                                                                                           
          4900                            7350                            7350                            4900                            4900                            7350                    1225                                   11025                         
                                                                                                                                
  2450            2450            2450            4900            2450            4900            2450            2450            2450            2450            2450            4900                                    3675                            7350         
                                                                                                                                                                                                                                     
                                                                                                                                                                                                                  1225            2450            2450            4900 

                                                                                                               {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                                                                                                  
                                                                                                                                                                          
                                                     {3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900}                                                                                                                   {0: 4900, 1: 4900, 2: 4900, 8: 4900, 9: 4900}                                                                         
                                                                                                                                                                                             
                      {3: 4900, 5: 2450, 7: 4900}                                                     {4: 4900, 5: 2450, 6: 4900}                                                     {0: 4900, 8: 4900, 9: 2450}                                 {1: 4900, 2: 4900, 9: 2450}                                                              
                                                                                                                                                             
       {5: 2450, 7: 2450}                      {3: 4900, 7: 2450}                      {4: 2450, 6: 4900}                      {4: 2450, 5: 2450}                      {0: 2450, 9: 2450}                      {0: 2450, 8: 4900}                {9: 1225}                                {1: 4900, 2: 4900, 9: 1225}                      
                                                                                                                                                                    
 {7: 2450}           {5: 2450}           {7: 2450}           {3: 4900}           {4: 2450}           {6: 4900}           {5: 2450}           {4: 2450}           {9: 2450}           {0: 2450}           {0: 2450}           {8: 4900}                                     {1: 2450, 9: 1225}                      {1: 2450, 2: 4900}      
                                                                                                                                                                                                                                                                                                 
                                                                                                                                                                                                                                                                     {9: 1225}           {1: 2450}           {1: 2450}           {2: 4900} 

                                                                                                           87.13                                                                                                                         
                                                                                                                      
                                           74.43282698757152                                                                                                 79.21314135063882                                                           
                                                                                                                                     
               62.51459711950175                                             65.56                                               77.97374897456932                         73.44564781387886                                             
                                                                                                             
 62.34855545200373           48.86363636363637           61.09324758842444            48.888888888888886           67.02025072324011           70.02141327623126           0.0                         69.33751119068934                 
                                                                                                                 
 0.0           0.0           0.0           0.0           0.0           0.0            0.0           0.0            0.0           0.0           0.0           0.0                         67.94582392776523            55.489614243323444 
                                                                                                                                                                                                           
                                                                                                                                                                                         0.0           0.0            0.0           0.0  

                                                                                   [379, 539, 70.315]
                                                               [651, 1073, 60.671]
                                                                                  [290, 534, 54.307]
                                          [1391, 2569, 54.146]
                                                                                 [281, 438, 64.155]
                                                              [709, 1496, 47.393]
                                                                                  [450, 1058, 42.533]
                     [2875, 5069, 56.717]
                                                                                [215, 427, 50.351]
                                                            [923, 1555, 59.357]
                                                                               [735, 1128, 65.16]
                                         [1443, 2500, 57.72]
                                                                              [166, 423, 39.243]
                                                             [457, 945, 48.36]
                                                                               [296, 522, 56.705]
 [6121, 10000, 61.21]
                                                                                  [284, 424, 66.981]
                                                              [685, 1037, 66.056]
                                                                                 [411, 613, 67.047]
                                         [1670, 2438, 68.499]
                                                                                [249, 393, 63.359]
                                                             [955, 1401, 68.166]
                                                                                 [732, 1008, 72.619]
                     [3265, 4931, 66.214]
                                                              [185, 259, 71.429]
                                          [1550, 2493, 62.174]
                                                                                                     [172, 299, 57.525]
                                                                                   [593, 886, 66.93]
                                                                                                    [430, 587, 73.254]
                                                               [1335, 2234, 59.758]
                                                                                                       [283, 427, 66.276]
                                                                                    [747, 1348, 55.415]
                                                                                                        [465, 921, 50.489]

                                                                                                      0.09999999999999987                                                                                                                       
                                                                                                                           
                                            0.16000000000000014                                                                                                 0.16000000000000014                                                             
                                                                                                                                     
               0.1585185185185185                                         0.22333333333333327                                      0.1585185185185185                          0.11325102880658444                                              
                                                                                                                
        0.5                   0.4444444444444445            0.4444444444444445                  0.5                         0.5                   0.4444444444444445           0.0                          0.14814814814814808                 
                                                                                                                       
 0.0           0.0            0.0           0.0             0.0           0.0            0.0           0.0           0.0           0.0            0.0           0.0                           0.4444444444444445            0.4444444444444445  
                                                                                                                                                                                                                  
                                                                                                                                                                                              0.0           0.0             0.0           0.0   

Time Taken by whole program is  2073.4293670654297
