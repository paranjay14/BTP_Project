['options.ckptDir: newDir_KM', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 16', 'options.mlpFC1: 516', 'options.mlpFC2: 16']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 177.956 | Train Acc: 37.506 
1 Train Loss: 145.234 | Train Acc: 49.384 
2 Train Loss: 136.029 | Train Acc: 52.553 
3 Train Loss: 130.495 | Train Acc: 54.624 
4 Train Loss: 126.714 | Train Acc: 55.814 
5 Train Loss: 123.980 | Train Acc: 56.949 
6 Train Loss: 121.057 | Train Acc: 57.814 
7 Train Loss: 118.400 | Train Acc: 59.047 
8 Train Loss: 115.725 | Train Acc: 59.947 
9 Train Loss: 113.133 | Train Acc: 60.778 
10 Train Loss: 110.440 | Train Acc: 61.871 
11 Train Loss: 108.610 | Train Acc: 62.447 
12 Train Loss: 106.663 | Train Acc: 63.131 
13 Train Loss: 105.405 | Train Acc: 63.439 
14 Train Loss: 103.329 | Train Acc: 64.208 
15 Train Loss: 101.570 | Train Acc: 64.833 
16 Train Loss: 100.632 | Train Acc: 65.310 
17 Train Loss: 99.249 | Train Acc: 65.859 
18 Train Loss: 97.858 | Train Acc: 66.114 
19 Train Loss: 96.561 | Train Acc: 66.716 
20 Train Loss: 93.073 | Train Acc: 68.184 
21 Train Loss: 92.450 | Train Acc: 68.184 
22 Train Loss: 91.767 | Train Acc: 68.563 
23 Train Loss: 91.453 | Train Acc: 68.465 
24 Train Loss: 90.543 | Train Acc: 68.929 
25 Train Loss: 90.315 | Train Acc: 69.082 
26 Train Loss: 90.020 | Train Acc: 69.096 
27 Train Loss: 89.560 | Train Acc: 69.296 
28 Train Loss: 88.968 | Train Acc: 69.524 
29 Train Loss: 88.610 | Train Acc: 69.608 
30 Train Loss: 88.114 | Train Acc: 69.902 
31 Train Loss: 87.722 | Train Acc: 70.104 
32 Train Loss: 87.169 | Train Acc: 70.116 
33 Train Loss: 86.493 | Train Acc: 70.280 
34 Train Loss: 86.249 | Train Acc: 70.476 
35 Train Loss: 85.617 | Train Acc: 70.753 
36 Train Loss: 85.302 | Train Acc: 70.957 
37 Train Loss: 84.776 | Train Acc: 71.186 
38 Train Loss: 84.499 | Train Acc: 71.284 
39 Train Loss: 83.934 | Train Acc: 71.312 
40 Train Loss: 82.320 | Train Acc: 71.996 
41 Train Loss: 81.999 | Train Acc: 72.224 
42 Train Loss: 81.669 | Train Acc: 72.347 
43 Train Loss: 81.580 | Train Acc: 72.437 
44 Train Loss: 81.344 | Train Acc: 72.520 
45 Train Loss: 81.283 | Train Acc: 72.429 
46 Train Loss: 81.186 | Train Acc: 72.631 
47 Train Loss: 81.020 | Train Acc: 72.508 
48 Train Loss: 80.742 | Train Acc: 72.682 
49 Train Loss: 80.627 | Train Acc: 72.751 
50 Train Loss: 80.462 | Train Acc: 72.855 
51 Train Loss: 80.187 | Train Acc: 73.000 
52 Train Loss: 80.194 | Train Acc: 72.910 
53 Train Loss: 80.012 | Train Acc: 72.957 
54 Train Loss: 79.738 | Train Acc: 73.037 
55 Train Loss: 79.447 | Train Acc: 73.200 
56 Train Loss: 79.390 | Train Acc: 73.245 
57 Train Loss: 79.152 | Train Acc: 73.324 
58 Train Loss: 79.075 | Train Acc: 73.161 
59 Train Loss: 78.819 | Train Acc: 73.376 
60 Train Loss: 78.056 | Train Acc: 73.741 
61 Train Loss: 78.025 | Train Acc: 73.908 
62 Train Loss: 77.882 | Train Acc: 73.888 
63 Train Loss: 77.874 | Train Acc: 73.851 
64 Train Loss: 77.801 | Train Acc: 73.849 
65 Train Loss: 77.711 | Train Acc: 73.859 
66 Train Loss: 77.614 | Train Acc: 73.935 
67 Train Loss: 77.616 | Train Acc: 73.888 
68 Train Loss: 77.543 | Train Acc: 73.929 
69 Train Loss: 77.411 | Train Acc: 74.065 
70 Train Loss: 77.398 | Train Acc: 74.059 
71 Train Loss: 77.324 | Train Acc: 74.027 
72 Train Loss: 77.247 | Train Acc: 74.002 
73 Train Loss: 77.214 | Train Acc: 74.114 
74 Train Loss: 77.100 | Train Acc: 74.133 
75 Train Loss: 77.033 | Train Acc: 74.214 
76 Train Loss: 77.028 | Train Acc: 74.176 
77 Train Loss: 76.922 | Train Acc: 74.114 
78 Train Loss: 76.770 | Train Acc: 74.190 
79 Train Loss: 76.740 | Train Acc: 74.276 
80 Train Loss: 76.404 | Train Acc: 74.416 
81 Train Loss: 76.379 | Train Acc: 74.408 
82 Train Loss: 76.358 | Train Acc: 74.402 
83 Train Loss: 76.324 | Train Acc: 74.418 
84 Train Loss: 76.298 | Train Acc: 74.480 
85 Train Loss: 76.261 | Train Acc: 74.506 
86 Train Loss: 76.250 | Train Acc: 74.429 
87 Train Loss: 76.233 | Train Acc: 74.498 
88 Train Loss: 76.177 | Train Acc: 74.527 
89 Train Loss: 76.203 | Train Acc: 74.390 
90 Train Loss: 76.134 | Train Acc: 74.514 
91 Train Loss: 76.109 | Train Acc: 74.484 
92 Train Loss: 76.074 | Train Acc: 74.465 
93 Train Loss: 76.065 | Train Acc: 74.535 
94 Train Loss: 76.007 | Train Acc: 74.518 
95 Train Loss: 75.997 | Train Acc: 74.531 
96 Train Loss: 75.989 | Train Acc: 74.531 
97 Train Loss: 75.932 | Train Acc: 74.518 
98 Train Loss: 75.886 | Train Acc: 74.629 
99 Train Loss: 75.880 | Train Acc: 74.588 
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 12544])
Time Taken by Kmeans is  74.66054487228394
Kmeans completed successfully...
printing expected split from k means
{9: 1, 2: 0, 1: 1, 5: 0, 4: 0, 7: 0, 3: 0, 6: 0, 0: 1, 8: 1}
Printing final_dict items...
{6: 0, 4: 0, 5: 0, 7: 0, 3: 0, 2: 1, 1: 1, 9: 1, 0: 1, 8: 1}
Image Statistics before MLP : L R :  24500 24500
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 81.596 | Acc: 82.112
1 Loss: 71.703 | Acc: 84.506
2 Loss: 67.376 | Acc: 85.265
3 Loss: 63.440 | Acc: 86.190
4 Loss: 61.177 | Acc: 86.635
5 Loss: 58.273 | Acc: 87.263
6 Loss: 56.207 | Acc: 87.767
7 Loss: 53.631 | Acc: 88.363
8 Loss: 51.365 | Acc: 88.886
9 Loss: 49.810 | Acc: 89.382
10 Loss: 43.070 | Acc: 90.724
11 Loss: 40.662 | Acc: 91.257
12 Loss: 38.856 | Acc: 91.680
13 Loss: 37.942 | Acc: 91.818
14 Loss: 36.783 | Acc: 92.096
15 Loss: 34.298 | Acc: 92.633
16 Loss: 33.958 | Acc: 92.682
17 Loss: 32.478 | Acc: 93.122
18 Loss: 31.381 | Acc: 93.394
19 Loss: 30.730 | Acc: 93.565
20 Loss: 26.656 | Acc: 94.453
21 Loss: 25.190 | Acc: 94.759
22 Loss: 24.638 | Acc: 94.929
23 Loss: 24.120 | Acc: 95.041
24 Loss: 23.063 | Acc: 95.282
25 Loss: 22.769 | Acc: 95.288
26 Loss: 22.429 | Acc: 95.512
27 Loss: 21.218 | Acc: 95.796
28 Loss: 21.253 | Acc: 95.739
29 Loss: 20.251 | Acc: 95.843
30 Loss: 18.454 | Acc: 96.229
31 Loss: 18.255 | Acc: 96.273
32 Loss: 17.860 | Acc: 96.341
33 Loss: 17.533 | Acc: 96.478
34 Loss: 17.359 | Acc: 96.567
35 Loss: 17.419 | Acc: 96.414
36 Loss: 17.347 | Acc: 96.576
37 Loss: 16.887 | Acc: 96.698
38 Loss: 16.624 | Acc: 96.698
39 Loss: 16.287 | Acc: 96.788
40 Loss: 16.056 | Acc: 96.751
41 Loss: 15.940 | Acc: 96.802
42 Loss: 15.679 | Acc: 96.947
43 Loss: 15.362 | Acc: 96.955
44 Loss: 15.614 | Acc: 96.876
45 Loss: 15.465 | Acc: 96.982
46 Loss: 14.893 | Acc: 97.088
47 Loss: 15.032 | Acc: 97.118
48 Loss: 14.975 | Acc: 97.045
49 Loss: 14.692 | Acc: 97.053
50 Loss: 14.919 | Acc: 97.092
51 Loss: 14.579 | Acc: 97.065
52 Loss: 14.780 | Acc: 97.069
53 Loss: 14.373 | Acc: 97.208
54 Loss: 14.400 | Acc: 97.090
55 Loss: 14.114 | Acc: 97.222
56 Loss: 14.182 | Acc: 97.157
57 Loss: 14.021 | Acc: 97.269
58 Loss: 14.042 | Acc: 97.220
59 Loss: 13.998 | Acc: 97.337
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([24500])
rTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([24500])
lValDict[data].shape:  torch.Size([500, 3, 32, 32])   lValDict[label].shape:  torch.Size([500])
rValDict[data].shape:  torch.Size([500, 3, 32, 32])   rValDict[label].shape:  torch.Size([500])
# of Left images:  24500.0
# of Right images:  24500.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [0, 0, 0, 4900, 4900, 4900, 4900, 4900, 0, 0]
rclasses:  [4900, 4900, 4900, 0, 0, 0, 0, 0, 4900, 4900]
noOfLeftClasses:  5
noOfRightClasses:  5
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
nodeId:  3 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
Running nodeId:  2
0 Train Loss: 148.419 | Train Acc: 36.886 
1 Train Loss: 124.093 | Train Acc: 49.902 
2 Train Loss: 115.656 | Train Acc: 53.996 
3 Train Loss: 110.865 | Train Acc: 56.282 
4 Train Loss: 108.328 | Train Acc: 57.216 
5 Train Loss: 105.612 | Train Acc: 58.535 
6 Train Loss: 103.156 | Train Acc: 59.669 
7 Train Loss: 100.542 | Train Acc: 60.755 
8 Train Loss: 98.652 | Train Acc: 61.539 
9 Train Loss: 97.370 | Train Acc: 61.841 
10 Train Loss: 95.279 | Train Acc: 62.698 
11 Train Loss: 94.064 | Train Acc: 63.416 
12 Train Loss: 92.492 | Train Acc: 64.314 
13 Train Loss: 90.451 | Train Acc: 65.163 
14 Train Loss: 89.675 | Train Acc: 65.510 
15 Train Loss: 87.881 | Train Acc: 66.151 
16 Train Loss: 85.653 | Train Acc: 67.033 
17 Train Loss: 84.483 | Train Acc: 67.531 
18 Train Loss: 83.603 | Train Acc: 67.935 
19 Train Loss: 81.650 | Train Acc: 68.731 
20 Train Loss: 78.061 | Train Acc: 70.641 
21 Train Loss: 76.937 | Train Acc: 70.845 
22 Train Loss: 76.522 | Train Acc: 71.273 
23 Train Loss: 75.733 | Train Acc: 71.286 
24 Train Loss: 75.007 | Train Acc: 71.571 
25 Train Loss: 74.333 | Train Acc: 72.204 
26 Train Loss: 73.736 | Train Acc: 72.433 
27 Train Loss: 73.108 | Train Acc: 72.722 
28 Train Loss: 72.822 | Train Acc: 72.653 
29 Train Loss: 72.154 | Train Acc: 72.988 
30 Train Loss: 71.591 | Train Acc: 73.090 
31 Train Loss: 71.446 | Train Acc: 73.171 
32 Train Loss: 71.169 | Train Acc: 73.180 
33 Train Loss: 70.125 | Train Acc: 73.771 
34 Train Loss: 69.565 | Train Acc: 73.943 
35 Train Loss: 69.021 | Train Acc: 74.192 
36 Train Loss: 68.771 | Train Acc: 74.253 
37 Train Loss: 68.449 | Train Acc: 74.592 
38 Train Loss: 68.042 | Train Acc: 74.445 
39 Train Loss: 67.633 | Train Acc: 74.563 
40 Train Loss: 65.740 | Train Acc: 75.820 
41 Train Loss: 65.531 | Train Acc: 75.771 
42 Train Loss: 65.305 | Train Acc: 75.698 
43 Train Loss: 65.162 | Train Acc: 75.796 
44 Train Loss: 65.032 | Train Acc: 76.029 
45 Train Loss: 64.946 | Train Acc: 75.878 
46 Train Loss: 64.813 | Train Acc: 75.996 
47 Train Loss: 64.578 | Train Acc: 76.131 
48 Train Loss: 64.624 | Train Acc: 75.967 
49 Train Loss: 64.396 | Train Acc: 76.257 
50 Train Loss: 64.077 | Train Acc: 76.522 
51 Train Loss: 63.801 | Train Acc: 76.457 
52 Train Loss: 63.717 | Train Acc: 76.543 
53 Train Loss: 63.712 | Train Acc: 76.478 
54 Train Loss: 63.291 | Train Acc: 76.608 
55 Train Loss: 63.208 | Train Acc: 76.845 
56 Train Loss: 62.972 | Train Acc: 76.829 
57 Train Loss: 62.886 | Train Acc: 76.743 
58 Train Loss: 62.544 | Train Acc: 76.922 
59 Train Loss: 62.192 | Train Acc: 77.122 
60 Train Loss: 61.612 | Train Acc: 77.510 
61 Train Loss: 61.543 | Train Acc: 77.571 
62 Train Loss: 61.431 | Train Acc: 77.592 
63 Train Loss: 61.423 | Train Acc: 77.522 
64 Train Loss: 61.301 | Train Acc: 77.710 
65 Train Loss: 61.195 | Train Acc: 77.714 
66 Train Loss: 61.143 | Train Acc: 77.596 
67 Train Loss: 61.073 | Train Acc: 77.620 
68 Train Loss: 61.038 | Train Acc: 77.649 
69 Train Loss: 60.974 | Train Acc: 77.727 
70 Train Loss: 60.816 | Train Acc: 77.780 
71 Train Loss: 60.818 | Train Acc: 77.763 
72 Train Loss: 60.745 | Train Acc: 77.861 
73 Train Loss: 60.716 | Train Acc: 77.812 
74 Train Loss: 60.553 | Train Acc: 77.902 
75 Train Loss: 60.521 | Train Acc: 77.988 
76 Train Loss: 60.530 | Train Acc: 77.845 
77 Train Loss: 60.411 | Train Acc: 78.024 
78 Train Loss: 60.260 | Train Acc: 77.992 
79 Train Loss: 60.311 | Train Acc: 77.824 
80 Train Loss: 59.920 | Train Acc: 78.261 
81 Train Loss: 59.903 | Train Acc: 78.245 
82 Train Loss: 59.821 | Train Acc: 78.216 
83 Train Loss: 59.801 | Train Acc: 78.322 
84 Train Loss: 59.819 | Train Acc: 78.216 
85 Train Loss: 59.786 | Train Acc: 78.224 
86 Train Loss: 59.732 | Train Acc: 78.229 
87 Train Loss: 59.727 | Train Acc: 78.220 
88 Train Loss: 59.662 | Train Acc: 78.249 
89 Train Loss: 59.651 | Train Acc: 78.314 
90 Train Loss: 59.619 | Train Acc: 78.294 
91 Train Loss: 59.608 | Train Acc: 78.282 
92 Train Loss: 59.534 | Train Acc: 78.420 
93 Train Loss: 59.518 | Train Acc: 78.359 
94 Train Loss: 59.503 | Train Acc: 78.261 
95 Train Loss: 59.508 | Train Acc: 78.322 
96 Train Loss: 59.456 | Train Acc: 78.388 
97 Train Loss: 59.391 | Train Acc: 78.355 
98 Train Loss: 59.398 | Train Acc: 78.298 
99 Train Loss: 59.379 | Train Acc: 78.359 
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Time Taken by Kmeans is  40.42735528945923
Kmeans completed successfully...
printing expected split from k means
{2: 1, 4: 0, 1: 1, 3: 1, 0: 1}
Printing final_dict items...
{4: 0, 0: 0, 2: 1, 1: 1, 3: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 96.330 | Acc: 66.649
1 Loss: 88.113 | Acc: 70.645
2 Loss: 83.495 | Acc: 72.931
3 Loss: 79.423 | Acc: 74.833
4 Loss: 76.631 | Acc: 75.731
5 Loss: 73.570 | Acc: 76.886
6 Loss: 69.587 | Acc: 78.588
7 Loss: 66.509 | Acc: 79.694
8 Loss: 63.563 | Acc: 80.690
9 Loss: 61.538 | Acc: 82.008
10 Loss: 51.965 | Acc: 85.163
11 Loss: 48.395 | Acc: 86.351
12 Loss: 46.555 | Acc: 86.963
13 Loss: 42.637 | Acc: 87.922
14 Loss: 41.115 | Acc: 88.494
15 Loss: 38.809 | Acc: 89.371
16 Loss: 36.272 | Acc: 90.000
17 Loss: 34.502 | Acc: 90.482
18 Loss: 33.238 | Acc: 91.139
19 Loss: 31.045 | Acc: 91.808
20 Loss: 25.923 | Acc: 93.298
21 Loss: 24.481 | Acc: 93.812
22 Loss: 24.182 | Acc: 93.816
23 Loss: 22.581 | Acc: 94.204
24 Loss: 21.855 | Acc: 94.269
25 Loss: 20.953 | Acc: 94.739
26 Loss: 20.033 | Acc: 95.049
27 Loss: 19.773 | Acc: 94.996
28 Loss: 18.805 | Acc: 95.404
29 Loss: 17.861 | Acc: 95.702
30 Loss: 16.651 | Acc: 95.902
31 Loss: 15.686 | Acc: 96.122
32 Loss: 15.271 | Acc: 96.286
33 Loss: 15.113 | Acc: 96.400
34 Loss: 13.858 | Acc: 96.588
35 Loss: 14.565 | Acc: 96.457
36 Loss: 14.128 | Acc: 96.612
37 Loss: 13.909 | Acc: 96.633
38 Loss: 13.390 | Acc: 96.865
39 Loss: 13.141 | Acc: 96.800
40 Loss: 12.693 | Acc: 97.098
41 Loss: 12.524 | Acc: 97.094
42 Loss: 12.559 | Acc: 97.016
43 Loss: 12.578 | Acc: 97.106
44 Loss: 12.539 | Acc: 96.931
45 Loss: 12.315 | Acc: 97.090
46 Loss: 12.722 | Acc: 97.057
47 Loss: 12.088 | Acc: 97.192
48 Loss: 11.486 | Acc: 97.278
49 Loss: 11.911 | Acc: 97.147
50 Loss: 11.351 | Acc: 97.298
51 Loss: 11.335 | Acc: 97.322
52 Loss: 11.247 | Acc: 97.396
53 Loss: 11.378 | Acc: 97.343
54 Loss: 11.174 | Acc: 97.473
55 Loss: 10.924 | Acc: 97.514
56 Loss: 11.182 | Acc: 97.429
57 Loss: 11.242 | Acc: 97.510
58 Loss: 10.874 | Acc: 97.424
59 Loss: 11.380 | Acc: 97.318
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [4900, 0, 0, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  5 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  3
0 Train Loss: 121.357 | Train Acc: 51.861 
1 Train Loss: 93.099 | Train Acc: 64.592 
2 Train Loss: 85.982 | Train Acc: 67.151 
3 Train Loss: 80.676 | Train Acc: 69.653 
4 Train Loss: 78.022 | Train Acc: 70.767 
5 Train Loss: 74.832 | Train Acc: 72.122 
6 Train Loss: 72.676 | Train Acc: 73.004 
7 Train Loss: 71.813 | Train Acc: 73.208 
8 Train Loss: 70.611 | Train Acc: 73.637 
9 Train Loss: 68.681 | Train Acc: 74.171 
10 Train Loss: 67.612 | Train Acc: 75.253 
11 Train Loss: 66.404 | Train Acc: 75.265 
12 Train Loss: 65.275 | Train Acc: 75.759 
13 Train Loss: 64.739 | Train Acc: 76.241 
14 Train Loss: 63.102 | Train Acc: 76.698 
15 Train Loss: 62.684 | Train Acc: 76.931 
16 Train Loss: 62.000 | Train Acc: 77.106 
17 Train Loss: 60.003 | Train Acc: 78.265 
18 Train Loss: 60.055 | Train Acc: 77.976 
19 Train Loss: 57.857 | Train Acc: 78.804 
20 Train Loss: 54.813 | Train Acc: 80.257 
21 Train Loss: 54.403 | Train Acc: 80.437 
22 Train Loss: 53.937 | Train Acc: 80.580 
23 Train Loss: 53.723 | Train Acc: 80.747 
24 Train Loss: 53.438 | Train Acc: 80.633 
25 Train Loss: 52.657 | Train Acc: 81.082 
26 Train Loss: 52.663 | Train Acc: 80.959 
27 Train Loss: 52.654 | Train Acc: 80.861 
28 Train Loss: 51.608 | Train Acc: 81.727 
29 Train Loss: 52.390 | Train Acc: 81.041 
30 Train Loss: 50.984 | Train Acc: 81.735 
31 Train Loss: 50.541 | Train Acc: 81.637 
32 Train Loss: 50.014 | Train Acc: 82.196 
33 Train Loss: 49.954 | Train Acc: 82.257 
34 Train Loss: 49.627 | Train Acc: 82.204 
35 Train Loss: 49.026 | Train Acc: 82.588 
36 Train Loss: 48.761 | Train Acc: 82.604 
37 Train Loss: 48.313 | Train Acc: 83.029 
38 Train Loss: 47.796 | Train Acc: 83.049 
39 Train Loss: 47.764 | Train Acc: 83.171 
40 Train Loss: 46.266 | Train Acc: 83.841 
41 Train Loss: 45.952 | Train Acc: 84.012 
42 Train Loss: 45.835 | Train Acc: 83.996 
43 Train Loss: 45.720 | Train Acc: 84.041 
44 Train Loss: 45.585 | Train Acc: 83.971 
45 Train Loss: 45.397 | Train Acc: 84.106 
46 Train Loss: 45.380 | Train Acc: 84.229 
47 Train Loss: 45.160 | Train Acc: 84.327 
48 Train Loss: 45.198 | Train Acc: 84.004 
49 Train Loss: 44.770 | Train Acc: 84.571 
50 Train Loss: 44.811 | Train Acc: 84.486 
51 Train Loss: 44.604 | Train Acc: 84.473 
52 Train Loss: 44.389 | Train Acc: 84.620 
53 Train Loss: 44.321 | Train Acc: 84.812 
54 Train Loss: 44.279 | Train Acc: 84.571 
55 Train Loss: 44.219 | Train Acc: 84.690 
56 Train Loss: 44.021 | Train Acc: 84.747 
57 Train Loss: 43.793 | Train Acc: 84.845 
58 Train Loss: 43.756 | Train Acc: 84.776 
59 Train Loss: 43.645 | Train Acc: 84.845 
60 Train Loss: 42.904 | Train Acc: 85.237 
61 Train Loss: 42.738 | Train Acc: 85.245 
62 Train Loss: 42.740 | Train Acc: 85.412 
63 Train Loss: 42.689 | Train Acc: 85.404 
64 Train Loss: 42.598 | Train Acc: 85.441 
65 Train Loss: 42.617 | Train Acc: 85.408 
66 Train Loss: 42.495 | Train Acc: 85.363 
67 Train Loss: 42.469 | Train Acc: 85.461 
68 Train Loss: 42.417 | Train Acc: 85.441 
69 Train Loss: 42.373 | Train Acc: 85.490 
70 Train Loss: 42.306 | Train Acc: 85.547 
71 Train Loss: 42.213 | Train Acc: 85.551 
72 Train Loss: 42.312 | Train Acc: 85.543 
73 Train Loss: 42.154 | Train Acc: 85.616 
74 Train Loss: 42.167 | Train Acc: 85.453 
75 Train Loss: 42.033 | Train Acc: 85.612 
76 Train Loss: 42.028 | Train Acc: 85.604 
77 Train Loss: 41.983 | Train Acc: 85.673 
78 Train Loss: 41.894 | Train Acc: 85.624 
79 Train Loss: 41.898 | Train Acc: 85.673 
80 Train Loss: 41.529 | Train Acc: 85.894 
81 Train Loss: 41.518 | Train Acc: 85.853 
82 Train Loss: 41.463 | Train Acc: 85.931 
83 Train Loss: 41.469 | Train Acc: 85.910 
84 Train Loss: 41.425 | Train Acc: 86.004 
85 Train Loss: 41.387 | Train Acc: 85.996 
86 Train Loss: 41.377 | Train Acc: 86.024 
87 Train Loss: 41.362 | Train Acc: 85.927 
88 Train Loss: 41.334 | Train Acc: 85.963 
89 Train Loss: 41.314 | Train Acc: 85.894 
90 Train Loss: 41.303 | Train Acc: 85.922 
91 Train Loss: 41.310 | Train Acc: 86.037 
92 Train Loss: 41.269 | Train Acc: 86.033 
93 Train Loss: 41.257 | Train Acc: 85.955 
94 Train Loss: 41.190 | Train Acc: 86.041 
95 Train Loss: 41.234 | Train Acc: 85.967 
96 Train Loss: 41.196 | Train Acc: 86.065 
97 Train Loss: 41.125 | Train Acc: 86.049 
98 Train Loss: 41.124 | Train Acc: 86.024 
99 Train Loss: 41.085 | Train Acc: 86.086 
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Time Taken by Kmeans is  36.4525465965271
Kmeans completed successfully...
printing expected split from k means
{4: 0, 2: 0, 1: 0, 0: 1, 3: 1}
Printing final_dict items...
{2: 0, 1: 0, 4: 1, 3: 1, 0: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 87.334 | Acc: 72.612
1 Loss: 76.802 | Acc: 77.196
2 Loss: 70.079 | Acc: 79.453
3 Loss: 64.649 | Acc: 81.731
4 Loss: 61.889 | Acc: 82.767
5 Loss: 57.006 | Acc: 84.212
6 Loss: 54.450 | Acc: 85.045
7 Loss: 52.533 | Acc: 85.518
8 Loss: 48.833 | Acc: 86.788
9 Loss: 46.663 | Acc: 87.371
10 Loss: 39.978 | Acc: 89.571
11 Loss: 37.193 | Acc: 90.045
12 Loss: 35.369 | Acc: 90.767
13 Loss: 34.320 | Acc: 91.392
14 Loss: 32.893 | Acc: 91.616
15 Loss: 30.945 | Acc: 92.029
16 Loss: 29.465 | Acc: 92.404
17 Loss: 27.532 | Acc: 93.106
18 Loss: 26.089 | Acc: 93.273
19 Loss: 25.996 | Acc: 93.482
20 Loss: 22.018 | Acc: 94.616
21 Loss: 20.910 | Acc: 94.796
22 Loss: 19.447 | Acc: 95.192
23 Loss: 19.405 | Acc: 95.253
24 Loss: 18.769 | Acc: 95.290
25 Loss: 18.621 | Acc: 95.339
26 Loss: 17.132 | Acc: 95.857
27 Loss: 17.598 | Acc: 95.739
28 Loss: 16.097 | Acc: 96.110
29 Loss: 15.606 | Acc: 96.184
30 Loss: 14.847 | Acc: 96.490
31 Loss: 14.245 | Acc: 96.645
32 Loss: 14.000 | Acc: 96.580
33 Loss: 13.449 | Acc: 96.808
34 Loss: 13.135 | Acc: 96.788
35 Loss: 13.505 | Acc: 96.661
36 Loss: 12.876 | Acc: 97.008
37 Loss: 12.603 | Acc: 97.024
38 Loss: 12.899 | Acc: 96.951
39 Loss: 12.612 | Acc: 96.861
40 Loss: 11.689 | Acc: 97.273
41 Loss: 11.471 | Acc: 97.245
42 Loss: 11.931 | Acc: 97.192
43 Loss: 12.117 | Acc: 97.127
44 Loss: 11.078 | Acc: 97.400
45 Loss: 11.716 | Acc: 97.114
46 Loss: 11.159 | Acc: 97.322
47 Loss: 10.811 | Acc: 97.469
48 Loss: 11.235 | Acc: 97.265
49 Loss: 11.366 | Acc: 97.269
50 Loss: 11.144 | Acc: 97.261
51 Loss: 11.048 | Acc: 97.416
52 Loss: 10.553 | Acc: 97.563
53 Loss: 10.845 | Acc: 97.527
54 Loss: 10.994 | Acc: 97.478
55 Loss: 10.362 | Acc: 97.527
56 Loss: 10.255 | Acc: 97.584
57 Loss: 10.636 | Acc: 97.522
58 Loss: 10.781 | Acc: 97.286
59 Loss: 10.240 | Acc: 97.633
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 4900, 4900, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  7 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  4
0 Train Loss: 62.035 | Train Acc: 67.357 
1 Train Loss: 45.327 | Train Acc: 79.122 
2 Train Loss: 41.353 | Train Acc: 81.602 
3 Train Loss: 39.232 | Train Acc: 82.633 
4 Train Loss: 37.625 | Train Acc: 83.602 
5 Train Loss: 35.754 | Train Acc: 84.908 
6 Train Loss: 35.021 | Train Acc: 85.143 
7 Train Loss: 34.568 | Train Acc: 85.286 
8 Train Loss: 33.319 | Train Acc: 85.980 
9 Train Loss: 32.138 | Train Acc: 86.653 
10 Train Loss: 30.943 | Train Acc: 86.857 
11 Train Loss: 29.907 | Train Acc: 87.551 
12 Train Loss: 28.742 | Train Acc: 88.173 
13 Train Loss: 27.908 | Train Acc: 88.735 
14 Train Loss: 27.398 | Train Acc: 88.867 
15 Train Loss: 26.279 | Train Acc: 89.561 
16 Train Loss: 26.132 | Train Acc: 89.592 
17 Train Loss: 25.229 | Train Acc: 89.867 
18 Train Loss: 24.034 | Train Acc: 90.684 
19 Train Loss: 23.900 | Train Acc: 90.327 
20 Train Loss: 21.014 | Train Acc: 92.235 
21 Train Loss: 20.849 | Train Acc: 92.041 
22 Train Loss: 20.091 | Train Acc: 92.429 
23 Train Loss: 19.934 | Train Acc: 92.622 
24 Train Loss: 19.694 | Train Acc: 92.735 
25 Train Loss: 19.573 | Train Acc: 92.735 
26 Train Loss: 19.177 | Train Acc: 92.765 
27 Train Loss: 18.966 | Train Acc: 92.888 
28 Train Loss: 18.539 | Train Acc: 93.184 
29 Train Loss: 18.325 | Train Acc: 93.276 
30 Train Loss: 18.053 | Train Acc: 93.418 
31 Train Loss: 17.739 | Train Acc: 93.439 
32 Train Loss: 17.270 | Train Acc: 93.714 
33 Train Loss: 17.018 | Train Acc: 93.694 
34 Train Loss: 16.963 | Train Acc: 93.929 
35 Train Loss: 16.830 | Train Acc: 93.857 
36 Train Loss: 16.700 | Train Acc: 94.061 
37 Train Loss: 16.655 | Train Acc: 93.837 
38 Train Loss: 16.600 | Train Acc: 93.918 
39 Train Loss: 15.966 | Train Acc: 94.143 
40 Train Loss: 14.881 | Train Acc: 94.990 
41 Train Loss: 14.817 | Train Acc: 94.949 
42 Train Loss: 14.738 | Train Acc: 95.092 
43 Train Loss: 14.625 | Train Acc: 94.980 
44 Train Loss: 14.665 | Train Acc: 94.898 
45 Train Loss: 14.367 | Train Acc: 95.337 
46 Train Loss: 14.336 | Train Acc: 95.173 
47 Train Loss: 14.300 | Train Acc: 95.184 
48 Train Loss: 14.250 | Train Acc: 95.082 
49 Train Loss: 14.035 | Train Acc: 95.347 
50 Train Loss: 14.075 | Train Acc: 95.265 
51 Train Loss: 14.001 | Train Acc: 95.357 
52 Train Loss: 13.858 | Train Acc: 95.184 
53 Train Loss: 13.840 | Train Acc: 95.347 
54 Train Loss: 13.733 | Train Acc: 95.561 
55 Train Loss: 13.645 | Train Acc: 95.551 
56 Train Loss: 13.554 | Train Acc: 95.449 
57 Train Loss: 13.394 | Train Acc: 95.653 
58 Train Loss: 13.518 | Train Acc: 95.510 
59 Train Loss: 13.216 | Train Acc: 95.755 
60 Train Loss: 12.894 | Train Acc: 95.888 
61 Train Loss: 12.825 | Train Acc: 96.051 
62 Train Loss: 12.779 | Train Acc: 95.847 
63 Train Loss: 12.753 | Train Acc: 95.898 
64 Train Loss: 12.675 | Train Acc: 96.020 
65 Train Loss: 12.688 | Train Acc: 96.051 
66 Train Loss: 12.641 | Train Acc: 96.092 
67 Train Loss: 12.574 | Train Acc: 96.163 
68 Train Loss: 12.626 | Train Acc: 96.041 
69 Train Loss: 12.563 | Train Acc: 95.959 
70 Train Loss: 12.568 | Train Acc: 95.918 
71 Train Loss: 12.564 | Train Acc: 96.061 
72 Train Loss: 12.406 | Train Acc: 96.194 
73 Train Loss: 12.498 | Train Acc: 96.122 
74 Train Loss: 12.482 | Train Acc: 96.102 
75 Train Loss: 12.361 | Train Acc: 96.031 
76 Train Loss: 12.312 | Train Acc: 96.173 
77 Train Loss: 12.478 | Train Acc: 96.051 
78 Train Loss: 12.292 | Train Acc: 96.204 
79 Train Loss: 12.227 | Train Acc: 96.276 
80 Train Loss: 12.078 | Train Acc: 96.214 
81 Train Loss: 12.060 | Train Acc: 96.398 
82 Train Loss: 12.028 | Train Acc: 96.398 
83 Train Loss: 12.041 | Train Acc: 96.286 
84 Train Loss: 12.013 | Train Acc: 96.388 
85 Train Loss: 12.003 | Train Acc: 96.357 
86 Train Loss: 11.986 | Train Acc: 96.347 
87 Train Loss: 11.970 | Train Acc: 96.347 
88 Train Loss: 11.957 | Train Acc: 96.245 
89 Train Loss: 11.947 | Train Acc: 96.418 
90 Train Loss: 11.930 | Train Acc: 96.418 
91 Train Loss: 11.909 | Train Acc: 96.347 
92 Train Loss: 11.908 | Train Acc: 96.378 
93 Train Loss: 11.950 | Train Acc: 96.327 
94 Train Loss: 11.884 | Train Acc: 96.398 
95 Train Loss: 11.883 | Train Acc: 96.429 
96 Train Loss: 11.847 | Train Acc: 96.418 
97 Train Loss: 11.853 | Train Acc: 96.439 
98 Train Loss: 11.822 | Train Acc: 96.449 
99 Train Loss: 11.856 | Train Acc: 96.327 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Time Taken by Kmeans is  12.476240634918213
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 85.739 | Acc: 80.367
1 Loss: 64.639 | Acc: 86.276
2 Loss: 53.969 | Acc: 88.592
3 Loss: 49.518 | Acc: 89.633
4 Loss: 44.449 | Acc: 90.643
5 Loss: 40.373 | Acc: 91.643
6 Loss: 35.593 | Acc: 92.592
7 Loss: 32.626 | Acc: 93.173
8 Loss: 29.744 | Acc: 93.776
9 Loss: 25.796 | Acc: 94.500
10 Loss: 17.187 | Acc: 96.449
11 Loss: 12.753 | Acc: 97.571
12 Loss: 11.984 | Acc: 97.724
13 Loss: 9.959 | Acc: 98.102
14 Loss: 9.008 | Acc: 98.163
15 Loss: 8.615 | Acc: 98.327
16 Loss: 7.842 | Acc: 98.592
17 Loss: 6.996 | Acc: 98.786
18 Loss: 6.642 | Acc: 98.745
19 Loss: 6.521 | Acc: 98.776
20 Loss: 3.470 | Acc: 99.398
21 Loss: 3.342 | Acc: 99.367
22 Loss: 2.617 | Acc: 99.684
23 Loss: 3.171 | Acc: 99.469
24 Loss: 1.956 | Acc: 99.643
25 Loss: 2.168 | Acc: 99.704
26 Loss: 1.671 | Acc: 99.745
27 Loss: 1.596 | Acc: 99.796
28 Loss: 2.202 | Acc: 99.694
29 Loss: 2.436 | Acc: 99.612
30 Loss: 1.560 | Acc: 99.796
31 Loss: 1.159 | Acc: 99.827
32 Loss: 0.852 | Acc: 99.888
33 Loss: 0.985 | Acc: 99.888
34 Loss: 0.891 | Acc: 99.918
35 Loss: 0.847 | Acc: 99.888
36 Loss: 1.201 | Acc: 99.867
37 Loss: 0.909 | Acc: 99.878
38 Loss: 0.690 | Acc: 99.929
39 Loss: 0.973 | Acc: 99.837
40 Loss: 0.842 | Acc: 99.888
41 Loss: 0.722 | Acc: 99.888
42 Loss: 0.556 | Acc: 99.929
43 Loss: 0.490 | Acc: 99.939
44 Loss: 0.618 | Acc: 99.908
45 Loss: 0.617 | Acc: 99.918
46 Loss: 0.731 | Acc: 99.898
47 Loss: 0.623 | Acc: 99.888
48 Loss: 0.654 | Acc: 99.888
49 Loss: 0.687 | Acc: 99.878
50 Loss: 0.577 | Acc: 99.939
51 Loss: 0.560 | Acc: 99.939
52 Loss: 0.515 | Acc: 99.918
53 Loss: 0.464 | Acc: 99.949
54 Loss: 0.640 | Acc: 99.918
55 Loss: 0.486 | Acc: 99.949
56 Loss: 0.479 | Acc: 99.929
57 Loss: 0.596 | Acc: 99.929
58 Loss: 0.605 | Acc: 99.888
59 Loss: 0.697 | Acc: 99.898
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 7
nodeId:  8 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
nodeId:  9 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  5
0 Train Loss: 90.815 | Train Acc: 56.293 
1 Train Loss: 74.133 | Train Acc: 68.265 
2 Train Loss: 67.184 | Train Acc: 71.694 
3 Train Loss: 62.143 | Train Acc: 74.469 
4 Train Loss: 57.917 | Train Acc: 76.687 
5 Train Loss: 55.214 | Train Acc: 77.762 
6 Train Loss: 52.961 | Train Acc: 79.075 
7 Train Loss: 50.888 | Train Acc: 79.612 
8 Train Loss: 49.788 | Train Acc: 80.150 
9 Train Loss: 47.731 | Train Acc: 80.844 
10 Train Loss: 45.708 | Train Acc: 82.027 
11 Train Loss: 45.413 | Train Acc: 82.565 
12 Train Loss: 43.575 | Train Acc: 82.932 
13 Train Loss: 43.207 | Train Acc: 83.143 
14 Train Loss: 41.562 | Train Acc: 83.599 
15 Train Loss: 40.897 | Train Acc: 83.980 
16 Train Loss: 40.540 | Train Acc: 84.102 
17 Train Loss: 40.014 | Train Acc: 84.211 
18 Train Loss: 38.958 | Train Acc: 84.980 
19 Train Loss: 38.653 | Train Acc: 84.878 
20 Train Loss: 35.394 | Train Acc: 86.612 
21 Train Loss: 34.729 | Train Acc: 86.837 
22 Train Loss: 34.395 | Train Acc: 87.150 
23 Train Loss: 33.999 | Train Acc: 87.252 
24 Train Loss: 34.174 | Train Acc: 87.156 
25 Train Loss: 33.631 | Train Acc: 87.626 
26 Train Loss: 33.485 | Train Acc: 87.551 
27 Train Loss: 33.218 | Train Acc: 87.694 
28 Train Loss: 32.936 | Train Acc: 87.680 
29 Train Loss: 33.168 | Train Acc: 87.503 
30 Train Loss: 32.408 | Train Acc: 88.082 
31 Train Loss: 31.985 | Train Acc: 88.156 
32 Train Loss: 31.706 | Train Acc: 88.497 
33 Train Loss: 31.614 | Train Acc: 88.272 
34 Train Loss: 31.195 | Train Acc: 88.748 
35 Train Loss: 31.033 | Train Acc: 88.435 
36 Train Loss: 30.716 | Train Acc: 88.687 
37 Train Loss: 30.636 | Train Acc: 88.932 
38 Train Loss: 30.290 | Train Acc: 88.884 
39 Train Loss: 30.064 | Train Acc: 89.041 
40 Train Loss: 28.889 | Train Acc: 89.925 
41 Train Loss: 28.740 | Train Acc: 89.844 
42 Train Loss: 28.891 | Train Acc: 89.925 
43 Train Loss: 28.555 | Train Acc: 90.014 
44 Train Loss: 28.455 | Train Acc: 90.034 
45 Train Loss: 28.487 | Train Acc: 90.034 
46 Train Loss: 28.240 | Train Acc: 90.218 
47 Train Loss: 28.378 | Train Acc: 90.048 
48 Train Loss: 28.141 | Train Acc: 90.299 
49 Train Loss: 28.049 | Train Acc: 90.068 
50 Train Loss: 28.067 | Train Acc: 90.116 
51 Train Loss: 28.052 | Train Acc: 90.116 
52 Train Loss: 27.613 | Train Acc: 90.483 
53 Train Loss: 27.741 | Train Acc: 90.361 
54 Train Loss: 27.548 | Train Acc: 90.585 
55 Train Loss: 27.323 | Train Acc: 90.524 
56 Train Loss: 27.429 | Train Acc: 90.435 
57 Train Loss: 27.172 | Train Acc: 90.810 
58 Train Loss: 27.266 | Train Acc: 90.626 
59 Train Loss: 27.530 | Train Acc: 90.177 
60 Train Loss: 26.597 | Train Acc: 91.109 
61 Train Loss: 26.493 | Train Acc: 91.122 
62 Train Loss: 26.491 | Train Acc: 91.095 
63 Train Loss: 26.392 | Train Acc: 91.061 
64 Train Loss: 26.400 | Train Acc: 91.061 
65 Train Loss: 26.382 | Train Acc: 91.129 
66 Train Loss: 26.248 | Train Acc: 91.218 
67 Train Loss: 26.226 | Train Acc: 91.252 
68 Train Loss: 26.263 | Train Acc: 91.109 
69 Train Loss: 26.330 | Train Acc: 91.034 
70 Train Loss: 26.110 | Train Acc: 91.272 
71 Train Loss: 26.147 | Train Acc: 91.109 
72 Train Loss: 26.100 | Train Acc: 91.299 
73 Train Loss: 26.080 | Train Acc: 91.272 
74 Train Loss: 26.026 | Train Acc: 91.259 
75 Train Loss: 25.941 | Train Acc: 91.286 
76 Train Loss: 25.910 | Train Acc: 91.286 
77 Train Loss: 25.984 | Train Acc: 91.136 
78 Train Loss: 25.798 | Train Acc: 91.347 
79 Train Loss: 25.972 | Train Acc: 91.204 
80 Train Loss: 25.635 | Train Acc: 91.524 
81 Train Loss: 25.628 | Train Acc: 91.483 
82 Train Loss: 25.555 | Train Acc: 91.633 
83 Train Loss: 25.524 | Train Acc: 91.619 
84 Train Loss: 25.511 | Train Acc: 91.544 
85 Train Loss: 25.549 | Train Acc: 91.585 
86 Train Loss: 25.520 | Train Acc: 91.626 
87 Train Loss: 25.445 | Train Acc: 91.585 
88 Train Loss: 25.470 | Train Acc: 91.605 
89 Train Loss: 25.438 | Train Acc: 91.605 
90 Train Loss: 25.416 | Train Acc: 91.626 
91 Train Loss: 25.428 | Train Acc: 91.687 
92 Train Loss: 25.412 | Train Acc: 91.673 
93 Train Loss: 25.423 | Train Acc: 91.605 
94 Train Loss: 25.324 | Train Acc: 91.619 
95 Train Loss: 25.368 | Train Acc: 91.755 
96 Train Loss: 25.325 | Train Acc: 91.578 
97 Train Loss: 25.334 | Train Acc: 91.667 
98 Train Loss: 25.310 | Train Acc: 91.612 
99 Train Loss: 25.280 | Train Acc: 91.694 
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 12544])
Time Taken by Kmeans is  23.76642370223999
Kmeans completed successfully...
printing expected split from k means
{1: 1, 0: 1, 2: 0}
Printing final_dict items...
{2: 0, 0: 1, 1: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 60.387 | Acc: 78.699
1 Loss: 44.406 | Acc: 85.747
2 Loss: 39.660 | Acc: 87.808
3 Loss: 34.435 | Acc: 89.315
4 Loss: 31.083 | Acc: 90.411
5 Loss: 27.424 | Acc: 91.685
6 Loss: 25.474 | Acc: 92.363
7 Loss: 21.838 | Acc: 93.411
8 Loss: 19.930 | Acc: 93.918
9 Loss: 18.993 | Acc: 94.281
10 Loss: 12.256 | Acc: 96.568
11 Loss: 9.546 | Acc: 97.260
12 Loss: 8.710 | Acc: 97.527
13 Loss: 7.992 | Acc: 97.719
14 Loss: 7.881 | Acc: 97.767
15 Loss: 7.347 | Acc: 97.952
16 Loss: 6.204 | Acc: 98.240
17 Loss: 5.695 | Acc: 98.527
18 Loss: 5.263 | Acc: 98.425
19 Loss: 5.339 | Acc: 98.589
20 Loss: 3.817 | Acc: 98.966
21 Loss: 3.200 | Acc: 99.260
22 Loss: 2.652 | Acc: 99.356
23 Loss: 2.165 | Acc: 99.438
24 Loss: 2.128 | Acc: 99.500
25 Loss: 2.483 | Acc: 99.377
26 Loss: 2.161 | Acc: 99.438
27 Loss: 2.188 | Acc: 99.418
28 Loss: 1.901 | Acc: 99.507
29 Loss: 2.054 | Acc: 99.473
30 Loss: 1.460 | Acc: 99.658
31 Loss: 1.462 | Acc: 99.712
32 Loss: 1.526 | Acc: 99.651
33 Loss: 1.360 | Acc: 99.603
34 Loss: 1.233 | Acc: 99.685
35 Loss: 0.917 | Acc: 99.801
36 Loss: 1.080 | Acc: 99.733
37 Loss: 0.954 | Acc: 99.788
38 Loss: 1.021 | Acc: 99.767
39 Loss: 1.058 | Acc: 99.760
40 Loss: 0.923 | Acc: 99.808
41 Loss: 1.091 | Acc: 99.788
42 Loss: 0.806 | Acc: 99.808
43 Loss: 0.993 | Acc: 99.801
44 Loss: 0.821 | Acc: 99.829
45 Loss: 1.094 | Acc: 99.781
46 Loss: 1.116 | Acc: 99.760
47 Loss: 0.776 | Acc: 99.829
48 Loss: 0.833 | Acc: 99.801
49 Loss: 0.784 | Acc: 99.829
50 Loss: 0.809 | Acc: 99.822
51 Loss: 0.757 | Acc: 99.808
52 Loss: 0.725 | Acc: 99.856
53 Loss: 0.647 | Acc: 99.870
54 Loss: 0.718 | Acc: 99.849
55 Loss: 0.804 | Acc: 99.829
56 Loss: 0.765 | Acc: 99.870
57 Loss: 0.635 | Acc: 99.863
58 Loss: 0.724 | Acc: 99.863
59 Loss: 0.865 | Acc: 99.842
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 6
nodeId:  10 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
nodeId:  11 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  6
0 Train Loss: 41.776 | Train Acc: 80.163 
1 Train Loss: 23.112 | Train Acc: 91.133 
2 Train Loss: 18.835 | Train Acc: 92.276 
3 Train Loss: 17.130 | Train Acc: 93.112 
4 Train Loss: 15.149 | Train Acc: 94.010 
5 Train Loss: 14.529 | Train Acc: 94.194 
6 Train Loss: 14.271 | Train Acc: 94.357 
7 Train Loss: 13.984 | Train Acc: 94.510 
8 Train Loss: 12.803 | Train Acc: 94.857 
9 Train Loss: 11.973 | Train Acc: 95.194 
10 Train Loss: 12.172 | Train Acc: 95.173 
11 Train Loss: 10.922 | Train Acc: 95.857 
12 Train Loss: 11.059 | Train Acc: 95.684 
13 Train Loss: 10.772 | Train Acc: 95.786 
14 Train Loss: 10.248 | Train Acc: 95.908 
15 Train Loss: 9.522 | Train Acc: 96.408 
16 Train Loss: 9.743 | Train Acc: 96.173 
17 Train Loss: 9.408 | Train Acc: 96.337 
18 Train Loss: 8.222 | Train Acc: 97.071 
19 Train Loss: 8.619 | Train Acc: 96.796 
20 Train Loss: 6.972 | Train Acc: 97.551 
21 Train Loss: 6.663 | Train Acc: 97.694 
22 Train Loss: 6.760 | Train Acc: 97.388 
23 Train Loss: 6.409 | Train Acc: 97.806 
24 Train Loss: 6.245 | Train Acc: 97.867 
25 Train Loss: 6.533 | Train Acc: 97.602 
26 Train Loss: 6.064 | Train Acc: 98.061 
27 Train Loss: 5.989 | Train Acc: 97.959 
28 Train Loss: 5.779 | Train Acc: 98.153 
29 Train Loss: 6.405 | Train Acc: 97.704 
30 Train Loss: 5.679 | Train Acc: 98.163 
31 Train Loss: 5.667 | Train Acc: 98.235 
32 Train Loss: 5.916 | Train Acc: 98.041 
33 Train Loss: 5.809 | Train Acc: 98.041 
34 Train Loss: 5.396 | Train Acc: 98.378 
35 Train Loss: 5.322 | Train Acc: 98.296 
36 Train Loss: 5.030 | Train Acc: 98.469 
37 Train Loss: 4.896 | Train Acc: 98.663 
38 Train Loss: 4.804 | Train Acc: 98.653 
39 Train Loss: 4.966 | Train Acc: 98.510 
40 Train Loss: 4.289 | Train Acc: 98.827 
41 Train Loss: 4.158 | Train Acc: 98.969 
42 Train Loss: 4.201 | Train Acc: 98.878 
43 Train Loss: 4.132 | Train Acc: 98.918 
44 Train Loss: 4.096 | Train Acc: 99.020 
45 Train Loss: 3.992 | Train Acc: 98.990 
46 Train Loss: 4.062 | Train Acc: 99.000 
47 Train Loss: 3.954 | Train Acc: 99.010 
48 Train Loss: 3.941 | Train Acc: 99.041 
49 Train Loss: 3.828 | Train Acc: 99.122 
50 Train Loss: 3.866 | Train Acc: 99.112 
51 Train Loss: 3.760 | Train Acc: 99.143 
52 Train Loss: 3.800 | Train Acc: 99.051 
53 Train Loss: 3.747 | Train Acc: 99.041 
54 Train Loss: 3.866 | Train Acc: 99.010 
55 Train Loss: 3.950 | Train Acc: 98.939 
56 Train Loss: 3.529 | Train Acc: 99.204 
57 Train Loss: 3.582 | Train Acc: 99.133 
58 Train Loss: 3.461 | Train Acc: 99.265 
59 Train Loss: 3.475 | Train Acc: 99.173 
60 Train Loss: 3.326 | Train Acc: 99.276 
61 Train Loss: 3.285 | Train Acc: 99.327 
62 Train Loss: 3.240 | Train Acc: 99.347 
63 Train Loss: 3.275 | Train Acc: 99.316 
64 Train Loss: 3.228 | Train Acc: 99.367 
65 Train Loss: 3.204 | Train Acc: 99.378 
66 Train Loss: 3.177 | Train Acc: 99.347 
67 Train Loss: 3.154 | Train Acc: 99.398 
68 Train Loss: 3.169 | Train Acc: 99.337 
69 Train Loss: 3.128 | Train Acc: 99.418 
70 Train Loss: 3.109 | Train Acc: 99.418 
71 Train Loss: 3.089 | Train Acc: 99.459 
72 Train Loss: 3.079 | Train Acc: 99.378 
73 Train Loss: 3.093 | Train Acc: 99.357 
74 Train Loss: 3.030 | Train Acc: 99.418 
75 Train Loss: 3.057 | Train Acc: 99.357 
76 Train Loss: 3.022 | Train Acc: 99.378 
77 Train Loss: 2.996 | Train Acc: 99.429 
78 Train Loss: 2.976 | Train Acc: 99.408 
79 Train Loss: 2.982 | Train Acc: 99.429 
80 Train Loss: 2.881 | Train Acc: 99.449 
81 Train Loss: 2.874 | Train Acc: 99.469 
82 Train Loss: 2.914 | Train Acc: 99.459 
83 Train Loss: 2.879 | Train Acc: 99.459 
84 Train Loss: 2.856 | Train Acc: 99.500 
85 Train Loss: 2.841 | Train Acc: 99.459 
86 Train Loss: 2.859 | Train Acc: 99.500 
87 Train Loss: 2.841 | Train Acc: 99.500 
88 Train Loss: 2.853 | Train Acc: 99.439 
89 Train Loss: 2.831 | Train Acc: 99.500 
90 Train Loss: 2.851 | Train Acc: 99.490 
91 Train Loss: 2.862 | Train Acc: 99.480 
92 Train Loss: 2.816 | Train Acc: 99.490 
93 Train Loss: 2.812 | Train Acc: 99.500 
94 Train Loss: 2.806 | Train Acc: 99.510 
95 Train Loss: 2.787 | Train Acc: 99.531 
96 Train Loss: 2.786 | Train Acc: 99.520 
97 Train Loss: 2.777 | Train Acc: 99.520 
98 Train Loss: 2.797 | Train Acc: 99.520 
99 Train Loss: 2.774 | Train Acc: 99.510 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Time Taken by Kmeans is  14.403296947479248
Kmeans completed successfully...
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 44.161 | Acc: 91.224
1 Loss: 29.023 | Acc: 94.378
2 Loss: 25.522 | Acc: 95.071
3 Loss: 22.248 | Acc: 95.602
4 Loss: 19.312 | Acc: 95.663
5 Loss: 17.859 | Acc: 96.449
6 Loss: 16.362 | Acc: 96.745
7 Loss: 13.203 | Acc: 97.602
8 Loss: 12.557 | Acc: 97.490
9 Loss: 10.333 | Acc: 98.041
10 Loss: 7.200 | Acc: 98.612
11 Loss: 4.885 | Acc: 99.092
12 Loss: 2.786 | Acc: 99.480
13 Loss: 2.876 | Acc: 99.418
14 Loss: 2.956 | Acc: 99.531
15 Loss: 2.857 | Acc: 99.469
16 Loss: 3.059 | Acc: 99.469
17 Loss: 2.473 | Acc: 99.520
18 Loss: 2.887 | Acc: 99.520
19 Loss: 2.009 | Acc: 99.643
20 Loss: 1.022 | Acc: 99.796
21 Loss: 0.991 | Acc: 99.878
22 Loss: 0.694 | Acc: 99.908
23 Loss: 0.476 | Acc: 99.959
24 Loss: 0.538 | Acc: 99.908
25 Loss: 0.716 | Acc: 99.847
26 Loss: 0.477 | Acc: 99.898
27 Loss: 0.408 | Acc: 99.959
28 Loss: 0.461 | Acc: 99.929
29 Loss: 0.520 | Acc: 99.939
30 Loss: 0.414 | Acc: 99.918
31 Loss: 0.262 | Acc: 99.980
32 Loss: 0.271 | Acc: 99.980
33 Loss: 0.302 | Acc: 99.949
34 Loss: 0.337 | Acc: 99.969
35 Loss: 0.404 | Acc: 99.949
36 Loss: 0.359 | Acc: 99.949
37 Loss: 0.208 | Acc: 99.959
38 Loss: 0.215 | Acc: 99.969
39 Loss: 0.160 | Acc: 99.980
40 Loss: 0.210 | Acc: 99.980
41 Loss: 0.145 | Acc: 99.990
42 Loss: 0.125 | Acc: 99.990
43 Loss: 0.175 | Acc: 99.990
44 Loss: 0.245 | Acc: 99.949
45 Loss: 0.326 | Acc: 99.980
46 Loss: 0.131 | Acc: 99.990
47 Loss: 0.197 | Acc: 99.980
48 Loss: 0.151 | Acc: 99.990
49 Loss: 0.110 | Acc: 100.000
50 Loss: 0.087 | Acc: 99.990
51 Loss: 0.138 | Acc: 99.980
52 Loss: 0.104 | Acc: 99.990
53 Loss: 0.134 | Acc: 99.969
54 Loss: 0.149 | Acc: 99.990
55 Loss: 0.078 | Acc: 100.000
56 Loss: 0.168 | Acc: 99.980
57 Loss: 0.134 | Acc: 99.980
58 Loss: 0.075 | Acc: 100.000
59 Loss: 0.102 | Acc: 99.990
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 2
nodeId:  12 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 4900
nodeId:  13 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  7
0 Train Loss: 92.721 | Train Acc: 55.939 
1 Train Loss: 71.781 | Train Acc: 69.224 
2 Train Loss: 64.810 | Train Acc: 72.871 
3 Train Loss: 60.267 | Train Acc: 74.782 
4 Train Loss: 56.892 | Train Acc: 76.748 
5 Train Loss: 53.879 | Train Acc: 78.177 
6 Train Loss: 51.864 | Train Acc: 78.918 
7 Train Loss: 50.338 | Train Acc: 79.816 
8 Train Loss: 49.264 | Train Acc: 80.252 
9 Train Loss: 48.119 | Train Acc: 80.592 
10 Train Loss: 47.007 | Train Acc: 81.653 
11 Train Loss: 46.126 | Train Acc: 81.728 
12 Train Loss: 45.425 | Train Acc: 82.095 
13 Train Loss: 43.706 | Train Acc: 83.082 
14 Train Loss: 42.795 | Train Acc: 83.177 
15 Train Loss: 42.843 | Train Acc: 83.388 
16 Train Loss: 41.001 | Train Acc: 84.129 
17 Train Loss: 40.541 | Train Acc: 84.456 
18 Train Loss: 38.820 | Train Acc: 85.150 
19 Train Loss: 37.702 | Train Acc: 85.721 
20 Train Loss: 34.704 | Train Acc: 86.891 
21 Train Loss: 34.065 | Train Acc: 87.163 
22 Train Loss: 33.301 | Train Acc: 87.660 
23 Train Loss: 33.208 | Train Acc: 87.442 
24 Train Loss: 32.318 | Train Acc: 88.007 
25 Train Loss: 32.067 | Train Acc: 88.347 
26 Train Loss: 31.783 | Train Acc: 88.313 
27 Train Loss: 31.596 | Train Acc: 88.252 
28 Train Loss: 30.799 | Train Acc: 88.837 
29 Train Loss: 30.694 | Train Acc: 88.653 
30 Train Loss: 30.318 | Train Acc: 88.878 
31 Train Loss: 29.507 | Train Acc: 89.388 
32 Train Loss: 28.990 | Train Acc: 89.653 
33 Train Loss: 29.001 | Train Acc: 89.769 
34 Train Loss: 28.442 | Train Acc: 89.619 
35 Train Loss: 28.402 | Train Acc: 89.639 
36 Train Loss: 27.945 | Train Acc: 90.027 
37 Train Loss: 27.597 | Train Acc: 90.211 
38 Train Loss: 27.237 | Train Acc: 90.374 
39 Train Loss: 26.886 | Train Acc: 90.469 
40 Train Loss: 26.000 | Train Acc: 91.109 
41 Train Loss: 25.651 | Train Acc: 91.190 
42 Train Loss: 25.428 | Train Acc: 91.102 
43 Train Loss: 25.496 | Train Acc: 91.116 
44 Train Loss: 25.488 | Train Acc: 91.265 
45 Train Loss: 25.139 | Train Acc: 91.320 
46 Train Loss: 25.194 | Train Acc: 91.286 
47 Train Loss: 24.941 | Train Acc: 91.612 
48 Train Loss: 24.857 | Train Acc: 91.497 
49 Train Loss: 24.685 | Train Acc: 91.571 
50 Train Loss: 24.650 | Train Acc: 91.653 
51 Train Loss: 24.754 | Train Acc: 91.340 
52 Train Loss: 24.251 | Train Acc: 91.884 
53 Train Loss: 24.207 | Train Acc: 91.694 
54 Train Loss: 24.037 | Train Acc: 91.728 
55 Train Loss: 23.959 | Train Acc: 91.762 
56 Train Loss: 23.900 | Train Acc: 91.993 
57 Train Loss: 23.794 | Train Acc: 91.891 
58 Train Loss: 23.635 | Train Acc: 91.952 
59 Train Loss: 23.483 | Train Acc: 92.259 
60 Train Loss: 23.038 | Train Acc: 92.279 
61 Train Loss: 22.974 | Train Acc: 92.218 
62 Train Loss: 22.946 | Train Acc: 92.367 
63 Train Loss: 22.887 | Train Acc: 92.388 
64 Train Loss: 22.835 | Train Acc: 92.327 
65 Train Loss: 22.784 | Train Acc: 92.381 
66 Train Loss: 22.760 | Train Acc: 92.463 
67 Train Loss: 22.708 | Train Acc: 92.469 
68 Train Loss: 22.702 | Train Acc: 92.340 
69 Train Loss: 22.609 | Train Acc: 92.435 
70 Train Loss: 22.576 | Train Acc: 92.429 
71 Train Loss: 22.571 | Train Acc: 92.415 
72 Train Loss: 22.539 | Train Acc: 92.524 
73 Train Loss: 22.453 | Train Acc: 92.565 
74 Train Loss: 22.451 | Train Acc: 92.571 
75 Train Loss: 22.365 | Train Acc: 92.599 
76 Train Loss: 22.295 | Train Acc: 92.626 
77 Train Loss: 22.345 | Train Acc: 92.646 
78 Train Loss: 22.311 | Train Acc: 92.558 
79 Train Loss: 22.177 | Train Acc: 92.714 
80 Train Loss: 21.991 | Train Acc: 92.721 
81 Train Loss: 21.950 | Train Acc: 92.871 
82 Train Loss: 21.936 | Train Acc: 92.837 
83 Train Loss: 21.900 | Train Acc: 92.864 
84 Train Loss: 21.906 | Train Acc: 92.776 
85 Train Loss: 21.883 | Train Acc: 92.891 
86 Train Loss: 21.876 | Train Acc: 92.837 
87 Train Loss: 21.859 | Train Acc: 92.932 
88 Train Loss: 21.848 | Train Acc: 92.850 
89 Train Loss: 21.831 | Train Acc: 92.816 
90 Train Loss: 21.777 | Train Acc: 92.871 
91 Train Loss: 21.799 | Train Acc: 92.837 
92 Train Loss: 21.767 | Train Acc: 92.769 
93 Train Loss: 21.758 | Train Acc: 92.898 
94 Train Loss: 21.733 | Train Acc: 93.000 
95 Train Loss: 21.707 | Train Acc: 92.959 
96 Train Loss: 21.697 | Train Acc: 92.823 
97 Train Loss: 21.660 | Train Acc: 92.816 
98 Train Loss: 21.644 | Train Acc: 92.993 
99 Train Loss: 21.635 | Train Acc: 92.912 
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 12544])
Time Taken by Kmeans is  24.52499556541443
Kmeans completed successfully...
printing expected split from k means
{1: 1, 0: 0, 2: 1}
Printing final_dict items...
{0: 0, 1: 1, 2: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 63.485 | Acc: 77.767
1 Loss: 51.414 | Acc: 83.466
2 Loss: 46.566 | Acc: 85.137
3 Loss: 42.005 | Acc: 86.932
4 Loss: 38.395 | Acc: 87.822
5 Loss: 35.287 | Acc: 88.890
6 Loss: 32.093 | Acc: 89.993
7 Loss: 28.366 | Acc: 90.795
8 Loss: 26.483 | Acc: 91.418
9 Loss: 23.323 | Acc: 92.582
10 Loss: 17.401 | Acc: 94.664
11 Loss: 14.903 | Acc: 95.452
12 Loss: 13.654 | Acc: 95.966
13 Loss: 12.706 | Acc: 96.253
14 Loss: 12.021 | Acc: 96.514
15 Loss: 11.533 | Acc: 96.452
16 Loss: 9.868 | Acc: 97.014
17 Loss: 9.024 | Acc: 97.322
18 Loss: 9.082 | Acc: 97.301
19 Loss: 8.586 | Acc: 97.459
20 Loss: 6.776 | Acc: 98.137
21 Loss: 5.965 | Acc: 98.267
22 Loss: 5.331 | Acc: 98.466
23 Loss: 5.037 | Acc: 98.630
24 Loss: 5.003 | Acc: 98.767
25 Loss: 4.288 | Acc: 98.719
26 Loss: 4.609 | Acc: 98.685
27 Loss: 3.721 | Acc: 98.979
28 Loss: 3.381 | Acc: 99.158
29 Loss: 4.120 | Acc: 98.836
30 Loss: 3.550 | Acc: 99.068
31 Loss: 2.802 | Acc: 99.247
32 Loss: 3.089 | Acc: 99.158
33 Loss: 2.683 | Acc: 99.308
34 Loss: 3.048 | Acc: 99.219
35 Loss: 2.605 | Acc: 99.336
36 Loss: 2.394 | Acc: 99.349
37 Loss: 2.543 | Acc: 99.411
38 Loss: 2.522 | Acc: 99.418
39 Loss: 2.203 | Acc: 99.473
40 Loss: 2.098 | Acc: 99.514
41 Loss: 2.324 | Acc: 99.466
42 Loss: 2.012 | Acc: 99.500
43 Loss: 2.021 | Acc: 99.493
44 Loss: 1.958 | Acc: 99.493
45 Loss: 2.231 | Acc: 99.411
46 Loss: 1.807 | Acc: 99.500
47 Loss: 1.862 | Acc: 99.527
48 Loss: 1.700 | Acc: 99.589
49 Loss: 1.895 | Acc: 99.514
50 Loss: 1.628 | Acc: 99.596
51 Loss: 1.506 | Acc: 99.521
52 Loss: 1.780 | Acc: 99.575
53 Loss: 1.662 | Acc: 99.575
54 Loss: 1.715 | Acc: 99.514
55 Loss: 1.593 | Acc: 99.623
56 Loss: 1.509 | Acc: 99.664
57 Loss: 1.434 | Acc: 99.651
58 Loss: 1.955 | Acc: 99.493
59 Loss: 1.477 | Acc: 99.623
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
nodeId:  14 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 4900
nodeId:  15 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  8
Running nodeId:  9
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 56.215 | Train Acc: 70.020 
1 Train Loss: 47.011 | Train Acc: 77.622 
2 Train Loss: 43.900 | Train Acc: 79.684 
3 Train Loss: 41.710 | Train Acc: 81.092 
4 Train Loss: 39.349 | Train Acc: 82.184 
5 Train Loss: 37.415 | Train Acc: 83.622 
6 Train Loss: 37.193 | Train Acc: 83.602 
7 Train Loss: 34.725 | Train Acc: 85.327 
8 Train Loss: 35.350 | Train Acc: 84.673 
9 Train Loss: 32.151 | Train Acc: 86.306 
10 Train Loss: 31.325 | Train Acc: 86.827 
11 Train Loss: 31.068 | Train Acc: 87.071 
12 Train Loss: 29.420 | Train Acc: 87.561 
13 Train Loss: 28.927 | Train Acc: 88.112 
14 Train Loss: 27.991 | Train Acc: 88.306 
15 Train Loss: 28.074 | Train Acc: 88.418 
16 Train Loss: 26.110 | Train Acc: 89.367 
17 Train Loss: 25.855 | Train Acc: 89.520 
18 Train Loss: 25.483 | Train Acc: 89.847 
19 Train Loss: 24.988 | Train Acc: 89.776 
20 Train Loss: 22.757 | Train Acc: 91.020 
21 Train Loss: 22.163 | Train Acc: 91.296 
22 Train Loss: 22.457 | Train Acc: 91.194 
23 Train Loss: 21.868 | Train Acc: 91.561 
24 Train Loss: 21.800 | Train Acc: 91.398 
25 Train Loss: 21.690 | Train Acc: 91.520 
26 Train Loss: 21.196 | Train Acc: 91.776 
27 Train Loss: 20.861 | Train Acc: 92.031 
28 Train Loss: 20.963 | Train Acc: 91.888 
29 Train Loss: 20.460 | Train Acc: 92.184 
30 Train Loss: 20.577 | Train Acc: 91.724 
31 Train Loss: 20.132 | Train Acc: 92.316 
32 Train Loss: 20.031 | Train Acc: 92.276 
33 Train Loss: 20.419 | Train Acc: 92.204 
34 Train Loss: 19.829 | Train Acc: 92.316 
35 Train Loss: 19.565 | Train Acc: 92.633 
36 Train Loss: 19.208 | Train Acc: 92.673 
37 Train Loss: 18.916 | Train Acc: 92.694 
38 Train Loss: 19.072 | Train Acc: 92.724 
39 Train Loss: 19.037 | Train Acc: 92.918 
40 Train Loss: 17.880 | Train Acc: 93.214 
41 Train Loss: 17.712 | Train Acc: 93.327 
42 Train Loss: 17.664 | Train Acc: 93.520 
43 Train Loss: 17.526 | Train Acc: 93.531 
44 Train Loss: 17.622 | Train Acc: 93.388 
45 Train Loss: 17.341 | Train Acc: 93.745 
46 Train Loss: 17.389 | Train Acc: 93.806 
47 Train Loss: 17.240 | Train Acc: 93.939 
48 Train Loss: 17.313 | Train Acc: 93.704 
49 Train Loss: 17.182 | Train Acc: 93.949 
50 Train Loss: 17.073 | Train Acc: 93.908 
51 Train Loss: 17.138 | Train Acc: 93.745 
52 Train Loss: 16.896 | Train Acc: 94.000 
53 Train Loss: 16.867 | Train Acc: 93.918 
54 Train Loss: 16.932 | Train Acc: 93.939 
55 Train Loss: 16.747 | Train Acc: 94.061 
56 Train Loss: 16.644 | Train Acc: 94.010 
57 Train Loss: 16.629 | Train Acc: 94.071 
58 Train Loss: 16.421 | Train Acc: 94.102 
59 Train Loss: 16.643 | Train Acc: 94.224 
60 Train Loss: 16.008 | Train Acc: 94.439 
61 Train Loss: 15.975 | Train Acc: 94.357 
62 Train Loss: 15.982 | Train Acc: 94.490 
63 Train Loss: 15.969 | Train Acc: 94.520 
64 Train Loss: 16.018 | Train Acc: 94.357 
65 Train Loss: 15.891 | Train Acc: 94.684 
66 Train Loss: 15.866 | Train Acc: 94.622 
67 Train Loss: 15.774 | Train Acc: 94.531 
68 Train Loss: 15.755 | Train Acc: 94.480 
69 Train Loss: 15.785 | Train Acc: 94.602 
70 Train Loss: 15.676 | Train Acc: 94.510 
71 Train Loss: 15.687 | Train Acc: 94.673 
72 Train Loss: 15.737 | Train Acc: 94.469 
73 Train Loss: 15.635 | Train Acc: 94.694 
74 Train Loss: 15.727 | Train Acc: 94.551 
75 Train Loss: 15.647 | Train Acc: 94.724 
76 Train Loss: 15.529 | Train Acc: 94.724 
77 Train Loss: 15.549 | Train Acc: 94.541 
78 Train Loss: 15.423 | Train Acc: 94.663 
79 Train Loss: 15.574 | Train Acc: 94.806 
80 Train Loss: 15.271 | Train Acc: 94.867 
81 Train Loss: 15.274 | Train Acc: 94.898 
82 Train Loss: 15.271 | Train Acc: 94.878 
83 Train Loss: 15.266 | Train Acc: 94.847 
84 Train Loss: 15.246 | Train Acc: 94.949 
85 Train Loss: 15.267 | Train Acc: 94.827 
86 Train Loss: 15.203 | Train Acc: 94.857 
87 Train Loss: 15.236 | Train Acc: 94.878 
88 Train Loss: 15.212 | Train Acc: 94.827 
89 Train Loss: 15.184 | Train Acc: 94.908 
90 Train Loss: 15.208 | Train Acc: 94.980 
91 Train Loss: 15.182 | Train Acc: 94.898 
92 Train Loss: 15.166 | Train Acc: 94.959 
93 Train Loss: 15.117 | Train Acc: 94.837 
94 Train Loss: 15.120 | Train Acc: 94.990 
95 Train Loss: 15.103 | Train Acc: 94.969 
96 Train Loss: 15.131 | Train Acc: 95.000 
97 Train Loss: 15.109 | Train Acc: 94.918 
98 Train Loss: 15.111 | Train Acc: 94.939 
99 Train Loss: 15.148 | Train Acc: 94.908 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Time Taken by Kmeans is  13.849404573440552
Kmeans completed successfully...
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 91.222 | Acc: 78.398
1 Loss: 71.915 | Acc: 84.704
2 Loss: 63.984 | Acc: 86.500
3 Loss: 57.134 | Acc: 88.020
4 Loss: 51.626 | Acc: 89.255
5 Loss: 48.188 | Acc: 89.898
6 Loss: 41.919 | Acc: 91.378
7 Loss: 39.899 | Acc: 91.969
8 Loss: 34.799 | Acc: 93.082
9 Loss: 31.958 | Acc: 93.245
10 Loss: 22.119 | Acc: 95.755
11 Loss: 17.612 | Acc: 96.388
12 Loss: 15.931 | Acc: 96.633
13 Loss: 13.011 | Acc: 97.561
14 Loss: 12.035 | Acc: 97.776
15 Loss: 10.223 | Acc: 98.000
16 Loss: 9.517 | Acc: 98.184
17 Loss: 9.226 | Acc: 98.153
18 Loss: 7.787 | Acc: 98.643
19 Loss: 8.323 | Acc: 98.429
20 Loss: 6.335 | Acc: 98.867
21 Loss: 4.131 | Acc: 99.296
22 Loss: 2.750 | Acc: 99.622
23 Loss: 3.180 | Acc: 99.378
24 Loss: 2.940 | Acc: 99.531
25 Loss: 2.855 | Acc: 99.490
26 Loss: 2.627 | Acc: 99.633
27 Loss: 1.923 | Acc: 99.745
28 Loss: 2.887 | Acc: 99.541
29 Loss: 2.899 | Acc: 99.520
30 Loss: 1.834 | Acc: 99.714
31 Loss: 1.975 | Acc: 99.704
32 Loss: 1.293 | Acc: 99.837
33 Loss: 1.611 | Acc: 99.806
34 Loss: 1.688 | Acc: 99.704
35 Loss: 1.613 | Acc: 99.755
36 Loss: 1.771 | Acc: 99.765
37 Loss: 1.469 | Acc: 99.765
38 Loss: 1.600 | Acc: 99.735
39 Loss: 1.599 | Acc: 99.776
40 Loss: 1.286 | Acc: 99.837
41 Loss: 1.314 | Acc: 99.796
42 Loss: 0.821 | Acc: 99.918
43 Loss: 1.310 | Acc: 99.796
44 Loss: 0.989 | Acc: 99.888
45 Loss: 1.059 | Acc: 99.867
46 Loss: 1.109 | Acc: 99.827
47 Loss: 1.005 | Acc: 99.898
48 Loss: 0.849 | Acc: 99.888
49 Loss: 0.846 | Acc: 99.837
50 Loss: 0.817 | Acc: 99.918
51 Loss: 0.868 | Acc: 99.918
52 Loss: 0.663 | Acc: 99.929
53 Loss: 0.749 | Acc: 99.908
54 Loss: 0.833 | Acc: 99.878
55 Loss: 0.874 | Acc: 99.918
56 Loss: 0.875 | Acc: 99.918
57 Loss: 0.969 | Acc: 99.867
58 Loss: 0.677 | Acc: 99.918
59 Loss: 0.863 | Acc: 99.867
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 5
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 4
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 5
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 4
nodeId:  16 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 4900
nodeId:  17 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  12
Running nodeId:  13
Running nodeId:  14
Running nodeId:  15
0 Train Loss: 44.480 | Train Acc: 79.224 
1 Train Loss: 32.722 | Train Acc: 85.969 
2 Train Loss: 29.654 | Train Acc: 87.357 
3 Train Loss: 27.115 | Train Acc: 88.898 
4 Train Loss: 25.857 | Train Acc: 89.643 
5 Train Loss: 24.534 | Train Acc: 89.888 
6 Train Loss: 22.619 | Train Acc: 90.939 
7 Train Loss: 21.152 | Train Acc: 91.286 
8 Train Loss: 21.197 | Train Acc: 91.235 
9 Train Loss: 19.896 | Train Acc: 92.031 
10 Train Loss: 18.982 | Train Acc: 92.643 
11 Train Loss: 17.736 | Train Acc: 93.082 
12 Train Loss: 18.143 | Train Acc: 93.071 
13 Train Loss: 17.194 | Train Acc: 93.571 
14 Train Loss: 16.662 | Train Acc: 93.316 
15 Train Loss: 15.458 | Train Acc: 94.224 
16 Train Loss: 15.399 | Train Acc: 94.143 
17 Train Loss: 15.245 | Train Acc: 94.245 
18 Train Loss: 14.446 | Train Acc: 94.643 
19 Train Loss: 13.598 | Train Acc: 95.082 
20 Train Loss: 12.506 | Train Acc: 95.633 
21 Train Loss: 12.079 | Train Acc: 95.796 
22 Train Loss: 11.787 | Train Acc: 96.000 
23 Train Loss: 11.731 | Train Acc: 95.980 
24 Train Loss: 11.972 | Train Acc: 95.724 
25 Train Loss: 11.317 | Train Acc: 96.173 
26 Train Loss: 11.421 | Train Acc: 96.143 
27 Train Loss: 11.101 | Train Acc: 96.367 
28 Train Loss: 11.010 | Train Acc: 96.337 
29 Train Loss: 11.051 | Train Acc: 96.265 
30 Train Loss: 11.311 | Train Acc: 96.245 
31 Train Loss: 11.023 | Train Acc: 96.133 
32 Train Loss: 10.633 | Train Acc: 96.520 
33 Train Loss: 10.392 | Train Acc: 96.653 
34 Train Loss: 10.654 | Train Acc: 96.439 
35 Train Loss: 10.298 | Train Acc: 96.571 
36 Train Loss: 10.103 | Train Acc: 96.684 
37 Train Loss: 10.115 | Train Acc: 96.684 
38 Train Loss: 10.230 | Train Acc: 96.490 
39 Train Loss: 9.564 | Train Acc: 96.827 
40 Train Loss: 9.016 | Train Acc: 97.276 
41 Train Loss: 8.928 | Train Acc: 97.357 
42 Train Loss: 8.873 | Train Acc: 97.194 
43 Train Loss: 8.821 | Train Acc: 97.459 
44 Train Loss: 8.754 | Train Acc: 97.408 
45 Train Loss: 8.669 | Train Acc: 97.337 
46 Train Loss: 8.661 | Train Acc: 97.418 
47 Train Loss: 8.600 | Train Acc: 97.398 
48 Train Loss: 8.565 | Train Acc: 97.469 
49 Train Loss: 8.543 | Train Acc: 97.510 
50 Train Loss: 8.391 | Train Acc: 97.551 
51 Train Loss: 8.347 | Train Acc: 97.459 
52 Train Loss: 8.373 | Train Acc: 97.582 
53 Train Loss: 8.282 | Train Acc: 97.480 
54 Train Loss: 8.357 | Train Acc: 97.439 
55 Train Loss: 8.424 | Train Acc: 97.398 
56 Train Loss: 8.075 | Train Acc: 97.663 
57 Train Loss: 8.102 | Train Acc: 97.653 
58 Train Loss: 8.069 | Train Acc: 97.735 
59 Train Loss: 7.976 | Train Acc: 97.673 
60 Train Loss: 7.717 | Train Acc: 97.898 
61 Train Loss: 7.737 | Train Acc: 97.786 
62 Train Loss: 7.690 | Train Acc: 97.847 
63 Train Loss: 7.645 | Train Acc: 97.806 
64 Train Loss: 7.631 | Train Acc: 97.908 
65 Train Loss: 7.580 | Train Acc: 97.990 
66 Train Loss: 7.577 | Train Acc: 97.878 
67 Train Loss: 7.562 | Train Acc: 97.980 
68 Train Loss: 7.597 | Train Acc: 97.898 
69 Train Loss: 7.567 | Train Acc: 97.969 
70 Train Loss: 7.500 | Train Acc: 97.990 
71 Train Loss: 7.494 | Train Acc: 98.010 
72 Train Loss: 7.458 | Train Acc: 97.949 
73 Train Loss: 7.482 | Train Acc: 97.949 
74 Train Loss: 7.382 | Train Acc: 97.980 
75 Train Loss: 7.480 | Train Acc: 98.031 
76 Train Loss: 7.440 | Train Acc: 97.959 
77 Train Loss: 7.393 | Train Acc: 98.051 
78 Train Loss: 7.323 | Train Acc: 98.010 
79 Train Loss: 7.333 | Train Acc: 97.939 
80 Train Loss: 7.201 | Train Acc: 98.112 
81 Train Loss: 7.191 | Train Acc: 98.082 
82 Train Loss: 7.171 | Train Acc: 98.031 
83 Train Loss: 7.173 | Train Acc: 98.122 
84 Train Loss: 7.161 | Train Acc: 98.082 
85 Train Loss: 7.131 | Train Acc: 98.163 
86 Train Loss: 7.140 | Train Acc: 98.041 
87 Train Loss: 7.122 | Train Acc: 98.143 
88 Train Loss: 7.113 | Train Acc: 98.133 
89 Train Loss: 7.106 | Train Acc: 98.061 
90 Train Loss: 7.095 | Train Acc: 98.153 
91 Train Loss: 7.084 | Train Acc: 98.153 
92 Train Loss: 7.111 | Train Acc: 98.184 
93 Train Loss: 7.082 | Train Acc: 98.102 
94 Train Loss: 7.053 | Train Acc: 98.133 
95 Train Loss: 7.036 | Train Acc: 98.184 
96 Train Loss: 7.048 | Train Acc: 98.092 
97 Train Loss: 7.044 | Train Acc: 98.184 
98 Train Loss: 7.049 | Train Acc: 98.133 
99 Train Loss: 7.033 | Train Acc: 98.153 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Time Taken by Kmeans is  12.211859941482544
Kmeans completed successfully...
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 68.656 | Acc: 85.255
1 Loss: 51.872 | Acc: 89.531
2 Loss: 44.244 | Acc: 91.235
3 Loss: 40.726 | Acc: 91.561
4 Loss: 35.688 | Acc: 92.786
5 Loss: 31.960 | Acc: 93.327
6 Loss: 30.739 | Acc: 94.235
7 Loss: 26.016 | Acc: 94.622
8 Loss: 24.696 | Acc: 95.031
9 Loss: 22.990 | Acc: 95.480
10 Loss: 15.850 | Acc: 97.092
11 Loss: 12.247 | Acc: 97.633
12 Loss: 11.814 | Acc: 97.847
13 Loss: 10.322 | Acc: 98.102
14 Loss: 9.685 | Acc: 98.347
15 Loss: 9.194 | Acc: 98.316
16 Loss: 8.981 | Acc: 98.398
17 Loss: 8.224 | Acc: 98.490
18 Loss: 8.229 | Acc: 98.571
19 Loss: 6.838 | Acc: 98.786
20 Loss: 4.550 | Acc: 99.235
21 Loss: 4.121 | Acc: 99.296
22 Loss: 3.285 | Acc: 99.480
23 Loss: 3.425 | Acc: 99.449
24 Loss: 2.976 | Acc: 99.500
25 Loss: 3.548 | Acc: 99.469
26 Loss: 2.468 | Acc: 99.643
27 Loss: 3.198 | Acc: 99.449
28 Loss: 2.873 | Acc: 99.490
29 Loss: 2.303 | Acc: 99.684
30 Loss: 2.181 | Acc: 99.704
31 Loss: 2.070 | Acc: 99.704
32 Loss: 1.464 | Acc: 99.806
33 Loss: 1.301 | Acc: 99.796
34 Loss: 1.230 | Acc: 99.847
35 Loss: 1.608 | Acc: 99.724
36 Loss: 1.324 | Acc: 99.776
37 Loss: 1.533 | Acc: 99.735
38 Loss: 1.196 | Acc: 99.816
39 Loss: 1.339 | Acc: 99.776
40 Loss: 1.501 | Acc: 99.796
41 Loss: 1.053 | Acc: 99.867
42 Loss: 1.158 | Acc: 99.816
43 Loss: 0.775 | Acc: 99.898
44 Loss: 0.767 | Acc: 99.929
45 Loss: 0.880 | Acc: 99.898
46 Loss: 0.846 | Acc: 99.888
47 Loss: 0.650 | Acc: 99.929
48 Loss: 0.608 | Acc: 99.949
49 Loss: 0.813 | Acc: 99.878
50 Loss: 0.817 | Acc: 99.867
51 Loss: 0.915 | Acc: 99.847
52 Loss: 0.833 | Acc: 99.908
53 Loss: 0.728 | Acc: 99.898
54 Loss: 0.739 | Acc: 99.878
55 Loss: 0.825 | Acc: 99.888
56 Loss: 0.551 | Acc: 99.949
57 Loss: 0.714 | Acc: 99.888
58 Loss: 0.921 | Acc: 99.857
59 Loss: 0.888 | Acc: 99.867
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 9
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 9
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  18 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 4900
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 61.210
Split Acc: 87.170
lTrainDict[data].shape:  torch.Size([5143, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([5143])
rTrainDict[data].shape:  torch.Size([4857, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4857])
# of Left images:  5143.0
# of Right images:  4857.0
giniRightRatio:  0.8370423131836109
giniLeftRatio:  0.8438497206606965
impurityDrop:  0.8442505686200225
giniGain:  0.055749431379977565
lclasses:  [91, 47, 424, 856, 856, 909, 909, 900, 59, 92]
rclasses:  [909, 953, 576, 144, 144, 91, 91, 100, 941, 908]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([5143, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5143
nodeId:  3 , imgTensorShape :  torch.Size([4857, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4857
Nodes sizes =  5 5
Node 2 Acc: 56.446
Split Acc: 65.584
lTrainDict[data].shape:  torch.Size([2046, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2046])
rTrainDict[data].shape:  torch.Size([3097, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3097])
# of Left images:  2046.0
# of Right images:  3097.0
giniRightRatio:  0.8123626049102901
giniLeftRatio:  0.774643129812934
impurityDrop:  0.7874436362150397
giniGain:  0.05640608444565687
lclasses:  [37, 23, 136, 487, 166, 301, 69, 748, 28, 51]
rclasses:  [54, 24, 288, 369, 690, 608, 840, 152, 31, 41]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([2046, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2046
nodeId:  5 , imgTensorShape :  torch.Size([3097, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3097
Nodes sizes =  2 3
Node 3 Acc: 65.287
Split Acc: 75.293
lTrainDict[data].shape:  torch.Size([1818, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1818])
rTrainDict[data].shape:  torch.Size([3039, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3039])
# of Left images:  1818.0
# of Right images:  3039.0
giniRightRatio:  0.7735479135394744
giniLeftRatio:  0.7543813787319326
impurityDrop:  0.762082049676325
giniGain:  0.0749602635072859
lclasses:  [82, 737, 463, 72, 83, 60, 60, 42, 74, 145]
rclasses:  [827, 216, 113, 72, 61, 31, 31, 58, 867, 763]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([1818, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1818
nodeId:  7 , imgTensorShape :  torch.Size([3039, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3039
Nodes sizes =  2 3
Node 4 Acc: 53.861
Split Acc: 54.448
lTrainDict[data].shape:  torch.Size([1026, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1026])
rTrainDict[data].shape:  torch.Size([1020, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1020])
# of Left images:  1026.0
# of Right images:  1020.0
giniRightRatio:  0.5222029988465975
giniLeftRatio:  0.7592820582971399
impurityDrop:  0.7606766409997902
giniGain:  0.013966488813143885
lclasses:  [24, 17, 92, 423, 83, 225, 56, 57, 20, 29]
rclasses:  [13, 6, 44, 64, 83, 76, 13, 691, 8, 22]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([1026, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 1026
nodeId:  9 , imgTensorShape :  torch.Size([1020, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 1020
Nodes sizes =  1 1
Node 5 Acc: 56.506
Split Acc: 61.737
lTrainDict[data].shape:  torch.Size([1096, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1096])
rTrainDict[data].shape:  torch.Size([2001, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2001])
# of Left images:  1096.0
# of Right images:  2001.0
giniRightRatio:  0.7888129898069457
giniLeftRatio:  0.5243087005168097
impurityDrop:  0.6439370772322385
giniGain:  0.16842552767805163
lclasses:  [22, 7, 82, 80, 72, 55, 741, 12, 14, 11]
rclasses:  [32, 17, 206, 289, 618, 553, 99, 140, 17, 30]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([1096, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1096
nodeId:  11 , imgTensorShape :  torch.Size([2001, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2001
Nodes sizes =  1 2
Node 6 Acc: 63.586
Split Acc: 63.751
lTrainDict[data].shape:  torch.Size([994, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([994])
rTrainDict[data].shape:  torch.Size([824, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([824])
# of Left images:  994.0
# of Right images:  824.0
giniRightRatio:  0.6796941276274862
giniLeftRatio:  0.462193685250335
impurityDrop:  0.4173210211676702
giniGain:  0.33706035756426234
lclasses:  [25, 714, 18, 14, 8, 5, 15, 9, 56, 130]
rclasses:  [57, 23, 445, 58, 75, 55, 45, 33, 18, 15]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([994, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 994
nodeId:  13 , imgTensorShape :  torch.Size([824, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 824
Nodes sizes =  1 1
Node 7 Acc: 68.213
Split Acc: 71.767
lTrainDict[data].shape:  torch.Size([1011, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1011])
rTrainDict[data].shape:  torch.Size([2028, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2028])
# of Left images:  1011.0
# of Right images:  2028.0
giniRightRatio:  0.7082117611817202
giniLeftRatio:  0.5360422102666905
impurityDrop:  0.622381674408991
giniGain:  0.15116623913048344
lclasses:  [676, 27, 72, 32, 35, 9, 6, 29, 75, 50]
rclasses:  [151, 189, 41, 40, 26, 22, 25, 29, 792, 713]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([1011, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 1011
nodeId:  15 , imgTensorShape :  torch.Size([2028, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2028
Nodes sizes =  1 2
Node 8 Acc: 41.228
Node 9 Acc: 67.745
Node 10 Acc: 67.609
Node 11 Acc: 51.774
Split Acc: 52.624
lTrainDict[data].shape:  torch.Size([1011, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1011])
rTrainDict[data].shape:  torch.Size([990, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([990])
# of Left images:  1011.0
# of Right images:  990.0
giniRightRatio:  0.6404081216202427
giniLeftRatio:  0.7049713292261873
impurityDrop:  0.706340851811768
giniGain:  0.08247213799517772
lclasses:  [10, 8, 85, 214, 52, 487, 50, 74, 11, 20]
rclasses:  [22, 9, 121, 75, 566, 66, 49, 66, 6, 10]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([1011, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1011
nodeId:  17 , imgTensorShape :  torch.Size([990, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 990
Nodes sizes =  1 1
Node 12 Acc: 71.831
Node 13 Acc: 54.005
Node 14 Acc: 66.864
Node 15 Acc: 68.984
Split Acc: 69.822
lTrainDict[data].shape:  torch.Size([1003, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1003])
rTrainDict[data].shape:  torch.Size([1025, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1025])
# of Left images:  1003.0
# of Right images:  1025.0
giniRightRatio:  0.4542534205829863
giniLeftRatio:  0.530780539736722
impurityDrop:  0.5291380064475687
giniGain:  0.17907375473415155
lclasses:  [50, 128, 22, 22, 11, 13, 16, 25, 46, 670]
rclasses:  [101, 61, 19, 18, 15, 9, 9, 4, 746, 43]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1003, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1003
nodeId:  19 , imgTensorShape :  torch.Size([1025, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 1025
Nodes sizes =  1 1
Node 16 Acc: 48.170
Node 17 Acc: 57.172
Node 18 Acc: 66.800
Node 19 Acc: 72.780
[[676  25  57  24  22  10  22  13 101  50]
 [ 27 714  23  17   9   8   7   6  61 128]
 [ 72  18 445  92 121  85  82  44  19  22]
 [ 32  14  58 423  75 214  80  64  18  22]
 [ 35   8  75  83 566  52  72  83  15  11]
 [  9   5  55 225  66 487  55  76   9  13]
 [  6  15  45  56  49  50 741  13   9  16]
 [ 29   9  33  57  66  74  12 691   4  25]
 [ 75  56  18  20   6  11  14   8 746  46]
 [ 50 130  15  29  10  20  11  22  43 670]]

Final Acc: 61.590

Level 0 Acc: 61.210
Level 1 Acc: 60.740
Level 2 Acc: 60.810
Level 3 Acc: 61.250
Level 4 Acc: 61.590

                                                             1                                                                 
                   ┌─────────────────────────────────────────┴───────────────────────────┐                                     
                   2                                                                     3                                     
       ┌───────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
       4                         5                                         6                           7                       
 ┌─────┴─────┐            ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
 8           9            10                   11                   12            13            14                   15        
                                        ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                        16            17                                                      18            19 

                                                       -1                                                      
                   ┌───────────────────────────────────┴───────────────────────┐                               
                   -1                                                          -1                              
       ┌───────────┴───────────┐                                   ┌───────────┴───────────┐                   
       -1                      -1                                  -1                      -1                  
 ┌─────┴─────┐           ┌─────┴───────────┐                 ┌─────┴─────┐           ┌─────┴───────────┐       
 3           7           6                 -1                1           2           0                 -1      
                                     ┌─────┴─────┐                                               ┌─────┴─────┐ 
                                     5           4                                               9           8 

                                                                         49000                                                                         
                           ┌───────────────────────────────────────────────┴───────────────────────────────┐                                           
                         24500                                                                           24500                                         
           ┌───────────────┴───────────────┐                                               ┌───────────────┴───────────────┐                           
          9800                           14700                                            9800                           14700                         
   ┌───────┴───────┐               ┌───────┴───────────────┐                       ┌───────┴───────┐               ┌───────┴───────────────┐           
  4900            4900            4900                    9800                    4900            4900            4900                    9800         
                                                   ┌───────┴───────┐                                                               ┌───────┴───────┐   
                                                  4900            4900                                                            4900            4900 

                                                   {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                  
                                   ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────┐                                                       
             {3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900}                                                       {0: 4900, 1: 4900, 2: 4900, 8: 4900, 9: 4900}                                 
               ┌───────────────────┴───────────────────┐                                                           ┌───────────────────┴───────────────────┐                                   
       {3: 4900, 7: 4900}                 {4: 4900, 5: 4900, 6: 4900}                                      {1: 4900, 2: 4900}                 {0: 4900, 8: 4900, 9: 4900}                      
     ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐                             ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐               
 {3: 4900}           {7: 4900}           {6: 4900}                 {4: 4900, 5: 4900}                {1: 4900}           {2: 4900}           {0: 4900}                 {8: 4900, 9: 4900}      
                                                                 ┌─────────┴─────────┐                                                                               ┌─────────┴─────────┐     
                                                             {5: 4900}           {4: 4900}                                                                       {9: 4900}           {8: 4900} 

                                                               87.17                                                                 
                       ┌─────────────────────────────────────────┴─────────────────────────────┐                                     
               65.58428932529652                                                       75.29339098208771                             
         ┌─────────────┴─────────────┐                                          ┌──────────────┴─────────────┐                       
 54.44770283479961           61.73716499838554                          63.751375137513755            71.7670286278381               
  ┌──────┴──────┐             ┌──────┴─────────────┐                     ┌──────┴──────┐              ┌──────┴─────────────┐         
 0.0           0.0           0.0           52.62368815592204            0.0           0.0            0.0            69.8224852071006 
                                            ┌──────┴──────┐                                                         ┌──────┴──────┐  
                                           0.0           0.0                                                       0.0           0.0 

                                                               ┌[423, 1026, 41.228]
                                          ┌[1102, 2046, 53.861]┤
                                          │                    └[691, 1020, 67.745]
                     ┌[2903, 5143, 56.446]┤
                     │                    │                    ┌[741, 1096, 67.609]
                     │                    └[1750, 3097, 56.506]┤
                     │                                         │                    ┌[487, 1011, 48.17]
                     │                                         └[1036, 2001, 51.774]┤
                     │                                                              └[566, 990, 57.172]
 [6121, 10000, 61.21]┤
                     │                                         ┌[714, 994, 71.831]
                     │                    ┌[1156, 1818, 63.586]┤
                     │                    │                    └[445, 824, 54.005]
                     └[3171, 4857, 65.287]┤
                                          │                    ┌[676, 1011, 66.864]
                                          └[2073, 3039, 68.213]┤
                                                               │                    ┌[670, 1003, 66.8]
                                                               └[1399, 2028, 68.984]┤
                                                                                    └[746, 1025, 72.78]

                                                         0.09999999999999987                                                         
                       ┌──────────────────────────────────────────┴───────────────────────────┐                                      
              0.24444444444444458                                                    0.24444444444444458                             
         ┌─────────────┴──────────────┐                                         ┌─────────────┴──────────────┐                       
        0.5                  0.41666666666666674                               0.5                  0.41666666666666674              
  ┌──────┴──────┐             ┌──────┴─────────────┐                     ┌──────┴──────┐             ┌──────┴─────────────┐          
 0.0           0.0           0.0                  0.5                   0.0           0.0           0.0                  0.5         
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐   
                                           0.0           0.0                                                      0.0           0.0  

Time Taken by whole program is  1599.97234582901
