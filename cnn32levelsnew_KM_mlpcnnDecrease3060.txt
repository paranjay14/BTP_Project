['options.ckptDir: cnn16levelsnewDir_KM', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 32', 'options.mlpFC1: 516', 'options.mlpFC2: 32']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 181.696 | Train Acc: 37.198 
1 Train Loss: 139.607 | Train Acc: 51.280 
2 Train Loss: 129.667 | Train Acc: 54.745 
3 Train Loss: 122.588 | Train Acc: 57.400 
4 Train Loss: 117.222 | Train Acc: 59.402 
5 Train Loss: 113.060 | Train Acc: 60.953 
6 Train Loss: 109.800 | Train Acc: 61.933 
7 Train Loss: 106.419 | Train Acc: 63.557 
8 Train Loss: 103.097 | Train Acc: 64.443 
9 Train Loss: 99.393 | Train Acc: 65.845 
10 Train Loss: 96.041 | Train Acc: 67.088 
11 Train Loss: 93.782 | Train Acc: 67.792 
12 Train Loss: 92.257 | Train Acc: 68.378 
13 Train Loss: 88.762 | Train Acc: 69.569 
14 Train Loss: 86.676 | Train Acc: 70.557 
15 Train Loss: 83.903 | Train Acc: 71.337 
16 Train Loss: 82.835 | Train Acc: 71.596 
17 Train Loss: 80.330 | Train Acc: 72.600 
18 Train Loss: 78.970 | Train Acc: 73.190 
19 Train Loss: 76.078 | Train Acc: 74.253 
20 Train Loss: 71.174 | Train Acc: 76.478 
21 Train Loss: 70.451 | Train Acc: 76.786 
22 Train Loss: 69.412 | Train Acc: 77.280 
23 Train Loss: 68.744 | Train Acc: 77.227 
24 Train Loss: 67.908 | Train Acc: 77.816 
25 Train Loss: 67.476 | Train Acc: 77.800 
26 Train Loss: 66.653 | Train Acc: 78.151 
27 Train Loss: 65.801 | Train Acc: 78.453 
28 Train Loss: 64.962 | Train Acc: 78.831 
29 Train Loss: 64.592 | Train Acc: 79.055 
30 Train Loss: 63.945 | Train Acc: 79.237 
31 Train Loss: 62.946 | Train Acc: 79.543 
32 Train Loss: 62.299 | Train Acc: 79.843 
33 Train Loss: 61.742 | Train Acc: 80.063 
34 Train Loss: 61.224 | Train Acc: 80.255 
35 Train Loss: 60.305 | Train Acc: 80.476 
36 Train Loss: 59.333 | Train Acc: 81.096 
37 Train Loss: 59.088 | Train Acc: 80.922 
38 Train Loss: 58.211 | Train Acc: 81.396 
39 Train Loss: 57.735 | Train Acc: 81.600 
40 Train Loss: 55.327 | Train Acc: 82.851 
41 Train Loss: 54.910 | Train Acc: 83.078 
42 Train Loss: 54.461 | Train Acc: 83.300 
43 Train Loss: 54.362 | Train Acc: 83.233 
44 Train Loss: 54.020 | Train Acc: 83.404 
45 Train Loss: 53.769 | Train Acc: 83.496 
46 Train Loss: 53.706 | Train Acc: 83.512 
47 Train Loss: 53.341 | Train Acc: 83.727 
48 Train Loss: 53.054 | Train Acc: 83.765 
49 Train Loss: 52.853 | Train Acc: 83.724 
50 Train Loss: 52.494 | Train Acc: 83.961 
51 Train Loss: 52.089 | Train Acc: 84.241 
52 Train Loss: 52.091 | Train Acc: 84.114 
53 Train Loss: 51.778 | Train Acc: 84.259 
54 Train Loss: 51.371 | Train Acc: 84.516 
55 Train Loss: 51.148 | Train Acc: 84.502 
56 Train Loss: 50.848 | Train Acc: 84.596 
57 Train Loss: 50.600 | Train Acc: 84.712 
58 Train Loss: 50.392 | Train Acc: 84.827 
59 Train Loss: 50.083 | Train Acc: 84.961 
60 Train Loss: 49.022 | Train Acc: 85.459 
61 Train Loss: 48.871 | Train Acc: 85.594 
62 Train Loss: 48.792 | Train Acc: 85.704 
63 Train Loss: 48.693 | Train Acc: 85.602 
64 Train Loss: 48.560 | Train Acc: 85.716 
65 Train Loss: 48.492 | Train Acc: 85.771 
66 Train Loss: 48.367 | Train Acc: 85.867 
67 Train Loss: 48.270 | Train Acc: 85.800 
68 Train Loss: 48.135 | Train Acc: 85.904 
69 Train Loss: 48.010 | Train Acc: 85.951 
70 Train Loss: 47.991 | Train Acc: 85.978 
71 Train Loss: 47.850 | Train Acc: 86.071 
72 Train Loss: 47.680 | Train Acc: 86.092 
73 Train Loss: 47.613 | Train Acc: 86.147 
74 Train Loss: 47.534 | Train Acc: 86.014 
75 Train Loss: 47.397 | Train Acc: 86.206 
76 Train Loss: 47.310 | Train Acc: 86.222 
77 Train Loss: 47.216 | Train Acc: 86.218 
78 Train Loss: 47.062 | Train Acc: 86.365 
79 Train Loss: 46.910 | Train Acc: 86.351 
80 Train Loss: 46.485 | Train Acc: 86.678 
81 Train Loss: 46.448 | Train Acc: 86.624 
82 Train Loss: 46.436 | Train Acc: 86.673 
83 Train Loss: 46.374 | Train Acc: 86.596 
84 Train Loss: 46.325 | Train Acc: 86.643 
85 Train Loss: 46.263 | Train Acc: 86.669 
86 Train Loss: 46.238 | Train Acc: 86.633 
87 Train Loss: 46.194 | Train Acc: 86.737 
88 Train Loss: 46.137 | Train Acc: 86.731 
89 Train Loss: 46.137 | Train Acc: 86.722 
90 Train Loss: 46.065 | Train Acc: 86.786 
91 Train Loss: 46.018 | Train Acc: 86.769 
92 Train Loss: 45.970 | Train Acc: 86.820 
93 Train Loss: 45.917 | Train Acc: 86.806 
94 Train Loss: 45.884 | Train Acc: 86.827 
95 Train Loss: 45.858 | Train Acc: 86.865 
96 Train Loss: 45.816 | Train Acc: 86.939 
97 Train Loss: 45.744 | Train Acc: 86.902 
98 Train Loss: 45.676 | Train Acc: 86.886 
99 Train Loss: 45.663 | Train Acc: 86.945 
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 25088])
Time Taken by Kmeans is  8.236042261123657
Kmeans completed successfully...
printing expected split from k means
{9: 1, 5: 0, 2: 0, 4: 0, 7: 0, 3: 0, 1: 1, 0: 1, 6: 0, 8: 1}
Printing final_dict items...
{9: 1, 5: 0, 2: 0, 4: 0, 7: 0, 3: 0, 1: 1, 0: 1, 6: 0, 8: 1}
Image Statistics before MLP : L R :  29400 19600
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 45.038 | Acc: 88.376
1 Loss: 36.169 | Acc: 90.865
2 Loss: 32.652 | Acc: 91.729
3 Loss: 29.774 | Acc: 92.451
4 Loss: 27.177 | Acc: 93.037
5 Loss: 24.296 | Acc: 93.761
6 Loss: 22.123 | Acc: 94.276
7 Loss: 20.833 | Acc: 94.631
8 Loss: 18.175 | Acc: 95.339
9 Loss: 16.678 | Acc: 95.739
10 Loss: 12.293 | Acc: 96.914
11 Loss: 10.852 | Acc: 97.222
12 Loss: 9.848 | Acc: 97.516
13 Loss: 8.596 | Acc: 97.829
14 Loss: 7.812 | Acc: 98.057
15 Loss: 7.557 | Acc: 98.122
16 Loss: 6.733 | Acc: 98.363
17 Loss: 6.801 | Acc: 98.337
18 Loss: 6.138 | Acc: 98.445
19 Loss: 5.747 | Acc: 98.614
20 Loss: 4.474 | Acc: 98.951
21 Loss: 3.794 | Acc: 99.147
22 Loss: 3.855 | Acc: 99.131
23 Loss: 3.267 | Acc: 99.224
24 Loss: 2.956 | Acc: 99.322
25 Loss: 3.208 | Acc: 99.210
26 Loss: 2.955 | Acc: 99.320
27 Loss: 2.822 | Acc: 99.363
28 Loss: 2.540 | Acc: 99.439
29 Loss: 2.718 | Acc: 99.386
30 Loss: 2.105 | Acc: 99.537
31 Loss: 2.031 | Acc: 99.592
32 Loss: 2.087 | Acc: 99.567
33 Loss: 1.885 | Acc: 99.563
34 Loss: 1.773 | Acc: 99.627
35 Loss: 1.811 | Acc: 99.600
36 Loss: 1.976 | Acc: 99.573
37 Loss: 1.851 | Acc: 99.594
38 Loss: 1.673 | Acc: 99.641
39 Loss: 1.533 | Acc: 99.678
40 Loss: 1.537 | Acc: 99.678
41 Loss: 1.628 | Acc: 99.647
42 Loss: 1.456 | Acc: 99.665
43 Loss: 1.549 | Acc: 99.673
44 Loss: 1.450 | Acc: 99.694
45 Loss: 1.323 | Acc: 99.739
46 Loss: 1.361 | Acc: 99.722
47 Loss: 1.263 | Acc: 99.737
48 Loss: 1.335 | Acc: 99.718
49 Loss: 1.217 | Acc: 99.753
50 Loss: 1.331 | Acc: 99.722
51 Loss: 1.371 | Acc: 99.714
52 Loss: 1.282 | Acc: 99.727
53 Loss: 1.070 | Acc: 99.773
54 Loss: 1.150 | Acc: 99.751
55 Loss: 1.224 | Acc: 99.763
56 Loss: 1.242 | Acc: 99.739
57 Loss: 1.287 | Acc: 99.741
58 Loss: 1.129 | Acc: 99.749
59 Loss: 1.184 | Acc: 99.741
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([29400, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([29400])
rTrainDict[data].shape:  torch.Size([19600, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([19600])
lValDict[data].shape:  torch.Size([600, 3, 32, 32])   lValDict[label].shape:  torch.Size([600])
rValDict[data].shape:  torch.Size([400, 3, 32, 32])   rValDict[label].shape:  torch.Size([400])
# of Left images:  29400.0
# of Right images:  19600.0
giniRightRatio:  0.75
giniLeftRatio:  0.8333333333333333
impurityDrop:  0.875
giniGain:  0.025000000000000022
lclasses:  [0, 0, 4900, 4900, 4900, 4900, 4900, 4900, 0, 0]
rclasses:  [4900, 4900, 0, 0, 0, 0, 0, 0, 4900, 4900]
noOfLeftClasses:  6
noOfRightClasses:  4
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([29400, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 6 ,  numData: 29400
nodeId:  3 , imgTensorShape :  torch.Size([19600, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 19600
Running nodeId:  2
0 Train Loss: 151.127 | Train Acc: 40.551 
1 Train Loss: 130.012 | Train Acc: 50.673 
2 Train Loss: 121.799 | Train Acc: 54.422 
3 Train Loss: 115.435 | Train Acc: 57.105 
4 Train Loss: 110.204 | Train Acc: 59.027 
5 Train Loss: 106.964 | Train Acc: 60.228 
6 Train Loss: 103.599 | Train Acc: 61.575 
7 Train Loss: 99.359 | Train Acc: 63.187 
8 Train Loss: 96.713 | Train Acc: 64.619 
9 Train Loss: 93.251 | Train Acc: 65.724 
10 Train Loss: 90.420 | Train Acc: 66.990 
11 Train Loss: 88.580 | Train Acc: 67.762 
12 Train Loss: 86.225 | Train Acc: 68.633 
13 Train Loss: 83.648 | Train Acc: 69.935 
14 Train Loss: 82.534 | Train Acc: 70.136 
15 Train Loss: 79.371 | Train Acc: 71.401 
16 Train Loss: 76.180 | Train Acc: 73.024 
17 Train Loss: 75.289 | Train Acc: 73.027 
18 Train Loss: 73.372 | Train Acc: 73.731 
19 Train Loss: 71.518 | Train Acc: 74.891 
20 Train Loss: 65.377 | Train Acc: 77.585 
21 Train Loss: 64.362 | Train Acc: 77.918 
22 Train Loss: 63.588 | Train Acc: 78.510 
23 Train Loss: 62.489 | Train Acc: 79.167 
24 Train Loss: 61.862 | Train Acc: 79.061 
25 Train Loss: 61.128 | Train Acc: 79.316 
26 Train Loss: 60.373 | Train Acc: 79.762 
27 Train Loss: 59.617 | Train Acc: 80.112 
28 Train Loss: 58.922 | Train Acc: 80.340 
29 Train Loss: 58.295 | Train Acc: 80.694 
30 Train Loss: 57.804 | Train Acc: 80.881 
31 Train Loss: 56.880 | Train Acc: 81.439 
32 Train Loss: 56.438 | Train Acc: 81.446 
33 Train Loss: 55.508 | Train Acc: 81.748 
34 Train Loss: 54.596 | Train Acc: 82.306 
35 Train Loss: 54.343 | Train Acc: 82.133 
36 Train Loss: 53.672 | Train Acc: 82.378 
37 Train Loss: 53.137 | Train Acc: 82.796 
38 Train Loss: 52.554 | Train Acc: 82.929 
39 Train Loss: 51.783 | Train Acc: 83.286 
40 Train Loss: 49.444 | Train Acc: 84.884 
41 Train Loss: 48.867 | Train Acc: 85.150 
42 Train Loss: 48.726 | Train Acc: 84.966 
43 Train Loss: 48.304 | Train Acc: 85.449 
44 Train Loss: 48.062 | Train Acc: 85.463 
45 Train Loss: 47.971 | Train Acc: 85.534 
46 Train Loss: 47.764 | Train Acc: 85.602 
47 Train Loss: 47.380 | Train Acc: 85.690 
48 Train Loss: 47.416 | Train Acc: 85.714 
49 Train Loss: 47.095 | Train Acc: 85.806 
50 Train Loss: 46.713 | Train Acc: 85.990 
51 Train Loss: 46.400 | Train Acc: 86.058 
52 Train Loss: 46.363 | Train Acc: 86.105 
53 Train Loss: 46.006 | Train Acc: 86.333 
54 Train Loss: 45.715 | Train Acc: 86.350 
55 Train Loss: 45.543 | Train Acc: 86.602 
56 Train Loss: 45.307 | Train Acc: 86.486 
57 Train Loss: 44.960 | Train Acc: 86.752 
58 Train Loss: 44.613 | Train Acc: 86.969 
59 Train Loss: 44.324 | Train Acc: 87.099 
60 Train Loss: 43.476 | Train Acc: 87.653 
61 Train Loss: 43.426 | Train Acc: 87.629 
62 Train Loss: 43.326 | Train Acc: 87.551 
63 Train Loss: 43.183 | Train Acc: 87.759 
64 Train Loss: 43.052 | Train Acc: 87.833 
65 Train Loss: 42.919 | Train Acc: 87.874 
66 Train Loss: 42.979 | Train Acc: 87.793 
67 Train Loss: 42.751 | Train Acc: 87.755 
68 Train Loss: 42.640 | Train Acc: 88.003 
69 Train Loss: 42.558 | Train Acc: 87.915 
70 Train Loss: 42.454 | Train Acc: 88.007 
71 Train Loss: 42.448 | Train Acc: 87.946 
72 Train Loss: 42.259 | Train Acc: 88.126 
73 Train Loss: 42.162 | Train Acc: 88.201 
74 Train Loss: 42.086 | Train Acc: 88.231 
75 Train Loss: 42.005 | Train Acc: 88.078 
76 Train Loss: 41.844 | Train Acc: 88.310 
77 Train Loss: 41.766 | Train Acc: 88.303 
78 Train Loss: 41.649 | Train Acc: 88.439 
79 Train Loss: 41.603 | Train Acc: 88.364 
80 Train Loss: 41.154 | Train Acc: 88.633 
81 Train Loss: 41.145 | Train Acc: 88.670 
82 Train Loss: 41.049 | Train Acc: 88.680 
83 Train Loss: 41.004 | Train Acc: 88.704 
84 Train Loss: 40.977 | Train Acc: 88.759 
85 Train Loss: 40.922 | Train Acc: 88.789 
86 Train Loss: 40.889 | Train Acc: 88.820 
87 Train Loss: 40.861 | Train Acc: 88.830 
88 Train Loss: 40.800 | Train Acc: 88.881 
89 Train Loss: 40.766 | Train Acc: 88.803 
CNN trained successfully...
image_next_flat.shape :  torch.Size([29400, 28224])
Time Taken by Kmeans is  8.482444047927856
Kmeans completed successfully...
printing expected split from k means
{2: 1, 0: 0, 3: 1, 5: 1, 1: 1, 4: 1}
Printing final_dict items...
{2: 1, 0: 0, 3: 1, 5: 1, 1: 1, 4: 1}
Image Statistics before MLP : L R :  4900 24500
expectedMlpLabels.shape :  torch.Size([29400])
0 Loss: 38.598 | Acc: 70.622
1 Loss: 33.231 | Acc: 77.184
2 Loss: 29.800 | Acc: 79.075
3 Loss: 26.975 | Acc: 81.636
4 Loss: 24.612 | Acc: 82.976
5 Loss: 21.578 | Acc: 85.224
6 Loss: 19.573 | Acc: 86.534
7 Loss: 17.624 | Acc: 87.898
8 Loss: 15.915 | Acc: 89.017
9 Loss: 15.078 | Acc: 89.820
10 Loss: 10.585 | Acc: 92.881
11 Loss: 9.475 | Acc: 93.956
12 Loss: 8.632 | Acc: 94.483
13 Loss: 7.713 | Acc: 95.061
14 Loss: 7.007 | Acc: 95.653
15 Loss: 6.514 | Acc: 95.912
16 Loss: 6.162 | Acc: 96.119
17 Loss: 5.829 | Acc: 96.422
18 Loss: 5.249 | Acc: 96.806
19 Loss: 5.029 | Acc: 96.997
20 Loss: 3.535 | Acc: 97.949
21 Loss: 3.503 | Acc: 98.010
22 Loss: 3.247 | Acc: 98.139
23 Loss: 3.056 | Acc: 98.231
24 Loss: 2.813 | Acc: 98.344
25 Loss: 2.688 | Acc: 98.395
26 Loss: 2.598 | Acc: 98.497
27 Loss: 2.471 | Acc: 98.633
28 Loss: 2.273 | Acc: 98.660
29 Loss: 2.213 | Acc: 98.752
30 Loss: 2.079 | Acc: 98.932
31 Loss: 1.764 | Acc: 98.993
32 Loss: 1.742 | Acc: 99.054
33 Loss: 1.668 | Acc: 99.105
34 Loss: 1.768 | Acc: 99.054
35 Loss: 1.609 | Acc: 99.136
36 Loss: 1.570 | Acc: 99.071
37 Loss: 1.692 | Acc: 99.122
38 Loss: 1.575 | Acc: 99.163
39 Loss: 1.592 | Acc: 99.099
40 Loss: 1.350 | Acc: 99.262
41 Loss: 1.409 | Acc: 99.316
42 Loss: 1.324 | Acc: 99.333
43 Loss: 1.362 | Acc: 99.276
44 Loss: 1.192 | Acc: 99.327
45 Loss: 1.251 | Acc: 99.289
46 Loss: 1.232 | Acc: 99.367
47 Loss: 1.279 | Acc: 99.354
48 Loss: 1.167 | Acc: 99.378
49 Loss: 1.358 | Acc: 99.337
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([24500])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([500, 3, 32, 32])   rValDict[label].shape:  torch.Size([500])
# of Left images:  4900.0
# of Right images:  24500.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.0
impurityDrop:  0.6400000000000001
giniGain:  0.19333333333333313
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 4900, 4900, 4900, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  5
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 2
nodeId:  4 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
nodeId:  5 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
Running nodeId:  3
0 Train Loss: 104.077 | Train Acc: 55.464 
1 Train Loss: 81.126 | Train Acc: 67.541 
2 Train Loss: 72.105 | Train Acc: 71.857 
3 Train Loss: 66.418 | Train Acc: 74.587 
4 Train Loss: 62.166 | Train Acc: 76.474 
5 Train Loss: 58.156 | Train Acc: 77.949 
6 Train Loss: 54.339 | Train Acc: 79.832 
7 Train Loss: 51.199 | Train Acc: 81.332 
8 Train Loss: 48.155 | Train Acc: 82.219 
9 Train Loss: 45.899 | Train Acc: 83.372 
10 Train Loss: 43.836 | Train Acc: 84.163 
11 Train Loss: 41.862 | Train Acc: 84.857 
12 Train Loss: 39.425 | Train Acc: 85.969 
13 Train Loss: 38.886 | Train Acc: 85.959 
14 Train Loss: 35.769 | Train Acc: 87.515 
15 Train Loss: 35.079 | Train Acc: 87.781 
16 Train Loss: 32.632 | Train Acc: 88.602 
17 Train Loss: 31.013 | Train Acc: 89.474 
18 Train Loss: 30.037 | Train Acc: 89.643 
19 Train Loss: 28.538 | Train Acc: 90.413 
20 Train Loss: 25.112 | Train Acc: 92.378 
21 Train Loss: 24.317 | Train Acc: 92.582 
22 Train Loss: 23.911 | Train Acc: 92.658 
23 Train Loss: 23.329 | Train Acc: 93.071 
24 Train Loss: 22.714 | Train Acc: 93.429 
25 Train Loss: 22.357 | Train Acc: 93.536 
26 Train Loss: 21.799 | Train Acc: 93.847 
27 Train Loss: 21.726 | Train Acc: 93.827 
28 Train Loss: 20.878 | Train Acc: 94.122 
29 Train Loss: 20.669 | Train Acc: 94.286 
30 Train Loss: 20.153 | Train Acc: 94.582 
31 Train Loss: 19.922 | Train Acc: 94.592 
32 Train Loss: 19.152 | Train Acc: 94.923 
33 Train Loss: 19.129 | Train Acc: 94.760 
34 Train Loss: 18.809 | Train Acc: 94.995 
35 Train Loss: 18.523 | Train Acc: 94.995 
36 Train Loss: 17.568 | Train Acc: 95.648 
37 Train Loss: 17.474 | Train Acc: 95.602 
38 Train Loss: 16.958 | Train Acc: 95.827 
39 Train Loss: 16.841 | Train Acc: 95.918 
40 Train Loss: 15.340 | Train Acc: 96.531 
41 Train Loss: 15.221 | Train Acc: 96.694 
42 Train Loss: 15.039 | Train Acc: 96.816 
43 Train Loss: 14.894 | Train Acc: 96.719 
44 Train Loss: 14.697 | Train Acc: 96.985 
45 Train Loss: 14.608 | Train Acc: 96.913 
46 Train Loss: 14.543 | Train Acc: 96.980 
47 Train Loss: 14.386 | Train Acc: 96.954 
48 Train Loss: 14.206 | Train Acc: 97.051 
49 Train Loss: 14.164 | Train Acc: 97.056 
50 Train Loss: 13.918 | Train Acc: 97.204 
51 Train Loss: 13.958 | Train Acc: 97.041 
52 Train Loss: 13.640 | Train Acc: 97.173 
53 Train Loss: 13.551 | Train Acc: 97.301 
54 Train Loss: 13.370 | Train Acc: 97.403 
55 Train Loss: 13.267 | Train Acc: 97.403 
56 Train Loss: 13.073 | Train Acc: 97.485 
57 Train Loss: 12.991 | Train Acc: 97.469 
58 Train Loss: 12.870 | Train Acc: 97.607 
59 Train Loss: 12.680 | Train Acc: 97.679 
60 Train Loss: 12.166 | Train Acc: 97.888 
61 Train Loss: 12.069 | Train Acc: 97.857 
62 Train Loss: 12.078 | Train Acc: 97.816 
63 Train Loss: 12.015 | Train Acc: 97.883 
64 Train Loss: 11.945 | Train Acc: 97.913 
65 Train Loss: 11.914 | Train Acc: 97.944 
66 Train Loss: 11.807 | Train Acc: 98.005 
67 Train Loss: 11.813 | Train Acc: 97.959 
68 Train Loss: 11.736 | Train Acc: 97.903 
69 Train Loss: 11.700 | Train Acc: 97.954 
70 Train Loss: 11.604 | Train Acc: 98.010 
71 Train Loss: 11.618 | Train Acc: 98.020 
72 Train Loss: 11.518 | Train Acc: 98.015 
73 Train Loss: 11.479 | Train Acc: 98.020 
74 Train Loss: 11.395 | Train Acc: 98.071 
75 Train Loss: 11.367 | Train Acc: 98.061 
76 Train Loss: 11.347 | Train Acc: 98.133 
77 Train Loss: 11.208 | Train Acc: 98.194 
78 Train Loss: 11.185 | Train Acc: 98.163 
79 Train Loss: 11.164 | Train Acc: 98.184 
80 Train Loss: 10.921 | Train Acc: 98.260 
81 Train Loss: 10.887 | Train Acc: 98.270 
82 Train Loss: 10.878 | Train Acc: 98.255 
83 Train Loss: 10.843 | Train Acc: 98.276 
84 Train Loss: 10.827 | Train Acc: 98.265 
85 Train Loss: 10.790 | Train Acc: 98.276 
86 Train Loss: 10.775 | Train Acc: 98.327 
87 Train Loss: 10.776 | Train Acc: 98.306 
88 Train Loss: 10.726 | Train Acc: 98.342 
89 Train Loss: 10.698 | Train Acc: 98.301 
CNN trained successfully...
image_next_flat.shape :  torch.Size([19600, 28224])
Time Taken by Kmeans is  3.6452949047088623
Kmeans completed successfully...
printing expected split from k means
{3: 0, 2: 0, 1: 0, 0: 1}
Printing final_dict items...
{3: 0, 2: 0, 1: 0, 0: 1}
Image Statistics before MLP : L R :  14700 4900
expectedMlpLabels.shape :  torch.Size([19600])
0 Loss: 44.937 | Acc: 78.602
1 Loss: 35.212 | Acc: 84.531
2 Loss: 30.233 | Acc: 87.240
3 Loss: 25.724 | Acc: 88.883
4 Loss: 22.356 | Acc: 90.342
5 Loss: 19.882 | Acc: 91.704
6 Loss: 17.590 | Acc: 92.587
7 Loss: 14.963 | Acc: 93.796
8 Loss: 13.644 | Acc: 94.454
9 Loss: 12.563 | Acc: 94.648
10 Loss: 7.976 | Acc: 96.704
11 Loss: 6.304 | Acc: 97.449
12 Loss: 5.559 | Acc: 97.786
13 Loss: 5.247 | Acc: 97.816
14 Loss: 4.654 | Acc: 98.168
15 Loss: 4.252 | Acc: 98.347
16 Loss: 4.365 | Acc: 98.372
17 Loss: 3.988 | Acc: 98.536
18 Loss: 3.465 | Acc: 98.668
19 Loss: 3.896 | Acc: 98.607
20 Loss: 2.810 | Acc: 98.995
21 Loss: 1.888 | Acc: 99.352
22 Loss: 1.832 | Acc: 99.301
23 Loss: 1.707 | Acc: 99.434
24 Loss: 1.711 | Acc: 99.398
25 Loss: 1.346 | Acc: 99.505
26 Loss: 1.433 | Acc: 99.520
27 Loss: 1.286 | Acc: 99.495
28 Loss: 1.436 | Acc: 99.459
29 Loss: 1.401 | Acc: 99.454
30 Loss: 1.179 | Acc: 99.587
31 Loss: 1.074 | Acc: 99.658
32 Loss: 1.066 | Acc: 99.663
33 Loss: 0.741 | Acc: 99.765
34 Loss: 0.879 | Acc: 99.704
35 Loss: 0.730 | Acc: 99.765
36 Loss: 0.898 | Acc: 99.704
37 Loss: 0.657 | Acc: 99.786
38 Loss: 0.614 | Acc: 99.827
39 Loss: 0.628 | Acc: 99.827
40 Loss: 0.568 | Acc: 99.862
41 Loss: 0.593 | Acc: 99.806
42 Loss: 0.536 | Acc: 99.842
43 Loss: 0.549 | Acc: 99.811
44 Loss: 0.634 | Acc: 99.811
45 Loss: 0.517 | Acc: 99.847
46 Loss: 0.532 | Acc: 99.832
47 Loss: 0.594 | Acc: 99.781
48 Loss: 0.469 | Acc: 99.862
49 Loss: 0.470 | Acc: 99.852
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([14700])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([300, 3, 32, 32])   lValDict[label].shape:  torch.Size([300])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  14700.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.6666666666666667
impurityDrop:  2.0
giniGain:  -1.25
lclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 0
nodeId:  6 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
nodeId:  7 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  4
Running nodeId:  5
0 Train Loss: 150.878 | Train Acc: 39.910 
1 Train Loss: 115.273 | Train Acc: 53.882 
2 Train Loss: 106.653 | Train Acc: 57.992 
3 Train Loss: 100.466 | Train Acc: 60.608 
4 Train Loss: 96.257 | Train Acc: 62.698 
5 Train Loss: 92.096 | Train Acc: 64.457 
6 Train Loss: 88.868 | Train Acc: 65.804 
7 Train Loss: 84.829 | Train Acc: 67.522 
8 Train Loss: 82.232 | Train Acc: 68.596 
9 Train Loss: 79.511 | Train Acc: 69.955 
10 Train Loss: 77.729 | Train Acc: 70.739 
11 Train Loss: 74.335 | Train Acc: 72.000 
12 Train Loss: 72.908 | Train Acc: 72.233 
13 Train Loss: 71.526 | Train Acc: 72.943 
14 Train Loss: 69.441 | Train Acc: 74.033 
15 Train Loss: 67.173 | Train Acc: 75.176 
16 Train Loss: 65.522 | Train Acc: 75.641 
17 Train Loss: 64.013 | Train Acc: 76.322 
18 Train Loss: 62.580 | Train Acc: 76.931 
19 Train Loss: 61.535 | Train Acc: 77.053 
20 Train Loss: 56.378 | Train Acc: 79.914 
21 Train Loss: 55.487 | Train Acc: 80.424 
22 Train Loss: 54.915 | Train Acc: 80.735 
23 Train Loss: 54.484 | Train Acc: 80.910 
24 Train Loss: 54.028 | Train Acc: 81.004 
25 Train Loss: 53.544 | Train Acc: 81.065 
26 Train Loss: 52.600 | Train Acc: 81.584 
27 Train Loss: 52.255 | Train Acc: 81.522 
28 Train Loss: 51.347 | Train Acc: 82.261 
29 Train Loss: 50.609 | Train Acc: 82.551 
30 Train Loss: 50.303 | Train Acc: 82.408 
31 Train Loss: 49.635 | Train Acc: 83.065 
32 Train Loss: 48.652 | Train Acc: 83.498 
33 Train Loss: 48.215 | Train Acc: 83.714 
34 Train Loss: 47.849 | Train Acc: 83.449 
35 Train Loss: 47.264 | Train Acc: 83.914 
36 Train Loss: 46.743 | Train Acc: 84.073 
37 Train Loss: 45.684 | Train Acc: 84.837 
38 Train Loss: 45.148 | Train Acc: 84.902 
39 Train Loss: 45.125 | Train Acc: 85.004 
40 Train Loss: 42.750 | Train Acc: 86.282 
41 Train Loss: 42.308 | Train Acc: 86.441 
42 Train Loss: 41.958 | Train Acc: 86.759 
43 Train Loss: 41.764 | Train Acc: 86.808 
44 Train Loss: 41.291 | Train Acc: 86.910 
45 Train Loss: 41.133 | Train Acc: 87.184 
46 Train Loss: 40.857 | Train Acc: 87.106 
47 Train Loss: 40.458 | Train Acc: 87.445 
48 Train Loss: 40.477 | Train Acc: 87.376 
49 Train Loss: 40.019 | Train Acc: 87.494 
50 Train Loss: 40.030 | Train Acc: 87.506 
51 Train Loss: 39.506 | Train Acc: 87.722 
52 Train Loss: 39.225 | Train Acc: 87.796 
53 Train Loss: 38.781 | Train Acc: 88.106 
54 Train Loss: 38.667 | Train Acc: 88.224 
55 Train Loss: 38.415 | Train Acc: 88.339 
56 Train Loss: 38.237 | Train Acc: 88.445 
57 Train Loss: 37.768 | Train Acc: 88.539 
58 Train Loss: 37.489 | Train Acc: 88.812 
59 Train Loss: 37.443 | Train Acc: 88.637 
60 Train Loss: 36.239 | Train Acc: 89.408 
61 Train Loss: 36.218 | Train Acc: 89.457 
62 Train Loss: 36.030 | Train Acc: 89.543 
63 Train Loss: 35.840 | Train Acc: 89.563 
64 Train Loss: 35.808 | Train Acc: 89.567 
65 Train Loss: 35.723 | Train Acc: 89.633 
66 Train Loss: 35.508 | Train Acc: 89.649 
67 Train Loss: 35.419 | Train Acc: 89.698 
68 Train Loss: 35.395 | Train Acc: 89.882 
69 Train Loss: 35.204 | Train Acc: 89.873 
70 Train Loss: 35.111 | Train Acc: 89.857 
71 Train Loss: 34.999 | Train Acc: 89.988 
72 Train Loss: 34.899 | Train Acc: 90.004 
73 Train Loss: 34.824 | Train Acc: 90.053 
74 Train Loss: 34.601 | Train Acc: 90.192 
75 Train Loss: 34.455 | Train Acc: 90.339 
76 Train Loss: 34.371 | Train Acc: 90.331 
77 Train Loss: 34.303 | Train Acc: 90.322 
78 Train Loss: 34.182 | Train Acc: 90.367 
79 Train Loss: 34.079 | Train Acc: 90.473 
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 31360])
Time Taken by Kmeans is  4.938876628875732
Kmeans completed successfully...
printing expected split from k means
{4: 0, 0: 1, 2: 1, 1: 1, 3: 1}
Printing final_dict items...
{4: 0, 0: 1, 2: 1, 1: 1, 3: 1}
Image Statistics before MLP : L R :  4900 19600
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 37.843 | Acc: 78.318
1 Loss: 27.793 | Acc: 85.633
2 Loss: 24.030 | Acc: 87.514
3 Loss: 20.218 | Acc: 89.404
4 Loss: 18.139 | Acc: 90.420
5 Loss: 16.077 | Acc: 91.335
6 Loss: 13.706 | Acc: 92.633
7 Loss: 12.017 | Acc: 93.714
8 Loss: 10.115 | Acc: 94.747
9 Loss: 9.576 | Acc: 95.118
10 Loss: 6.132 | Acc: 96.784
11 Loss: 4.642 | Acc: 97.718
12 Loss: 3.782 | Acc: 98.171
13 Loss: 3.692 | Acc: 98.200
14 Loss: 3.780 | Acc: 98.163
15 Loss: 3.360 | Acc: 98.473
16 Loss: 3.015 | Acc: 98.547
17 Loss: 2.831 | Acc: 98.747
18 Loss: 2.807 | Acc: 98.718
19 Loss: 2.305 | Acc: 98.906
20 Loss: 1.628 | Acc: 99.282
21 Loss: 1.247 | Acc: 99.453
22 Loss: 1.290 | Acc: 99.424
23 Loss: 1.298 | Acc: 99.429
24 Loss: 1.131 | Acc: 99.502
25 Loss: 0.996 | Acc: 99.580
26 Loss: 0.858 | Acc: 99.665
27 Loss: 0.982 | Acc: 99.576
28 Loss: 0.873 | Acc: 99.620
29 Loss: 0.743 | Acc: 99.678
30 Loss: 0.672 | Acc: 99.702
31 Loss: 0.655 | Acc: 99.727
32 Loss: 0.713 | Acc: 99.702
33 Loss: 0.670 | Acc: 99.755
34 Loss: 0.571 | Acc: 99.759
35 Loss: 0.604 | Acc: 99.698
36 Loss: 0.586 | Acc: 99.800
37 Loss: 0.486 | Acc: 99.792
38 Loss: 0.519 | Acc: 99.800
39 Loss: 0.396 | Acc: 99.861
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([19600, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([19600])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([400, 3, 32, 32])   rValDict[label].shape:  torch.Size([400])
# of Left images:  4900.0
# of Right images:  19600.0
giniRightRatio:  0.75
giniLeftRatio:  0.0
impurityDrop:  0.5625
giniGain:  0.23750000000000016
lclasses:  [0, 0, 0, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [4900, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  4
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
nodeId:  8 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 8 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 4900
nodeId:  9 , imgTensorShape :  torch.Size([19600, 3, 32, 32])
nodeId: 9 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 19600
Running nodeId:  6
0 Train Loss: 80.967 | Train Acc: 65.361 
1 Train Loss: 59.811 | Train Acc: 75.231 
2 Train Loss: 53.489 | Train Acc: 78.599 
3 Train Loss: 49.003 | Train Acc: 80.592 
4 Train Loss: 45.241 | Train Acc: 82.558 
5 Train Loss: 42.736 | Train Acc: 83.429 
6 Train Loss: 40.406 | Train Acc: 84.517 
7 Train Loss: 38.071 | Train Acc: 85.762 
8 Train Loss: 36.753 | Train Acc: 86.000 
9 Train Loss: 34.372 | Train Acc: 87.306 
10 Train Loss: 32.903 | Train Acc: 88.102 
11 Train Loss: 31.224 | Train Acc: 88.531 
12 Train Loss: 29.795 | Train Acc: 89.361 
13 Train Loss: 28.104 | Train Acc: 89.986 
14 Train Loss: 27.089 | Train Acc: 90.660 
15 Train Loss: 25.658 | Train Acc: 90.918 
16 Train Loss: 23.509 | Train Acc: 92.184 
17 Train Loss: 23.228 | Train Acc: 91.932 
18 Train Loss: 21.582 | Train Acc: 92.980 
19 Train Loss: 20.452 | Train Acc: 93.327 
20 Train Loss: 17.265 | Train Acc: 95.034 
21 Train Loss: 16.830 | Train Acc: 95.279 
22 Train Loss: 16.427 | Train Acc: 95.320 
23 Train Loss: 15.897 | Train Acc: 95.592 
24 Train Loss: 15.709 | Train Acc: 95.701 
25 Train Loss: 15.411 | Train Acc: 95.891 
26 Train Loss: 15.006 | Train Acc: 96.102 
27 Train Loss: 14.290 | Train Acc: 96.374 
28 Train Loss: 14.111 | Train Acc: 96.497 
29 Train Loss: 13.673 | Train Acc: 96.490 
30 Train Loss: 13.233 | Train Acc: 96.912 
31 Train Loss: 13.104 | Train Acc: 96.844 
32 Train Loss: 12.435 | Train Acc: 97.272 
33 Train Loss: 12.129 | Train Acc: 97.442 
34 Train Loss: 11.888 | Train Acc: 97.565 
35 Train Loss: 11.629 | Train Acc: 97.571 
36 Train Loss: 11.092 | Train Acc: 97.850 
37 Train Loss: 10.922 | Train Acc: 97.850 
38 Train Loss: 10.351 | Train Acc: 98.095 
39 Train Loss: 10.088 | Train Acc: 98.061 
40 Train Loss: 9.165 | Train Acc: 98.612 
41 Train Loss: 9.061 | Train Acc: 98.667 
42 Train Loss: 8.922 | Train Acc: 98.741 
43 Train Loss: 8.757 | Train Acc: 98.803 
44 Train Loss: 8.707 | Train Acc: 98.776 
45 Train Loss: 8.461 | Train Acc: 98.925 
46 Train Loss: 8.348 | Train Acc: 98.912 
47 Train Loss: 8.286 | Train Acc: 98.912 
48 Train Loss: 8.172 | Train Acc: 98.986 
49 Train Loss: 8.194 | Train Acc: 98.898 
50 Train Loss: 7.962 | Train Acc: 99.007 
51 Train Loss: 7.941 | Train Acc: 99.000 
52 Train Loss: 7.769 | Train Acc: 99.075 
53 Train Loss: 7.695 | Train Acc: 99.027 
54 Train Loss: 7.498 | Train Acc: 99.143 
55 Train Loss: 7.387 | Train Acc: 99.177 
56 Train Loss: 7.278 | Train Acc: 99.211 
57 Train Loss: 7.220 | Train Acc: 99.245 
58 Train Loss: 7.109 | Train Acc: 99.204 
59 Train Loss: 6.943 | Train Acc: 99.224 
60 Train Loss: 6.560 | Train Acc: 99.435 
61 Train Loss: 6.542 | Train Acc: 99.381 
62 Train Loss: 6.467 | Train Acc: 99.401 
63 Train Loss: 6.428 | Train Acc: 99.395 
64 Train Loss: 6.431 | Train Acc: 99.415 
65 Train Loss: 6.348 | Train Acc: 99.429 
66 Train Loss: 6.286 | Train Acc: 99.476 
67 Train Loss: 6.284 | Train Acc: 99.456 
68 Train Loss: 6.179 | Train Acc: 99.490 
69 Train Loss: 6.184 | Train Acc: 99.469 
70 Train Loss: 6.152 | Train Acc: 99.503 
71 Train Loss: 6.068 | Train Acc: 99.531 
72 Train Loss: 6.007 | Train Acc: 99.537 
73 Train Loss: 5.999 | Train Acc: 99.517 
74 Train Loss: 5.960 | Train Acc: 99.517 
75 Train Loss: 5.905 | Train Acc: 99.551 
76 Train Loss: 5.847 | Train Acc: 99.551 
77 Train Loss: 5.826 | Train Acc: 99.537 
78 Train Loss: 5.778 | Train Acc: 99.537 
79 Train Loss: 5.720 | Train Acc: 99.531 
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 31360])
Time Taken by Kmeans is  3.2016332149505615
Kmeans completed successfully...
printing expected split from k means
{2: 0, 1: 1, 0: 0}
Printing final_dict items...
{2: 0, 1: 1, 0: 0}
Image Statistics before MLP : L R :  9800 4900
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 45.011 | Acc: 86.370
1 Loss: 31.443 | Acc: 90.774
2 Loss: 25.202 | Acc: 92.884
3 Loss: 20.965 | Acc: 94.048
4 Loss: 17.512 | Acc: 94.870
5 Loss: 15.375 | Acc: 95.521
6 Loss: 13.195 | Acc: 96.123
7 Loss: 11.678 | Acc: 96.596
8 Loss: 8.783 | Acc: 97.582
9 Loss: 7.871 | Acc: 97.589
10 Loss: 4.158 | Acc: 98.877
11 Loss: 3.175 | Acc: 99.151
12 Loss: 2.342 | Acc: 99.384
13 Loss: 2.557 | Acc: 99.336
14 Loss: 2.448 | Acc: 99.329
15 Loss: 2.288 | Acc: 99.425
16 Loss: 2.447 | Acc: 99.473
17 Loss: 2.300 | Acc: 99.411
18 Loss: 1.437 | Acc: 99.596
19 Loss: 2.269 | Acc: 99.438
20 Loss: 1.265 | Acc: 99.692
21 Loss: 0.753 | Acc: 99.815
22 Loss: 0.706 | Acc: 99.842
23 Loss: 0.558 | Acc: 99.856
24 Loss: 0.499 | Acc: 99.863
25 Loss: 0.569 | Acc: 99.856
26 Loss: 0.542 | Acc: 99.863
27 Loss: 0.596 | Acc: 99.863
28 Loss: 0.400 | Acc: 99.904
29 Loss: 0.438 | Acc: 99.877
30 Loss: 0.324 | Acc: 99.911
31 Loss: 0.233 | Acc: 99.945
32 Loss: 0.378 | Acc: 99.925
33 Loss: 0.255 | Acc: 99.966
34 Loss: 0.449 | Acc: 99.925
35 Loss: 0.243 | Acc: 99.973
36 Loss: 0.221 | Acc: 99.952
37 Loss: 0.291 | Acc: 99.959
38 Loss: 0.230 | Acc: 99.938
39 Loss: 0.133 | Acc: 99.973
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  9800.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.5
impurityDrop:  1.0
giniGain:  -0.33333333333333326
lclasses:  [4900, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  10 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 10 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  11 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 11 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  7
Running nodeId:  8
Running nodeId:  9
0 Train Loss: 132.040 | Train Acc: 41.673 
1 Train Loss: 104.415 | Train Acc: 56.128 
2 Train Loss: 97.519 | Train Acc: 59.388 
3 Train Loss: 92.492 | Train Acc: 62.194 
4 Train Loss: 89.243 | Train Acc: 63.643 
5 Train Loss: 86.266 | Train Acc: 65.077 
6 Train Loss: 82.812 | Train Acc: 66.980 
7 Train Loss: 79.643 | Train Acc: 67.954 
8 Train Loss: 78.428 | Train Acc: 68.796 
9 Train Loss: 74.987 | Train Acc: 70.413 
10 Train Loss: 72.936 | Train Acc: 71.041 
11 Train Loss: 70.478 | Train Acc: 72.362 
12 Train Loss: 68.360 | Train Acc: 73.337 
13 Train Loss: 66.339 | Train Acc: 74.250 
14 Train Loss: 65.655 | Train Acc: 74.561 
15 Train Loss: 62.774 | Train Acc: 75.878 
16 Train Loss: 61.891 | Train Acc: 76.194 
17 Train Loss: 59.392 | Train Acc: 77.204 
18 Train Loss: 58.312 | Train Acc: 77.526 
19 Train Loss: 56.108 | Train Acc: 78.770 
20 Train Loss: 51.524 | Train Acc: 81.219 
21 Train Loss: 50.369 | Train Acc: 81.760 
22 Train Loss: 49.939 | Train Acc: 82.056 
23 Train Loss: 49.041 | Train Acc: 82.541 
24 Train Loss: 47.952 | Train Acc: 83.097 
25 Train Loss: 47.786 | Train Acc: 82.801 
26 Train Loss: 46.728 | Train Acc: 83.561 
27 Train Loss: 45.904 | Train Acc: 84.010 
28 Train Loss: 45.468 | Train Acc: 84.010 
29 Train Loss: 44.478 | Train Acc: 84.663 
30 Train Loss: 43.654 | Train Acc: 85.051 
31 Train Loss: 43.429 | Train Acc: 84.755 
32 Train Loss: 42.545 | Train Acc: 85.622 
33 Train Loss: 41.852 | Train Acc: 85.781 
34 Train Loss: 41.227 | Train Acc: 85.954 
35 Train Loss: 40.437 | Train Acc: 86.469 
36 Train Loss: 39.732 | Train Acc: 86.658 
37 Train Loss: 39.082 | Train Acc: 87.041 
38 Train Loss: 38.462 | Train Acc: 87.393 
39 Train Loss: 37.917 | Train Acc: 87.679 
40 Train Loss: 35.780 | Train Acc: 88.832 
41 Train Loss: 35.585 | Train Acc: 89.005 
42 Train Loss: 35.232 | Train Acc: 89.148 
43 Train Loss: 34.872 | Train Acc: 89.495 
44 Train Loss: 34.765 | Train Acc: 89.352 
45 Train Loss: 34.418 | Train Acc: 89.776 
46 Train Loss: 34.093 | Train Acc: 89.663 
47 Train Loss: 33.898 | Train Acc: 89.781 
48 Train Loss: 33.571 | Train Acc: 89.974 
49 Train Loss: 33.516 | Train Acc: 89.949 
50 Train Loss: 33.134 | Train Acc: 90.143 
51 Train Loss: 32.738 | Train Acc: 90.500 
52 Train Loss: 32.499 | Train Acc: 90.628 
53 Train Loss: 32.537 | Train Acc: 90.515 
54 Train Loss: 31.896 | Train Acc: 90.791 
55 Train Loss: 31.719 | Train Acc: 90.745 
56 Train Loss: 31.625 | Train Acc: 90.959 
57 Train Loss: 31.282 | Train Acc: 91.046 
58 Train Loss: 30.946 | Train Acc: 91.189 
59 Train Loss: 30.792 | Train Acc: 91.240 
60 Train Loss: 29.859 | Train Acc: 91.827 
61 Train Loss: 29.802 | Train Acc: 91.959 
62 Train Loss: 29.532 | Train Acc: 91.974 
63 Train Loss: 29.534 | Train Acc: 91.898 
64 Train Loss: 29.344 | Train Acc: 92.082 
65 Train Loss: 29.309 | Train Acc: 91.990 
66 Train Loss: 29.160 | Train Acc: 92.128 
67 Train Loss: 29.160 | Train Acc: 92.153 
68 Train Loss: 28.949 | Train Acc: 92.230 
69 Train Loss: 28.996 | Train Acc: 92.020 
CNN trained successfully...
image_next_flat.shape :  torch.Size([19600, 34496])
Time Taken by Kmeans is  7.666818380355835
Kmeans completed successfully...
printing expected split from k means
{2: 0, 1: 0, 0: 1, 3: 0}
Printing final_dict items...
{2: 0, 1: 0, 0: 1, 3: 0}
Image Statistics before MLP : L R :  14700 4900
expectedMlpLabels.shape :  torch.Size([19600])
0 Loss: 61.571 | Acc: 65.230
1 Loss: 54.652 | Acc: 71.362
2 Loss: 49.815 | Acc: 73.643
3 Loss: 44.737 | Acc: 77.245
4 Loss: 40.006 | Acc: 80.168
5 Loss: 35.630 | Acc: 82.622
6 Loss: 31.199 | Acc: 85.439
7 Loss: 27.642 | Acc: 87.378
8 Loss: 23.536 | Acc: 89.633
9 Loss: 20.369 | Acc: 91.194
10 Loss: 13.759 | Acc: 94.429
11 Loss: 10.107 | Acc: 95.918
12 Loss: 8.815 | Acc: 96.474
13 Loss: 7.946 | Acc: 96.893
14 Loss: 6.680 | Acc: 97.434
15 Loss: 7.135 | Acc: 97.281
16 Loss: 6.061 | Acc: 97.699
17 Loss: 6.053 | Acc: 97.827
18 Loss: 5.408 | Acc: 97.954
19 Loss: 5.610 | Acc: 98.000
20 Loss: 3.777 | Acc: 98.724
21 Loss: 2.921 | Acc: 99.026
22 Loss: 2.880 | Acc: 99.046
23 Loss: 2.581 | Acc: 99.092
24 Loss: 2.335 | Acc: 99.245
25 Loss: 2.363 | Acc: 99.199
26 Loss: 2.047 | Acc: 99.352
27 Loss: 1.971 | Acc: 99.311
28 Loss: 2.388 | Acc: 99.168
29 Loss: 1.904 | Acc: 99.327
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([14700])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([300, 3, 32, 32])   lValDict[label].shape:  torch.Size([300])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  14700.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.6666666666666667
impurityDrop:  2.0
giniGain:  -1.25
lclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 3
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 3
nodeId:  12 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 12 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
nodeId:  13 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 13 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  10
0 Train Loss: 77.555 | Train Acc: 59.112 
1 Train Loss: 56.256 | Train Acc: 70.816 
2 Train Loss: 49.910 | Train Acc: 76.163 
3 Train Loss: 44.966 | Train Acc: 79.337 
4 Train Loss: 40.780 | Train Acc: 81.929 
5 Train Loss: 38.005 | Train Acc: 83.541 
6 Train Loss: 36.186 | Train Acc: 84.500 
7 Train Loss: 33.457 | Train Acc: 85.684 
8 Train Loss: 31.578 | Train Acc: 86.929 
9 Train Loss: 29.087 | Train Acc: 88.398 
10 Train Loss: 28.089 | Train Acc: 88.480 
11 Train Loss: 26.074 | Train Acc: 89.888 
12 Train Loss: 25.111 | Train Acc: 89.939 
13 Train Loss: 24.472 | Train Acc: 90.286 
14 Train Loss: 22.321 | Train Acc: 91.449 
15 Train Loss: 20.600 | Train Acc: 92.439 
16 Train Loss: 20.018 | Train Acc: 92.745 
17 Train Loss: 18.931 | Train Acc: 92.755 
18 Train Loss: 17.711 | Train Acc: 93.347 
19 Train Loss: 16.349 | Train Acc: 94.286 
20 Train Loss: 13.903 | Train Acc: 95.592 
21 Train Loss: 13.302 | Train Acc: 96.122 
22 Train Loss: 12.863 | Train Acc: 96.204 
23 Train Loss: 12.412 | Train Acc: 96.531 
24 Train Loss: 12.160 | Train Acc: 96.827 
25 Train Loss: 11.656 | Train Acc: 96.806 
26 Train Loss: 11.274 | Train Acc: 97.071 
27 Train Loss: 11.012 | Train Acc: 97.306 
28 Train Loss: 10.595 | Train Acc: 97.367 
29 Train Loss: 10.235 | Train Acc: 97.561 
30 Train Loss: 10.074 | Train Acc: 97.510 
31 Train Loss: 9.595 | Train Acc: 97.776 
32 Train Loss: 9.208 | Train Acc: 98.031 
33 Train Loss: 8.960 | Train Acc: 97.888 
34 Train Loss: 8.690 | Train Acc: 98.163 
35 Train Loss: 8.274 | Train Acc: 98.286 
36 Train Loss: 8.022 | Train Acc: 98.337 
37 Train Loss: 7.634 | Train Acc: 98.469 
38 Train Loss: 7.650 | Train Acc: 98.602 
39 Train Loss: 7.040 | Train Acc: 98.908 
40 Train Loss: 6.378 | Train Acc: 99.102 
41 Train Loss: 6.241 | Train Acc: 99.184 
42 Train Loss: 6.090 | Train Acc: 99.235 
43 Train Loss: 5.993 | Train Acc: 99.306 
44 Train Loss: 6.028 | Train Acc: 99.184 
45 Train Loss: 5.857 | Train Acc: 99.296 
46 Train Loss: 5.698 | Train Acc: 99.327 
47 Train Loss: 5.641 | Train Acc: 99.357 
48 Train Loss: 5.605 | Train Acc: 99.459 
49 Train Loss: 5.417 | Train Acc: 99.459 
50 Train Loss: 5.261 | Train Acc: 99.449 
51 Train Loss: 5.280 | Train Acc: 99.469 
52 Train Loss: 5.198 | Train Acc: 99.551 
53 Train Loss: 5.162 | Train Acc: 99.510 
54 Train Loss: 4.941 | Train Acc: 99.561 
55 Train Loss: 4.925 | Train Acc: 99.531 
56 Train Loss: 4.758 | Train Acc: 99.561 
57 Train Loss: 4.678 | Train Acc: 99.643 
58 Train Loss: 4.686 | Train Acc: 99.612 
59 Train Loss: 4.515 | Train Acc: 99.582 
60 Train Loss: 4.246 | Train Acc: 99.765 
61 Train Loss: 4.165 | Train Acc: 99.755 
62 Train Loss: 4.136 | Train Acc: 99.745 
63 Train Loss: 4.087 | Train Acc: 99.755 
64 Train Loss: 4.058 | Train Acc: 99.776 
65 Train Loss: 4.055 | Train Acc: 99.755 
66 Train Loss: 3.999 | Train Acc: 99.776 
67 Train Loss: 3.966 | Train Acc: 99.776 
68 Train Loss: 3.933 | Train Acc: 99.765 
69 Train Loss: 3.890 | Train Acc: 99.786 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 34496])
Time Taken by Kmeans is  2.7078821659088135
Kmeans completed successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 97.624 | Acc: 76.398
1 Loss: 68.514 | Acc: 85.143
2 Loss: 54.654 | Acc: 88.755
3 Loss: 43.815 | Acc: 90.898
4 Loss: 35.566 | Acc: 92.551
5 Loss: 29.148 | Acc: 94.153
6 Loss: 22.979 | Acc: 95.602
7 Loss: 19.472 | Acc: 96.051
8 Loss: 16.670 | Acc: 96.714
9 Loss: 14.597 | Acc: 97.122
10 Loss: 6.741 | Acc: 98.786
11 Loss: 3.484 | Acc: 99.459
12 Loss: 3.702 | Acc: 99.367
13 Loss: 3.098 | Acc: 99.510
14 Loss: 2.093 | Acc: 99.673
15 Loss: 3.342 | Acc: 99.429
16 Loss: 3.816 | Acc: 99.337
17 Loss: 2.737 | Acc: 99.520
18 Loss: 1.949 | Acc: 99.653
19 Loss: 2.521 | Acc: 99.592
20 Loss: 1.995 | Acc: 99.653
21 Loss: 0.954 | Acc: 99.837
22 Loss: 0.763 | Acc: 99.878
23 Loss: 1.035 | Acc: 99.857
24 Loss: 0.831 | Acc: 99.837
25 Loss: 0.597 | Acc: 99.929
26 Loss: 0.603 | Acc: 99.929
27 Loss: 0.410 | Acc: 99.969
28 Loss: 0.483 | Acc: 99.949
29 Loss: 0.581 | Acc: 99.908
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  14 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 14 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 4900
nodeId:  15 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 15 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  11
Running nodeId:  12
0 Train Loss: 93.630 | Train Acc: 57.769 
1 Train Loss: 69.102 | Train Acc: 71.054 
2 Train Loss: 60.456 | Train Acc: 75.327 
3 Train Loss: 55.354 | Train Acc: 77.626 
4 Train Loss: 50.896 | Train Acc: 79.721 
5 Train Loss: 47.912 | Train Acc: 81.476 
6 Train Loss: 44.828 | Train Acc: 82.755 
7 Train Loss: 43.328 | Train Acc: 83.211 
8 Train Loss: 40.330 | Train Acc: 84.585 
9 Train Loss: 37.821 | Train Acc: 85.476 
10 Train Loss: 37.371 | Train Acc: 85.973 
11 Train Loss: 35.046 | Train Acc: 86.714 
12 Train Loss: 32.488 | Train Acc: 88.286 
13 Train Loss: 32.405 | Train Acc: 87.857 
14 Train Loss: 30.040 | Train Acc: 88.952 
15 Train Loss: 29.095 | Train Acc: 89.381 
16 Train Loss: 29.946 | Train Acc: 88.993 
17 Train Loss: 26.329 | Train Acc: 90.782 
18 Train Loss: 24.713 | Train Acc: 91.497 
19 Train Loss: 24.973 | Train Acc: 91.286 
20 Train Loss: 20.760 | Train Acc: 93.497 
21 Train Loss: 19.995 | Train Acc: 93.857 
22 Train Loss: 19.498 | Train Acc: 94.109 
23 Train Loss: 18.965 | Train Acc: 94.476 
24 Train Loss: 18.916 | Train Acc: 94.558 
25 Train Loss: 19.027 | Train Acc: 94.265 
26 Train Loss: 17.856 | Train Acc: 95.075 
27 Train Loss: 17.374 | Train Acc: 95.095 
28 Train Loss: 17.538 | Train Acc: 94.925 
29 Train Loss: 16.590 | Train Acc: 95.408 
30 Train Loss: 16.360 | Train Acc: 95.619 
31 Train Loss: 16.036 | Train Acc: 95.687 
32 Train Loss: 15.750 | Train Acc: 95.748 
33 Train Loss: 15.212 | Train Acc: 96.068 
34 Train Loss: 14.617 | Train Acc: 96.177 
35 Train Loss: 14.475 | Train Acc: 96.197 
36 Train Loss: 15.025 | Train Acc: 96.007 
37 Train Loss: 14.190 | Train Acc: 96.490 
38 Train Loss: 13.900 | Train Acc: 96.490 
39 Train Loss: 12.824 | Train Acc: 97.259 
40 Train Loss: 11.944 | Train Acc: 97.585 
41 Train Loss: 11.743 | Train Acc: 97.782 
42 Train Loss: 11.474 | Train Acc: 97.782 
43 Train Loss: 11.415 | Train Acc: 97.823 
44 Train Loss: 11.659 | Train Acc: 97.578 
45 Train Loss: 11.056 | Train Acc: 97.946 
46 Train Loss: 11.014 | Train Acc: 97.884 
47 Train Loss: 10.897 | Train Acc: 98.000 
48 Train Loss: 10.896 | Train Acc: 97.986 
49 Train Loss: 10.546 | Train Acc: 98.184 
50 Train Loss: 10.507 | Train Acc: 98.150 
51 Train Loss: 10.364 | Train Acc: 98.116 
52 Train Loss: 10.172 | Train Acc: 98.238 
53 Train Loss: 10.326 | Train Acc: 98.163 
54 Train Loss: 10.017 | Train Acc: 98.299 
55 Train Loss: 9.943 | Train Acc: 98.252 
56 Train Loss: 9.683 | Train Acc: 98.429 
57 Train Loss: 9.585 | Train Acc: 98.429 
58 Train Loss: 9.600 | Train Acc: 98.442 
59 Train Loss: 9.407 | Train Acc: 98.537 
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 37632])
Time Taken by Kmeans is  3.874206304550171
Kmeans completed successfully...
printing expected split from k means
{1: 0, 0: 0, 2: 1}
Printing final_dict items...
{1: 0, 0: 0, 2: 1}
Image Statistics before MLP : L R :  9800 4900
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 59.313 | Acc: 78.890
1 Loss: 42.451 | Acc: 86.623
2 Loss: 34.090 | Acc: 89.733
3 Loss: 29.280 | Acc: 91.356
4 Loss: 24.815 | Acc: 92.527
5 Loss: 20.930 | Acc: 93.685
6 Loss: 17.292 | Acc: 94.760
7 Loss: 14.715 | Acc: 95.719
8 Loss: 12.036 | Acc: 96.452
9 Loss: 10.635 | Acc: 96.938
10 Loss: 5.696 | Acc: 98.342
11 Loss: 4.453 | Acc: 98.753
12 Loss: 3.747 | Acc: 99.089
13 Loss: 3.954 | Acc: 98.966
14 Loss: 2.869 | Acc: 99.240
15 Loss: 2.824 | Acc: 99.226
16 Loss: 2.572 | Acc: 99.363
17 Loss: 2.645 | Acc: 99.267
18 Loss: 2.058 | Acc: 99.514
19 Loss: 2.352 | Acc: 99.349
20 Loss: 1.466 | Acc: 99.637
21 Loss: 1.221 | Acc: 99.733
22 Loss: 0.832 | Acc: 99.781
23 Loss: 0.732 | Acc: 99.842
24 Loss: 0.815 | Acc: 99.801
25 Loss: 0.836 | Acc: 99.815
26 Loss: 0.725 | Acc: 99.795
27 Loss: 0.684 | Acc: 99.870
28 Loss: 0.625 | Acc: 99.863
29 Loss: 0.522 | Acc: 99.897
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  9800.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.5
impurityDrop:  1.0
giniGain:  -0.33333333333333326
lclasses:  [4900, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  16 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 16 ,  parentId: 12 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  17 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 17 ,  parentId: 12 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  13
Running nodeId:  14
Running nodeId:  15
Running nodeId:  16
0 Train Loss: 65.316 | Train Acc: 68.194 
1 Train Loss: 43.373 | Train Acc: 79.112 
2 Train Loss: 39.564 | Train Acc: 81.796 
3 Train Loss: 37.127 | Train Acc: 83.347 
4 Train Loss: 34.871 | Train Acc: 85.184 
5 Train Loss: 33.493 | Train Acc: 85.806 
6 Train Loss: 31.588 | Train Acc: 86.633 
7 Train Loss: 29.940 | Train Acc: 87.388 
8 Train Loss: 29.173 | Train Acc: 87.908 
9 Train Loss: 28.350 | Train Acc: 88.143 
10 Train Loss: 26.435 | Train Acc: 89.122 
11 Train Loss: 24.709 | Train Acc: 89.857 
12 Train Loss: 23.882 | Train Acc: 90.490 
13 Train Loss: 22.927 | Train Acc: 90.592 
14 Train Loss: 21.649 | Train Acc: 91.337 
15 Train Loss: 20.982 | Train Acc: 91.745 
16 Train Loss: 19.656 | Train Acc: 92.571 
17 Train Loss: 18.658 | Train Acc: 92.980 
18 Train Loss: 18.126 | Train Acc: 92.745 
19 Train Loss: 17.021 | Train Acc: 93.735 
20 Train Loss: 14.640 | Train Acc: 95.163 
21 Train Loss: 14.331 | Train Acc: 95.306 
22 Train Loss: 13.396 | Train Acc: 95.867 
23 Train Loss: 13.017 | Train Acc: 95.949 
24 Train Loss: 12.820 | Train Acc: 96.051 
25 Train Loss: 12.114 | Train Acc: 96.469 
26 Train Loss: 12.533 | Train Acc: 96.061 
27 Train Loss: 11.633 | Train Acc: 96.776 
28 Train Loss: 11.575 | Train Acc: 96.612 
29 Train Loss: 10.999 | Train Acc: 97.071 
30 Train Loss: 10.613 | Train Acc: 96.990 
31 Train Loss: 10.424 | Train Acc: 97.276 
32 Train Loss: 10.264 | Train Acc: 97.347 
33 Train Loss: 9.890 | Train Acc: 97.449 
34 Train Loss: 10.225 | Train Acc: 97.041 
35 Train Loss: 9.338 | Train Acc: 97.755 
36 Train Loss: 9.233 | Train Acc: 97.796 
37 Train Loss: 8.618 | Train Acc: 98.102 
38 Train Loss: 8.324 | Train Acc: 98.224 
39 Train Loss: 8.358 | Train Acc: 97.969 
40 Train Loss: 7.336 | Train Acc: 98.551 
41 Train Loss: 7.249 | Train Acc: 98.582 
42 Train Loss: 7.022 | Train Acc: 98.714 
43 Train Loss: 7.164 | Train Acc: 98.643 
44 Train Loss: 6.842 | Train Acc: 98.755 
45 Train Loss: 6.752 | Train Acc: 98.745 
46 Train Loss: 6.627 | Train Acc: 98.827 
47 Train Loss: 6.597 | Train Acc: 98.867 
48 Train Loss: 6.482 | Train Acc: 98.959 
49 Train Loss: 6.418 | Train Acc: 98.867 
50 Train Loss: 6.313 | Train Acc: 98.980 
51 Train Loss: 6.272 | Train Acc: 99.010 
52 Train Loss: 6.022 | Train Acc: 98.959 
53 Train Loss: 6.084 | Train Acc: 99.061 
54 Train Loss: 5.859 | Train Acc: 99.102 
55 Train Loss: 5.893 | Train Acc: 99.112 
56 Train Loss: 5.810 | Train Acc: 99.143 
57 Train Loss: 5.700 | Train Acc: 99.204 
58 Train Loss: 5.514 | Train Acc: 99.276 
59 Train Loss: 5.512 | Train Acc: 99.265 
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 40768])
Time Taken by Kmeans is  3.2488975524902344
Kmeans completed successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 89.119 | Acc: 79.480
1 Loss: 67.565 | Acc: 85.602
2 Loss: 56.334 | Acc: 88.245
3 Loss: 47.528 | Acc: 89.796
4 Loss: 39.162 | Acc: 92.020
5 Loss: 35.107 | Acc: 92.857
6 Loss: 27.745 | Acc: 94.316
7 Loss: 24.277 | Acc: 95.163
8 Loss: 19.696 | Acc: 96.316
9 Loss: 20.369 | Acc: 96.031
10 Loss: 10.520 | Acc: 98.112
11 Loss: 6.473 | Acc: 98.847
12 Loss: 4.403 | Acc: 99.245
13 Loss: 4.926 | Acc: 99.031
14 Loss: 3.444 | Acc: 99.347
15 Loss: 4.415 | Acc: 99.306
16 Loss: 3.631 | Acc: 99.429
17 Loss: 3.973 | Acc: 99.265
18 Loss: 2.995 | Acc: 99.520
19 Loss: 4.348 | Acc: 99.306
20 Loss: 1.845 | Acc: 99.684
21 Loss: 1.263 | Acc: 99.857
22 Loss: 1.231 | Acc: 99.837
23 Loss: 0.848 | Acc: 99.878
24 Loss: 0.889 | Acc: 99.847
25 Loss: 0.806 | Acc: 99.908
26 Loss: 1.197 | Acc: 99.806
27 Loss: 0.713 | Acc: 99.939
28 Loss: 0.616 | Acc: 99.898
29 Loss: 0.662 | Acc: 99.857
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
MAX DEPTH REACHED 6
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 4
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 5
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 4
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 5
nodeId:  18 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 18 ,  parentId: 16 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 4900
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 16 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 62.520
Split Acc: 92.700
lTrainDict[data].shape:  torch.Size([5988, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([5988])
rTrainDict[data].shape:  torch.Size([4012, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4012])
# of Left images:  5988.0
# of Right images:  4012.0
giniRightRatio:  0.7922586925166675
giniLeftRatio:  0.851633962648075
impurityDrop:  0.880877615135528
giniGain:  0.019122384864472042
lclasses:  [136, 60, 895, 928, 949, 969, 951, 937, 69, 94]
rclasses:  [864, 940, 105, 72, 51, 31, 49, 63, 931, 906]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([5988, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 6 ,  numData: 5988
nodeId:  3 , imgTensorShape :  torch.Size([4012, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 4012
Nodes sizes =  6 4
Node 2 Acc: 56.496
Split Acc: 81.981
lTrainDict[data].shape:  torch.Size([929, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([929])
rTrainDict[data].shape:  torch.Size([5059, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([5059])
# of Left images:  929.0
# of Right images:  5059.0
giniRightRatio:  0.8421884463469429
giniLeftRatio:  0.6651062927485485
impurityDrop:  0.8096702963779947
giniGain:  0.0419636662700803
lclasses:  [55, 7, 511, 81, 97, 66, 52, 40, 11, 9]
rclasses:  [81, 53, 384, 847, 852, 903, 899, 897, 58, 85]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([929, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 929
nodeId:  5 , imgTensorShape :  torch.Size([5059, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5059
Nodes sizes =  1 5
Node 3 Acc: 71.785
Split Acc: 83.574
lTrainDict[data].shape:  torch.Size([3033, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([3033])
rTrainDict[data].shape:  torch.Size([979, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([979])
# of Left images:  3033.0
# of Right images:  979.0
giniRightRatio:  0.46944778030155226
giniLeftRatio:  0.741663005978092
impurityDrop:  1.3127866766007812
giniGain:  -0.5205279840841137
lclasses:  [160, 923, 41, 58, 27, 18, 41, 39, 856, 870]
rclasses:  [704, 17, 64, 14, 24, 13, 8, 24, 75, 36]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([3033, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3033
nodeId:  7 , imgTensorShape :  torch.Size([979, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 979
Nodes sizes =  3 1
Node 4 Acc: 55.005
Node 5 Acc: 57.838
Split Acc: 79.047
lTrainDict[data].shape:  torch.Size([977, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([977])
rTrainDict[data].shape:  torch.Size([4082, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4082])
# of Left images:  977.0
# of Right images:  4082.0
giniRightRatio:  0.8257652230211578
giniLeftRatio:  0.46904179967292764
impurityDrop:  0.740385804939036
giniGain:  0.10180264140790685
lclasses:  [6, 7, 36, 51, 86, 61, 5, 701, 11, 13]
rclasses:  [75, 46, 348, 796, 766, 842, 894, 196, 47, 72]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([977, 3, 32, 32])
nodeId: 8 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 977
nodeId:  9 , imgTensorShape :  torch.Size([4082, 3, 32, 32])
nodeId: 9 ,  parentId: 5 ,  level: 3 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 4082
Nodes sizes =  1 4
Node 6 Acc: 72.535
Split Acc: 82.196
lTrainDict[data].shape:  torch.Size([2083, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2083])
rTrainDict[data].shape:  torch.Size([950, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([950])
# of Left images:  2083.0
# of Right images:  950.0
giniRightRatio:  0.3548653739612188
giniLeftRatio:  0.647580521188719
impurityDrop:  0.9966818494084639
giniGain:  -0.25501884343037196
lclasses:  [89, 896, 23, 38, 16, 15, 32, 37, 98, 839]
rclasses:  [71, 27, 18, 20, 11, 3, 9, 2, 758, 31]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([2083, 3, 32, 32])
nodeId: 10 ,  parentId: 6 ,  level: 3 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2083
nodeId:  11 , imgTensorShape :  torch.Size([950, 3, 32, 32])
nodeId: 11 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 950
Nodes sizes =  2 1
Node 7 Acc: 71.910
Node 8 Acc: 71.750
Node 9 Acc: 54.557
Split Acc: 64.037
lTrainDict[data].shape:  torch.Size([3141, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([3141])
rTrainDict[data].shape:  torch.Size([941, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([941])
# of Left images:  3141.0
# of Right images:  941.0
giniRightRatio:  0.7189990524923742
giniLeftRatio:  0.8138756184065061
impurityDrop:  1.0356911816488974
giniGain:  -0.20992595862773955
lclasses:  [56, 31, 275, 358, 700, 638, 838, 159, 35, 51]
rclasses:  [19, 15, 73, 438, 66, 204, 56, 37, 12, 21]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([3141, 3, 32, 32])
nodeId: 12 ,  parentId: 9 ,  level: 4 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3141
nodeId:  13 , imgTensorShape :  torch.Size([941, 3, 32, 32])
nodeId: 13 ,  parentId: 9 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 941
Nodes sizes =  3 1
Node 10 Acc: 70.811
Split Acc: 72.252
lTrainDict[data].shape:  torch.Size([1010, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1010])
rTrainDict[data].shape:  torch.Size([1073, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1073])
# of Left images:  1010.0
# of Right images:  1073.0
giniRightRatio:  0.5026973176216356
giniLeftRatio:  0.4121184197627684
impurityDrop:  0.4174366588728417
giniGain:  0.2301438623158773
lclasses:  [26, 765, 8, 11, 4, 8, 25, 9, 55, 99]
rclasses:  [63, 131, 15, 27, 12, 7, 7, 28, 43, 740]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([1010, 3, 32, 32])
nodeId: 14 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 1010
nodeId:  15 , imgTensorShape :  torch.Size([1073, 3, 32, 32])
nodeId: 15 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1073
Nodes sizes =  1 1
Node 11 Acc: 79.789
Node 12 Acc: 56.256
Split Acc: 61.891
lTrainDict[data].shape:  torch.Size([2168, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2168])
rTrainDict[data].shape:  torch.Size([973, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([973])
# of Left images:  2168.0
# of Right images:  973.0
giniRightRatio:  0.46961274028787536
giniLeftRatio:  0.7974547596029467
impurityDrop:  1.200097321865547
giniGain:  -0.38622170345904094
lclasses:  [38, 25, 207, 296, 646, 599, 139, 146, 28, 44]
rclasses:  [18, 6, 68, 62, 54, 39, 699, 13, 7, 7]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([2168, 3, 32, 32])
nodeId: 16 ,  parentId: 12 ,  level: 5 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2168
nodeId:  17 , imgTensorShape :  torch.Size([973, 3, 32, 32])
nodeId: 17 ,  parentId: 12 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 973
Nodes sizes =  2 1
Node 13 Acc: 46.546
Node 14 Acc: 75.743
Node 15 Acc: 68.966
Node 16 Acc: 49.954
Split Acc: 50.507
lTrainDict[data].shape:  torch.Size([1069, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1069])
rTrainDict[data].shape:  torch.Size([1099, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1099])
# of Left images:  1069.0
# of Right images:  1099.0
giniRightRatio:  0.7154489853874934
giniLeftRatio:  0.6821846387827375
impurityDrop:  0.6830926737219027
giniGain:  0.1143620858810439
lclasses:  [25, 12, 121, 92, 568, 72, 80, 68, 15, 16]
rclasses:  [13, 13, 86, 204, 78, 527, 59, 78, 13, 28]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1069, 3, 32, 32])
nodeId: 18 ,  parentId: 16 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 1069
nodeId:  19 , imgTensorShape :  torch.Size([1099, 3, 32, 32])
nodeId: 19 ,  parentId: 16 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1099
Nodes sizes =  1 1
Node 17 Acc: 71.840
Node 18 Acc: 53.134
Node 19 Acc: 47.953
[[704  26  55  19  25  13  18   6  71  63]
 [ 17 765   7  15  12  13   6   7  27 131]
 [ 64   8 511  73 121  86  68  36  18  15]
 [ 14  11  81 438  92 204  62  51  20  27]
 [ 24   4  97  66 568  78  54  86  11  12]
 [ 13   8  66 204  72 527  39  61   3   7]
 [  8  25  52  56  80  59 699   5   9   7]
 [ 24   9  40  37  68  78  13 701   2  28]
 [ 75  55  11  12  15  13   7  11 758  43]
 [ 36  99   9  21  16  28   7  13  31 740]]

Final Acc: 64.110

Level 0 Acc: 62.520
Level 1 Acc: 62.630
Level 2 Acc: 63.410
Level 3 Acc: 63.760
Level 4 Acc: 63.840
Level 5 Acc: 63.990
Level 6 Acc: 64.110

                                                 1                                                                           
       ┌─────────────────────────────────────────┴───────────┐                                                               
       3                                                     2                                                               
 ┌─────┴─────────────┐                                 ┌─────┴───────────┐                                                   
 7                   6                                 4                 5                                                   
              ┌──────┴─────────────┐                               ┌─────┴─────────────┐                                     
              11                   10                              8                   9                                     
                            ┌──────┴──────┐                                     ┌──────┴─────────────┐                       
                            14            15                                    13                   12                      
                                                                                              ┌──────┴─────────────┐         
                                                                                              17                   16        
                                                                                                            ┌──────┴──────┐  
                                                                                                            18            19 

                                           -1                                                                  
       ┌───────────────────────────────────┴───────────┐                                                       
       -1                                              -1                                                      
 ┌─────┴───────────┐                             ┌─────┴───────────┐                                           
 0                 -1                            2                 -1                                          
             ┌─────┴───────────┐                             ┌─────┴───────────┐                               
             8                 -1                            7                 -1                              
                         ┌─────┴─────┐                                   ┌─────┴───────────┐                   
                         1           9                                   3                 -1                  
                                                                                     ┌─────┴───────────┐       
                                                                                     6                 -1      
                                                                                                 ┌─────┴─────┐ 
                                                                                                 4           5 

                                                         49000                                                                                         
           ┌───────────────────────────────────────────────┴───────────────┐                                                                           
         19600                                                           29400                                                                         
   ┌───────┴───────────────┐                                       ┌───────┴───────────────┐                                                           
  4900                   14700                                    4900                   24500                                                         
                   ┌───────┴───────────────┐                                       ┌───────┴───────────────┐                                           
                  4900                    9800                                    4900                   19600                                         
                                   ┌───────┴───────┐                                               ┌───────┴───────────────┐                           
                                  4900            4900                                            4900                   14700                         
                                                                                                                   ┌───────┴───────────────┐           
                                                                                                                  4900                    9800         
                                                                                                                                   ┌───────┴───────┐   
                                                                                                                                  4900            4900 

                                  {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                                                                
                   ┌───────────────────────────────────────────────────────────┴────────────────────────────────┐                                                                                                           
  {0: 4900, 1: 4900, 8: 4900, 9: 4900}                                               {2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900}                                                                                 
       ┌─────────┴───────────────────┐                                                         ┌─────────┴───────────────────────────┐                                                                                      
   {0: 4900}            {1: 4900, 8: 4900, 9: 4900}                                        {2: 4900}           {3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900}                                                                
                           ┌─────────┴───────────────────┐                                                             ┌─────────┴───────────────────────┐                                                                  
                       {8: 4900}                 {1: 4900, 9: 4900}                                                {7: 4900}            {3: 4900, 4: 4900, 5: 4900, 6: 4900}                                                
                                               ┌─────────┴─────────┐                                                                         ┌─────────┴───────────────────┐                                                
                                           {1: 4900}           {9: 4900}                                                                 {3: 4900}            {4: 4900, 5: 4900, 6: 4900}                                   
                                                                                                                                                                 ┌─────────┴───────────────────┐                            
                                                                                                                                                             {6: 4900}                 {4: 4900, 5: 4900}                   
                                                                                                                                                                                     ┌─────────┴─────────┐                  
                                                                                                                                                                                 {4: 4900}           {5: 4900}              

                                                 92.7                                                                               
         ┌─────────────────────────────────────────┴─────────────┐                                                                  
 83.57427716849452                                       81.98062792251169                                                          
  ┌──────┴─────────────┐                                  ┌──────┴─────────────┐                                                    
 0.0           82.19584569732937                         0.0            79.047242538051                                             
                ┌──────┴─────────────┐                                  ┌──────┴─────────────┐                                      
               0.0           72.25156024963994                         0.0           64.03723664870162                              
                              ┌──────┴──────┐                                         ┌──────┴──────────────┐                       
                             0.0           0.0                                       0.0           61.891117478510026               
                                                                                                    ┌──────┴─────────────┐          
                                                                                                   0.0           50.50738007380074  
                                                                                                                  ┌──────┴──────┐   
                                                                                                                 0.0           0.0  

                                          ┌[704, 979, 71.91]
                     ┌[2880, 4012, 71.785]┤
                     │                    │                    ┌[758, 950, 79.789]
                     │                    └[2200, 3033, 72.535]┤
                     │                                         │                    ┌[765, 1010, 75.743]
                     │                                         └[1475, 2083, 70.811]┤
                     │                                                              └[740, 1073, 68.966]
 [6252, 10000, 62.52]┤
                     │                    ┌[511, 929, 55.005]
                     └[3383, 5988, 56.496]┤
                                          │                    ┌[701, 977, 71.75]
                                          └[2926, 5059, 57.838]┤
                                                               │                    ┌[438, 941, 46.546]
                                                               └[2227, 4082, 54.557]┤
                                                                                    │                    ┌[699, 973, 71.84]
                                                                                    └[1767, 3141, 56.256]┤
                                                                                                         │                    ┌[568, 1069, 53.134]
                                                                                                         └[1083, 2168, 49.954]┤
                                                                                                                              └[527, 1099, 47.953]

                                            0.025000000000000022                                                                         
         ┌───────────────────────────────────────────┴──────────────┐                                                                    
       -1.25                                               0.19333333333333313                                                           
  ┌──────┴───────────────┐                                   ┌──────┴──────────────┐                                                     
 0.0            -0.33333333333333326                        0.0           0.23750000000000016                                            
                 ┌──────┴─────────────┐                                    ┌──────┴─────────────┐                                        
                0.0                  0.5                                  0.0                 -1.25                                      
                               ┌──────┴──────┐                                           ┌──────┴───────────────┐                        
                              0.0           0.0                                         0.0            -0.33333333333333326              
                                                                                                        ┌──────┴─────────────┐           
                                                                                                       0.0                  0.5          
                                                                                                                      ┌──────┴──────┐    
                                                                                                                     0.0           0.0   

Time Taken by whole program is  35.833641962210336  minutes.
