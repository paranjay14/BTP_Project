['options.ckptDir: valDir1024_cOut16_mFC2_16', 'options.maxDepth: 6', 'options.cnnLR: 0.001', 'options.mlpLR: 0.001', 'options.cnnEpochs: 100', 'options.mlpEpochs: 60', 'options.cnnOut: 16', 'options.mlpFC1: 1024', 'options.mlpFC2: 16']
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  49000 ,  len(valInputDict["data"]):  1000 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([49000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 49000
Running nodeId:  1
0 Train Loss: 177.956 | Train Acc: 37.506 | Val Loss: 1.554 | Val Accuracy: 45.300
10 Train Loss: 110.440 | Train Acc: 61.871 | Val Loss: 1.218 | Val Accuracy: 58.300
20 Train Loss: 95.641 | Train Acc: 66.978 | Val Loss: 1.156 | Val Accuracy: 60.100
30 Train Loss: 86.108 | Train Acc: 70.427 | Val Loss: 1.148 | Val Accuracy: 62.400
40 Train Loss: 77.209 | Train Acc: 73.724 | Val Loss: 1.152 | Val Accuracy: 61.300
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 71.861 | Train Acc: 75.508 | Val Loss: 1.186 | Val Accuracy: 62.100
60 Train Loss: 65.164 | Train Acc: 78.429 | Val Loss: 1.173 | Val Accuracy: 61.500
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 63.992 | Train Acc: 78.869 | Val Loss: 1.183 | Val Accuracy: 61.100
80 Train Loss: 62.439 | Train Acc: 79.669 | Val Loss: 1.183 | Val Accuracy: 61.100
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 62.157 | Train Acc: 79.829 | Val Loss: 1.187 | Val Accuracy: 61.100
CNN trained successfully...
image_next_flat.shape :  torch.Size([49000, 12544])
Kmeans trained successfully...
printing expected split from k means
{8: 0, 5: 1, 9: 0, 2: 1, 4: 1, 0: 0, 1: 0, 7: 1, 6: 1, 3: 1}
Printing final_dict items...
{8: 0, 0: 0, 9: 0, 1: 0, 2: 0, 3: 1, 7: 1, 5: 1, 4: 1, 6: 1}
Image Statistics before MLP : L R :  24500 24500
expectedMlpLabels.shape :  torch.Size([49000])
0 Loss: 83.496 | Acc: 81.473
1 Loss: 70.117 | Acc: 84.682
2 Loss: 65.605 | Acc: 85.839
3 Loss: 62.576 | Acc: 86.569
4 Loss: 58.443 | Acc: 87.329
5 Loss: 56.059 | Acc: 87.635
6 Loss: 53.416 | Acc: 88.455
7 Loss: 50.211 | Acc: 89.116
8 Loss: 48.114 | Acc: 89.420
9 Loss: 45.629 | Acc: 90.100
10 Loss: 38.585 | Acc: 91.639
11 Loss: 35.594 | Acc: 92.222
12 Loss: 33.771 | Acc: 92.771
13 Loss: 31.979 | Acc: 93.088
14 Loss: 31.030 | Acc: 93.384
15 Loss: 29.467 | Acc: 93.608
16 Loss: 27.784 | Acc: 94.167
17 Loss: 26.125 | Acc: 94.682
18 Loss: 24.969 | Acc: 94.849
19 Loss: 23.774 | Acc: 95.051
20 Loss: 19.587 | Acc: 96.022
21 Loss: 18.116 | Acc: 96.312
22 Loss: 17.432 | Acc: 96.500
23 Loss: 16.999 | Acc: 96.584
24 Loss: 16.050 | Acc: 96.773
25 Loss: 15.429 | Acc: 96.969
26 Loss: 15.143 | Acc: 96.939
27 Loss: 14.419 | Acc: 97.163
28 Loss: 13.849 | Acc: 97.237
29 Loss: 13.406 | Acc: 97.347
30 Loss: 11.465 | Acc: 97.690
31 Loss: 11.164 | Acc: 97.763
32 Loss: 11.451 | Acc: 97.786
33 Loss: 10.988 | Acc: 97.894
34 Loss: 10.372 | Acc: 98.024
35 Loss: 10.605 | Acc: 97.982
36 Loss: 10.219 | Acc: 98.012
37 Loss: 10.206 | Acc: 98.059
38 Loss: 10.465 | Acc: 97.986
39 Loss: 9.867 | Acc: 98.229
40 Loss: 9.440 | Acc: 98.249
41 Loss: 8.975 | Acc: 98.261
42 Loss: 9.298 | Acc: 98.220
43 Loss: 9.150 | Acc: 98.224
44 Loss: 8.688 | Acc: 98.343
45 Loss: 8.608 | Acc: 98.406
46 Loss: 8.533 | Acc: 98.480
47 Loss: 8.618 | Acc: 98.371
48 Loss: 8.216 | Acc: 98.431
49 Loss: 8.317 | Acc: 98.429
50 Loss: 7.524 | Acc: 98.614
51 Loss: 8.156 | Acc: 98.508
52 Loss: 7.973 | Acc: 98.531
53 Loss: 7.888 | Acc: 98.518
54 Loss: 7.565 | Acc: 98.565
55 Loss: 7.983 | Acc: 98.522
56 Loss: 7.919 | Acc: 98.480
57 Loss: 7.828 | Acc: 98.514
58 Loss: 7.712 | Acc: 98.582
59 Loss: 7.502 | Acc: 98.655
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([24500])
rTrainDict[data].shape:  torch.Size([24500, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([24500])
lValDict[data].shape:  torch.Size([500, 3, 32, 32])   lValDict[label].shape:  torch.Size([500])
rValDict[data].shape:  torch.Size([500, 3, 32, 32])   rValDict[label].shape:  torch.Size([500])
# of Left images:  24500.0
# of Right images:  24500.0
giniRightRatio:  0.8000000000000002
giniLeftRatio:  0.8000000000000002
impurityDrop:  0.8000000000000002
giniGain:  0.09999999999999987
lclasses:  [4900, 4900, 4900, 0, 0, 0, 0, 0, 4900, 4900]
rclasses:  [0, 0, 0, 4900, 4900, 4900, 4900, 4900, 0, 0]
noOfLeftClasses:  5
noOfRightClasses:  5
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
nodeId:  3 , imgTensorShape :  torch.Size([24500, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 24500
Running nodeId:  2
0 Train Loss: 121.566 | Train Acc: 52.498 | Val Loss: 1.008 | Val Accuracy: 62.400
10 Train Loss: 65.624 | Train Acc: 75.804 | Val Loss: 0.733 | Val Accuracy: 73.600
20 Train Loss: 53.584 | Train Acc: 80.678 | Val Loss: 0.712 | Val Accuracy: 75.600
30 Train Loss: 46.210 | Train Acc: 83.404 | Val Loss: 0.722 | Val Accuracy: 76.000
40 Train Loss: 40.424 | Train Acc: 85.649 | Val Loss: 0.753 | Val Accuracy: 75.600
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 35.239 | Train Acc: 87.833 | Val Loss: 0.799 | Val Accuracy: 73.800
60 Train Loss: 30.890 | Train Acc: 90.139 | Val Loss: 0.793 | Val Accuracy: 74.200
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 30.015 | Train Acc: 90.478 | Val Loss: 0.800 | Val Accuracy: 74.400
80 Train Loss: 28.984 | Train Acc: 91.049 | Val Loss: 0.802 | Val Accuracy: 74.800
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 28.734 | Train Acc: 91.102 | Val Loss: 0.799 | Val Accuracy: 74.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Kmeans trained successfully...
printing expected split from k means
{4: 0, 3: 1, 2: 0, 1: 0, 0: 1}
Printing final_dict items...
{2: 0, 4: 0, 1: 1, 3: 1, 0: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 79.467 | Acc: 75.567
1 Loss: 67.803 | Acc: 80.273
2 Loss: 61.782 | Acc: 82.461
3 Loss: 57.343 | Acc: 84.135
4 Loss: 54.010 | Acc: 85.114
5 Loss: 50.387 | Acc: 86.167
6 Loss: 46.841 | Acc: 87.057
7 Loss: 45.385 | Acc: 87.396
8 Loss: 42.804 | Acc: 88.302
9 Loss: 38.943 | Acc: 89.359
10 Loss: 30.637 | Acc: 91.661
11 Loss: 28.274 | Acc: 92.380
12 Loss: 26.953 | Acc: 92.771
13 Loss: 24.137 | Acc: 93.629
14 Loss: 22.736 | Acc: 93.914
15 Loss: 21.120 | Acc: 94.522
16 Loss: 19.555 | Acc: 95.024
17 Loss: 18.489 | Acc: 95.212
18 Loss: 17.436 | Acc: 95.531
19 Loss: 17.228 | Acc: 95.404
20 Loss: 12.972 | Acc: 96.788
21 Loss: 12.338 | Acc: 97.041
22 Loss: 10.761 | Acc: 97.306
23 Loss: 10.671 | Acc: 97.408
24 Loss: 9.909 | Acc: 97.531
25 Loss: 9.582 | Acc: 97.539
26 Loss: 8.955 | Acc: 97.878
27 Loss: 8.864 | Acc: 97.861
28 Loss: 8.921 | Acc: 97.820
29 Loss: 8.283 | Acc: 98.053
30 Loss: 6.987 | Acc: 98.314
31 Loss: 6.594 | Acc: 98.347
32 Loss: 6.235 | Acc: 98.584
33 Loss: 6.131 | Acc: 98.539
34 Loss: 6.105 | Acc: 98.620
35 Loss: 5.957 | Acc: 98.653
36 Loss: 6.073 | Acc: 98.506
37 Loss: 5.909 | Acc: 98.616
38 Loss: 5.495 | Acc: 98.706
39 Loss: 5.067 | Acc: 98.894
40 Loss: 4.934 | Acc: 98.812
41 Loss: 5.199 | Acc: 98.829
42 Loss: 4.701 | Acc: 98.878
43 Loss: 4.902 | Acc: 98.841
44 Loss: 4.760 | Acc: 98.906
45 Loss: 4.428 | Acc: 99.000
46 Loss: 4.542 | Acc: 98.898
47 Loss: 4.835 | Acc: 98.792
48 Loss: 4.527 | Acc: 98.894
49 Loss: 4.129 | Acc: 99.061
50 Loss: 4.127 | Acc: 99.029
51 Loss: 4.688 | Acc: 98.988
52 Loss: 4.015 | Acc: 99.004
53 Loss: 4.137 | Acc: 99.073
54 Loss: 4.423 | Acc: 98.971
55 Loss: 4.011 | Acc: 99.086
56 Loss: 4.451 | Acc: 98.967
57 Loss: 4.021 | Acc: 99.073
58 Loss: 4.410 | Acc: 98.959
59 Loss: 4.144 | Acc: 99.041
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [0, 0, 4900, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [4900, 4900, 0, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  5 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  3
0 Train Loss: 136.016 | Train Acc: 43.033 | Val Loss: 1.267 | Val Accuracy: 48.400
10 Train Loss: 86.765 | Train Acc: 66.694 | Val Loss: 0.952 | Val Accuracy: 63.600
20 Train Loss: 71.114 | Train Acc: 72.984 | Val Loss: 0.943 | Val Accuracy: 65.000
30 Train Loss: 63.576 | Train Acc: 76.249 | Val Loss: 0.982 | Val Accuracy: 64.400
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 56.642 | Train Acc: 79.094 | Val Loss: 1.018 | Val Accuracy: 64.600
50 Train Loss: 50.873 | Train Acc: 82.180 | Val Loss: 1.018 | Val Accuracy: 64.200
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 49.825 | Train Acc: 82.494 | Val Loss: 1.039 | Val Accuracy: 63.400
70 Train Loss: 48.359 | Train Acc: 83.241 | Val Loss: 1.039 | Val Accuracy: 63.600
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 48.016 | Train Acc: 83.469 | Val Loss: 1.040 | Val Accuracy: 63.600
90 Train Loss: 47.769 | Train Acc: 83.551 | Val Loss: 1.039 | Val Accuracy: 64.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([24500, 12544])
Kmeans trained successfully...
printing expected split from k means
{2: 1, 4: 0, 1: 1, 3: 1, 0: 1}
Printing final_dict items...
{4: 0, 0: 0, 2: 1, 3: 1, 1: 1}
Image Statistics before MLP : L R :  9800 14700
expectedMlpLabels.shape :  torch.Size([24500])
0 Loss: 97.136 | Acc: 65.543
1 Loss: 87.810 | Acc: 70.445
2 Loss: 83.490 | Acc: 72.327
3 Loss: 78.564 | Acc: 74.286
4 Loss: 75.646 | Acc: 75.620
5 Loss: 71.323 | Acc: 77.612
6 Loss: 68.159 | Acc: 78.665
7 Loss: 64.233 | Acc: 80.441
8 Loss: 61.106 | Acc: 81.327
9 Loss: 57.459 | Acc: 82.735
10 Loss: 47.139 | Acc: 86.167
11 Loss: 43.639 | Acc: 87.563
12 Loss: 40.234 | Acc: 88.600
13 Loss: 37.228 | Acc: 89.514
14 Loss: 35.599 | Acc: 89.857
15 Loss: 33.189 | Acc: 90.853
16 Loss: 31.674 | Acc: 91.127
17 Loss: 29.041 | Acc: 91.931
18 Loss: 26.817 | Acc: 92.759
19 Loss: 26.532 | Acc: 92.849
20 Loss: 21.217 | Acc: 94.412
21 Loss: 19.003 | Acc: 95.053
22 Loss: 19.005 | Acc: 95.127
23 Loss: 17.360 | Acc: 95.441
24 Loss: 16.919 | Acc: 95.833
25 Loss: 15.820 | Acc: 96.045
26 Loss: 15.096 | Acc: 96.176
27 Loss: 14.522 | Acc: 96.420
28 Loss: 13.701 | Acc: 96.604
29 Loss: 13.138 | Acc: 96.620
30 Loss: 11.551 | Acc: 97.192
31 Loss: 11.075 | Acc: 97.290
32 Loss: 11.074 | Acc: 97.335
33 Loss: 10.341 | Acc: 97.498
34 Loss: 10.044 | Acc: 97.543
35 Loss: 9.729 | Acc: 97.629
36 Loss: 9.946 | Acc: 97.486
37 Loss: 9.499 | Acc: 97.763
38 Loss: 9.323 | Acc: 97.763
39 Loss: 9.141 | Acc: 97.853
40 Loss: 8.460 | Acc: 98.012
41 Loss: 8.062 | Acc: 98.200
42 Loss: 8.134 | Acc: 98.118
43 Loss: 8.028 | Acc: 98.110
44 Loss: 8.122 | Acc: 98.069
45 Loss: 7.933 | Acc: 98.033
46 Loss: 7.885 | Acc: 98.057
47 Loss: 7.744 | Acc: 98.212
48 Loss: 7.424 | Acc: 98.322
49 Loss: 7.358 | Acc: 98.253
50 Loss: 7.383 | Acc: 98.265
51 Loss: 7.430 | Acc: 98.363
52 Loss: 7.431 | Acc: 98.224
53 Loss: 7.133 | Acc: 98.233
54 Loss: 7.227 | Acc: 98.322
55 Loss: 7.136 | Acc: 98.441
56 Loss: 7.442 | Acc: 98.224
57 Loss: 7.380 | Acc: 98.273
58 Loss: 7.140 | Acc: 98.380
59 Loss: 6.721 | Acc: 98.457
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([9800])
rTrainDict[data].shape:  torch.Size([14700, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([14700])
lValDict[data].shape:  torch.Size([200, 3, 32, 32])   lValDict[label].shape:  torch.Size([200])
rValDict[data].shape:  torch.Size([300, 3, 32, 32])   rValDict[label].shape:  torch.Size([300])
# of Left images:  9800.0
# of Right images:  14700.0
giniRightRatio:  0.6666666666666667
giniLeftRatio:  0.5
impurityDrop:  0.5555555555555556
giniGain:  0.24444444444444458
lclasses:  [4900, 0, 0, 0, 4900, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 4900, 4900, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  3
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
nodeId:  7 , imgTensorShape :  torch.Size([14700, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 14700
Running nodeId:  4
0 Train Loss: 36.629 | Train Acc: 84.857 | Val Loss: 0.304 | Val Accuracy: 90.000
10 Train Loss: 13.863 | Train Acc: 94.878 | Val Loss: 0.203 | Val Accuracy: 91.500
20 Train Loss: 8.958 | Train Acc: 96.694 | Val Loss: 0.213 | Val Accuracy: 92.500
30 Train Loss: 6.438 | Train Acc: 97.929 | Val Loss: 0.240 | Val Accuracy: 92.000
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 4.602 | Train Acc: 98.592 | Val Loss: 0.298 | Val Accuracy: 92.000
50 Train Loss: 2.786 | Train Acc: 99.469 | Val Loss: 0.277 | Val Accuracy: 92.500
60 Train Loss: 2.629 | Train Acc: 99.582 | Val Loss: 0.268 | Val Accuracy: 93.000
70 Train Loss: 2.259 | Train Acc: 99.653 | Val Loss: 0.257 | Val Accuracy: 93.000
Epoch     9: reducing learning rate of group 0 to 4.0000e-05.
80 Train Loss: 1.941 | Train Acc: 99.765 | Val Loss: 0.321 | Val Accuracy: 92.000
90 Train Loss: 1.630 | Train Acc: 99.867 | Val Loss: 0.320 | Val Accuracy: 92.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 52.371 | Acc: 89.531
1 Loss: 36.174 | Acc: 93.020
2 Loss: 30.297 | Acc: 94.204
3 Loss: 26.049 | Acc: 95.184
4 Loss: 25.413 | Acc: 95.367
5 Loss: 20.199 | Acc: 96.071
6 Loss: 18.073 | Acc: 96.469
7 Loss: 15.940 | Acc: 96.959
8 Loss: 16.335 | Acc: 96.673
9 Loss: 12.186 | Acc: 97.673
10 Loss: 7.105 | Acc: 98.663
11 Loss: 4.728 | Acc: 99.163
12 Loss: 4.114 | Acc: 99.235
13 Loss: 3.658 | Acc: 99.418
14 Loss: 2.963 | Acc: 99.500
15 Loss: 3.206 | Acc: 99.306
16 Loss: 2.837 | Acc: 99.510
17 Loss: 1.826 | Acc: 99.612
18 Loss: 2.432 | Acc: 99.500
19 Loss: 1.970 | Acc: 99.684
20 Loss: 1.197 | Acc: 99.806
21 Loss: 0.765 | Acc: 99.918
22 Loss: 0.486 | Acc: 99.959
23 Loss: 0.677 | Acc: 99.908
24 Loss: 0.425 | Acc: 99.918
25 Loss: 0.393 | Acc: 99.939
26 Loss: 0.257 | Acc: 99.980
27 Loss: 0.809 | Acc: 99.847
28 Loss: 0.611 | Acc: 99.918
29 Loss: 0.623 | Acc: 99.888
30 Loss: 0.200 | Acc: 99.990
31 Loss: 0.197 | Acc: 99.969
32 Loss: 0.308 | Acc: 99.949
33 Loss: 0.161 | Acc: 99.980
34 Loss: 0.209 | Acc: 99.949
35 Loss: 0.218 | Acc: 99.949
36 Loss: 0.169 | Acc: 99.969
37 Loss: 0.134 | Acc: 99.990
38 Loss: 0.111 | Acc: 100.000
39 Loss: 0.166 | Acc: 99.980
40 Loss: 0.094 | Acc: 100.000
41 Loss: 0.102 | Acc: 99.990
42 Loss: 0.088 | Acc: 100.000
43 Loss: 0.064 | Acc: 100.000
44 Loss: 0.085 | Acc: 99.990
45 Loss: 0.120 | Acc: 99.990
46 Loss: 0.146 | Acc: 99.990
47 Loss: 0.075 | Acc: 100.000
48 Loss: 0.067 | Acc: 99.990
49 Loss: 0.063 | Acc: 100.000
50 Loss: 0.072 | Acc: 99.990
51 Loss: 0.102 | Acc: 99.980
52 Loss: 0.048 | Acc: 100.000
53 Loss: 0.050 | Acc: 100.000
54 Loss: 0.073 | Acc: 100.000
55 Loss: 0.042 | Acc: 100.000
56 Loss: 0.064 | Acc: 99.990
57 Loss: 0.049 | Acc: 100.000
58 Loss: 0.199 | Acc: 99.959
59 Loss: 0.033 | Acc: 100.000
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 2
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 2
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 9
nodeId:  8 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 4900
nodeId:  9 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  5
0 Train Loss: 85.390 | Train Acc: 61.320 | Val Loss: 0.703 | Val Accuracy: 72.333
10 Train Loss: 42.430 | Train Acc: 83.204 | Val Loss: 0.485 | Val Accuracy: 79.667
20 Train Loss: 32.792 | Train Acc: 87.605 | Val Loss: 0.492 | Val Accuracy: 79.333
30 Train Loss: 27.026 | Train Acc: 90.007 | Val Loss: 0.513 | Val Accuracy: 80.333
40 Train Loss: 22.518 | Train Acc: 91.673 | Val Loss: 0.549 | Val Accuracy: 79.333
Epoch     6: reducing learning rate of group 0 to 2.0000e-04.
50 Train Loss: 18.499 | Train Acc: 93.218 | Val Loss: 0.654 | Val Accuracy: 76.667
60 Train Loss: 14.473 | Train Acc: 95.884 | Val Loss: 0.598 | Val Accuracy: 80.000
Epoch     8: reducing learning rate of group 0 to 4.0000e-05.
70 Train Loss: 13.818 | Train Acc: 95.966 | Val Loss: 0.611 | Val Accuracy: 80.333
80 Train Loss: 13.045 | Train Acc: 96.490 | Val Loss: 0.622 | Val Accuracy: 80.000
Epoch    10: reducing learning rate of group 0 to 8.0000e-06.
90 Train Loss: 12.945 | Train Acc: 96.497 | Val Loss: 0.625 | Val Accuracy: 80.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 12544])
Kmeans trained successfully...
printing expected split from k means
{2: 0, 1: 0, 0: 1}
Printing final_dict items...
{1: 0, 2: 1, 0: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 44.845 | Acc: 85.637
1 Loss: 34.136 | Acc: 89.630
2 Loss: 28.452 | Acc: 91.185
3 Loss: 25.706 | Acc: 92.096
4 Loss: 22.171 | Acc: 93.048
5 Loss: 19.392 | Acc: 93.870
6 Loss: 16.950 | Acc: 94.418
7 Loss: 15.260 | Acc: 95.363
8 Loss: 13.432 | Acc: 96.021
9 Loss: 11.590 | Acc: 96.719
10 Loss: 6.898 | Acc: 98.014
11 Loss: 5.349 | Acc: 98.493
12 Loss: 4.169 | Acc: 98.938
13 Loss: 4.093 | Acc: 98.801
14 Loss: 3.195 | Acc: 99.178
15 Loss: 4.384 | Acc: 98.842
16 Loss: 3.094 | Acc: 99.226
17 Loss: 3.122 | Acc: 99.130
18 Loss: 2.949 | Acc: 99.205
19 Loss: 2.563 | Acc: 99.329
20 Loss: 1.479 | Acc: 99.651
21 Loss: 0.827 | Acc: 99.836
22 Loss: 0.783 | Acc: 99.822
23 Loss: 0.969 | Acc: 99.760
24 Loss: 0.929 | Acc: 99.795
25 Loss: 0.812 | Acc: 99.842
26 Loss: 0.602 | Acc: 99.877
27 Loss: 0.695 | Acc: 99.870
28 Loss: 0.771 | Acc: 99.822
29 Loss: 0.693 | Acc: 99.815
30 Loss: 0.549 | Acc: 99.849
31 Loss: 0.737 | Acc: 99.856
32 Loss: 0.354 | Acc: 99.938
33 Loss: 0.336 | Acc: 99.925
34 Loss: 0.348 | Acc: 99.918
35 Loss: 0.350 | Acc: 99.918
36 Loss: 0.399 | Acc: 99.911
37 Loss: 0.224 | Acc: 99.973
38 Loss: 0.386 | Acc: 99.945
39 Loss: 0.314 | Acc: 99.925
40 Loss: 0.276 | Acc: 99.973
41 Loss: 0.242 | Acc: 99.966
42 Loss: 0.205 | Acc: 99.973
43 Loss: 0.190 | Acc: 99.945
44 Loss: 0.141 | Acc: 99.979
45 Loss: 0.200 | Acc: 99.959
46 Loss: 0.161 | Acc: 99.959
47 Loss: 0.284 | Acc: 99.952
48 Loss: 0.247 | Acc: 99.932
49 Loss: 0.197 | Acc: 99.973
50 Loss: 0.194 | Acc: 99.959
51 Loss: 0.207 | Acc: 99.952
52 Loss: 0.125 | Acc: 99.993
53 Loss: 0.211 | Acc: 99.952
54 Loss: 0.189 | Acc: 99.979
55 Loss: 0.096 | Acc: 100.000
56 Loss: 0.103 | Acc: 99.986
57 Loss: 0.167 | Acc: 99.986
58 Loss: 0.191 | Acc: 99.952
59 Loss: 0.171 | Acc: 99.973
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 1
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 1
nodeId:  10 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 4900
nodeId:  11 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  6
0 Train Loss: 52.682 | Train Acc: 73.194 | Val Loss: 0.476 | Val Accuracy: 80.500
10 Train Loss: 27.819 | Train Acc: 88.776 | Val Loss: 0.373 | Val Accuracy: 81.500
20 Train Loss: 22.608 | Train Acc: 91.102 | Val Loss: 0.323 | Val Accuracy: 86.000
30 Train Loss: 18.561 | Train Acc: 92.582 | Val Loss: 0.327 | Val Accuracy: 85.500
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 14.794 | Train Acc: 94.469 | Val Loss: 0.353 | Val Accuracy: 85.000
50 Train Loss: 11.810 | Train Acc: 96.429 | Val Loss: 0.350 | Val Accuracy: 86.000
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 11.140 | Train Acc: 96.643 | Val Loss: 0.357 | Val Accuracy: 86.000
70 Train Loss: 10.276 | Train Acc: 97.153 | Val Loss: 0.345 | Val Accuracy: 85.500
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 10.208 | Train Acc: 97.051 | Val Loss: 0.348 | Val Accuracy: 85.500
90 Train Loss: 9.981 | Train Acc: 97.296 | Val Loss: 0.349 | Val Accuracy: 86.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 91.272 | Acc: 78.806
1 Loss: 67.858 | Acc: 85.388
2 Loss: 59.972 | Acc: 87.143
3 Loss: 54.041 | Acc: 89.061
4 Loss: 50.988 | Acc: 89.653
5 Loss: 44.955 | Acc: 90.653
6 Loss: 41.535 | Acc: 91.235
7 Loss: 38.558 | Acc: 92.112
8 Loss: 35.247 | Acc: 92.765
9 Loss: 30.935 | Acc: 93.531
10 Loss: 21.357 | Acc: 96.020
11 Loss: 17.131 | Acc: 96.622
12 Loss: 14.379 | Acc: 97.255
13 Loss: 13.398 | Acc: 97.378
14 Loss: 11.154 | Acc: 97.867
15 Loss: 10.553 | Acc: 97.980
16 Loss: 9.571 | Acc: 98.153
17 Loss: 9.265 | Acc: 98.235
18 Loss: 6.883 | Acc: 98.827
19 Loss: 6.285 | Acc: 98.837
20 Loss: 4.369 | Acc: 99.276
21 Loss: 3.314 | Acc: 99.459
22 Loss: 2.901 | Acc: 99.500
23 Loss: 2.662 | Acc: 99.582
24 Loss: 2.031 | Acc: 99.673
25 Loss: 2.246 | Acc: 99.643
26 Loss: 2.926 | Acc: 99.561
27 Loss: 2.255 | Acc: 99.653
28 Loss: 2.331 | Acc: 99.714
29 Loss: 2.014 | Acc: 99.653
30 Loss: 1.340 | Acc: 99.806
31 Loss: 1.115 | Acc: 99.867
32 Loss: 1.238 | Acc: 99.867
33 Loss: 0.855 | Acc: 99.908
34 Loss: 1.194 | Acc: 99.867
35 Loss: 0.929 | Acc: 99.878
36 Loss: 0.904 | Acc: 99.898
37 Loss: 0.679 | Acc: 99.949
38 Loss: 0.723 | Acc: 99.918
39 Loss: 0.838 | Acc: 99.898
40 Loss: 0.653 | Acc: 99.949
41 Loss: 0.546 | Acc: 99.959
42 Loss: 0.439 | Acc: 99.969
43 Loss: 0.642 | Acc: 99.929
44 Loss: 0.459 | Acc: 99.949
45 Loss: 0.357 | Acc: 100.000
46 Loss: 0.383 | Acc: 99.959
47 Loss: 0.633 | Acc: 99.918
48 Loss: 0.557 | Acc: 99.918
49 Loss: 0.455 | Acc: 99.959
50 Loss: 0.437 | Acc: 99.939
51 Loss: 0.523 | Acc: 99.929
52 Loss: 0.481 | Acc: 99.959
53 Loss: 0.407 | Acc: 99.969
54 Loss: 0.287 | Acc: 100.000
55 Loss: 0.475 | Acc: 99.959
56 Loss: 0.527 | Acc: 99.908
57 Loss: 0.471 | Acc: 99.959
58 Loss: 0.509 | Acc: 99.929
59 Loss: 0.454 | Acc: 99.939
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 7
nodeId:  12 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 4900
nodeId:  13 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  7
0 Train Loss: 89.932 | Train Acc: 57.537 | Val Loss: 0.782 | Val Accuracy: 63.000
10 Train Loss: 49.197 | Train Acc: 80.354 | Val Loss: 0.637 | Val Accuracy: 73.667
20 Train Loss: 40.101 | Train Acc: 84.245 | Val Loss: 0.653 | Val Accuracy: 74.000
30 Train Loss: 34.261 | Train Acc: 86.966 | Val Loss: 0.705 | Val Accuracy: 71.667
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 29.254 | Train Acc: 89.265 | Val Loss: 0.739 | Val Accuracy: 73.000
50 Train Loss: 24.649 | Train Acc: 91.673 | Val Loss: 0.733 | Val Accuracy: 72.333
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 23.711 | Train Acc: 92.211 | Val Loss: 0.759 | Val Accuracy: 73.000
70 Train Loss: 22.728 | Train Acc: 92.939 | Val Loss: 0.741 | Val Accuracy: 72.000
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 22.477 | Train Acc: 93.034 | Val Loss: 0.747 | Val Accuracy: 71.667
90 Train Loss: 22.258 | Train Acc: 93.088 | Val Loss: 0.747 | Val Accuracy: 72.000
CNN trained successfully...
image_next_flat.shape :  torch.Size([14700, 12544])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0, 2: 0}
Printing final_dict items...
{2: 0, 0: 1, 1: 1}
Image Statistics before MLP : L R :  4900 9800
expectedMlpLabels.shape :  torch.Size([14700])
0 Loss: 58.909 | Acc: 79.041
1 Loss: 45.352 | Acc: 85.507
2 Loss: 39.979 | Acc: 87.863
3 Loss: 36.004 | Acc: 89.007
4 Loss: 32.236 | Acc: 90.082
5 Loss: 28.824 | Acc: 91.322
6 Loss: 26.002 | Acc: 92.226
7 Loss: 23.775 | Acc: 92.692
8 Loss: 21.336 | Acc: 93.288
9 Loss: 18.043 | Acc: 94.562
10 Loss: 12.313 | Acc: 96.356
11 Loss: 9.591 | Acc: 97.158
12 Loss: 8.095 | Acc: 97.671
13 Loss: 7.472 | Acc: 97.760
14 Loss: 7.178 | Acc: 97.993
15 Loss: 5.904 | Acc: 98.329
16 Loss: 5.773 | Acc: 98.397
17 Loss: 6.295 | Acc: 98.267
18 Loss: 5.347 | Acc: 98.397
19 Loss: 5.020 | Acc: 98.644
20 Loss: 2.659 | Acc: 99.342
21 Loss: 2.106 | Acc: 99.452
22 Loss: 1.785 | Acc: 99.555
23 Loss: 1.817 | Acc: 99.500
24 Loss: 1.563 | Acc: 99.651
25 Loss: 1.482 | Acc: 99.623
26 Loss: 1.582 | Acc: 99.630
27 Loss: 1.145 | Acc: 99.788
28 Loss: 1.351 | Acc: 99.699
29 Loss: 1.423 | Acc: 99.664
30 Loss: 1.069 | Acc: 99.767
31 Loss: 0.828 | Acc: 99.795
32 Loss: 0.783 | Acc: 99.856
33 Loss: 0.677 | Acc: 99.822
34 Loss: 0.694 | Acc: 99.877
35 Loss: 0.785 | Acc: 99.767
36 Loss: 0.603 | Acc: 99.856
37 Loss: 0.855 | Acc: 99.801
38 Loss: 0.588 | Acc: 99.884
39 Loss: 0.963 | Acc: 99.760
40 Loss: 0.594 | Acc: 99.877
41 Loss: 0.424 | Acc: 99.911
42 Loss: 0.525 | Acc: 99.932
43 Loss: 0.557 | Acc: 99.856
44 Loss: 0.602 | Acc: 99.870
45 Loss: 0.422 | Acc: 99.925
46 Loss: 0.533 | Acc: 99.877
47 Loss: 0.348 | Acc: 99.938
48 Loss: 0.406 | Acc: 99.911
49 Loss: 0.521 | Acc: 99.863
50 Loss: 0.385 | Acc: 99.925
51 Loss: 0.419 | Acc: 99.932
52 Loss: 0.384 | Acc: 99.932
53 Loss: 0.493 | Acc: 99.925
54 Loss: 0.398 | Acc: 99.938
55 Loss: 0.462 | Acc: 99.932
56 Loss: 0.368 | Acc: 99.925
57 Loss: 0.302 | Acc: 99.952
58 Loss: 0.318 | Acc: 99.973
59 Loss: 0.447 | Acc: 99.897
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([9800, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([9800])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([200, 3, 32, 32])   rValDict[label].shape:  torch.Size([200])
# of Left images:  4900.0
# of Right images:  9800.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 0, 4900, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 6
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 6
nodeId:  14 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 4900
nodeId:  15 , imgTensorShape :  torch.Size([9800, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 9800
Running nodeId:  8
Running nodeId:  9
Running nodeId:  10
Running nodeId:  11
0 Train Loss: 64.201 | Train Acc: 65.092 | Val Loss: 0.537 | Val Accuracy: 71.500
10 Train Loss: 32.767 | Train Acc: 86.010 | Val Loss: 0.452 | Val Accuracy: 77.000
20 Train Loss: 24.788 | Train Acc: 89.765 | Val Loss: 0.352 | Val Accuracy: 83.500
30 Train Loss: 19.487 | Train Acc: 92.480 | Val Loss: 0.372 | Val Accuracy: 83.000
40 Train Loss: 15.198 | Train Acc: 94.367 | Val Loss: 0.401 | Val Accuracy: 85.000
50 Train Loss: 12.068 | Train Acc: 95.653 | Val Loss: 0.400 | Val Accuracy: 87.500
60 Train Loss: 8.923 | Train Acc: 97.602 | Val Loss: 0.568 | Val Accuracy: 80.500
Epoch     8: reducing learning rate of group 0 to 2.0000e-04.
70 Train Loss: 6.585 | Train Acc: 98.286 | Val Loss: 0.526 | Val Accuracy: 80.500
80 Train Loss: 4.914 | Train Acc: 99.286 | Val Loss: 0.567 | Val Accuracy: 82.000
Epoch    10: reducing learning rate of group 0 to 4.0000e-05.
90 Train Loss: 4.565 | Train Acc: 99.367 | Val Loss: 0.601 | Val Accuracy: 81.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 91.033 | Acc: 78.847
1 Loss: 66.517 | Acc: 86.276
2 Loss: 55.783 | Acc: 88.388
3 Loss: 47.699 | Acc: 90.296
4 Loss: 39.587 | Acc: 91.837
5 Loss: 34.111 | Acc: 93.347
6 Loss: 27.917 | Acc: 94.357
7 Loss: 23.833 | Acc: 95.276
8 Loss: 24.423 | Acc: 95.173
9 Loss: 19.339 | Acc: 96.296
10 Loss: 11.057 | Acc: 98.092
11 Loss: 7.673 | Acc: 98.755
12 Loss: 5.435 | Acc: 99.122
13 Loss: 5.432 | Acc: 99.071
14 Loss: 5.312 | Acc: 99.061
15 Loss: 4.338 | Acc: 99.347
16 Loss: 4.686 | Acc: 99.296
17 Loss: 4.113 | Acc: 99.245
18 Loss: 3.276 | Acc: 99.490
19 Loss: 3.481 | Acc: 99.439
20 Loss: 2.732 | Acc: 99.684
21 Loss: 1.635 | Acc: 99.786
22 Loss: 1.675 | Acc: 99.755
23 Loss: 1.185 | Acc: 99.827
24 Loss: 1.151 | Acc: 99.857
25 Loss: 1.246 | Acc: 99.857
26 Loss: 1.095 | Acc: 99.867
27 Loss: 0.875 | Acc: 99.898
28 Loss: 1.070 | Acc: 99.888
29 Loss: 0.880 | Acc: 99.939
30 Loss: 0.680 | Acc: 99.939
31 Loss: 0.573 | Acc: 99.939
32 Loss: 0.603 | Acc: 99.939
33 Loss: 0.733 | Acc: 99.898
34 Loss: 0.719 | Acc: 99.918
35 Loss: 0.547 | Acc: 99.929
36 Loss: 0.828 | Acc: 99.867
37 Loss: 0.422 | Acc: 99.959
38 Loss: 0.391 | Acc: 99.959
39 Loss: 0.463 | Acc: 99.949
40 Loss: 0.380 | Acc: 99.949
41 Loss: 0.327 | Acc: 99.959
42 Loss: 0.416 | Acc: 99.980
43 Loss: 0.497 | Acc: 99.959
44 Loss: 0.308 | Acc: 99.959
45 Loss: 0.379 | Acc: 99.969
46 Loss: 0.253 | Acc: 99.990
47 Loss: 0.360 | Acc: 99.959
48 Loss: 0.346 | Acc: 99.949
49 Loss: 0.350 | Acc: 99.959
50 Loss: 0.271 | Acc: 99.980
51 Loss: 0.533 | Acc: 99.939
52 Loss: 0.216 | Acc: 99.990
53 Loss: 0.326 | Acc: 99.980
54 Loss: 0.386 | Acc: 99.939
55 Loss: 0.328 | Acc: 99.949
56 Loss: 0.265 | Acc: 99.959
57 Loss: 0.207 | Acc: 99.980
58 Loss: 0.311 | Acc: 99.959
59 Loss: 0.218 | Acc: 99.980
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  16 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 4900
nodeId:  17 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  12
Running nodeId:  13
Running nodeId:  14
Running nodeId:  15
0 Train Loss: 53.296 | Train Acc: 72.224 | Val Loss: 0.442 | Val Accuracy: 80.500
10 Train Loss: 32.549 | Train Acc: 86.061 | Val Loss: 0.413 | Val Accuracy: 83.500
20 Train Loss: 24.521 | Train Acc: 90.163 | Val Loss: 0.439 | Val Accuracy: 84.000
30 Train Loss: 20.279 | Train Acc: 91.796 | Val Loss: 0.481 | Val Accuracy: 83.000
Epoch     5: reducing learning rate of group 0 to 2.0000e-04.
40 Train Loss: 16.192 | Train Acc: 94.000 | Val Loss: 0.574 | Val Accuracy: 81.000
50 Train Loss: 12.816 | Train Acc: 96.122 | Val Loss: 0.541 | Val Accuracy: 79.500
Epoch     7: reducing learning rate of group 0 to 4.0000e-05.
60 Train Loss: 12.002 | Train Acc: 96.571 | Val Loss: 0.558 | Val Accuracy: 79.500
70 Train Loss: 11.485 | Train Acc: 96.806 | Val Loss: 0.564 | Val Accuracy: 80.000
Epoch     9: reducing learning rate of group 0 to 8.0000e-06.
80 Train Loss: 11.360 | Train Acc: 96.898 | Val Loss: 0.563 | Val Accuracy: 79.000
90 Train Loss: 11.198 | Train Acc: 97.082 | Val Loss: 0.562 | Val Accuracy: 78.500
CNN trained successfully...
image_next_flat.shape :  torch.Size([9800, 12544])
Kmeans trained successfully...
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics before MLP : L R :  4900 4900
expectedMlpLabels.shape :  torch.Size([9800])
0 Loss: 88.067 | Acc: 80.000
1 Loss: 70.443 | Acc: 84.857
2 Loss: 62.777 | Acc: 87.010
3 Loss: 56.104 | Acc: 88.082
4 Loss: 48.564 | Acc: 90.163
5 Loss: 43.385 | Acc: 90.704
6 Loss: 38.478 | Acc: 92.184
7 Loss: 35.908 | Acc: 92.653
8 Loss: 28.701 | Acc: 94.378
9 Loss: 25.896 | Acc: 94.663
10 Loss: 15.683 | Acc: 97.204
11 Loss: 12.494 | Acc: 97.520
12 Loss: 10.191 | Acc: 98.173
13 Loss: 8.186 | Acc: 98.551
14 Loss: 7.419 | Acc: 98.765
15 Loss: 7.473 | Acc: 98.745
16 Loss: 5.855 | Acc: 98.918
17 Loss: 6.518 | Acc: 98.816
18 Loss: 5.599 | Acc: 98.847
19 Loss: 4.896 | Acc: 99.204
20 Loss: 3.025 | Acc: 99.520
21 Loss: 2.766 | Acc: 99.561
22 Loss: 1.613 | Acc: 99.806
23 Loss: 1.396 | Acc: 99.786
24 Loss: 1.787 | Acc: 99.724
25 Loss: 2.153 | Acc: 99.694
26 Loss: 1.682 | Acc: 99.724
27 Loss: 1.343 | Acc: 99.796
28 Loss: 1.499 | Acc: 99.806
29 Loss: 0.830 | Acc: 99.908
30 Loss: 0.964 | Acc: 99.867
31 Loss: 0.605 | Acc: 99.949
32 Loss: 0.918 | Acc: 99.816
33 Loss: 0.726 | Acc: 99.929
34 Loss: 0.556 | Acc: 99.918
35 Loss: 0.639 | Acc: 99.929
36 Loss: 0.545 | Acc: 99.918
37 Loss: 0.539 | Acc: 99.939
38 Loss: 0.623 | Acc: 99.929
39 Loss: 0.672 | Acc: 99.929
40 Loss: 0.445 | Acc: 99.939
41 Loss: 0.364 | Acc: 99.959
42 Loss: 0.388 | Acc: 99.969
43 Loss: 0.338 | Acc: 99.980
44 Loss: 0.494 | Acc: 99.939
45 Loss: 0.426 | Acc: 99.939
46 Loss: 0.388 | Acc: 99.949
47 Loss: 0.317 | Acc: 99.959
48 Loss: 0.398 | Acc: 99.949
49 Loss: 0.469 | Acc: 99.908
50 Loss: 0.315 | Acc: 99.949
51 Loss: 0.313 | Acc: 99.959
52 Loss: 0.408 | Acc: 99.949
53 Loss: 0.426 | Acc: 99.949
54 Loss: 0.296 | Acc: 99.959
55 Loss: 0.327 | Acc: 99.969
56 Loss: 0.298 | Acc: 99.969
57 Loss: 0.405 | Acc: 99.959
58 Loss: 0.495 | Acc: 99.949
59 Loss: 0.246 | Acc: 99.980
MLP trained successfully...
lTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4900])
rTrainDict[data].shape:  torch.Size([4900, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([4900])
lValDict[data].shape:  torch.Size([100, 3, 32, 32])   lValDict[label].shape:  torch.Size([100])
rValDict[data].shape:  torch.Size([100, 3, 32, 32])   rValDict[label].shape:  torch.Size([100])
# of Left images:  4900.0
# of Right images:  4900.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 4900, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [4900, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 5
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 4
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 5
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 4
nodeId:  18 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 4900
nodeId:  19 , imgTensorShape :  torch.Size([4900, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 4900
Running nodeId:  16
Running nodeId:  17
Running nodeId:  18
Running nodeId:  19
TESTING STARTS
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 60.490
Split Acc: 86.950
lTrainDict[data].shape:  torch.Size([4915, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([4915])
rTrainDict[data].shape:  torch.Size([5085, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([5085])
# of Left images:  4915.0
# of Right images:  5085.0
giniRightRatio:  0.8432853873530513
giniLeftRatio:  0.8392942484080849
impurityDrop:  0.8394276788152911
giniGain:  0.0605723211847089
lclasses:  [911, 952, 582, 145, 153, 103, 99, 110, 946, 914]
rclasses:  [89, 48, 418, 855, 847, 897, 901, 890, 54, 86]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([4915, 3, 32, 32])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 4915
nodeId:  3 , imgTensorShape :  torch.Size([5085, 3, 32, 32])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 5 ,  numData: 5085
Nodes sizes =  5 5
Node 2 Acc: 65.310
Split Acc: 75.341
lTrainDict[data].shape:  torch.Size([1904, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1904])
rTrainDict[data].shape:  torch.Size([3011, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3011])
# of Left images:  1904.0
# of Right images:  3011.0
giniRightRatio:  0.762080938474128
giniLeftRatio:  0.7769103965115459
impurityDrop:  0.7714583174522893
giniGain:  0.06783593095579554
lclasses:  [117, 138, 495, 88, 99, 73, 60, 80, 50, 704]
rclasses:  [794, 814, 87, 57, 54, 30, 39, 30, 896, 210]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([1904, 3, 32, 32])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1904
nodeId:  5 , imgTensorShape :  torch.Size([3011, 3, 32, 32])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3011
Nodes sizes =  2 3
Node 3 Acc: 56.735
Split Acc: 65.841
lTrainDict[data].shape:  torch.Size([2013, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([2013])
rTrainDict[data].shape:  torch.Size([3072, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([3072])
# of Left images:  2013.0
# of Right images:  3072.0
giniRightRatio:  0.8129261864556208
giniLeftRatio:  0.7716820300436631
impurityDrop:  0.7858999863067696
giniGain:  0.05738540104628165
lclasses:  [32, 19, 131, 496, 168, 294, 65, 734, 26, 48]
rclasses:  [57, 29, 287, 359, 679, 603, 836, 156, 28, 38]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([2013, 3, 32, 32])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2013
nodeId:  7 , imgTensorShape :  torch.Size([3072, 3, 32, 32])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3072
Nodes sizes =  2 3
Node 4 Acc: 60.819
Split Acc: 61.239
lTrainDict[data].shape:  torch.Size([888, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([888])
rTrainDict[data].shape:  torch.Size([1016, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1016])
# of Left images:  888.0
# of Right images:  1016.0
giniRightRatio:  0.5182105989211978
giniLeftRatio:  0.6808370870870872
impurityDrop:  0.6603487106252429
giniGain:  0.116561685886303
lclasses:  [61, 12, 477, 61, 90, 60, 47, 45, 20, 15]
rclasses:  [56, 126, 18, 27, 9, 13, 13, 35, 30, 689]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([888, 3, 32, 32])
nodeId: 8 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 888
nodeId:  9 , imgTensorShape :  torch.Size([1016, 3, 32, 32])
nodeId: 9 ,  parentId: 4 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1016
Nodes sizes =  1 1
Node 5 Acc: 69.445
Split Acc: 78.047
lTrainDict[data].shape:  torch.Size([972, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([972])
rTrainDict[data].shape:  torch.Size([2039, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2039])
# of Left images:  972.0
# of Right images:  2039.0
giniRightRatio:  0.6778245978793613
giniLeftRatio:  0.4156674964859693
impurityDrop:  0.5528531890738797
giniGain:  0.20922774940024824
lclasses:  [20, 732, 11, 14, 7, 6, 13, 5, 52, 112]
rclasses:  [774, 82, 76, 43, 47, 24, 26, 25, 844, 98]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([972, 3, 32, 32])
nodeId: 10 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 972
nodeId:  11 , imgTensorShape :  torch.Size([2039, 3, 32, 32])
nodeId: 11 ,  parentId: 5 ,  level: 3 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2039
Nodes sizes =  1 2
Node 6 Acc: 54.396
Split Acc: 55.440
lTrainDict[data].shape:  torch.Size([985, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([985])
rTrainDict[data].shape:  torch.Size([1028, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1028])
# of Left images:  985.0
# of Right images:  1028.0
giniRightRatio:  0.537598979545489
giniLeftRatio:  0.7402571568450618
impurityDrop:  0.7317802097401186
giniGain:  0.0399018203035445
lclasses:  [20, 14, 84, 433, 78, 211, 53, 51, 18, 23]
rclasses:  [12, 5, 47, 63, 90, 83, 12, 683, 8, 25]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([985, 3, 32, 32])
nodeId: 12 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 985
nodeId:  13 , imgTensorShape :  torch.Size([1028, 3, 32, 32])
nodeId: 13 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 1028
Nodes sizes =  1 1
Node 7 Acc: 56.673
Split Acc: 61.719
lTrainDict[data].shape:  torch.Size([1056, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1056])
rTrainDict[data].shape:  torch.Size([2016, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([2016])
# of Left images:  1056.0
# of Right images:  2016.0
giniRightRatio:  0.792906746031746
giniLeftRatio:  0.5050863751147842
impurityDrop:  0.6421436945990517
giniGain:  0.17078249185656902
lclasses:  [22, 11, 78, 75, 83, 32, 729, 8, 8, 10]
rclasses:  [35, 18, 209, 284, 596, 571, 107, 148, 20, 28]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([1056, 3, 32, 32])
nodeId: 14 ,  parentId: 7 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1056
nodeId:  15 , imgTensorShape :  torch.Size([2016, 3, 32, 32])
nodeId: 15 ,  parentId: 7 ,  level: 3 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2016
Nodes sizes =  1 2
Node 8 Acc: 53.716
Node 9 Acc: 67.815
Node 10 Acc: 75.309
Node 11 Acc: 67.729
Split Acc: 70.917
lTrainDict[data].shape:  torch.Size([1024, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1024])
rTrainDict[data].shape:  torch.Size([1015, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([1015])
# of Left images:  1024.0
# of Right images:  1015.0
giniRightRatio:  0.42545657502001993
giniLeftRatio:  0.5360488891601562
impurityDrop:  0.537029510664847
giniGain:  0.14079508721451428
lclasses:  [685, 44, 60, 26, 31, 11, 16, 18, 83, 50]
rclasses:  [89, 38, 16, 17, 16, 13, 10, 7, 761, 48]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([1024, 3, 32, 32])
nodeId: 16 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 1024
nodeId:  17 , imgTensorShape :  torch.Size([1015, 3, 32, 32])
nodeId: 17 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 1015
Nodes sizes =  1 1
Node 12 Acc: 43.959
Node 13 Acc: 66.440
Node 14 Acc: 69.034
Node 15 Acc: 50.942
Split Acc: 51.984
lTrainDict[data].shape:  torch.Size([1029, 3, 32, 32])   lTrainDict[label].shape:  torch.Size([1029])
rTrainDict[data].shape:  torch.Size([987, 3, 32, 32])   rTrainDict[label].shape:  torch.Size([987])
# of Left images:  1029.0
# of Right images:  987.0
giniRightRatio:  0.6637410962574254
giniLeftRatio:  0.7016256453990732
impurityDrop:  0.7032377538731859
giniGain:  0.08966899215856017
lclasses:  [14, 7, 92, 194, 54, 506, 47, 90, 10, 15]
rclasses:  [21, 11, 117, 90, 542, 65, 60, 58, 10, 13]
noOfLeftClasses:  10
noOfRightClasses:  10
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1029, 3, 32, 32])
nodeId: 18 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1029
nodeId:  19 , imgTensorShape :  torch.Size([987, 3, 32, 32])
nodeId: 19 ,  parentId: 15 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 987
Nodes sizes =  1 1
Node 16 Acc: 66.895
Node 17 Acc: 74.975
Node 18 Acc: 49.174
Node 19 Acc: 54.914
[[685  20  61  20  21  14  22  12  89  56]
 [ 44 732  12  14  11   7  11   5  38 126]
 [ 60  11 477  84 117  92  78  47  16  18]
 [ 26  14  61 433  90 194  75  63  17  27]
 [ 31   7  90  78 542  54  83  90  16   9]
 [ 11   6  60 211  65 506  32  83  13  13]
 [ 16  13  47  53  60  47 729  12  10  13]
 [ 18   5  45  51  58  90   8 683   7  35]
 [ 83  52  20  18  10  10   8   8 761  30]
 [ 50 112  15  23  13  15  10  25  48 689]]

Acc: 62.370

                                                             1                                                                 
                   ┌─────────────────────────────────────────┴───────────────────────────┐                                     
                   2                                                                     3                                     
       ┌───────────┴─────────────┐                                         ┌─────────────┴─────────────┐                       
       4                         5                                         6                           7                       
 ┌─────┴─────┐            ┌──────┴─────────────┐                    ┌──────┴──────┐             ┌──────┴─────────────┐         
 8           9            10                   11                   12            13            14                   15        
                                        ┌──────┴──────┐                                                       ┌──────┴──────┐  
                                        16            17                                                      18            19 

                                                       -1                                                      
                   ┌───────────────────────────────────┴───────────────────────┐                               
                   -1                                                          -1                              
       ┌───────────┴───────────┐                                   ┌───────────┴───────────┐                   
       -1                      -1                                  -1                      -1                  
 ┌─────┴─────┐           ┌─────┴───────────┐                 ┌─────┴─────┐           ┌─────┴───────────┐       
 2           9           1                 -1                3           7           6                 -1      
                                     ┌─────┴─────┐                                               ┌─────┴─────┐ 
                                     0           8                                               5           4 

                                                                         49000                                                                         
                           ┌───────────────────────────────────────────────┴───────────────────────────────┐                                           
                         24500                                                                           24500                                         
           ┌───────────────┴───────────────┐                                               ┌───────────────┴───────────────┐                           
          9800                           14700                                            9800                           14700                         
   ┌───────┴───────┐               ┌───────┴───────────────┐                       ┌───────┴───────┐               ┌───────┴───────────────┐           
  4900            4900            4900                    9800                    4900            4900            4900                    9800         
                                                   ┌───────┴───────┐                                                               ┌───────┴───────┐   
                                                  4900            4900                                                            4900            4900 

                                                   {0: 4900, 1: 4900, 2: 4900, 3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900, 8: 4900, 9: 4900}                                                  
                                   ┌───────────────────────────────────────────────────────────┴───────────────────────────────────────┐                                                       
             {0: 4900, 1: 4900, 2: 4900, 8: 4900, 9: 4900}                                                       {3: 4900, 4: 4900, 5: 4900, 6: 4900, 7: 4900}                                 
               ┌───────────────────┴───────────────────┐                                                           ┌───────────────────┴───────────────────┐                                   
       {2: 4900, 9: 4900}                 {0: 4900, 1: 4900, 8: 4900}                                      {3: 4900, 7: 4900}                 {4: 4900, 5: 4900, 6: 4900}                      
     ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐                             ┌─────────┴─────────┐                   ┌─────────┴───────────────────┐               
 {2: 4900}           {9: 4900}           {1: 4900}                 {0: 4900, 8: 4900}                {3: 4900}           {7: 4900}           {6: 4900}                 {4: 4900, 5: 4900}      
                                                                 ┌─────────┴─────────┐                                                                               ┌─────────┴─────────┐     
                                                             {0: 4900}           {8: 4900}                                                                       {5: 4900}           {4: 4900} 

                                                                 86.95                                                                 
                         ┌─────────────────────────────────────────┴─────────────────────────────┐                                     
                 75.34079348931841                                                       65.84070796460178                             
          ┌──────────────┴─────────────┐                                          ┌──────────────┴─────────────┐                       
  61.239495798319325           78.04716041182331                          55.439642324888226                61.71875                   
   ┌──────┴──────┐              ┌──────┴─────────────┐                     ┌──────┴──────┐              ┌──────┴─────────────┐         
  0.0           0.0            0.0           70.91711623344777            0.0           0.0            0.0           51.98412698412698 
                                              ┌──────┴──────┐                                                         ┌──────┴──────┐  
                                             0.0           0.0                                                       0.0           0.0 

                                                         0.09999999999999987                                                         
                       ┌──────────────────────────────────────────┴───────────────────────────┐                                      
              0.24444444444444458                                                    0.24444444444444458                             
         ┌─────────────┴──────────────┐                                         ┌─────────────┴──────────────┐                       
        0.5                  0.41666666666666674                               0.5                  0.41666666666666674              
  ┌──────┴──────┐             ┌──────┴─────────────┐                     ┌──────┴──────┐             ┌──────┴─────────────┐          
 0.0           0.0           0.0                  0.5                   0.0           0.0           0.0                  0.5         
                                            ┌──────┴──────┐                                                        ┌──────┴──────┐   
                                           0.0           0.0                                                      0.0           0.0  

