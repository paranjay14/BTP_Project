==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
len(trainInputDict["data"]):  50000 ,  len(valInputDict["data"]):  0 ,  len(testInputDict["data"]):  10000
nodeId:  1 , imgTensorShape :  torch.Size([50000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 50000
Running nodeId:  1
0 Train Loss: 184.331 | Train Acc: 35.594
1 Train Loss: 156.986 | Train Acc: 45.550
2 Train Loss: 143.024 | Train Acc: 50.202
3 Train Loss: 133.872 | Train Acc: 53.052
4 Train Loss: 128.128 | Train Acc: 55.610
5 Train Loss: 124.072 | Train Acc: 56.642
6 Train Loss: 120.928 | Train Acc: 57.856
7 Train Loss: 119.191 | Train Acc: 58.362
8 Train Loss: 115.601 | Train Acc: 59.762
9 Train Loss: 113.113 | Train Acc: 60.756
10 Train Loss: 111.613 | Train Acc: 61.390
11 Train Loss: 109.033 | Train Acc: 62.284
12 Train Loss: 107.403 | Train Acc: 63.028
13 Train Loss: 105.135 | Train Acc: 63.486
14 Train Loss: 102.759 | Train Acc: 64.640
15 Train Loss: 100.968 | Train Acc: 65.326
16 Train Loss: 99.422 | Train Acc: 65.902
17 Train Loss: 98.420 | Train Acc: 66.026
18 Train Loss: 96.983 | Train Acc: 66.594
19 Train Loss: 96.742 | Train Acc: 67.034
20 Train Loss: 91.688 | Train Acc: 68.830
21 Train Loss: 91.066 | Train Acc: 68.994
22 Train Loss: 90.212 | Train Acc: 69.388
23 Train Loss: 90.099 | Train Acc: 69.268
24 Train Loss: 89.615 | Train Acc: 69.568
25 Train Loss: 89.408 | Train Acc: 69.580
26 Train Loss: 88.419 | Train Acc: 70.114
27 Train Loss: 88.295 | Train Acc: 70.004
28 Train Loss: 87.661 | Train Acc: 70.208
29 Train Loss: 87.482 | Train Acc: 70.330
30 Train Loss: 86.917 | Train Acc: 70.456
31 Train Loss: 86.426 | Train Acc: 70.676
32 Train Loss: 85.984 | Train Acc: 71.006
33 Train Loss: 85.628 | Train Acc: 70.884
34 Train Loss: 85.329 | Train Acc: 71.016
35 Train Loss: 84.569 | Train Acc: 71.282
36 Train Loss: 84.272 | Train Acc: 71.398
37 Train Loss: 84.005 | Train Acc: 71.634
38 Train Loss: 83.766 | Train Acc: 71.666
39 Train Loss: 83.259 | Train Acc: 71.824
40 Train Loss: 81.343 | Train Acc: 72.730
41 Train Loss: 81.136 | Train Acc: 72.734
42 Train Loss: 80.919 | Train Acc: 72.796
43 Train Loss: 80.958 | Train Acc: 72.738
44 Train Loss: 80.734 | Train Acc: 72.824
45 Train Loss: 80.562 | Train Acc: 72.924
46 Train Loss: 80.417 | Train Acc: 73.044
47 Train Loss: 80.327 | Train Acc: 72.850
48 Train Loss: 79.979 | Train Acc: 73.124
49 Train Loss: 79.837 | Train Acc: 73.110
50 Train Loss: 79.757 | Train Acc: 73.176
51 Train Loss: 79.503 | Train Acc: 73.344
52 Train Loss: 79.568 | Train Acc: 73.372
53 Train Loss: 79.355 | Train Acc: 73.428
54 Train Loss: 79.097 | Train Acc: 73.414
55 Train Loss: 79.039 | Train Acc: 73.514
56 Train Loss: 78.963 | Train Acc: 73.524
57 Train Loss: 78.562 | Train Acc: 73.746
58 Train Loss: 78.553 | Train Acc: 73.714
59 Train Loss: 78.543 | Train Acc: 73.618
60 Train Loss: 77.557 | Train Acc: 74.096
61 Train Loss: 77.403 | Train Acc: 74.116
62 Train Loss: 77.401 | Train Acc: 74.148
63 Train Loss: 77.312 | Train Acc: 74.250
64 Train Loss: 77.294 | Train Acc: 74.156
65 Train Loss: 77.271 | Train Acc: 74.204
66 Train Loss: 77.155 | Train Acc: 74.176
67 Train Loss: 77.142 | Train Acc: 74.200
68 Train Loss: 77.007 | Train Acc: 74.430
69 Train Loss: 76.965 | Train Acc: 74.362
70 Train Loss: 76.985 | Train Acc: 74.254
71 Train Loss: 76.905 | Train Acc: 74.376
72 Train Loss: 76.820 | Train Acc: 74.400
73 Train Loss: 76.723 | Train Acc: 74.426
74 Train Loss: 76.751 | Train Acc: 74.532
75 Train Loss: 76.608 | Train Acc: 74.356
76 Train Loss: 76.576 | Train Acc: 74.498
77 Train Loss: 76.485 | Train Acc: 74.478
78 Train Loss: 76.399 | Train Acc: 74.560
79 Train Loss: 76.412 | Train Acc: 74.482
80 Train Loss: 75.996 | Train Acc: 74.590
81 Train Loss: 75.988 | Train Acc: 74.718
82 Train Loss: 75.945 | Train Acc: 74.672
83 Train Loss: 75.917 | Train Acc: 74.706
84 Train Loss: 75.870 | Train Acc: 74.752
85 Train Loss: 75.869 | Train Acc: 74.748
86 Train Loss: 75.852 | Train Acc: 74.774
87 Train Loss: 75.824 | Train Acc: 74.796
88 Train Loss: 75.795 | Train Acc: 74.830
89 Train Loss: 75.761 | Train Acc: 74.750
90 Train Loss: 75.726 | Train Acc: 74.806
91 Train Loss: 75.700 | Train Acc: 74.838
92 Train Loss: 75.719 | Train Acc: 74.810
93 Train Loss: 75.663 | Train Acc: 74.884
94 Train Loss: 75.641 | Train Acc: 74.810
95 Train Loss: 75.619 | Train Acc: 74.940
96 Train Loss: 75.599 | Train Acc: 74.812
97 Train Loss: 75.542 | Train Acc: 74.874
98 Train Loss: 75.548 | Train Acc: 74.918
99 Train Loss: 75.501 | Train Acc: 74.892
CNN trained successfully...
image_next_flat.shape :  torch.Size([50000, 12544])
printing expected split from k means
{9: 0, 1: 1, 8: 0, 7: 1, 4: 1, 0: 0, 3: 1, 2: 1, 5: 1, 6: 1}
Printing final_dict items...
{9: 0, 1: 1, 8: 0, 7: 1, 4: 1, 0: 0, 3: 1, 2: 1, 5: 1, 6: 1}
Image Statistics : L R :  15000 35000
expectedMlpLabels.shape :  torch.Size([50000])
0 Loss: 51.831 | Acc: 79.496
1 Loss: 43.486 | Acc: 83.858
2 Loss: 39.324 | Acc: 85.696
3 Loss: 37.039 | Acc: 86.628
4 Loss: 34.417 | Acc: 87.664
5 Loss: 31.947 | Acc: 88.632
6 Loss: 29.807 | Acc: 89.638
7 Loss: 28.140 | Acc: 90.136
8 Loss: 25.943 | Acc: 90.846
9 Loss: 24.576 | Acc: 91.476
10 Loss: 19.247 | Acc: 93.414
11 Loss: 17.638 | Acc: 94.072
12 Loss: 16.024 | Acc: 94.494
13 Loss: 15.272 | Acc: 94.752
14 Loss: 14.347 | Acc: 95.164
15 Loss: 12.810 | Acc: 95.710
16 Loss: 12.556 | Acc: 95.682
17 Loss: 12.078 | Acc: 95.938
18 Loss: 11.323 | Acc: 96.262
19 Loss: 10.313 | Acc: 96.618
20 Loss: 8.574 | Acc: 97.140
21 Loss: 7.529 | Acc: 97.476
22 Loss: 7.691 | Acc: 97.458
23 Loss: 7.123 | Acc: 97.714
24 Loss: 6.815 | Acc: 97.846
25 Loss: 6.796 | Acc: 97.788
26 Loss: 6.122 | Acc: 98.052
27 Loss: 6.104 | Acc: 98.026
28 Loss: 5.944 | Acc: 98.058
29 Loss: 5.908 | Acc: 98.060
30 Loss: 5.094 | Acc: 98.406
31 Loss: 4.715 | Acc: 98.526
32 Loss: 4.953 | Acc: 98.458
33 Loss: 4.508 | Acc: 98.602
34 Loss: 4.533 | Acc: 98.580
35 Loss: 4.160 | Acc: 98.698
36 Loss: 4.188 | Acc: 98.694
37 Loss: 4.123 | Acc: 98.728
38 Loss: 4.167 | Acc: 98.676
39 Loss: 3.857 | Acc: 98.766
40 Loss: 3.818 | Acc: 98.814
41 Loss: 3.741 | Acc: 98.854
42 Loss: 3.763 | Acc: 98.844
43 Loss: 3.568 | Acc: 98.856
44 Loss: 3.514 | Acc: 98.938
45 Loss: 3.503 | Acc: 98.862
46 Loss: 3.379 | Acc: 98.960
47 Loss: 3.460 | Acc: 98.928
48 Loss: 3.486 | Acc: 98.898
49 Loss: 3.436 | Acc: 98.940
50 Loss: 3.332 | Acc: 98.966
51 Loss: 3.272 | Acc: 99.008
52 Loss: 3.236 | Acc: 98.992
53 Loss: 3.350 | Acc: 98.940
54 Loss: 3.239 | Acc: 98.980
55 Loss: 3.246 | Acc: 99.062
56 Loss: 3.187 | Acc: 99.000
57 Loss: 3.216 | Acc: 98.984
58 Loss: 3.259 | Acc: 98.998
59 Loss: 3.175 | Acc: 98.992
MLP trained successfully...
# of Left images:  15000.0
# of Right images:  35000.0
giniRightRatio:  0.8571428571428572
giniLeftRatio:  0.6666666666666667
impurityDrop:  0.7755102040816326
giniGain:  0.1244897959183674
lclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 5000, 5000]
rclasses:  [0, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  7
lTrainDict[data].shape:  torch.Size([15000, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([15000])
rTrainDict[data].shape:  torch.Size([35000, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([35000])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([15000, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 15000
nodeId:  3 , imgTensorShape :  torch.Size([35000, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 7 ,  numData: 35000
Running nodeId:  2
0 Train Loss: 69.570 | Train Acc: 69.740
1 Train Loss: 50.525 | Train Acc: 80.140
2 Train Loss: 44.684 | Train Acc: 82.813
3 Train Loss: 40.471 | Train Acc: 84.773
4 Train Loss: 38.953 | Train Acc: 85.167
5 Train Loss: 37.103 | Train Acc: 86.253
6 Train Loss: 35.508 | Train Acc: 86.693
7 Train Loss: 33.015 | Train Acc: 88.000
8 Train Loss: 31.446 | Train Acc: 88.507
9 Train Loss: 30.851 | Train Acc: 88.853
10 Train Loss: 31.104 | Train Acc: 88.640
11 Train Loss: 28.553 | Train Acc: 89.500
12 Train Loss: 27.977 | Train Acc: 89.713
13 Train Loss: 26.284 | Train Acc: 90.493
14 Train Loss: 25.575 | Train Acc: 90.613
15 Train Loss: 24.646 | Train Acc: 90.860
16 Train Loss: 23.788 | Train Acc: 91.433
17 Train Loss: 23.156 | Train Acc: 91.453
18 Train Loss: 22.253 | Train Acc: 92.127
19 Train Loss: 21.633 | Train Acc: 92.260
20 Train Loss: 18.804 | Train Acc: 93.653
21 Train Loss: 18.184 | Train Acc: 93.660
22 Train Loss: 17.753 | Train Acc: 94.080
23 Train Loss: 17.534 | Train Acc: 94.327
24 Train Loss: 17.221 | Train Acc: 94.320
25 Train Loss: 16.884 | Train Acc: 94.347
26 Train Loss: 16.659 | Train Acc: 94.553
27 Train Loss: 16.193 | Train Acc: 94.827
28 Train Loss: 16.049 | Train Acc: 94.800
29 Train Loss: 15.540 | Train Acc: 95.113
30 Train Loss: 15.545 | Train Acc: 94.873
31 Train Loss: 14.929 | Train Acc: 95.220
32 Train Loss: 14.683 | Train Acc: 95.320
33 Train Loss: 14.443 | Train Acc: 95.473
34 Train Loss: 13.990 | Train Acc: 95.867
35 Train Loss: 13.933 | Train Acc: 95.693
36 Train Loss: 13.536 | Train Acc: 95.867
37 Train Loss: 13.663 | Train Acc: 95.673
38 Train Loss: 13.052 | Train Acc: 96.060
39 Train Loss: 12.761 | Train Acc: 96.313
40 Train Loss: 11.822 | Train Acc: 96.893
41 Train Loss: 11.623 | Train Acc: 97.027
42 Train Loss: 11.502 | Train Acc: 97.027
43 Train Loss: 11.354 | Train Acc: 97.120
44 Train Loss: 11.448 | Train Acc: 97.080
45 Train Loss: 11.130 | Train Acc: 97.207
46 Train Loss: 11.163 | Train Acc: 97.127
47 Train Loss: 11.002 | Train Acc: 97.193
48 Train Loss: 10.860 | Train Acc: 97.393
49 Train Loss: 10.899 | Train Acc: 97.247
50 Train Loss: 10.697 | Train Acc: 97.400
51 Train Loss: 10.551 | Train Acc: 97.480
52 Train Loss: 10.543 | Train Acc: 97.460
53 Train Loss: 10.353 | Train Acc: 97.507
54 Train Loss: 10.311 | Train Acc: 97.613
55 Train Loss: 10.291 | Train Acc: 97.440
56 Train Loss: 10.057 | Train Acc: 97.567
57 Train Loss: 9.967 | Train Acc: 97.640
58 Train Loss: 9.990 | Train Acc: 97.580
59 Train Loss: 9.821 | Train Acc: 97.687
60 Train Loss: 9.357 | Train Acc: 97.927
61 Train Loss: 9.294 | Train Acc: 98.020
62 Train Loss: 9.295 | Train Acc: 97.967
63 Train Loss: 9.224 | Train Acc: 97.987
64 Train Loss: 9.180 | Train Acc: 98.020
65 Train Loss: 9.150 | Train Acc: 98.027
66 Train Loss: 9.099 | Train Acc: 98.100
67 Train Loss: 9.074 | Train Acc: 98.020
68 Train Loss: 9.014 | Train Acc: 98.120
69 Train Loss: 9.026 | Train Acc: 98.093
70 Train Loss: 8.940 | Train Acc: 98.073
71 Train Loss: 8.924 | Train Acc: 98.107
72 Train Loss: 8.889 | Train Acc: 98.160
73 Train Loss: 8.836 | Train Acc: 98.127
74 Train Loss: 8.794 | Train Acc: 98.147
75 Train Loss: 8.762 | Train Acc: 98.187
76 Train Loss: 8.692 | Train Acc: 98.207
77 Train Loss: 8.681 | Train Acc: 98.207
78 Train Loss: 8.634 | Train Acc: 98.213
79 Train Loss: 8.566 | Train Acc: 98.273
80 Train Loss: 8.410 | Train Acc: 98.307
81 Train Loss: 8.395 | Train Acc: 98.340
82 Train Loss: 8.373 | Train Acc: 98.327
83 Train Loss: 8.347 | Train Acc: 98.347
84 Train Loss: 8.346 | Train Acc: 98.333
85 Train Loss: 8.320 | Train Acc: 98.320
86 Train Loss: 8.305 | Train Acc: 98.353
87 Train Loss: 8.311 | Train Acc: 98.367
88 Train Loss: 8.289 | Train Acc: 98.420
89 Train Loss: 8.275 | Train Acc: 98.373
90 Train Loss: 8.241 | Train Acc: 98.333
91 Train Loss: 8.229 | Train Acc: 98.400
92 Train Loss: 8.216 | Train Acc: 98.360
93 Train Loss: 8.188 | Train Acc: 98.387
94 Train Loss: 8.188 | Train Acc: 98.373
95 Train Loss: 8.161 | Train Acc: 98.387
96 Train Loss: 8.140 | Train Acc: 98.353
97 Train Loss: 8.127 | Train Acc: 98.407
98 Train Loss: 8.119 | Train Acc: 98.413
99 Train Loss: 8.106 | Train Acc: 98.407
CNN trained successfully...
image_next_flat.shape :  torch.Size([15000, 9216])
printing expected split from k means
{2: 0, 0: 1, 1: 1}
Printing final_dict items...
{2: 0, 0: 1, 1: 1}
Image Statistics : L R :  5000 10000
expectedMlpLabels.shape :  torch.Size([15000])
0 Loss: 38.537 | Acc: 87.680
1 Loss: 27.381 | Acc: 92.187
2 Loss: 25.044 | Acc: 92.727
3 Loss: 21.138 | Acc: 93.773
4 Loss: 18.500 | Acc: 94.560
5 Loss: 15.539 | Acc: 95.487
6 Loss: 13.548 | Acc: 95.967
7 Loss: 11.242 | Acc: 96.693
8 Loss: 9.923 | Acc: 96.953
9 Loss: 8.079 | Acc: 97.580
10 Loss: 3.842 | Acc: 98.953
11 Loss: 2.719 | Acc: 99.360
12 Loss: 2.038 | Acc: 99.447
13 Loss: 2.250 | Acc: 99.380
14 Loss: 1.805 | Acc: 99.527
15 Loss: 1.642 | Acc: 99.573
16 Loss: 1.421 | Acc: 99.633
17 Loss: 2.088 | Acc: 99.393
18 Loss: 2.040 | Acc: 99.513
19 Loss: 1.313 | Acc: 99.653
20 Loss: 0.561 | Acc: 99.893
21 Loss: 0.532 | Acc: 99.873
22 Loss: 0.412 | Acc: 99.913
23 Loss: 0.552 | Acc: 99.893
24 Loss: 0.413 | Acc: 99.913
25 Loss: 0.206 | Acc: 99.927
26 Loss: 0.390 | Acc: 99.907
27 Loss: 0.343 | Acc: 99.927
28 Loss: 0.264 | Acc: 99.947
29 Loss: 0.291 | Acc: 99.920
30 Loss: 0.294 | Acc: 99.947
31 Loss: 0.259 | Acc: 99.947
32 Loss: 0.314 | Acc: 99.920
33 Loss: 0.125 | Acc: 99.967
34 Loss: 0.152 | Acc: 99.967
35 Loss: 0.102 | Acc: 99.980
36 Loss: 0.232 | Acc: 99.973
37 Loss: 0.182 | Acc: 99.953
38 Loss: 0.207 | Acc: 99.960
39 Loss: 0.121 | Acc: 99.987
40 Loss: 0.288 | Acc: 99.927
41 Loss: 0.144 | Acc: 99.953
42 Loss: 0.183 | Acc: 99.967
43 Loss: 0.037 | Acc: 100.000
44 Loss: 0.077 | Acc: 99.973
45 Loss: 0.097 | Acc: 99.980
46 Loss: 0.070 | Acc: 99.980
47 Loss: 0.118 | Acc: 99.987
48 Loss: 0.129 | Acc: 99.980
49 Loss: 0.200 | Acc: 99.973
50 Loss: 0.047 | Acc: 99.993
51 Loss: 0.040 | Acc: 99.993
52 Loss: 0.106 | Acc: 99.980
53 Loss: 0.108 | Acc: 99.967
54 Loss: 0.102 | Acc: 99.987
55 Loss: 0.061 | Acc: 99.987
56 Loss: 0.037 | Acc: 99.993
57 Loss: 0.057 | Acc: 99.993
58 Loss: 0.032 | Acc: 100.000
59 Loss: 0.052 | Acc: 99.987
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  10000.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 0, 5000, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([5000, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([10000, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([10000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 9
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 9
nodeId:  4 , imgTensorShape :  torch.Size([5000, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 5000
nodeId:  5 , imgTensorShape :  torch.Size([10000, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 10000
Running nodeId:  3
0 Train Loss: 136.354 | Train Acc: 48.957
1 Train Loss: 112.812 | Train Acc: 58.386
2 Train Loss: 103.631 | Train Acc: 62.157
3 Train Loss: 98.840 | Train Acc: 63.874
4 Train Loss: 95.031 | Train Acc: 65.257
5 Train Loss: 92.871 | Train Acc: 66.349
6 Train Loss: 91.016 | Train Acc: 66.706
7 Train Loss: 88.872 | Train Acc: 67.474
8 Train Loss: 86.910 | Train Acc: 68.377
9 Train Loss: 85.826 | Train Acc: 69.031
10 Train Loss: 84.342 | Train Acc: 69.631
11 Train Loss: 82.501 | Train Acc: 70.117
12 Train Loss: 81.446 | Train Acc: 70.246
13 Train Loss: 80.414 | Train Acc: 70.909
14 Train Loss: 79.551 | Train Acc: 71.066
15 Train Loss: 78.391 | Train Acc: 71.700
16 Train Loss: 77.174 | Train Acc: 72.243
17 Train Loss: 76.098 | Train Acc: 72.394
18 Train Loss: 75.214 | Train Acc: 72.974
19 Train Loss: 74.179 | Train Acc: 73.140
20 Train Loss: 70.088 | Train Acc: 74.789
21 Train Loss: 69.078 | Train Acc: 75.303
22 Train Loss: 68.903 | Train Acc: 75.377
23 Train Loss: 68.461 | Train Acc: 75.591
24 Train Loss: 68.010 | Train Acc: 75.869
25 Train Loss: 67.387 | Train Acc: 76.020
26 Train Loss: 66.889 | Train Acc: 76.274
27 Train Loss: 66.492 | Train Acc: 76.154
28 Train Loss: 66.091 | Train Acc: 76.491
29 Train Loss: 65.838 | Train Acc: 76.609
30 Train Loss: 65.400 | Train Acc: 76.766
31 Train Loss: 64.791 | Train Acc: 76.989
32 Train Loss: 64.602 | Train Acc: 77.183
33 Train Loss: 64.179 | Train Acc: 77.194
34 Train Loss: 63.492 | Train Acc: 77.440
35 Train Loss: 63.196 | Train Acc: 77.677
36 Train Loss: 62.942 | Train Acc: 77.829
37 Train Loss: 62.164 | Train Acc: 78.026
38 Train Loss: 62.309 | Train Acc: 77.863
39 Train Loss: 61.341 | Train Acc: 78.457
40 Train Loss: 59.558 | Train Acc: 79.183
41 Train Loss: 59.335 | Train Acc: 79.263
42 Train Loss: 59.198 | Train Acc: 79.249
43 Train Loss: 59.069 | Train Acc: 79.371
44 Train Loss: 58.917 | Train Acc: 79.346
45 Train Loss: 58.728 | Train Acc: 79.546
46 Train Loss: 58.613 | Train Acc: 79.589
47 Train Loss: 58.243 | Train Acc: 79.769
48 Train Loss: 58.115 | Train Acc: 79.731
49 Train Loss: 58.011 | Train Acc: 79.720
50 Train Loss: 57.741 | Train Acc: 79.994
51 Train Loss: 57.647 | Train Acc: 79.880
52 Train Loss: 57.494 | Train Acc: 79.989
53 Train Loss: 57.346 | Train Acc: 79.997
54 Train Loss: 57.118 | Train Acc: 80.097
55 Train Loss: 56.942 | Train Acc: 80.114
56 Train Loss: 56.960 | Train Acc: 80.163
57 Train Loss: 56.747 | Train Acc: 80.329
58 Train Loss: 56.356 | Train Acc: 80.369
59 Train Loss: 56.287 | Train Acc: 80.503
60 Train Loss: 55.438 | Train Acc: 80.871
61 Train Loss: 55.284 | Train Acc: 80.906
62 Train Loss: 55.265 | Train Acc: 81.031
63 Train Loss: 55.202 | Train Acc: 80.931
64 Train Loss: 55.114 | Train Acc: 80.966
65 Train Loss: 54.984 | Train Acc: 81.011
66 Train Loss: 55.009 | Train Acc: 80.934
67 Train Loss: 54.857 | Train Acc: 81.089
68 Train Loss: 54.832 | Train Acc: 81.017
69 Train Loss: 54.821 | Train Acc: 81.011
70 Train Loss: 54.634 | Train Acc: 81.200
71 Train Loss: 54.557 | Train Acc: 81.146
72 Train Loss: 54.529 | Train Acc: 81.134
73 Train Loss: 54.446 | Train Acc: 81.286
74 Train Loss: 54.392 | Train Acc: 81.343
75 Train Loss: 54.363 | Train Acc: 81.231
76 Train Loss: 54.253 | Train Acc: 81.277
77 Train Loss: 54.181 | Train Acc: 81.377
78 Train Loss: 54.106 | Train Acc: 81.400
79 Train Loss: 54.055 | Train Acc: 81.351
80 Train Loss: 53.641 | Train Acc: 81.594
81 Train Loss: 53.616 | Train Acc: 81.589
82 Train Loss: 53.590 | Train Acc: 81.606
83 Train Loss: 53.553 | Train Acc: 81.517
84 Train Loss: 53.530 | Train Acc: 81.646
85 Train Loss: 53.502 | Train Acc: 81.649
86 Train Loss: 53.453 | Train Acc: 81.606
87 Train Loss: 53.453 | Train Acc: 81.651
88 Train Loss: 53.431 | Train Acc: 81.643
89 Train Loss: 53.362 | Train Acc: 81.691
90 Train Loss: 53.370 | Train Acc: 81.646
91 Train Loss: 53.314 | Train Acc: 81.694
92 Train Loss: 53.293 | Train Acc: 81.751
93 Train Loss: 53.248 | Train Acc: 81.774
94 Train Loss: 53.231 | Train Acc: 81.720
95 Train Loss: 53.212 | Train Acc: 81.706
96 Train Loss: 53.189 | Train Acc: 81.717
97 Train Loss: 53.143 | Train Acc: 81.814
98 Train Loss: 53.134 | Train Acc: 81.809
99 Train Loss: 53.058 | Train Acc: 81.774
CNN trained successfully...
image_next_flat.shape :  torch.Size([35000, 9216])
printing expected split from k means
{5: 0, 3: 0, 1: 0, 6: 0, 2: 0, 4: 0, 0: 1}
Printing final_dict items...
{5: 0, 3: 0, 1: 0, 6: 0, 2: 0, 4: 0, 0: 1}
Image Statistics : L R :  30000 5000
expectedMlpLabels.shape :  torch.Size([35000])
0 Loss: 11.488 | Acc: 92.963
1 Loss: 7.883 | Acc: 95.463
2 Loss: 6.302 | Acc: 96.043
3 Loss: 5.565 | Acc: 96.266
4 Loss: 4.621 | Acc: 96.683
5 Loss: 4.215 | Acc: 97.134
6 Loss: 3.473 | Acc: 97.486
7 Loss: 2.984 | Acc: 97.700
8 Loss: 2.641 | Acc: 98.120
9 Loss: 2.406 | Acc: 98.191
10 Loss: 1.518 | Acc: 98.860
11 Loss: 0.864 | Acc: 99.451
12 Loss: 0.716 | Acc: 99.497
13 Loss: 0.659 | Acc: 99.557
14 Loss: 0.653 | Acc: 99.623
15 Loss: 0.644 | Acc: 99.549
16 Loss: 0.627 | Acc: 99.549
17 Loss: 0.497 | Acc: 99.686
18 Loss: 0.554 | Acc: 99.649
19 Loss: 0.404 | Acc: 99.751
20 Loss: 0.270 | Acc: 99.831
21 Loss: 0.218 | Acc: 99.900
22 Loss: 0.234 | Acc: 99.871
23 Loss: 0.202 | Acc: 99.886
24 Loss: 0.130 | Acc: 99.929
25 Loss: 0.198 | Acc: 99.914
26 Loss: 0.195 | Acc: 99.891
27 Loss: 0.159 | Acc: 99.894
28 Loss: 0.113 | Acc: 99.949
29 Loss: 0.164 | Acc: 99.951
30 Loss: 0.108 | Acc: 99.951
31 Loss: 0.064 | Acc: 99.974
32 Loss: 0.088 | Acc: 99.963
33 Loss: 0.101 | Acc: 99.977
34 Loss: 0.098 | Acc: 99.954
35 Loss: 0.094 | Acc: 99.977
36 Loss: 0.113 | Acc: 99.971
37 Loss: 0.064 | Acc: 99.966
38 Loss: 0.080 | Acc: 99.963
39 Loss: 0.088 | Acc: 99.954
40 Loss: 0.132 | Acc: 99.960
41 Loss: 0.080 | Acc: 99.966
42 Loss: 0.050 | Acc: 99.986
43 Loss: 0.116 | Acc: 99.980
44 Loss: 0.049 | Acc: 99.989
45 Loss: 0.076 | Acc: 99.977
46 Loss: 0.063 | Acc: 99.977
47 Loss: 0.055 | Acc: 99.980
48 Loss: 0.040 | Acc: 99.991
49 Loss: 0.052 | Acc: 99.980
50 Loss: 0.041 | Acc: 99.986
51 Loss: 0.070 | Acc: 99.980
52 Loss: 0.051 | Acc: 99.983
53 Loss: 0.056 | Acc: 99.989
54 Loss: 0.070 | Acc: 99.974
55 Loss: 0.109 | Acc: 99.986
56 Loss: 0.039 | Acc: 99.991
57 Loss: 0.054 | Acc: 99.980
58 Loss: 0.094 | Acc: 99.983
59 Loss: 0.050 | Acc: 99.983
MLP trained successfully...
# of Left images:  30000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.8333333333333333
impurityDrop:  5.0
giniGain:  -4.142857142857142
lclasses:  [0, 5000, 5000, 5000, 5000, 5000, 5000, 0, 0, 0]
rclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  6
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([30000, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([30000])
rTrainDict[data].shape:  torch.Size([5000, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 1
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 1
nodeId:  6 , imgTensorShape :  torch.Size([30000, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 6 ,  numData: 30000
nodeId:  7 , imgTensorShape :  torch.Size([5000, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  4
Running nodeId:  5
0 Train Loss: 42.895 | Train Acc: 80.620
1 Train Loss: 28.400 | Train Acc: 88.080
2 Train Loss: 25.321 | Train Acc: 89.670
3 Train Loss: 23.411 | Train Acc: 90.150
4 Train Loss: 22.225 | Train Acc: 91.090
5 Train Loss: 21.677 | Train Acc: 91.340
6 Train Loss: 19.724 | Train Acc: 92.090
7 Train Loss: 18.790 | Train Acc: 92.490
8 Train Loss: 17.573 | Train Acc: 93.050
9 Train Loss: 16.424 | Train Acc: 93.360
10 Train Loss: 15.582 | Train Acc: 93.700
11 Train Loss: 15.827 | Train Acc: 93.460
12 Train Loss: 14.034 | Train Acc: 94.490
13 Train Loss: 12.952 | Train Acc: 94.950
14 Train Loss: 13.605 | Train Acc: 94.670
15 Train Loss: 12.457 | Train Acc: 94.960
16 Train Loss: 11.261 | Train Acc: 95.400
17 Train Loss: 11.344 | Train Acc: 95.510
18 Train Loss: 10.693 | Train Acc: 95.720
19 Train Loss: 9.318 | Train Acc: 96.450
20 Train Loss: 7.480 | Train Acc: 97.590
21 Train Loss: 7.339 | Train Acc: 97.730
22 Train Loss: 7.054 | Train Acc: 97.960
23 Train Loss: 6.783 | Train Acc: 97.980
24 Train Loss: 6.359 | Train Acc: 98.130
25 Train Loss: 6.161 | Train Acc: 98.240
26 Train Loss: 6.201 | Train Acc: 98.310
27 Train Loss: 6.166 | Train Acc: 98.170
28 Train Loss: 5.804 | Train Acc: 98.310
29 Train Loss: 5.683 | Train Acc: 98.380
30 Train Loss: 5.524 | Train Acc: 98.440
31 Train Loss: 5.137 | Train Acc: 98.690
32 Train Loss: 4.976 | Train Acc: 98.720
33 Train Loss: 4.834 | Train Acc: 98.840
34 Train Loss: 4.805 | Train Acc: 98.750
35 Train Loss: 4.451 | Train Acc: 99.020
36 Train Loss: 4.419 | Train Acc: 98.910
37 Train Loss: 4.248 | Train Acc: 98.920
38 Train Loss: 4.110 | Train Acc: 99.140
39 Train Loss: 3.976 | Train Acc: 99.100
40 Train Loss: 3.501 | Train Acc: 99.430
41 Train Loss: 3.330 | Train Acc: 99.450
42 Train Loss: 3.248 | Train Acc: 99.510
43 Train Loss: 3.246 | Train Acc: 99.480
44 Train Loss: 3.154 | Train Acc: 99.530
45 Train Loss: 3.100 | Train Acc: 99.560
46 Train Loss: 3.040 | Train Acc: 99.550
47 Train Loss: 3.040 | Train Acc: 99.550
48 Train Loss: 2.939 | Train Acc: 99.550
49 Train Loss: 2.889 | Train Acc: 99.590
50 Train Loss: 2.827 | Train Acc: 99.630
51 Train Loss: 2.776 | Train Acc: 99.600
52 Train Loss: 2.702 | Train Acc: 99.660
53 Train Loss: 2.678 | Train Acc: 99.640
54 Train Loss: 2.660 | Train Acc: 99.680
55 Train Loss: 2.663 | Train Acc: 99.620
56 Train Loss: 2.518 | Train Acc: 99.720
57 Train Loss: 2.496 | Train Acc: 99.710
58 Train Loss: 2.418 | Train Acc: 99.730
59 Train Loss: 2.353 | Train Acc: 99.770
60 Train Loss: 2.219 | Train Acc: 99.800
61 Train Loss: 2.167 | Train Acc: 99.780
62 Train Loss: 2.163 | Train Acc: 99.800
63 Train Loss: 2.159 | Train Acc: 99.780
64 Train Loss: 2.138 | Train Acc: 99.770
65 Train Loss: 2.113 | Train Acc: 99.790
66 Train Loss: 2.107 | Train Acc: 99.780
67 Train Loss: 2.067 | Train Acc: 99.800
68 Train Loss: 2.063 | Train Acc: 99.800
69 Train Loss: 2.047 | Train Acc: 99.790
70 Train Loss: 2.032 | Train Acc: 99.790
71 Train Loss: 1.984 | Train Acc: 99.850
72 Train Loss: 1.993 | Train Acc: 99.870
73 Train Loss: 1.968 | Train Acc: 99.810
74 Train Loss: 1.936 | Train Acc: 99.820
75 Train Loss: 1.929 | Train Acc: 99.840
76 Train Loss: 1.926 | Train Acc: 99.790
77 Train Loss: 1.902 | Train Acc: 99.840
78 Train Loss: 1.863 | Train Acc: 99.860
79 Train Loss: 1.833 | Train Acc: 99.870
80 Train Loss: 1.773 | Train Acc: 99.880
81 Train Loss: 1.761 | Train Acc: 99.890
82 Train Loss: 1.751 | Train Acc: 99.890
83 Train Loss: 1.751 | Train Acc: 99.870
84 Train Loss: 1.742 | Train Acc: 99.880
85 Train Loss: 1.735 | Train Acc: 99.880
86 Train Loss: 1.726 | Train Acc: 99.890
87 Train Loss: 1.720 | Train Acc: 99.880
88 Train Loss: 1.713 | Train Acc: 99.880
89 Train Loss: 1.700 | Train Acc: 99.880
90 Train Loss: 1.694 | Train Acc: 99.880
91 Train Loss: 1.688 | Train Acc: 99.920
92 Train Loss: 1.680 | Train Acc: 99.910
93 Train Loss: 1.668 | Train Acc: 99.890
94 Train Loss: 1.659 | Train Acc: 99.910
95 Train Loss: 1.661 | Train Acc: 99.920
96 Train Loss: 1.662 | Train Acc: 99.920
97 Train Loss: 1.644 | Train Acc: 99.910
98 Train Loss: 1.634 | Train Acc: 99.900
99 Train Loss: 1.626 | Train Acc: 99.910
CNN trained successfully...
image_next_flat.shape :  torch.Size([10000, 6400])
printing expected split from k means
{1: 1, 0: 0}
Printing final_dict items...
{1: 1, 0: 0}
Image Statistics : L R :  5000 5000
expectedMlpLabels.shape :  torch.Size([10000])
0 Loss: 60.792 | Acc: 86.620
1 Loss: 37.943 | Acc: 92.470
2 Loss: 31.189 | Acc: 93.960
3 Loss: 26.093 | Acc: 94.680
4 Loss: 22.794 | Acc: 95.230
5 Loss: 18.868 | Acc: 96.190
6 Loss: 18.042 | Acc: 96.500
7 Loss: 14.159 | Acc: 97.130
8 Loss: 11.988 | Acc: 97.810
9 Loss: 11.272 | Acc: 97.650
10 Loss: 6.791 | Acc: 98.790
11 Loss: 3.585 | Acc: 99.360
12 Loss: 2.968 | Acc: 99.410
13 Loss: 3.162 | Acc: 99.440
14 Loss: 2.501 | Acc: 99.560
15 Loss: 1.995 | Acc: 99.610
16 Loss: 1.436 | Acc: 99.690
17 Loss: 3.702 | Acc: 99.410
18 Loss: 2.285 | Acc: 99.700
19 Loss: 2.903 | Acc: 99.450
20 Loss: 1.113 | Acc: 99.860
21 Loss: 0.476 | Acc: 99.930
22 Loss: 0.257 | Acc: 99.980
23 Loss: 0.223 | Acc: 99.950
24 Loss: 0.464 | Acc: 99.910
25 Loss: 0.859 | Acc: 99.920
26 Loss: 0.494 | Acc: 99.900
27 Loss: 0.280 | Acc: 99.980
28 Loss: 0.240 | Acc: 99.970
29 Loss: 0.155 | Acc: 99.970
30 Loss: 0.171 | Acc: 99.980
31 Loss: 0.165 | Acc: 99.960
32 Loss: 0.172 | Acc: 99.970
33 Loss: 0.157 | Acc: 99.970
34 Loss: 0.090 | Acc: 99.990
35 Loss: 0.210 | Acc: 99.980
36 Loss: 0.216 | Acc: 99.940
37 Loss: 0.033 | Acc: 100.000
38 Loss: 0.079 | Acc: 99.980
39 Loss: 0.031 | Acc: 100.000
40 Loss: 0.070 | Acc: 99.990
41 Loss: 0.064 | Acc: 99.990
42 Loss: 0.060 | Acc: 99.970
43 Loss: 0.137 | Acc: 99.990
44 Loss: 0.138 | Acc: 99.990
45 Loss: 0.030 | Acc: 100.000
46 Loss: 0.038 | Acc: 100.000
47 Loss: 0.056 | Acc: 99.990
48 Loss: 0.144 | Acc: 99.980
49 Loss: 0.082 | Acc: 99.990
50 Loss: 0.123 | Acc: 99.990
51 Loss: 0.023 | Acc: 100.000
52 Loss: 0.037 | Acc: 99.990
53 Loss: 0.036 | Acc: 99.990
54 Loss: 0.150 | Acc: 99.990
55 Loss: 0.010 | Acc: 100.000
56 Loss: 0.046 | Acc: 100.000
57 Loss: 0.025 | Acc: 100.000
58 Loss: 0.011 | Acc: 100.000
59 Loss: 0.018 | Acc: 100.000
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([5000, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 0
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 8
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 0
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 8
nodeId:  8 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 8 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 5000
nodeId:  9 , imgTensorShape :  torch.Size([5000, 16, 20, 20])
nodeId: 9 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  6
0 Train Loss: 127.200 | Train Acc: 51.107
1 Train Loss: 105.800 | Train Acc: 60.103
2 Train Loss: 99.092 | Train Acc: 62.863
3 Train Loss: 96.457 | Train Acc: 63.827
4 Train Loss: 94.831 | Train Acc: 64.717
5 Train Loss: 93.200 | Train Acc: 65.073
6 Train Loss: 91.071 | Train Acc: 66.040
7 Train Loss: 89.259 | Train Acc: 66.537
8 Train Loss: 87.972 | Train Acc: 67.433
9 Train Loss: 87.724 | Train Acc: 67.520
10 Train Loss: 86.099 | Train Acc: 68.173
11 Train Loss: 84.138 | Train Acc: 68.940
12 Train Loss: 83.952 | Train Acc: 68.720
13 Train Loss: 83.200 | Train Acc: 69.347
14 Train Loss: 81.992 | Train Acc: 69.653
15 Train Loss: 80.215 | Train Acc: 70.243
16 Train Loss: 80.009 | Train Acc: 70.310
17 Train Loss: 78.683 | Train Acc: 70.847
18 Train Loss: 78.300 | Train Acc: 71.087
19 Train Loss: 77.013 | Train Acc: 71.697
20 Train Loss: 73.546 | Train Acc: 73.180
21 Train Loss: 72.790 | Train Acc: 73.433
22 Train Loss: 72.045 | Train Acc: 73.637
23 Train Loss: 71.806 | Train Acc: 73.830
24 Train Loss: 71.295 | Train Acc: 74.077
25 Train Loss: 70.901 | Train Acc: 74.207
26 Train Loss: 70.842 | Train Acc: 74.287
27 Train Loss: 70.160 | Train Acc: 74.660
28 Train Loss: 69.709 | Train Acc: 74.537
29 Train Loss: 69.529 | Train Acc: 74.827
30 Train Loss: 69.198 | Train Acc: 74.820
31 Train Loss: 68.800 | Train Acc: 75.083
32 Train Loss: 68.609 | Train Acc: 75.270
33 Train Loss: 68.350 | Train Acc: 75.300
34 Train Loss: 67.506 | Train Acc: 75.513
35 Train Loss: 67.400 | Train Acc: 75.597
36 Train Loss: 67.422 | Train Acc: 75.487
37 Train Loss: 67.197 | Train Acc: 75.803
38 Train Loss: 66.379 | Train Acc: 76.000
39 Train Loss: 65.773 | Train Acc: 76.463
40 Train Loss: 64.003 | Train Acc: 77.147
41 Train Loss: 63.834 | Train Acc: 77.203
42 Train Loss: 63.593 | Train Acc: 77.267
43 Train Loss: 63.530 | Train Acc: 77.400
44 Train Loss: 63.408 | Train Acc: 77.567
45 Train Loss: 63.265 | Train Acc: 77.397
46 Train Loss: 62.926 | Train Acc: 77.627
47 Train Loss: 62.969 | Train Acc: 77.533
48 Train Loss: 62.780 | Train Acc: 77.590
49 Train Loss: 62.638 | Train Acc: 77.650
50 Train Loss: 62.488 | Train Acc: 77.817
51 Train Loss: 62.317 | Train Acc: 77.867
52 Train Loss: 62.076 | Train Acc: 77.883
53 Train Loss: 61.963 | Train Acc: 78.013
54 Train Loss: 61.773 | Train Acc: 78.033
55 Train Loss: 61.633 | Train Acc: 78.177
56 Train Loss: 61.609 | Train Acc: 78.127
57 Train Loss: 61.577 | Train Acc: 78.073
58 Train Loss: 61.159 | Train Acc: 78.390
59 Train Loss: 60.930 | Train Acc: 78.337
60 Train Loss: 60.276 | Train Acc: 78.733
61 Train Loss: 60.126 | Train Acc: 78.733
62 Train Loss: 60.013 | Train Acc: 78.793
63 Train Loss: 60.002 | Train Acc: 78.930
64 Train Loss: 59.917 | Train Acc: 78.920
65 Train Loss: 59.859 | Train Acc: 79.050
66 Train Loss: 59.815 | Train Acc: 78.893
67 Train Loss: 59.775 | Train Acc: 78.907
68 Train Loss: 59.748 | Train Acc: 78.997
69 Train Loss: 59.672 | Train Acc: 79.120
70 Train Loss: 59.493 | Train Acc: 79.073
71 Train Loss: 59.498 | Train Acc: 79.060
72 Train Loss: 59.500 | Train Acc: 79.017
73 Train Loss: 59.374 | Train Acc: 79.100
74 Train Loss: 59.316 | Train Acc: 79.250
75 Train Loss: 59.273 | Train Acc: 79.340
76 Train Loss: 59.159 | Train Acc: 79.213
77 Train Loss: 59.072 | Train Acc: 79.257
78 Train Loss: 59.041 | Train Acc: 79.183
79 Train Loss: 59.106 | Train Acc: 79.203
80 Train Loss: 58.579 | Train Acc: 79.497
81 Train Loss: 58.565 | Train Acc: 79.600
82 Train Loss: 58.569 | Train Acc: 79.467
83 Train Loss: 58.524 | Train Acc: 79.483
84 Train Loss: 58.497 | Train Acc: 79.607
85 Train Loss: 58.451 | Train Acc: 79.517
86 Train Loss: 58.431 | Train Acc: 79.523
87 Train Loss: 58.406 | Train Acc: 79.597
88 Train Loss: 58.391 | Train Acc: 79.523
89 Train Loss: 58.377 | Train Acc: 79.643
90 Train Loss: 58.392 | Train Acc: 79.603
91 Train Loss: 58.285 | Train Acc: 79.597
92 Train Loss: 58.313 | Train Acc: 79.603
93 Train Loss: 58.282 | Train Acc: 79.510
94 Train Loss: 58.253 | Train Acc: 79.667
95 Train Loss: 58.216 | Train Acc: 79.550
96 Train Loss: 58.179 | Train Acc: 79.607
97 Train Loss: 58.156 | Train Acc: 79.647
98 Train Loss: 58.128 | Train Acc: 79.710
99 Train Loss: 58.144 | Train Acc: 79.637
CNN trained successfully...
image_next_flat.shape :  torch.Size([30000, 6400])
printing expected split from k means
{0: 0, 1: 1, 2: 0, 4: 1, 5: 1, 3: 1}
Printing final_dict items...
{0: 0, 1: 1, 2: 0, 4: 1, 5: 1, 3: 1}
Image Statistics : L R :  10000 20000
expectedMlpLabels.shape :  torch.Size([30000])
0 Loss: 69.267 | Acc: 76.457
1 Loss: 59.860 | Acc: 79.823
2 Loss: 54.873 | Acc: 81.763
3 Loss: 51.744 | Acc: 82.543
4 Loss: 48.653 | Acc: 83.830
5 Loss: 46.179 | Acc: 84.573
6 Loss: 43.185 | Acc: 85.663
7 Loss: 40.500 | Acc: 86.677
8 Loss: 37.577 | Acc: 87.683
9 Loss: 35.057 | Acc: 88.480
10 Loss: 27.630 | Acc: 91.107
11 Loss: 24.750 | Acc: 92.190
12 Loss: 22.286 | Acc: 93.030
13 Loss: 20.377 | Acc: 93.660
14 Loss: 18.829 | Acc: 94.137
15 Loss: 17.118 | Acc: 94.533
16 Loss: 16.066 | Acc: 95.097
17 Loss: 14.379 | Acc: 95.643
18 Loss: 13.485 | Acc: 96.050
19 Loss: 12.404 | Acc: 96.260
20 Loss: 8.968 | Acc: 97.353
21 Loss: 8.683 | Acc: 97.493
22 Loss: 7.904 | Acc: 97.790
23 Loss: 7.365 | Acc: 97.877
24 Loss: 7.085 | Acc: 97.947
25 Loss: 6.565 | Acc: 98.210
26 Loss: 6.368 | Acc: 98.177
27 Loss: 6.193 | Acc: 98.370
28 Loss: 5.551 | Acc: 98.460
29 Loss: 5.621 | Acc: 98.450
30 Loss: 4.908 | Acc: 98.717
31 Loss: 4.365 | Acc: 98.797
32 Loss: 4.178 | Acc: 98.860
33 Loss: 4.019 | Acc: 98.933
34 Loss: 3.705 | Acc: 98.960
35 Loss: 3.539 | Acc: 99.093
36 Loss: 3.639 | Acc: 99.010
37 Loss: 3.703 | Acc: 99.033
38 Loss: 3.407 | Acc: 99.110
39 Loss: 3.332 | Acc: 99.103
40 Loss: 3.319 | Acc: 99.127
41 Loss: 2.962 | Acc: 99.230
42 Loss: 3.006 | Acc: 99.210
43 Loss: 3.073 | Acc: 99.250
44 Loss: 2.641 | Acc: 99.323
45 Loss: 2.888 | Acc: 99.273
46 Loss: 2.945 | Acc: 99.280
47 Loss: 2.824 | Acc: 99.247
48 Loss: 2.932 | Acc: 99.237
49 Loss: 2.807 | Acc: 99.240
50 Loss: 2.771 | Acc: 99.340
51 Loss: 2.724 | Acc: 99.337
52 Loss: 2.737 | Acc: 99.380
53 Loss: 3.078 | Acc: 99.223
54 Loss: 2.811 | Acc: 99.303
55 Loss: 2.429 | Acc: 99.420
56 Loss: 2.672 | Acc: 99.390
57 Loss: 2.532 | Acc: 99.323
58 Loss: 2.616 | Acc: 99.323
59 Loss: 2.792 | Acc: 99.343
MLP trained successfully...
# of Left images:  10000.0
# of Right images:  20000.0
giniRightRatio:  0.75
giniLeftRatio:  0.5
impurityDrop:  0.625
giniGain:  0.20833333333333326
lclasses:  [5000, 0, 5000, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 0, 5000, 5000, 5000, 0, 0, 0, 0]
noOfLeftClasses:  2
noOfRightClasses:  4
lTrainDict[data].shape:  torch.Size([10000, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([10000])
rTrainDict[data].shape:  torch.Size([20000, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([20000])
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([10000, 16, 20, 20])
nodeId: 10 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 10000
nodeId:  11 , imgTensorShape :  torch.Size([20000, 16, 20, 20])
nodeId: 11 ,  parentId: 6 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 20000
Running nodeId:  7
Running nodeId:  8
Running nodeId:  9
Running nodeId:  10
0 Train Loss: 45.364 | Train Acc: 78.890
1 Train Loss: 38.550 | Train Acc: 82.680
2 Train Loss: 35.901 | Train Acc: 84.160
3 Train Loss: 34.836 | Train Acc: 84.600
4 Train Loss: 33.508 | Train Acc: 85.410
5 Train Loss: 32.138 | Train Acc: 85.960
6 Train Loss: 31.064 | Train Acc: 86.480
7 Train Loss: 30.110 | Train Acc: 87.050
8 Train Loss: 29.636 | Train Acc: 87.100
9 Train Loss: 28.616 | Train Acc: 87.590
10 Train Loss: 27.689 | Train Acc: 87.930
11 Train Loss: 26.691 | Train Acc: 88.630
12 Train Loss: 25.802 | Train Acc: 88.800
13 Train Loss: 25.282 | Train Acc: 89.270
14 Train Loss: 24.484 | Train Acc: 90.060
15 Train Loss: 23.964 | Train Acc: 90.000
16 Train Loss: 23.945 | Train Acc: 89.990
17 Train Loss: 22.309 | Train Acc: 90.850
18 Train Loss: 21.149 | Train Acc: 91.310
19 Train Loss: 20.326 | Train Acc: 91.680
20 Train Loss: 18.075 | Train Acc: 93.060
21 Train Loss: 17.435 | Train Acc: 93.430
22 Train Loss: 17.244 | Train Acc: 93.580
23 Train Loss: 16.937 | Train Acc: 93.470
24 Train Loss: 16.659 | Train Acc: 93.500
25 Train Loss: 16.369 | Train Acc: 93.840
26 Train Loss: 15.871 | Train Acc: 94.050
27 Train Loss: 15.926 | Train Acc: 94.020
28 Train Loss: 15.513 | Train Acc: 94.040
29 Train Loss: 15.240 | Train Acc: 94.390
30 Train Loss: 15.065 | Train Acc: 94.260
31 Train Loss: 14.602 | Train Acc: 94.750
32 Train Loss: 14.317 | Train Acc: 94.740
33 Train Loss: 14.027 | Train Acc: 94.940
34 Train Loss: 14.055 | Train Acc: 94.930
35 Train Loss: 13.629 | Train Acc: 95.280
36 Train Loss: 13.292 | Train Acc: 95.400
37 Train Loss: 13.203 | Train Acc: 95.310
38 Train Loss: 12.838 | Train Acc: 95.710
39 Train Loss: 12.488 | Train Acc: 95.830
40 Train Loss: 11.547 | Train Acc: 96.390
41 Train Loss: 11.364 | Train Acc: 96.630
42 Train Loss: 11.394 | Train Acc: 96.610
43 Train Loss: 11.289 | Train Acc: 96.520
44 Train Loss: 11.170 | Train Acc: 96.640
45 Train Loss: 11.004 | Train Acc: 96.750
46 Train Loss: 10.957 | Train Acc: 96.900
47 Train Loss: 10.795 | Train Acc: 96.920
48 Train Loss: 10.769 | Train Acc: 96.830
49 Train Loss: 10.654 | Train Acc: 96.810
50 Train Loss: 10.496 | Train Acc: 97.030
51 Train Loss: 10.452 | Train Acc: 96.990
52 Train Loss: 10.408 | Train Acc: 97.080
53 Train Loss: 10.184 | Train Acc: 97.070
54 Train Loss: 10.072 | Train Acc: 97.220
55 Train Loss: 9.999 | Train Acc: 97.260
56 Train Loss: 9.944 | Train Acc: 97.250
57 Train Loss: 9.903 | Train Acc: 97.170
58 Train Loss: 9.677 | Train Acc: 97.270
59 Train Loss: 9.640 | Train Acc: 97.450
60 Train Loss: 9.139 | Train Acc: 97.660
61 Train Loss: 9.079 | Train Acc: 97.750
62 Train Loss: 9.045 | Train Acc: 97.790
63 Train Loss: 8.955 | Train Acc: 97.800
64 Train Loss: 9.005 | Train Acc: 97.770
65 Train Loss: 8.886 | Train Acc: 97.760
66 Train Loss: 8.859 | Train Acc: 97.880
67 Train Loss: 8.812 | Train Acc: 97.780
68 Train Loss: 8.824 | Train Acc: 97.800
69 Train Loss: 8.764 | Train Acc: 97.840
70 Train Loss: 8.705 | Train Acc: 97.880
71 Train Loss: 8.644 | Train Acc: 97.850
72 Train Loss: 8.629 | Train Acc: 97.880
73 Train Loss: 8.623 | Train Acc: 97.850
74 Train Loss: 8.523 | Train Acc: 98.080
75 Train Loss: 8.531 | Train Acc: 97.910
76 Train Loss: 8.451 | Train Acc: 97.970
77 Train Loss: 8.394 | Train Acc: 97.980
78 Train Loss: 8.412 | Train Acc: 97.940
79 Train Loss: 8.328 | Train Acc: 98.030
80 Train Loss: 8.160 | Train Acc: 98.030
81 Train Loss: 8.169 | Train Acc: 98.020
82 Train Loss: 8.133 | Train Acc: 98.040
83 Train Loss: 8.104 | Train Acc: 98.070
84 Train Loss: 8.085 | Train Acc: 98.110
85 Train Loss: 8.087 | Train Acc: 98.020
86 Train Loss: 8.056 | Train Acc: 98.140
87 Train Loss: 8.043 | Train Acc: 98.160
88 Train Loss: 8.049 | Train Acc: 98.140
89 Train Loss: 8.014 | Train Acc: 98.040
90 Train Loss: 8.006 | Train Acc: 98.100
91 Train Loss: 7.984 | Train Acc: 98.190
92 Train Loss: 7.970 | Train Acc: 98.140
93 Train Loss: 7.948 | Train Acc: 98.140
94 Train Loss: 7.914 | Train Acc: 98.210
95 Train Loss: 7.914 | Train Acc: 98.130
96 Train Loss: 7.890 | Train Acc: 98.190
97 Train Loss: 7.874 | Train Acc: 98.240
98 Train Loss: 7.861 | Train Acc: 98.220
99 Train Loss: 7.855 | Train Acc: 98.120
CNN trained successfully...
image_next_flat.shape :  torch.Size([10000, 4096])
printing expected split from k means
{1: 0, 0: 1}
Printing final_dict items...
{1: 0, 0: 1}
Image Statistics : L R :  5000 5000
expectedMlpLabels.shape :  torch.Size([10000])
0 Loss: 77.378 | Acc: 82.500
1 Loss: 58.281 | Acc: 87.790
2 Loss: 48.015 | Acc: 90.260
3 Loss: 42.923 | Acc: 90.900
4 Loss: 38.195 | Acc: 91.900
5 Loss: 34.906 | Acc: 93.240
6 Loss: 30.724 | Acc: 93.680
7 Loss: 27.561 | Acc: 94.690
8 Loss: 21.711 | Acc: 95.780
9 Loss: 17.849 | Acc: 96.540
10 Loss: 10.566 | Acc: 98.030
11 Loss: 7.357 | Acc: 98.800
12 Loss: 8.003 | Acc: 98.570
13 Loss: 5.372 | Acc: 98.960
14 Loss: 4.454 | Acc: 99.180
15 Loss: 6.109 | Acc: 98.930
16 Loss: 4.532 | Acc: 99.230
17 Loss: 4.249 | Acc: 99.330
18 Loss: 3.457 | Acc: 99.420
19 Loss: 2.332 | Acc: 99.620
20 Loss: 2.266 | Acc: 99.540
21 Loss: 1.610 | Acc: 99.720
22 Loss: 1.405 | Acc: 99.790
23 Loss: 1.610 | Acc: 99.760
24 Loss: 1.100 | Acc: 99.850
25 Loss: 0.594 | Acc: 99.940
26 Loss: 0.834 | Acc: 99.820
27 Loss: 0.992 | Acc: 99.820
28 Loss: 0.645 | Acc: 99.900
29 Loss: 0.856 | Acc: 99.860
30 Loss: 0.615 | Acc: 99.910
31 Loss: 0.434 | Acc: 99.920
32 Loss: 0.358 | Acc: 99.950
33 Loss: 0.321 | Acc: 99.960
34 Loss: 0.299 | Acc: 99.950
35 Loss: 0.530 | Acc: 99.950
36 Loss: 0.295 | Acc: 99.950
37 Loss: 0.410 | Acc: 99.940
38 Loss: 0.300 | Acc: 99.940
39 Loss: 0.327 | Acc: 99.950
40 Loss: 0.146 | Acc: 99.960
41 Loss: 0.175 | Acc: 99.970
42 Loss: 0.248 | Acc: 99.970
43 Loss: 0.184 | Acc: 99.970
44 Loss: 0.224 | Acc: 99.950
45 Loss: 0.292 | Acc: 99.960
46 Loss: 0.227 | Acc: 99.970
47 Loss: 0.119 | Acc: 99.990
48 Loss: 0.363 | Acc: 99.940
49 Loss: 0.242 | Acc: 99.960
50 Loss: 0.096 | Acc: 99.990
51 Loss: 0.175 | Acc: 99.980
52 Loss: 0.211 | Acc: 99.950
53 Loss: 0.229 | Acc: 99.950
54 Loss: 0.030 | Acc: 100.000
55 Loss: 0.114 | Acc: 99.990
56 Loss: 0.085 | Acc: 99.990
57 Loss: 0.148 | Acc: 99.970
58 Loss: 0.083 | Acc: 99.980
59 Loss: 0.055 | Acc: 99.990
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 4
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 2
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 4
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 2
nodeId:  12 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 12 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 5000
nodeId:  13 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 13 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  11
0 Train Loss: 85.778 | Train Acc: 63.645
1 Train Loss: 72.874 | Train Acc: 69.460
2 Train Loss: 68.365 | Train Acc: 71.775
3 Train Loss: 66.434 | Train Acc: 72.315
4 Train Loss: 64.712 | Train Acc: 73.075
5 Train Loss: 63.448 | Train Acc: 73.715
6 Train Loss: 61.432 | Train Acc: 74.930
7 Train Loss: 60.517 | Train Acc: 74.780
8 Train Loss: 59.802 | Train Acc: 75.435
9 Train Loss: 58.330 | Train Acc: 76.130
10 Train Loss: 57.610 | Train Acc: 76.595
11 Train Loss: 57.043 | Train Acc: 76.665
12 Train Loss: 55.415 | Train Acc: 77.360
13 Train Loss: 53.798 | Train Acc: 78.370
14 Train Loss: 53.303 | Train Acc: 78.615
15 Train Loss: 52.884 | Train Acc: 78.595
16 Train Loss: 51.878 | Train Acc: 79.085
17 Train Loss: 51.294 | Train Acc: 79.525
18 Train Loss: 50.899 | Train Acc: 79.360
19 Train Loss: 49.443 | Train Acc: 80.220
20 Train Loss: 46.205 | Train Acc: 81.740
21 Train Loss: 45.892 | Train Acc: 81.895
22 Train Loss: 45.362 | Train Acc: 82.235
23 Train Loss: 45.073 | Train Acc: 82.270
24 Train Loss: 44.532 | Train Acc: 82.475
25 Train Loss: 44.519 | Train Acc: 82.655
26 Train Loss: 44.024 | Train Acc: 82.515
27 Train Loss: 44.060 | Train Acc: 82.860
28 Train Loss: 43.557 | Train Acc: 83.170
29 Train Loss: 43.255 | Train Acc: 83.210
30 Train Loss: 42.866 | Train Acc: 83.405
31 Train Loss: 42.549 | Train Acc: 83.650
32 Train Loss: 42.209 | Train Acc: 83.820
33 Train Loss: 41.714 | Train Acc: 83.930
34 Train Loss: 41.821 | Train Acc: 83.845
35 Train Loss: 41.609 | Train Acc: 83.795
36 Train Loss: 41.080 | Train Acc: 84.440
37 Train Loss: 40.231 | Train Acc: 84.755
38 Train Loss: 40.575 | Train Acc: 84.670
39 Train Loss: 39.908 | Train Acc: 84.815
40 Train Loss: 38.677 | Train Acc: 85.550
41 Train Loss: 38.383 | Train Acc: 85.825
42 Train Loss: 38.411 | Train Acc: 85.665
43 Train Loss: 38.154 | Train Acc: 85.830
44 Train Loss: 38.098 | Train Acc: 85.840
45 Train Loss: 37.856 | Train Acc: 86.020
46 Train Loss: 37.714 | Train Acc: 85.945
47 Train Loss: 37.725 | Train Acc: 85.865
48 Train Loss: 37.527 | Train Acc: 86.085
49 Train Loss: 37.514 | Train Acc: 86.150
50 Train Loss: 37.417 | Train Acc: 86.135
51 Train Loss: 37.226 | Train Acc: 86.215
52 Train Loss: 37.085 | Train Acc: 86.145
53 Train Loss: 36.927 | Train Acc: 86.220
54 Train Loss: 36.773 | Train Acc: 86.575
55 Train Loss: 36.810 | Train Acc: 86.295
56 Train Loss: 36.602 | Train Acc: 86.425
57 Train Loss: 36.433 | Train Acc: 86.595
58 Train Loss: 36.371 | Train Acc: 86.635
59 Train Loss: 36.280 | Train Acc: 86.510
60 Train Loss: 35.576 | Train Acc: 87.100
61 Train Loss: 35.454 | Train Acc: 87.255
62 Train Loss: 35.446 | Train Acc: 87.125
63 Train Loss: 35.391 | Train Acc: 87.080
64 Train Loss: 35.339 | Train Acc: 87.220
65 Train Loss: 35.306 | Train Acc: 87.205
66 Train Loss: 35.262 | Train Acc: 87.430
67 Train Loss: 35.147 | Train Acc: 87.265
68 Train Loss: 35.155 | Train Acc: 87.420
69 Train Loss: 35.092 | Train Acc: 87.465
70 Train Loss: 35.049 | Train Acc: 87.395
71 Train Loss: 34.974 | Train Acc: 87.620
72 Train Loss: 34.874 | Train Acc: 87.415
73 Train Loss: 34.928 | Train Acc: 87.320
74 Train Loss: 34.825 | Train Acc: 87.365
75 Train Loss: 34.774 | Train Acc: 87.685
76 Train Loss: 34.751 | Train Acc: 87.515
77 Train Loss: 34.718 | Train Acc: 87.785
78 Train Loss: 34.649 | Train Acc: 87.600
79 Train Loss: 34.573 | Train Acc: 87.645
80 Train Loss: 34.305 | Train Acc: 87.745
81 Train Loss: 34.296 | Train Acc: 87.750
82 Train Loss: 34.243 | Train Acc: 87.845
83 Train Loss: 34.232 | Train Acc: 87.805
84 Train Loss: 34.200 | Train Acc: 87.900
85 Train Loss: 34.199 | Train Acc: 87.975
86 Train Loss: 34.161 | Train Acc: 87.830
87 Train Loss: 34.145 | Train Acc: 87.840
88 Train Loss: 34.107 | Train Acc: 87.920
89 Train Loss: 34.118 | Train Acc: 87.840
90 Train Loss: 34.092 | Train Acc: 87.975
91 Train Loss: 34.086 | Train Acc: 87.825
92 Train Loss: 34.055 | Train Acc: 87.955
93 Train Loss: 34.003 | Train Acc: 87.995
94 Train Loss: 34.004 | Train Acc: 87.875
95 Train Loss: 33.970 | Train Acc: 87.850
96 Train Loss: 33.942 | Train Acc: 87.965
97 Train Loss: 33.947 | Train Acc: 87.945
98 Train Loss: 33.941 | Train Acc: 88.000
99 Train Loss: 33.891 | Train Acc: 87.950
CNN trained successfully...
image_next_flat.shape :  torch.Size([20000, 4096])
printing expected split from k means
{3: 0, 0: 0, 1: 0, 2: 1}
Printing final_dict items...
{3: 0, 0: 0, 1: 0, 2: 1}
Image Statistics : L R :  15000 5000
expectedMlpLabels.shape :  torch.Size([20000])
0 Loss: 28.924 | Acc: 87.585
1 Loss: 23.212 | Acc: 89.735
2 Loss: 21.606 | Acc: 90.930
3 Loss: 19.420 | Acc: 91.610
4 Loss: 18.407 | Acc: 91.995
5 Loss: 17.367 | Acc: 92.275
6 Loss: 15.918 | Acc: 92.905
7 Loss: 14.801 | Acc: 93.275
8 Loss: 13.382 | Acc: 93.880
9 Loss: 12.757 | Acc: 93.930
10 Loss: 9.273 | Acc: 95.765
11 Loss: 7.745 | Acc: 96.595
12 Loss: 7.026 | Acc: 96.885
13 Loss: 6.302 | Acc: 97.285
14 Loss: 5.945 | Acc: 97.515
15 Loss: 5.418 | Acc: 97.810
16 Loss: 4.936 | Acc: 97.935
17 Loss: 4.644 | Acc: 98.125
18 Loss: 4.020 | Acc: 98.320
19 Loss: 3.941 | Acc: 98.315
20 Loss: 2.694 | Acc: 98.850
21 Loss: 2.360 | Acc: 99.080
22 Loss: 2.114 | Acc: 99.125
23 Loss: 2.226 | Acc: 99.080
24 Loss: 2.002 | Acc: 99.220
25 Loss: 1.594 | Acc: 99.345
26 Loss: 1.442 | Acc: 99.475
27 Loss: 1.324 | Acc: 99.480
28 Loss: 1.585 | Acc: 99.400
29 Loss: 1.419 | Acc: 99.455
30 Loss: 1.315 | Acc: 99.580
31 Loss: 1.057 | Acc: 99.625
32 Loss: 0.764 | Acc: 99.740
33 Loss: 0.814 | Acc: 99.740
34 Loss: 0.798 | Acc: 99.665
35 Loss: 0.879 | Acc: 99.705
36 Loss: 0.791 | Acc: 99.750
37 Loss: 0.716 | Acc: 99.765
38 Loss: 0.596 | Acc: 99.840
39 Loss: 0.666 | Acc: 99.765
40 Loss: 0.667 | Acc: 99.740
41 Loss: 0.596 | Acc: 99.790
42 Loss: 0.602 | Acc: 99.835
43 Loss: 0.468 | Acc: 99.805
44 Loss: 0.567 | Acc: 99.800
45 Loss: 0.504 | Acc: 99.845
46 Loss: 0.538 | Acc: 99.790
47 Loss: 0.588 | Acc: 99.765
48 Loss: 0.680 | Acc: 99.850
49 Loss: 0.490 | Acc: 99.840
50 Loss: 0.455 | Acc: 99.845
51 Loss: 0.417 | Acc: 99.830
52 Loss: 0.453 | Acc: 99.850
53 Loss: 0.387 | Acc: 99.845
54 Loss: 0.440 | Acc: 99.860
55 Loss: 0.390 | Acc: 99.850
56 Loss: 0.377 | Acc: 99.870
57 Loss: 0.332 | Acc: 99.865
58 Loss: 0.557 | Acc: 99.860
59 Loss: 0.431 | Acc: 99.880
MLP trained successfully...
# of Left images:  15000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.6666666666666667
impurityDrop:  2.0
giniGain:  -1.25
lclasses:  [5000, 5000, 0, 5000, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 0, 5000, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  3
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([15000, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([15000])
rTrainDict[data].shape:  torch.Size([5000, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 6
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 6
nodeId:  14 , imgTensorShape :  torch.Size([15000, 16, 16, 16])
nodeId: 14 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 15000
nodeId:  15 , imgTensorShape :  torch.Size([5000, 16, 16, 16])
nodeId: 15 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  12
Running nodeId:  13
Running nodeId:  14
0 Train Loss: 73.525 | Train Acc: 66.660
1 Train Loss: 63.635 | Train Acc: 72.180
2 Train Loss: 60.921 | Train Acc: 73.600
3 Train Loss: 58.679 | Train Acc: 74.673
4 Train Loss: 56.788 | Train Acc: 75.500
5 Train Loss: 55.006 | Train Acc: 76.333
6 Train Loss: 53.505 | Train Acc: 77.207
7 Train Loss: 52.303 | Train Acc: 77.933
8 Train Loss: 50.868 | Train Acc: 78.433
9 Train Loss: 50.269 | Train Acc: 78.800
10 Train Loss: 48.068 | Train Acc: 80.147
11 Train Loss: 47.177 | Train Acc: 80.280
12 Train Loss: 46.254 | Train Acc: 80.807
13 Train Loss: 45.845 | Train Acc: 80.893
14 Train Loss: 44.403 | Train Acc: 81.933
15 Train Loss: 43.604 | Train Acc: 82.033
16 Train Loss: 42.867 | Train Acc: 82.387
17 Train Loss: 42.216 | Train Acc: 82.913
18 Train Loss: 41.733 | Train Acc: 83.100
19 Train Loss: 40.096 | Train Acc: 83.827
20 Train Loss: 37.246 | Train Acc: 85.620
21 Train Loss: 36.624 | Train Acc: 85.820
22 Train Loss: 36.354 | Train Acc: 86.020
23 Train Loss: 36.130 | Train Acc: 86.027
24 Train Loss: 35.716 | Train Acc: 86.287
25 Train Loss: 35.550 | Train Acc: 86.540
26 Train Loss: 35.096 | Train Acc: 86.593
27 Train Loss: 34.806 | Train Acc: 86.780
28 Train Loss: 34.708 | Train Acc: 86.693
29 Train Loss: 34.426 | Train Acc: 86.760
30 Train Loss: 34.287 | Train Acc: 86.787
31 Train Loss: 33.943 | Train Acc: 87.073
32 Train Loss: 33.423 | Train Acc: 87.153
33 Train Loss: 33.277 | Train Acc: 87.260
34 Train Loss: 32.874 | Train Acc: 87.680
35 Train Loss: 32.580 | Train Acc: 87.553
36 Train Loss: 32.286 | Train Acc: 87.773
37 Train Loss: 31.977 | Train Acc: 87.860
38 Train Loss: 31.731 | Train Acc: 87.953
39 Train Loss: 31.363 | Train Acc: 88.093
40 Train Loss: 30.255 | Train Acc: 88.880
41 Train Loss: 30.132 | Train Acc: 88.933
42 Train Loss: 29.998 | Train Acc: 89.160
43 Train Loss: 29.903 | Train Acc: 89.060
44 Train Loss: 29.767 | Train Acc: 89.053
45 Train Loss: 29.800 | Train Acc: 89.133
46 Train Loss: 29.556 | Train Acc: 89.180
47 Train Loss: 29.439 | Train Acc: 89.340
48 Train Loss: 29.370 | Train Acc: 89.340
49 Train Loss: 29.239 | Train Acc: 89.167
50 Train Loss: 29.208 | Train Acc: 89.293
51 Train Loss: 29.059 | Train Acc: 89.587
52 Train Loss: 29.037 | Train Acc: 89.420
53 Train Loss: 28.816 | Train Acc: 89.660
54 Train Loss: 28.662 | Train Acc: 89.647
55 Train Loss: 28.599 | Train Acc: 89.740
56 Train Loss: 28.443 | Train Acc: 89.647
57 Train Loss: 28.390 | Train Acc: 89.860
58 Train Loss: 28.260 | Train Acc: 89.793
59 Train Loss: 28.318 | Train Acc: 89.733
60 Train Loss: 27.637 | Train Acc: 90.287
61 Train Loss: 27.572 | Train Acc: 90.200
62 Train Loss: 27.528 | Train Acc: 90.247
63 Train Loss: 27.461 | Train Acc: 90.360
64 Train Loss: 27.444 | Train Acc: 90.187
65 Train Loss: 27.379 | Train Acc: 90.227
66 Train Loss: 27.332 | Train Acc: 90.340
67 Train Loss: 27.314 | Train Acc: 90.293
68 Train Loss: 27.279 | Train Acc: 90.353
69 Train Loss: 27.275 | Train Acc: 90.287
70 Train Loss: 27.193 | Train Acc: 90.460
71 Train Loss: 27.143 | Train Acc: 90.380
72 Train Loss: 27.128 | Train Acc: 90.520
73 Train Loss: 27.079 | Train Acc: 90.427
74 Train Loss: 27.037 | Train Acc: 90.413
75 Train Loss: 26.976 | Train Acc: 90.587
76 Train Loss: 26.989 | Train Acc: 90.493
77 Train Loss: 26.933 | Train Acc: 90.567
78 Train Loss: 26.850 | Train Acc: 90.620
79 Train Loss: 26.778 | Train Acc: 90.693
80 Train Loss: 26.598 | Train Acc: 90.707
81 Train Loss: 26.571 | Train Acc: 90.780
82 Train Loss: 26.520 | Train Acc: 90.700
83 Train Loss: 26.515 | Train Acc: 90.700
84 Train Loss: 26.488 | Train Acc: 90.707
85 Train Loss: 26.482 | Train Acc: 90.720
86 Train Loss: 26.464 | Train Acc: 90.627
87 Train Loss: 26.436 | Train Acc: 90.773
88 Train Loss: 26.435 | Train Acc: 90.767
89 Train Loss: 26.444 | Train Acc: 90.807
90 Train Loss: 26.407 | Train Acc: 90.740
91 Train Loss: 26.372 | Train Acc: 90.800
92 Train Loss: 26.374 | Train Acc: 90.753
93 Train Loss: 26.347 | Train Acc: 90.840
94 Train Loss: 26.328 | Train Acc: 90.813
95 Train Loss: 26.316 | Train Acc: 90.767
96 Train Loss: 26.285 | Train Acc: 90.900
97 Train Loss: 26.266 | Train Acc: 90.800
98 Train Loss: 26.273 | Train Acc: 90.860
99 Train Loss: 26.247 | Train Acc: 90.833
CNN trained successfully...
image_next_flat.shape :  torch.Size([15000, 2304])
printing expected split from k means
{2: 0, 0: 1, 1: 1}
Printing final_dict items...
{2: 0, 0: 1, 1: 1}
Image Statistics : L R :  5000 10000
expectedMlpLabels.shape :  torch.Size([15000])
0 Loss: 42.236 | Acc: 86.513
1 Loss: 32.837 | Acc: 90.307
2 Loss: 29.988 | Acc: 91.280
3 Loss: 27.399 | Acc: 91.953
4 Loss: 26.229 | Acc: 92.093
5 Loss: 24.584 | Acc: 92.920
6 Loss: 23.888 | Acc: 92.773
7 Loss: 21.731 | Acc: 93.507
8 Loss: 21.622 | Acc: 93.507
9 Loss: 19.897 | Acc: 93.893
10 Loss: 15.879 | Acc: 95.447
11 Loss: 13.039 | Acc: 96.173
12 Loss: 12.023 | Acc: 96.433
13 Loss: 10.961 | Acc: 96.767
14 Loss: 10.041 | Acc: 97.160
15 Loss: 8.582 | Acc: 97.320
16 Loss: 7.777 | Acc: 97.647
17 Loss: 6.833 | Acc: 98.007
18 Loss: 6.756 | Acc: 98.007
19 Loss: 6.236 | Acc: 98.207
20 Loss: 3.882 | Acc: 98.880
21 Loss: 3.006 | Acc: 99.120
22 Loss: 2.972 | Acc: 99.233
23 Loss: 2.371 | Acc: 99.427
24 Loss: 2.100 | Acc: 99.447
25 Loss: 2.307 | Acc: 99.320
26 Loss: 1.988 | Acc: 99.513
27 Loss: 1.941 | Acc: 99.447
28 Loss: 1.953 | Acc: 99.493
29 Loss: 1.690 | Acc: 99.533
30 Loss: 1.329 | Acc: 99.600
31 Loss: 0.930 | Acc: 99.753
32 Loss: 1.191 | Acc: 99.740
33 Loss: 0.749 | Acc: 99.800
34 Loss: 0.766 | Acc: 99.827
35 Loss: 1.011 | Acc: 99.720
36 Loss: 0.913 | Acc: 99.747
37 Loss: 0.897 | Acc: 99.793
38 Loss: 0.875 | Acc: 99.813
39 Loss: 0.647 | Acc: 99.807
40 Loss: 0.927 | Acc: 99.800
41 Loss: 0.707 | Acc: 99.847
42 Loss: 0.459 | Acc: 99.887
43 Loss: 0.641 | Acc: 99.873
44 Loss: 0.584 | Acc: 99.833
45 Loss: 0.466 | Acc: 99.900
46 Loss: 0.647 | Acc: 99.873
47 Loss: 0.452 | Acc: 99.887
48 Loss: 0.638 | Acc: 99.827
49 Loss: 0.470 | Acc: 99.900
50 Loss: 0.429 | Acc: 99.893
51 Loss: 0.494 | Acc: 99.887
52 Loss: 0.495 | Acc: 99.893
53 Loss: 0.381 | Acc: 99.920
54 Loss: 0.561 | Acc: 99.873
55 Loss: 0.352 | Acc: 99.893
56 Loss: 0.432 | Acc: 99.887
57 Loss: 0.371 | Acc: 99.880
58 Loss: 0.422 | Acc: 99.900
59 Loss: 0.334 | Acc: 99.927
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  10000.0
giniRightRatio:  0.5
giniLeftRatio:  0.0
impurityDrop:  0.25
giniGain:  0.41666666666666674
lclasses:  [0, 0, 5000, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [5000, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  2
lTrainDict[data].shape:  torch.Size([5000, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([10000, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([10000])
RETURNING FROM WORK...
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 7
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 7
nodeId:  16 , imgTensorShape :  torch.Size([5000, 16, 12, 12])
nodeId: 16 ,  parentId: 14 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 5000
nodeId:  17 , imgTensorShape :  torch.Size([10000, 16, 12, 12])
nodeId: 17 ,  parentId: 14 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 10000
Running nodeId:  15
Running nodeId:  16
Running nodeId:  17
0 Train Loss: 60.483 | Train Acc: 67.820
1 Train Loss: 53.780 | Train Acc: 72.660
2 Train Loss: 50.941 | Train Acc: 74.620
3 Train Loss: 47.982 | Train Acc: 76.600
4 Train Loss: 45.271 | Train Acc: 78.510
5 Train Loss: 42.253 | Train Acc: 80.420
6 Train Loss: 40.866 | Train Acc: 80.920
7 Train Loss: 39.648 | Train Acc: 82.100
8 Train Loss: 37.733 | Train Acc: 83.120
9 Train Loss: 36.307 | Train Acc: 83.720
10 Train Loss: 35.502 | Train Acc: 83.880
11 Train Loss: 33.822 | Train Acc: 84.910
12 Train Loss: 32.608 | Train Acc: 85.790
13 Train Loss: 31.796 | Train Acc: 86.340
14 Train Loss: 30.475 | Train Acc: 86.960
15 Train Loss: 30.239 | Train Acc: 86.830
16 Train Loss: 29.419 | Train Acc: 87.450
17 Train Loss: 28.983 | Train Acc: 87.700
18 Train Loss: 28.206 | Train Acc: 87.930
19 Train Loss: 28.257 | Train Acc: 87.810
20 Train Loss: 26.390 | Train Acc: 88.980
21 Train Loss: 25.445 | Train Acc: 89.690
22 Train Loss: 25.223 | Train Acc: 89.850
23 Train Loss: 24.967 | Train Acc: 90.050
24 Train Loss: 25.071 | Train Acc: 89.800
25 Train Loss: 24.502 | Train Acc: 90.050
26 Train Loss: 24.243 | Train Acc: 90.170
27 Train Loss: 24.214 | Train Acc: 90.150
28 Train Loss: 23.985 | Train Acc: 90.360
29 Train Loss: 23.921 | Train Acc: 90.530
30 Train Loss: 23.943 | Train Acc: 90.270
31 Train Loss: 23.450 | Train Acc: 90.950
32 Train Loss: 23.386 | Train Acc: 90.630
33 Train Loss: 23.295 | Train Acc: 90.790
34 Train Loss: 23.446 | Train Acc: 90.300
35 Train Loss: 22.893 | Train Acc: 90.950
36 Train Loss: 22.879 | Train Acc: 90.860
37 Train Loss: 22.590 | Train Acc: 91.210
38 Train Loss: 22.492 | Train Acc: 91.150
39 Train Loss: 22.301 | Train Acc: 91.190
40 Train Loss: 21.665 | Train Acc: 91.380
41 Train Loss: 21.487 | Train Acc: 91.690
42 Train Loss: 21.382 | Train Acc: 91.760
43 Train Loss: 21.311 | Train Acc: 91.910
44 Train Loss: 21.364 | Train Acc: 91.810
45 Train Loss: 21.222 | Train Acc: 91.820
46 Train Loss: 21.347 | Train Acc: 91.770
47 Train Loss: 21.187 | Train Acc: 91.600
48 Train Loss: 21.116 | Train Acc: 91.910
49 Train Loss: 21.131 | Train Acc: 91.890
50 Train Loss: 20.950 | Train Acc: 91.870
51 Train Loss: 20.992 | Train Acc: 91.880
52 Train Loss: 20.891 | Train Acc: 91.910
53 Train Loss: 20.875 | Train Acc: 91.960
54 Train Loss: 20.776 | Train Acc: 92.140
55 Train Loss: 20.715 | Train Acc: 91.930
56 Train Loss: 20.651 | Train Acc: 92.160
57 Train Loss: 20.628 | Train Acc: 92.180
58 Train Loss: 20.547 | Train Acc: 92.200
59 Train Loss: 20.562 | Train Acc: 92.290
60 Train Loss: 20.165 | Train Acc: 92.480
61 Train Loss: 20.143 | Train Acc: 92.450
62 Train Loss: 20.122 | Train Acc: 92.340
63 Train Loss: 20.077 | Train Acc: 92.320
64 Train Loss: 20.059 | Train Acc: 92.470
65 Train Loss: 20.135 | Train Acc: 92.450
66 Train Loss: 20.018 | Train Acc: 92.560
67 Train Loss: 20.013 | Train Acc: 92.520
68 Train Loss: 19.993 | Train Acc: 92.300
69 Train Loss: 19.934 | Train Acc: 92.500
70 Train Loss: 19.942 | Train Acc: 92.580
71 Train Loss: 19.888 | Train Acc: 92.800
72 Train Loss: 19.930 | Train Acc: 92.400
73 Train Loss: 19.870 | Train Acc: 92.590
74 Train Loss: 19.863 | Train Acc: 92.610
75 Train Loss: 19.818 | Train Acc: 92.420
76 Train Loss: 19.826 | Train Acc: 92.590
77 Train Loss: 19.793 | Train Acc: 92.590
78 Train Loss: 19.824 | Train Acc: 92.430
79 Train Loss: 19.761 | Train Acc: 92.520
80 Train Loss: 19.594 | Train Acc: 92.700
81 Train Loss: 19.595 | Train Acc: 92.710
82 Train Loss: 19.597 | Train Acc: 92.650
83 Train Loss: 19.572 | Train Acc: 92.730
84 Train Loss: 19.566 | Train Acc: 92.750
85 Train Loss: 19.540 | Train Acc: 92.760
86 Train Loss: 19.548 | Train Acc: 92.720
87 Train Loss: 19.536 | Train Acc: 92.660
88 Train Loss: 19.530 | Train Acc: 92.740
89 Train Loss: 19.526 | Train Acc: 92.760
90 Train Loss: 19.507 | Train Acc: 92.770
91 Train Loss: 19.495 | Train Acc: 92.720
92 Train Loss: 19.496 | Train Acc: 92.730
93 Train Loss: 19.468 | Train Acc: 92.660
94 Train Loss: 19.464 | Train Acc: 92.790
95 Train Loss: 19.482 | Train Acc: 92.770
96 Train Loss: 19.464 | Train Acc: 92.700
97 Train Loss: 19.453 | Train Acc: 92.760
98 Train Loss: 19.444 | Train Acc: 92.720
99 Train Loss: 19.427 | Train Acc: 92.760
CNN trained successfully...
image_next_flat.shape :  torch.Size([10000, 1024])
printing expected split from k means
{0: 0, 1: 1}
Printing final_dict items...
{0: 0, 1: 1}
Image Statistics : L R :  5000 5000
expectedMlpLabels.shape :  torch.Size([10000])
0 Loss: 100.207 | Acc: 75.270
1 Loss: 69.692 | Acc: 84.880
2 Loss: 64.014 | Acc: 86.220
3 Loss: 55.652 | Acc: 88.290
4 Loss: 56.009 | Acc: 87.910
5 Loss: 53.044 | Acc: 88.980
6 Loss: 51.027 | Acc: 89.330
7 Loss: 50.931 | Acc: 89.320
8 Loss: 48.883 | Acc: 90.070
9 Loss: 48.588 | Acc: 89.670
10 Loss: 43.179 | Acc: 91.330
11 Loss: 40.872 | Acc: 91.750
12 Loss: 41.023 | Acc: 91.930
13 Loss: 40.056 | Acc: 92.260
14 Loss: 39.152 | Acc: 92.170
15 Loss: 39.317 | Acc: 92.130
16 Loss: 37.335 | Acc: 92.760
17 Loss: 37.378 | Acc: 92.210
18 Loss: 37.282 | Acc: 92.980
19 Loss: 36.516 | Acc: 92.710
20 Loss: 33.116 | Acc: 93.880
21 Loss: 30.687 | Acc: 94.290
22 Loss: 30.721 | Acc: 94.060
23 Loss: 30.699 | Acc: 94.190
24 Loss: 29.236 | Acc: 94.650
25 Loss: 29.747 | Acc: 94.330
26 Loss: 28.439 | Acc: 94.630
27 Loss: 28.026 | Acc: 94.830
28 Loss: 26.498 | Acc: 95.220
29 Loss: 25.868 | Acc: 95.290
30 Loss: 24.330 | Acc: 95.510
31 Loss: 22.673 | Acc: 96.030
32 Loss: 22.458 | Acc: 95.940
33 Loss: 22.238 | Acc: 96.060
34 Loss: 21.794 | Acc: 95.980
35 Loss: 21.174 | Acc: 95.960
36 Loss: 21.131 | Acc: 96.080
37 Loss: 20.553 | Acc: 96.230
38 Loss: 19.977 | Acc: 96.170
39 Loss: 19.759 | Acc: 96.260
40 Loss: 18.526 | Acc: 96.680
41 Loss: 18.619 | Acc: 96.520
42 Loss: 19.059 | Acc: 96.480
43 Loss: 18.313 | Acc: 96.620
44 Loss: 18.385 | Acc: 96.570
45 Loss: 18.076 | Acc: 96.830
46 Loss: 17.161 | Acc: 96.820
47 Loss: 16.542 | Acc: 96.830
48 Loss: 17.365 | Acc: 96.750
49 Loss: 17.411 | Acc: 96.600
50 Loss: 17.327 | Acc: 96.860
51 Loss: 16.663 | Acc: 96.930
52 Loss: 16.595 | Acc: 97.030
53 Loss: 16.516 | Acc: 96.940
54 Loss: 16.397 | Acc: 96.990
55 Loss: 15.616 | Acc: 97.140
56 Loss: 15.378 | Acc: 97.080
57 Loss: 16.345 | Acc: 97.020
58 Loss: 16.257 | Acc: 97.100
59 Loss: 16.074 | Acc: 97.060
MLP trained successfully...
# of Left images:  5000.0
# of Right images:  5000.0
giniRightRatio:  0.0
giniLeftRatio:  0.0
impurityDrop:  0.0
giniGain:  0.5
lclasses:  [5000, 0, 0, 0, 0, 0, 0, 0, 0, 0]
rclasses:  [0, 5000, 0, 0, 0, 0, 0, 0, 0, 0]
noOfLeftClasses:  1
noOfRightClasses:  1
lTrainDict[data].shape:  torch.Size([5000, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([5000])
rTrainDict[data].shape:  torch.Size([5000, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([5000])
RETURNING FROM WORK...
MAX DEPTH REACHED 6
CLASS THRESHOLD REACHED 1 IN LEFT 1 2 3
CLASS THRESHOLD REACHED 1 IN RIGHT 1 2 5
DOMINANCE THRESHOLD REACHED IN LEFT 1.0 0.95 3
DOMINANCE THRESHOLD REACHED IN RIGHT 1.0 0.95 5
nodeId:  18 , imgTensorShape :  torch.Size([5000, 16, 8, 8])
nodeId: 18 ,  parentId: 17 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 5000
nodeId:  19 , imgTensorShape :  torch.Size([5000, 16, 8, 8])
nodeId: 19 ,  parentId: 17 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 5000
Running nodeId:  18
Running nodeId:  19
nodeId:  1 , imgTensorShape :  torch.Size([10000, 3, 32, 32])
nodeId: 1 ,  parentId: 0 ,  level: 0 ,  lchildId: 2 ,  rchildId: 3 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 10 ,  numData: 10000
Node 1 Acc: 61.200
Split Acc: 89.620
# of Left images:  3054.0
# of Right images:  6946.0
giniRightRatio:  0.8744473118240345
giniLeftRatio:  0.7678192877474183
impurityDrop:  0.8275653674632533
giniGain:  0.07243463253674676
lclasses:  [849, 196, 111, 62, 62, 31, 33, 51, 882, 777]
rclasses:  [151, 804, 889, 938, 938, 969, 967, 949, 118, 223]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([3054, 16, 28, 28])   lTrainDict[label].shape:  torch.Size([3054])
rTrainDict[data].shape:  torch.Size([6946, 16, 28, 28])   rTrainDict[label].shape:  torch.Size([6946])
RETURNING FROM WORK...
nodeId:  2 , imgTensorShape :  torch.Size([3054, 16, 28, 28])
nodeId: 2 ,  parentId: 1 ,  level: 1 ,  lchildId: 4 ,  rchildId: 5 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3054
nodeId:  3 , imgTensorShape :  torch.Size([6946, 16, 28, 28])
nodeId: 3 ,  parentId: 1 ,  level: 1 ,  lchildId: 6 ,  rchildId: 7 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 7 ,  numData: 6946
Nodes sizes =  3 7
Node 2 Acc: 70.465
Split Acc: 77.472
# of Left images:  1004.0
# of Right images:  2050.0
giniRightRatio:  0.6674569898869721
giniLeftRatio:  0.4796253234075649
impurityDrop:  0.5754652859136429
giniGain:  0.19235400183377538
lclasses:  [44, 125, 13, 25, 3, 9, 16, 28, 31, 710]
rclasses:  [805, 71, 98, 37, 59, 22, 17, 23, 851, 67]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1004, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([1004])
rTrainDict[data].shape:  torch.Size([2050, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([2050])
RETURNING FROM WORK...
nodeId:  4 , imgTensorShape :  torch.Size([1004, 16, 24, 24])
nodeId: 4 ,  parentId: 2 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 9 ,  numClasses: 1 ,  numData: 1004
nodeId:  5 , imgTensorShape :  torch.Size([2050, 16, 24, 24])
nodeId: 5 ,  parentId: 2 ,  level: 2 ,  lchildId: 8 ,  rchildId: 9 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2050
Nodes sizes =  1 2
Node 3 Acc: 59.056
Split Acc: 91.247
# of Left images:  5981.0
# of Right images:  965.0
giniRightRatio:  0.39329055813578884
giniLeftRatio:  0.852874094611759
impurityDrop:  3.241755979547993
giniGain:  -2.3673086677239583
lclasses:  [131, 61, 882, 923, 933, 966, 956, 935, 68, 126]
rclasses:  [20, 743, 7, 15, 5, 3, 11, 14, 50, 97]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([5981, 16, 24, 24])   lTrainDict[label].shape:  torch.Size([5981])
rTrainDict[data].shape:  torch.Size([965, 16, 24, 24])   rTrainDict[label].shape:  torch.Size([965])
RETURNING FROM WORK...
nodeId:  6 , imgTensorShape :  torch.Size([5981, 16, 24, 24])
nodeId: 6 ,  parentId: 3 ,  level: 2 ,  lchildId: 10 ,  rchildId: 11 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 6 ,  numData: 5981
nodeId:  7 , imgTensorShape :  torch.Size([965, 16, 24, 24])
nodeId: 7 ,  parentId: 3 ,  level: 2 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 1 ,  numClasses: 1 ,  numData: 965
Nodes sizes =  6 1
Node 4 Acc: 70.717
Node 5 Acc: 72.244
Split Acc: 73.268
# of Left images:  1078.0
# of Right images:  972.0
giniRightRatio:  0.3720088401158359
giniLeftRatio:  0.5161313639977834
impurityDrop:  0.5318484293593949
giniGain:  0.1356085605275772
lclasses:  [737, 33, 82, 21, 38, 16, 9, 20, 86, 36]
rclasses:  [68, 38, 16, 16, 21, 6, 8, 3, 765, 31]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1078, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1078])
rTrainDict[data].shape:  torch.Size([972, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([972])
RETURNING FROM WORK...
nodeId:  8 , imgTensorShape :  torch.Size([1078, 16, 20, 20])
nodeId: 8 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 0 ,  numClasses: 1 ,  numData: 1078
nodeId:  9 , imgTensorShape :  torch.Size([972, 16, 20, 20])
nodeId: 9 ,  parentId: 5 ,  level: 3 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 8 ,  numClasses: 1 ,  numData: 972
Nodes sizes =  1 1
Node 6 Acc: 56.914
Split Acc: 77.930
# of Left images:  1792.0
# of Right images:  4189.0
giniRightRatio:  0.826933822346503
giniLeftRatio:  0.7330185247927297
impurityDrop:  0.7867580731900548
giniGain:  0.06611602142170425
lclasses:  [66, 13, 623, 123, 651, 105, 88, 77, 25, 21]
rclasses:  [65, 48, 259, 800, 282, 861, 868, 858, 43, 105]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1792, 16, 20, 20])   lTrainDict[label].shape:  torch.Size([1792])
rTrainDict[data].shape:  torch.Size([4189, 16, 20, 20])   rTrainDict[label].shape:  torch.Size([4189])
RETURNING FROM WORK...
nodeId:  10 , imgTensorShape :  torch.Size([1792, 16, 20, 20])
nodeId: 10 ,  parentId: 6 ,  level: 3 ,  lchildId: 12 ,  rchildId: 13 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 1792
nodeId:  11 , imgTensorShape :  torch.Size([4189, 16, 20, 20])
nodeId: 11 ,  parentId: 6 ,  level: 3 ,  lchildId: 14 ,  rchildId: 15 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 4 ,  numData: 4189
Nodes sizes =  2 4
Node 7 Acc: 76.995
Node 8 Acc: 68.367
Node 9 Acc: 78.704
Node 10 Acc: 58.259
Split Acc: 58.594
# of Left images:  880.0
# of Right images:  912.0
giniRightRatio:  0.656259618344106
giniLeftRatio:  0.593357438016529
impurityDrop:  0.5955645320631107
giniGain:  0.137453992729619
lclasses:  [21, 3, 114, 45, 541, 51, 39, 50, 7, 9]
rclasses:  [45, 10, 509, 78, 110, 54, 49, 27, 18, 12]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([880, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([880])
rTrainDict[data].shape:  torch.Size([912, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([912])
RETURNING FROM WORK...
nodeId:  12 , imgTensorShape :  torch.Size([880, 16, 16, 16])
nodeId: 12 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 4 ,  numClasses: 1 ,  numData: 880
nodeId:  13 , imgTensorShape :  torch.Size([912, 16, 16, 16])
nodeId: 13 ,  parentId: 10 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 2 ,  numClasses: 1 ,  numData: 912
Nodes sizes =  1 1
Node 11 Acc: 57.341
Split Acc: 74.529
# of Left images:  3109.0
# of Right images:  1080.0
giniRightRatio:  0.510289780521262
giniLeftRatio:  0.7923375013617486
impurityDrop:  1.322221599125959
giniGain:  -0.4952877767794559
lclasses:  [48, 28, 185, 714, 223, 824, 125, 841, 36, 85]
rclasses:  [17, 20, 74, 86, 59, 37, 743, 17, 7, 20]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([3109, 16, 16, 16])   lTrainDict[label].shape:  torch.Size([3109])
rTrainDict[data].shape:  torch.Size([1080, 16, 16, 16])   rTrainDict[label].shape:  torch.Size([1080])
RETURNING FROM WORK...
nodeId:  14 , imgTensorShape :  torch.Size([3109, 16, 16, 16])
nodeId: 14 ,  parentId: 11 ,  level: 4 ,  lchildId: 16 ,  rchildId: 17 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 3 ,  numData: 3109
nodeId:  15 , imgTensorShape :  torch.Size([1080, 16, 16, 16])
nodeId: 15 ,  parentId: 11 ,  level: 4 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 6 ,  numClasses: 1 ,  numData: 1080
Nodes sizes =  3 1
Node 12 Acc: 61.477
Node 13 Acc: 55.811
Node 14 Acc: 53.072
Split Acc: 67.996
# of Left images:  991.0
# of Right images:  2118.0
giniRightRatio:  0.7552374939923192
giniLeftRatio:  0.4952809391486039
impurityDrop:  0.6336053193699764
giniGain:  0.1587321819917722
lclasses:  [11, 8, 34, 51, 78, 66, 14, 693, 8, 28]
rclasses:  [37, 20, 151, 663, 145, 758, 111, 148, 28, 57]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([991, 16, 12, 12])   lTrainDict[label].shape:  torch.Size([991])
rTrainDict[data].shape:  torch.Size([2118, 16, 12, 12])   rTrainDict[label].shape:  torch.Size([2118])
RETURNING FROM WORK...
nodeId:  16 , imgTensorShape :  torch.Size([991, 16, 12, 12])
nodeId: 16 ,  parentId: 14 ,  level: 5 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 7 ,  numClasses: 1 ,  numData: 991
nodeId:  17 , imgTensorShape :  torch.Size([2118, 16, 12, 12])
nodeId: 17 ,  parentId: 14 ,  level: 5 ,  lchildId: 18 ,  rchildId: 19 ,  isLeaf: False ,  leafClass: -1 ,  numClasses: 2 ,  numData: 2118
Nodes sizes =  1 2
Node 15 Acc: 68.796
Node 16 Acc: 69.929
Node 17 Acc: 44.523
Split Acc: 44.334
# of Left images:  1048.0
# of Right images:  1070.0
giniRightRatio:  0.718925670364224
giniLeftRatio:  0.7445752724200221
impurityDrop:  0.7440478974244823
giniGain:  0.011189596567836912
lclasses:  [22, 13, 69, 440, 81, 259, 59, 56, 19, 30]
rclasses:  [15, 7, 82, 223, 64, 499, 52, 92, 9, 27]
noOfLeftClasses:  10
noOfRightClasses:  10
lTrainDict[data].shape:  torch.Size([1048, 16, 8, 8])   lTrainDict[label].shape:  torch.Size([1048])
rTrainDict[data].shape:  torch.Size([1070, 16, 8, 8])   rTrainDict[label].shape:  torch.Size([1070])
RETURNING FROM WORK...
nodeId:  18 , imgTensorShape :  torch.Size([1048, 16, 8, 8])
nodeId: 18 ,  parentId: 17 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 3 ,  numClasses: 1 ,  numData: 1048
nodeId:  19 , imgTensorShape :  torch.Size([1070, 16, 8, 8])
nodeId: 19 ,  parentId: 17 ,  level: 6 ,  lchildId: -1 ,  rchildId: -1 ,  isLeaf: True ,  leafClass: 5 ,  numClasses: 1 ,  numData: 1070
Nodes sizes =  1 1
Node 18 Acc: 41.985
Node 19 Acc: 46.636
[[737  20  45  22  21  15  17  11  68  44]
 [ 33 743  10  13   3   7  20   8  38 125]
 [ 82   7 509  69 114  82  74  34  16  13]
 [ 21  15  78 440  45 223  86  51  16  25]
 [ 38   5 110  81 541  64  59  78  21   3]
 [ 16   3  54 259  51 499  37  66   6   9]
 [  9  11  49  59  39  52 743  14   8  16]
 [ 20  14  27  56  50  92  17 693   3  28]
 [ 86  50  18  19   7   9   7   8 765  31]
 [ 36  97  12  30   9  27  20  28  31 710]]

Acc: 63.800

                               1                                                                                           
                                                                                      
       2                                   3                                                                               
                                                                     
 4                 5                 7                                 6                                                   
                                                                                 
             8           9                               10                          11                                    
                                                                                      
                                                  12            13            15                   14                      
                                                                                                     
                                                                                            16                   17        
                                                                                                            
                                                                                                          18            19 

                               -1                                                                              
                                                                          
       -1                                  -1                                                                  
                                                             
 9                 -1                1                             -1                                          
                                                                         
             0           8                             -1                      -1                              
                                                                               
                                                 4           2           6                 -1                  
                                                                                            
                                                                                     7                 -1      
                                                                                                  
                                                                                                 3           5 

                                         50000                                                                                                         
                                                                                                      
         15000                                           35000                                                                                         
                                                                                     
  5000                   10000                    5000                                   30000                                                         
                                                                                                     
                  5000            5000                                   10000                           20000                                         
                                                                                                             
                                                                  5000            5000            5000                   15000                         
                                                                                                                              
                                                                                                                  5000                   10000         
                                                                                                                                      
                                                                                                                                  5000            5000 

          {0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}                                                                                                                
                                                                                                                                      
  {0: 5000, 8: 5000, 9: 5000}                                {1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000}                                                                                        
                                                                                                                                  
 {9: 5000}                 {0: 5000, 8: 5000}                        {1: 5000}                   {2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000}                                                             
                                                                                                                                                  
                     {0: 5000}           {8: 5000}                                             {2: 5000, 4: 5000}                 {3: 5000, 5: 5000, 6: 5000, 7: 5000}                                              
                                                                                                                                                                
                                                                                         {4: 5000}           {2: 5000}             {6: 5000}            {3: 5000, 5: 5000, 7: 5000}                                 
                                                                                                                                                                                     
                                                                                                                                                       {7: 5000}                 {3: 5000, 5: 5000}                 
                                                                                                                                                                                               
                                                                                                                                                                           {3: 5000}           {5: 5000}            

                             0.1244897959183674                                                                                       
                                                                                          
 0.41666666666666674                         -4.142857142857142                                                                       
                                                                            
 0.0                  0.5                    0.0                        0.20833333333333326                                           
                                                                                          
               0.0           0.0                                  0.5                        -1.25                                    
                                                                                                
                                                           0.0           0.0           0.0           0.41666666666666674              
                                                                                                                
                                                                                                     0.0                  0.5         
                                                                                                                       
                                                                                                                   0.0           0.0  

